import * as g                           from '../../types/genetics'

export const ABC: g.snapMargin = [] as any;
export const MDL: g.OrganelleType[] = [ "dAudio", "rawText" ];
export const DNA: g.gene[] = [
	{
		"title": "Robots that Smell",
		"text": "While out for a walk in my neighborhood, I caught a whiff of something that instantly made me think of my grandmother's house. I haven't experienced that smell—either from its original source or elsewhere—in well over a decade, but the memory of being back at my grandmother's house was immediate and striking. On the other hand, I can't really remember or recreate that smell in my mind; either it's there or it isn't. I have convenient analog and digital methods of recording images and sounds so that I can see and hear them later, but no way to capture the scent of a dish at a restaurant, a favorite vacation spot, or any other smell that moves me in some way. I don't normally think of smelling as being something within the province of machines. I understand, of course, that devices like smoke detectors and breathalyzers perform what amounts to mechanical olfaction of sorts, but I was still sort of surprised to learn that increasingly sophisticated artificial noses are being incorporated into robots and other devices. What intrigues me more than anything is how such sensors might work. How does one go about measuring and quantifying something as broad and seemingly subjective as smell? Name That Smell All smells result from molecules of various chemicals floating through the air. Not all substances have a smell—only those containing chemicals that are volatile (meaning they evaporate easily). Our nasal cavities contain millions of neural receptors, of about 350 different types—all of which respond to different chemicals. Depending on which chemicals are present and in what quantities, different sets of odorant receptor neurons are activated; the brain decodes each pattern and assigns a meaning to it: “floral,” “putrid,” “Grandma's house,” or whatever. Therefore, getting a machine to do the same thing involves two challenges: detecting individual chemical components, and figuring out what a specific combination of components in a given proportion represents. One way to detect chemicals in the air is to use large, expensive laboratory machines such as gas chromatographs and time-of-flight mass spectrometers. These devices can very accurately detect miniscule amounts of volatile chemicals in air samples—but they also detect substances that have nothing to do with smell, so determining just which parts of their output are relevant adds more complexity to the problem. They are also, so far at least, not very portable. But other, more direct—and more compact—methods of artificial smell detection are under development. Here are some examples: * A quartz crystal microbalance (QCM) sensor is a tiny device that can detect a single, arbitrary chemical. This sensor consists of a quartz crystal vibrating at a known frequency. It's coated with a material that can absorb molecules only of a very specific size and shape. When it does, its mass increases slightly, changing the frequency of the crystal's vibration. A simple circuit detects the change and signals that the chemical in question is present. Given an array of QCM sensors, each with a coating that responds to a different chemical, you can detect a wide range of smells. * A variation on this idea under development by IBM in Zürich is the cantilever sensor: a series of flexible, microscopic silicon beams—each coated with a different polymer. When one of the beams absorbs a specific chemical, it bends slightly; the chip to which the beams are attached detects this change. * An entirely different approach being studied at the University of Illinois involves using vapor-sensitive dyes called metalloporphyrins that change color when exposed to certain chemicals. By examining the “before” and “after” states of an array of these dyes, a computer can essentially “see” smells. Decoding output from an array of sensors (of whatever sort) is an interesting challenge, because substances that are very similar chemically sometimes smell much different from each other; conversely, substances that smell nearly the same can be completely different at the molecular level. For this task, researchers often rely on neural networks, software that can be trained to identify patterns and make educated guesses about new combinations based on their similarities to patterns that have already been verified. So where is all this technology going to be put to use? And what about those robots? Follow Your Nose Artificial noses show the most promise in applications where the human nose is insufficiently sensitive or discriminating. For example, sensors could detect when food is spoiled long before a human nose could—an artificial nose may be built into your refrigerator one day. Just as the bacteria that cause spoilage produce distinctive odors, so do some disease-causing bacteria. Devices now in development will be able to diagnose certain illnesses by smelling blood samples. But it's one thing to be able to identify an odor in a test tube; it's another to be able to trace the source of an airborne scent. This is where robots come in: a mobile platform with an artificial nose can continuously sample the air, reorienting itself dynamically to move in the direction where an odor is strongest. This makes robots that can smell ideal for locating gas leaks, explosives, drugs, and other dangerous stuff—since robots can go places where it would be unsafe to send a human or a dog. One rather gruesome use for sniffing robots is locating buried bodies; this is but one of many possible forensic applications. A mechanical bloodhound may be years in the future, but it's not at all far-fetched. If You Could Bottle This Smell… Several years ago a company called DigiScents made headlines with its iSmell device, a desktop computer peripheral that could synthesize thousands of scents. Their idea was that games could be enhanced with smells (presumably lots of smoke and burnt rubber), email from that special someone could be scented with perfume, and so on. When DigiScents went out of business in 2001 before the iSmell became commercially available, no one was particularly surprised—why do we need to smell computer games, anyway? But I think the real problem was that they only had half of the solution ready: the output but no input. I suspect that if someone created a pocket-sized gadget that could record the scent of a bakery, garden, or any other smell you encounter and play it back accurately on command, it would be a huge success. I, for one, would gladly pay for a machine that could make scents of my childhood. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/05/01/smell_the_roses.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/05/01/Smell__.ce0e2cb16ae9.mp3"
	},
	{
		"title": "Jumping Spiders",
		"text": "A reader wrote in with a comment about one of my articles on the fauna of Costa Rica, wondering if I’d ever written anything about jumping spiders. I didn’t see any jumping spiders (that I know of) in Costa Rica. (Though I did see one in Spider-Man. Does that count?) So I added “jumping spiders” to my list of topics to research. There were, unsurprisingly, tens of thousands of Web pages to be found about the 5,000 or so species of spiders in the family Salticidae (or Salticids), commonly known as “jumping spiders.” I was sure there must be numerous interesting tidbits of information to extract, but what I found was not at all what I was expecting. On page after page, I kept reading descriptions of jumping spiders like these: “personalities of the spider world” … “friendly little creatures that always like to jump on your camera or your fingers” … “affectionately referred to as Charlies, Herbies or Salties” … “among the most beautiful and delightful of all arthropods” … “comical, engaging” … “their anthropomorphic nature endears them to most people.” OK, wait a minute—we are talking about spiders here, right? Spiders have always been on my “avoid if at all possible” list. Even looking at pictures of them gives me the creeps. Am I really supposed to feel especially fond of a spider that could jump on me? But clearly, something about these spiders (apart from the obvious fact that they jump) has caught the fancy of a great many people—or at least, a great many spider fans. Might As Well Jump For starters, jumping spiders are not big and scary. Although there is a great deal of variation among the thousands of species, they tend to be quite small—generally about 5–10 millimeters long. (So that much larger, so-called jumping spider Peter Parker sees in Spider-Man was in fact nothing of the sort—it was an Avondale spider, which doesn’t jump.) And although they do use their two hind pairs of legs to jump, pouncing on their prey, even the largest jumping spiders will jump only 16cm (about 6 inches). That prey, by the way, will generally be insects—jumping spiders are harmless to humans (which is not to say they might not bite on occasion). When they jump, they leave a thread of silk attached to their starting point so that they can return easily if their attack was unsuccessful. In other words, it’s the arachnid equivalent of bungee jumping. For those willing to get close enough to these spiders for a good look—perhaps with the help of a magnifying glass—one of the most striking features is the spiders' eyes. All spiders have four pairs of eyes, but in jumping spiders, one of the pairs (the anterior median, or front and center pair) is unusually large. This gives them that “puppy dog” look that makes it easier to think of them as animals, rather than as “creepy things.” Jumping spiders have excellent vision, with the capability of altering their field of vision in a way that has been compared to a zoom lens. This, plus the positioning of the other six eyes, gives the spiders the visual acuity needed to identify, follow, and strike at their prey with great precision. I Only Have Eyes for Hue The spiders' eyes are also sensitive to color, which is significant because some of the species also have very striking coloring—with the males typically being more colorful than the females. Some jumping spiders have elaborate mating rituals, in which the male performs an impressive and often very silly-looking dance in order to attract a female’s attention; the colored markings on the male’s body apparently figure into the female’s evaluation of the performance. (The name Salticidae, by the way, comes from a Latin root that can mean either “jump” or “dance.”) Jumping spiders of one kind or another are found on every continent except Antarctica. They are a splendid example of adaptation, as numerous species have developed physical appearances that mimic those of other creatures. These disguises provide camouflage—in some cases, making them more effective hunters, and in others, making them less visible to predators. Some jumping spiders look amazingly like ants; others have body shapes resembling termites, scorpions, beetles, or even—I’m not making this up—bird droppings. Which just goes to show you: there’s more to jumping spiders than meets the eyes. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/23/jumping_spider.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/23/Jumping.6aa1b407c33.mp3"
	},
	{
		"title": "Magnetohydrodynamic Propulsion",
		"text": "In the 1990 film The Hunt for Red October (based on the Tom Clancy novel of the same name), Sean Connery plays the captain of a Russian submarine. This much I remembered from having seen the film many years ago. I did not recall that the submarine in question—the eponymous “Red October”—used a special high-tech propulsion system that, having no moving parts, was silent. I'm sure my science fiction filter was on, and I just assumed at the time that the top-secret engine was the sort of almost-plausible futuristic contrivance any modern spy movie will have—and not worth taking very seriously. Just a few years later, though, Mitsubishi demonstrated a boat using a propulsion system of roughly the design Clancy described in his novel. And now variations on this technique are being used in electrical generators, nuclear reactors, and even spacecraft design. Gimme an “M” The scientific principle in question is known as magnetohydrodynamics, which is a fairly straightforward combination of magneto (as in magnet), hydro (as in water), and dynamics (as in motion). Those in the biz call it MHD for short. And yes: it uses magnetism to cause motion in water (or another fluid). MHD is not by any means a new discovery—academic researchers have been working on this since at least the 1960s, and the Journal Magnetohydrodynamics has been published since 1965 by the University of Latvia. But in recent years, MHD designs have begun to appear more frequently in everything from large-scale commercial operations to high school science fair projects. The basic concept is simple, even though it relies on some complex math and physics. When a conductive fluid (such as saltwater, liquid metal, or even plasma) is exposed to a magnetic field and an electric current at right angles to each other, their interaction propels the fluid in a direction perpendicular to the other two axes. In other words, the fluid itself functions more or less as the moving part of an electric motor. You can demonstrate this effect on a small scale if you have a free afternoon, a few tools, and a bathtub. Take a small plastic tube and glue a pair of nice, strong magnets onto the top and bottom (opposite poles facing inward). Then glue strips of metal to the insides of the tube on the left and right; these will be the electrodes. Affix this assembly to the bottom of a small toy boat. Wire the electrodes to a fairly high-power battery (being careful, of course, to keep the battery dry), and float the entire contraption in a saturated solution of salt and water. If the battery is strong enough and the boat is small enough, it will start moving through the water. The Solid-State Paddlewheel Of course, if you want to power a boat large enough to hold passengers, the engines will have to be pretty large. You're going to need some very strong magnets—think helium-cooled superconducting electromagnets—plus an awful lot of electricity to provide current to the electrodes. Even then, you may find (as Mitsubishi did) that the thrust produced is a bit underwhelming. The prototype boats were expected to reach speeds of 200 kilometers per hour, but only got up to 15 km/h. Even though MHD drives have virtually no drag (unlike propellers), the energy conversion efficiency is currently pretty low. (Had they used the same amount of electricity to power conventional motors, the boats would have gone much faster.) Further technological advances are needed to make this a practical propulsion system for marine vessels. As far as I know, there are no submarines using such drives now, but a Red October is at least more plausible than I'd previously have suspected. However, I should point out that MHD drives are only sort of quiet. By this I mean there's no noise from an engine or propeller, but the electrodes do produce huge numbers of bubbles—after all, this design amounts to magnetically enhanced electrolysis, and electrolysis separates water molecules into hydrogen and oxygen atoms. So a submarine with an MHD drive would not be quite as stealthy as you might imagine. Much more promising are designs that use other kinds of fluids that conduct electricity better. For example, plasma-based propulsion systems being studied for long-distance space travel use a variation on MHD. It remains to be seen whether technological innovations will make MHD an efficient and practical means of propulsion (terrestrial or otherwise), but the mere fact that you can induce motion in a fluid without either moving parts or combustion seems incredibly cool to me. As with so many scientific discoveries, truth is much more exciting than fiction. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/23/mhd.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/23/MHD.26dcaec99106.mp3"
	},
	{
		"title": "The Coriolis Force ",
		"text": "I just finished an experiment in which I demonstrated something many people would claim is impossible. I filled the kitchen sink and the bathroom sink with water, and then I pulled the plugs. The water in the bathroom sink drained clockwise, while the water in the kitchen sink drained counterclockwise. According to a popular urban myth that has been circulating (sorry) for eons, water always drains in one direction in the northern hemisphere and in the opposite direction in the southern hemisphere. (Accounts differ as to which is which, but we'll get to that shortly.) If true, one of my sinks has just defied the laws of nature. Since it is seemingly very easy to disprove this myth, its persistence for all these years suggests an unfortunate lack of intellectual rigor among the general public. However, it turns out that there is a kernel of truth to this story after all—in, shall we say, a roundabout way. The Effects of Force The reason usually given for the supposed variation in the rotational direction of drainage is the Coriolis force—a type of inertial force that affects moving objects in a rotating system, causing them to curve in one direction or another. (This phenomenon is sometimes referred to as the Coriolis effect—though strictly speaking, a Coriolis effect is simply any perceived change resulting from the Coriolis force; I'll stick with the latter term in the interest of simplicity.) A thought experiment might illustrate this concept well. Let's say you and a friend are playing catch, and there just happens to be a merry-go-round between you. You can throw the ball straight ahead, and it will go just where you expect it to. However, if you and your friend hop onto opposite sides of the merry-go-round and try to play catch while it's in motion, you'll find that the ball you throw straight ahead curves to the side (which side and how far depend on the direction and speed of the merry-go-round). That's the Coriolis force at work. It was named after French scientist Gaspard-Gustave Coriolis, who demonstrated it in 1835. If you apply this concept to a really large rotating system, like Earth, it can have some fascinating effects. The planet's rotation causes not only objects like balls but currents of wind and water to deflect rightward in the northern hemisphere, and leftward in the southern hemisphere—regardless of their direction of motion. Round and Round We Go Since wind in the northern hemisphere curves to the right, you might draw the reasonable conclusion that circular patterns of wind, such as hurricanes, will rotate clockwise in the northern hemisphere and counterclockwise in the southern. In a hurricane, however, the wind is rotating around a low-pressure area in the center. But a low-pressure zone introduces another force into the mix: a pressure gradient force, which pulls the wind inward. Because the pressure gradient force is stronger than the Coriolis force, hurricanes rotate counterclockwise in the northern hemisphere and clockwise in the southern hemisphere. However, when a high-pressure zone is at the center of a weather system, the situation is reversed—clockwise spin in the northern hemisphere and counterclockwise in the southern. Is your head spinning yet? So let's get back to the water in the sink. You put it in motion when you pull the plug, at which point you may assume the Coriolis force will pull it in a rightward direction in the northern hemisphere, resulting in clockwise rotation. But as with hurricanes, you have another force at work—in this case, gravity. It pulls the water inward, toward the drain, and since gravity is much more powerful than the Coriolis force, you should in fact get counterclockwise rotation in the northern hemisphere. Right? Well, only under ideal conditions, which are certain not to exist in your bathroom. Because the Coriolis force is so weak, its effects are normally noticeable only on rather large systems. In small systems, other factors usually make the Coriolis force irrelevant. For instance, if the water in your sink has even the tiniest residual motion from when you filled it—and it can retain traces of motion for hours—that will be more than enough to counter the Coriolis force and set the water spinning in the direction of that original motion. If your sink is not perfectly round, or if the walls or drain have any irregularities, those tiny contours can also affect the direction of the water's rotation as it drains—again, more than compensating for the Coriolis force. If you had an extremely large sink (as in, say, the size of a hot tub) with no imperfections, and if the water had been carefully kept still and protected from air currents for a day or so, and if the drain were very small, and if the act of removing the plug were done in such a way as to prevent any influence on the water's direction, then you could reliably expect counterclockwise drainage in the northern hemisphere due to the Coriolis force. In fact, just such an experiment was performed successfully in 1962 at M.I.T. But under ordinary circumstances, regardless of your location on the planet, the water will go down the drain pretty much however it wants to. You may discover, as I did, different directions in different sinks—or even different directions in the same sink on different occasions, depending on how you filled it. Another legend down the drain. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/23/Coriolis.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/23/Coriolis.780e02dc5fea.mp3"
	},
	{
		"title": "The Hidden Lives of Sloths",
		"text": "There are times—quite a few of them, for better or worse—when I'm confronted with evidence that something I've believed (or assumed) to be the case for years is simply wrong. These occasions can be a source of embarrassment, such as the time a few years ago when a friend pointed out to me that I always misspelled the word “embarrassed.” Being someone who takes the use of language seriously, this came as quite a blow to me. Most of the time, however, I greet epiphanies of mistaken assumptions with equanimity, if not pleasure. I love to learn, and most learning requires a certain amount of unlearning. I had several such experiences in rapid succession while visiting a wildlife sanctuary in Costa Rica. Aviarios del Caribe, located near Cahuita on the Caribbean coast, is a sloth rehabilitation center. Sloths that are injured or orphaned are brought here and cared for, and then—if they're able to fend for themselves—released back into the rain forest. A volunteer had patiently explained many of the differences between two-toed and three-toed sloths, about which more later. But as I was watching a baby two-toed sloth, I noticed with some puzzlement that it actually had three toes on each foot. Clearly there was an interesting story here, but that was just the beginning of the strange and wonderful things I was to discover about sloths. Digital Communication First, let's talk about those toes. Sloth expert Judy Arroyo explained to me that all sloths actually have three “toes”—that is, three digits on their hind limbs, if you want to think of them as feet. The difference is in the “fingers”—the digits on the fore limbs. Two-toed sloths have two; three-toed sloths have three. So why weren't they called “two-fingered” and “three-fingered”? Apparently it was a problem of translation. According to Arroyo, the Spanish word used to describe the sloths' digits can mean either finger or toe, and the English word choice turned out to be a bit misleading. Whether you call them fingers or toes, sloths use them to great advantage. They're hooked and very strong, which makes them handy for climbing or—more frequently—hanging upside-down for extended periods of time high in the trees. Sloths sleep up to 18 hours per day, and when awake, spend most of their time munching on leaves. They move (very slowly, of course) from tree to tree every day or two, and descend to the ground only about once a week to urinate and defecate. Two-toed and three-toed sloths share many traits in common, but I was surprised to discover how many differences there were. The two-toed sloth (Choloepus hoffmani) has light brown fur and is nocturnal. The three-toed sloth (Bradypus variegatus) has, as its name suggests, variegated fur. It's active during the day, so it's the one you're most likely to see on a rain forest hike. Males have distinctive markings on their backs that identify them uniquely, in much the same way as fingerprints. And the extra bones in the three-toed sloth's neck enable it to turn its head almost 360°. The Value of a Green Back What I find most interesting about the three-toed sloth is the symbiotic relationship it has with other organisms. One effect of the sloth's languid pace of life is that it can't be bothered to groom itself. This turns out to be beneficial to several varieties of algae and mold that grow inside the sloth's hollow hairs. The algae effectively turn the sloth green, giving it excellent camouflage among the leaves. The camouflage is crucial to the sloth's survival, because its inability to move quickly makes it an easy target for the harpy eagle. But the symbiosis doesn't end there. The algae in the sloth's fur provides food for a great many insects. (I should point out, incidentally, that sloths have extremely long fur, making them appear much larger than they really are.) Beetles have been found by the hundreds living on a single sloth. Another insect that calls the sloth home is a type of moth—Bradipodicola hahneli (or “sloth moth” to most people). The sloth's fur provides both food and protection for the moth. Not only does it feed on the algae, but it also deposits its eggs in the sloth's droppings, where they pupate and hatch, and then fly off to look for another sloth to live on. For a Good Time, Call Sloths are not known as particularly social creatures, but they do spend enough time with the opposite sex to reproduce. One of the studies underway at Aviarios del Caribe when I was there involved the mating habits of three-toed sloths. We saw a video in which a female sloth named Buttercup let out a blood-curdling mating call that sounded like a woman shrieking. Immediately, males from as far away as 700 meters began rushing toward the sound. By “rushing,” I mean crawling at the breakneck speed of about 200 meters per day. But for a sloth, this single-minded, deliberate movement—on the ground, no less, in plain view of predators—is definitely rushing. Ah, the things we do for love. Females usually give birth once a year, and with gestation periods of about six months, that means they spend about half their adult lives pregnant. When a sloth reaches six months of age, it's old enough to be left on its own. Before that time, however, if a youngster falls from a tree, the mother will not attempt to rescue it; the risk of attack by a bird or jaguar is too great. Young sloths separated from their mothers in this way are the main wards of the sloth rehabilitation center I visited. Other residents were injured by contact with an electrical line, or orphaned when an eagle attacked the mother. Staff members and volunteers nurse the sloths back to health, and participate in a variety of scientific studies and conservation projects. Buttercup was the center's first resident, and has been there for about 13 years. She serves as a living mascot, helping to promote awareness and research of her species. Slow Is Beautiful Sloths' slow, graceful movements have been compared to those of a t'ai chi master. I agree with that assessment—and coincidentally it was for a t'ai chi retreat that I went to Costa Rica in the first place. But sloths have also been called “ugly,” and here I must disagree. Up close, sloths are actually quite cute, and the shape of their faces gives the impression of a permanent smile. In the wild, of course, the menagerie of plants and critters growing in the fur can be off-putting, but a well-groomed sloth is—and I'm speaking from experience here—downright cuddly. Sloths share their name with one of the so-called “deadly sins” because their slow metabolism gives them the appearance of laziness. But slow and lazy are two different things. The grace, balance, and gentleness of the sloth—not to mention its hospitality toward the other creatures that depend on it—are traits I could aspire to emulate. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/23/Sloths.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/23/Sloths.336ac9886039.mp3"
	},
	{
		"title": "Crows that Make Tools",
		"text": "I've seen numerous books about the differences between men and women. My own theory is that the main difference has to do with tools. When I walk into the tool section of a hardware store—guys, you know what I'm talking about—I get wide-eyed and giddy. Every tool suggests a new project or task. I want to come up with things to make or repair simply to justify owning another obscure tool. Although, to be perfectly honest, I don't even care that much about using the tools, I just want to own them. One day when I was helping a friend of mine install some kitchen cabinets, he pointed out a particular piece of decorative trim that had cost US$100, then mentioned that he didn't have the right kind of saw to cut it with. “Oh well,” he said with mock resignation, “I may have to break down and buy one. Too bad it costs $200.” I said, “It seems a pity to pay more for the tool than the material you'll use it on.” My friend replied, “Not really—I have two pieces of trim to cut!” We laughed about this because to guys, tool ownership is its own reward. Women, on the whole, don't seem to appreciate the stereotypical male trait of wanting equipment for its own sake. This is equally true for things like computers and stereo components. Women don't understand why we would spend our money on seemingly useless or frivolous tools instead of, say, shoes. But there are also, of course, counterexamples. I know women who are carpenters, computer geeks, and hi-fi buffs, as well as guys who like shoes better than tools. For every theory about the important differences between men and women, there seems to be a reason to doubt it. Tools Are for the Birds Likewise, humans, on the whole, tend to think of the ability to make and use tools as a defining characteristic of our species, something that sets us apart from other animals, that proves we're more intelligent and more highly evolved. But here again, there are counterexamples. A few species of animals use tools, the canonical example being a stick pressed into service to fish insects out of a log or burrow for food. But there are even a few—very few—nonhuman species that make their own tools. It's not too much of a stretch to think of other primates making tools—especially if you've read Congo by Michael Crichton. And in fact, some chimpanzees and orangutans have been known to make simple tools (though not, as far as anyone knows, stone paddles). But even some birds have been observed to make their own tools. The latest species to make waves among scientists and achieve worldwide acclaim is the New Caledonian crow (Corvus moneduloides), a bird with surprising and impressive abilities. At the University of Oxford, researchers in the Behavioural Ecology Research Group are studying tool use among New Caledonian crows. It's one thing to observe animals using tools in the wild, but in the relatively controlled environment of a university laboratory, scientists are able to watch (and film) the crows much more extensively and determine in greater detail how they behave. Their findings over the last several years have given the crows (and the people studying them) minor celebrity status. Time after time, the crows have unhesitatingly used a variety of wooden tools to retrieve food by pushing or pulling it out of a tube. But these crows also make new tools to accomplish specific tasks. It had long been known that New Caledonian crows in the wild made simple tools from leaves and twigs, but they have even figured out how to make tools out of materials they could never have encountered before. In one experiment, researchers provided a pair of crows, Betty and Abel, with two pieces of wire—one straight, one hooked. They put some food in a small bucket with a handle and dropped the bucket into a tube, so that the only way to retrieve it would be to pull it out with the hooked wire. After Abel tried and failed, he flew off with the hooked wire, leaving Betty with the straight wire. No problem—she immediately bent it into a hook, pulled out the bucket, and had lunch. The first time I saw a video of this, I was absolutely stunned. It sounds like such a simple task, but it is just not the kind of ability I've ever thought of animals as having—certainly not birds. Crows Just Want to Have Fun New Caledonian crows—at least those being observed in the lab—seem to use tools constantly, not just when they're trying to get food. This poses some unexpected challenges for the scientists who work with them. The crows are so adept at using tools that researchers have come into the lab to find the fire alarms disassembled. And crows are just as likely to try prodding around in an electrical socket as a test tube. If you thought it was difficult to child-proof your living room, imagine crow-proofing a university research facility. But lest you think these crows are all work and no play, they also seem to use tools just to have fun. Dr. Jackie Chappell, a researcher who spent years working with the crows, had this to say about the way they like to play: One aviary in particular has an obsession with stones. They pick stones up from the aviary floor and bring them into the housing room. We then find stones everywhere. They carefully place them inside the tubes that we use to test their tool use, and they have hammered perfectly sized stones into holes we've drilled in logs to give them natural probing sites. They are such a tight fit that we can't get them out. They also play at rolling pebbles inside a tube. We have some film of them carefully inserting a pebble into a plastic tube, then slowly lifting one end of the tube so that the pebble rolls to the other end (and makes a nice noise—we don't know if this is the objective), then they repeat the procedure from the other end. This can go on for minutes on end. Is “Bird Brain” a Compliment? While it's very interesting that New Caledonian crows make and use tools, what exactly does this prove? By itself, nothing. But what scientists studying the New Caledonian crow hope to demonstrate is evidence of complex cognitive abilities—including things like abstract reasoning. It may be that the crows' cognitive abilities are limited to tool-related tasks, or it could be that they're more general. A series of experiments is underway to find out. One type of experiment involves selectivity. Observation in the wild suggests that crows select their tools according to the task at hand (or beak). Given a range of tasks and materials the crows have never encountered before, will they consistently select (or make) the best tool for the job? Likewise, are they flexible in their use of tools? Having used a certain type of tool for a given task, will they also use less-suitable tools for the same task if necessary? And does their use of tools suggest an implicit understanding of the basic rules of physics? You've Got Questions? We've Got Birds Tool use by New Caledonian crows also raises a host of other questions. For instance, how do they learn to do this? Are there secret tool-making classes in the trees, or do young birds just watch their parents attentively? Once acquired, how does the knowledge spread? Is there something unique in their social interactions that facilitates learning about tools? And why don't other birds make tools? The New Caledonian crow doesn't have the largest brain among birds or the most complex social system, so what makes it unique in this regard? Could other birds learn how to use tools too, given the right environment? For that matter, could a New Caledonian crow teach another species of bird to use tools? These are just a few of the many questions scientists are hoping to answer. How soon these answers arrive will depend on whether the researchers can keep ahead of the birds. The crows are so clever at solving problems that they often come up with entirely novel ways of accomplishing tasks, thus derailing carefully designed experiments. As I read about the research, I'm reminded of the white mice in Douglas Adams's Life, the Universe, and Everything. The furry little creatures were really “hyperintelligent pan-dimensional beings”; while scientists thought they were running experiments on the mice, the mice were actually experimenting on humans. But I don't worry about a conspiracy of crows. Any creature that likes tools is OK with me. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/23/crow.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/23/Crows.4932e078f4de.mp3"
	},
	{
		"title": "Leaf Cutter Ants",
		"text": "I'm a city person at heart, but every now and then I like to get far away from the chaos and soak in some nature. On the two trips I've taken to Costa Rica, I've found it ideal for such a getaway. It's quite a contrast from my usual environment—everything from the food to the climate is different, not to mention the language, driving habits, and so on. But we adapt rapidly, as humans tend to do. After a few days, we become accustomed to the heat and, to a lesser extent, the humidity. We get used to seeing the occasional frog or lizard in the shower. The sights, sounds, and smells which were so foreign just a week earlier begin to seem commonplace. “Honey, look! Up in the tree!” one of us will say. What, another sloth, a family of monkeys, a toucan? Ho hum. Been there, done that. The novelty of such sightings wears off much too quickly. The Ants Go Marching One by One, Hurrah, Hurrah Such was the case with leaf cutter ants. At first you think it's an optical illusion. You'll glance at the ground and detect a line of movement, just a rustle. You look at a bare strip in the grass and think: The leaves can't possibly be marching across the ground. You try to figure out what you're seeing, whether it's moving plants or plant-shaped bugs of some kind. On closer inspection—much closer—you see tiny ants, almost blending into the soil, carrying comparatively huge slices of leaves in a long column. Ah: leaf cutter ants. Yes, I think I read about them somewhere. They climb trees, slice up the leaves, and carry them off to their nests. Got it. Once you've figured out what it is, it doesn't seem especially remarkable. Everywhere we went in Costa Rica—rain forest, beach, and everywhere in between—we saw these long columns of tiny marching leaves. They could be fun to watch if you had nothing better to do. Once I dropped a couple of new leaves onto a trail, just to see what would happen. Sure enough, within a few minutes the ants had checked them out, picked them up, and started carrying them toward home. Hats Off to the Soldier A week later on a nature hike near the Arenal Volcano, our guide, Paolo, stopped the group when we came to a column of leaf cutter ants. By this time I had seen dozens of these, so I wasn't paying much attention. Paolo picked up one of the larger ants—a soldier—and asked me for my hat. “Excuse me?” I said. I couldn't comprehend what my hat had to do with the ant. He repeated the question. “Your hat—can I borrow it?” I stood there puzzled for a few seconds, then took off my hat and handed it to him. Paolo held the chin strap of my hat up to the ant, which pinched it between its mandibles. Then, still holding onto the ant, Paolo let go of the hat. The ant held it firmly. OK, now I was paying attention. Watching an ant carry a leaf a few times its size is mildly impressive the first time, but seeing an ant hold my hat—this was something else altogether. The ant was apparently unharmed, but undoubtedly suffering the ant equivalent of psychological trauma. Paolo put it back on the trail and picked up another one. This time he repeated the trick with a branch. Not a twig, mind you, but a hefty branch nearly a meter long and perhaps two centimeters at its thickest point. The ant held it for only a few seconds, but that was more than enough for Paolo to make his point. These little guys are seriously strong. The mandibles seem to have a mind of their own, too: they'll keep holding on just as tightly even if the ant dies. Because of this, they are sometimes used to close wounds in a pinch (so to speak). The technique is to hold the ant so its mandibles pinch either side of a cut, then twist the body off, leaving the head in place. A bit gruesome, but it makes a fair substitute for a suture. The World's Smallest Agriculturalists This was just the beginning of the surprising things we were to learn about leaf cutter ants. The most obvious question we had was what they did with all those leaves once they got where they were going. I figured they either ate them or used them as a building material. In fact they do neither: their digestive systems can't break down the cellulose in leaves, and they live in underground nests (which, by the way, can be enormous, holding as many as 10,000,000 ants). When the ants arrive home with their leaves, they hand them off to specialized workers that chop them up into even smaller pieces, cover them with their own droppings, and use them as a medium for growing the fungus that the ants actually eat. In other words, the ants are basically fungus farmers. The ants and the fungus form a textbook symbiotic relationship—each depends on, and benefits, the other. The fungus thrives on the food provided by the ants, which also give it a cool, moist environment to grow in and weed out any other plants competing for its food and space. The ants also enable the fungus to propagate, which it would otherwise be unable to do. In exchange, the fungus serves as food for the ants. Flies Can Be a Headache Another thing we noticed was that much smaller ants would often ride on top of the leaf fragments as they made their way along the path in the jaws of the delivery ants (known as foragers). Paolo told us they serve a sort of quality control function. That may be true, but further research showed them to have an even more important and much weirder role. It seems that a bug called the coffin fly likes to land on an ant and lay eggs on its head. When the eggs hatch, the larvae burrow into the head and feed on the ant's brain. There being so little brain to go around, there isn't enough for both the ant and the fly, and the ant dies. Ordinarily, ants can defend themselves against the files, but not when they're carrying a giant leaf. So the tiny tag-along ants, known as minima, defend the foragers against the nasty coffin flies. Leaf cutter ants will travel quite a distance—up to 100 meters from their nest—to locate just the right plants to defoliate. Quite often I watched the ants pass by what appeared to my unsophisticated eye to be perfectly yummy trees right near their nest. Apparently the ants have developed a subtle art of leaf selection, choosing only the ones most conducive to the growth of their food. A large colony of leaf cutter ants can bring in as much as 34kg (75 lb.) of leaves per day, comparable in mass to the daily grass intake of a cow. Although leaf cutter ants are sometimes regarded as a pest—they damage both food crops and ornamental plants—they do much more good for the ecosystem than damage. They aerate the soil and produce nutrient-rich fertilizers. The symbiotic relationship they have with the fungus they use for food is a favorite research subject among biologists. And, of course, for jaded tourists like me, they provide both entertainment and a reminder that there are more interesting things around us than meet the eye. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/23/ant_.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/23/Ants.687a9456bb8.mp3"
	},
	{
		"title": "Poison Dart Frogs",
		"text": "Where I come from, frogs were always considered harmless, even comical, creatures. Not that you'd want to have one in your bathtub with you, but you imagined them leading a leisurely amphibian life, hopping from one lily pad to the next, keeping the pond free of insects, and croaking happily away. Kermit, of course, epitomized the friendliness and goofiness of frogs. He sang, “It's not easy being green,” but his biggest problem seemed to be that his girlfriend was a pig. In countless high school biology classes, students have had to set aside their anthropomorphic image of frogs to dissect them and study their anatomy. Although the students sometimes consider this quite unpleasant, you could hardly imagine a less scary specimen. And of course there's fried frogs' legs, a fairly bland but unobjectionable dish I've enjoyed in New Orleans. A Touch of Color In the tropical rain forests of Central and South America, however, frogs conjure up a rather different image. If you look on the ground—under broad leaves, near puddles, or in other cool, moist places—you're likely to see a tiny splash of color. Only about one inch (2.5cm) long, poison dart frogs contrast vividly with the dull greens and browns of their habitat. But poison dart frogs differ from their larger, greener cousins in a more important way. Their name comes from the fact that glands on their backs secrete a poison that is sometimes rubbed on the tips of darts or arrows for hunting. They are, in a passive way, quite dangerous, and about as far from Kermit as you can get. There are about 170 different species of poison dart frog. Their appearance varies greatly from one species to the next, but the colors are always very bright. Every neon shade of red, orange, yellow, green, and blue is represented. One species, the Strawberry Poison Dart Frog (Dendrobates pumilio), is sometimes called the “blue jean frog” because it has a bright red or orange body with blue legs. Another, the Harlequin (Dendrobates histrionicus), has spots that contrast sharply with its base skin color, though the pair of colors varies from one group of frogs to the next. Of Mice and Men Just how poisonous are poison dart frogs? Well, that depends. Generally speaking, the secretions from a poison dart frog's back cannot permeate unbroken human skin, so they can be handled safely as long as you don't have any open cuts and are careful to wash your hands afterward. The poison causes problems only if it gets into your bloodstream (either directly or through ingestion). Even then, it probably won't kill you, though some species are much more toxic than others. The statistic usually quoted about the Golden Poison Dart Frog (Phylobates terriblis), for example, is that its skin contains enough of the alkaloid chemical Batrachotoxin to kill 20,000 mice. Some Web sites claim this equates to eight adult humans, though actually the number is closer to 100. But the frogs don't bite, so you'll only get into trouble if you try snacking on one. Poison dart frogs reportedly become less poisonous over time when in captivity, apparently due to a change in diet. The toxin is created from chemicals found in insects the frogs eat in the wild; without access to exactly the right kinds of food, the toxicity rapidly fades. Of course, poison dart frogs in captivity also have less need of this natural defense mechanism, which reduces their appeal to natural predators from spiders to birds. Take Two Frogs and Call Me in the Morning For a number of years researchers have been investigating medical applications for frog toxins. The secretion from the Ecuadorian species Epipedrobates tricolor has been adapted to create a pain killer called ABT-594 (nicknamed “epibatidine” in honor of the frog). Epibatadine has been described as being 200 times more potent than morphine, with fewer side effects. Poison dart frog secretions also show promise for the development of muscle relaxants and heart stimulants. You may have heard of people getting high from licking toads that secrete a hallucinogenic chemical. That is an entirely different (and arguably more benign) substance from that found on poison dart frogs. Kissing a frog is unlikely to turn it into a handsome prince, though if you kiss the wrong kind of frog there's no telling what you may experience. Personally, I have a general policy of avoiding lip contact with any wildlife and I think I'll stick to it. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/21/frog-1.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/21/Frogs.5d6aa959be70.mp3"
	},
	{
		"title": "The Argentinosaurus",
		"text": "Bruce Chatwin begins his book In Patagonia with a description of a small piece of skin in a glass case in his grandmother’s dining room. When Chatwin was a young boy, his grandmother told him that this piece of skin, covered with coarse reddish hairs and pinned to a card, was from a brontosaurus that her cousin Charley had discovered preserved in a glacier in Patagonia. This peculiar artifact so captured the boy’s imagination that decades later—long after his grandmother had died and the skin fragment had been discarded—Chatwin set out on his own adventure to Patagonia. One of his goals on this trip was to discover the true origin of the animal whose hide was such a familiar memory from his childhood—and with any luck, find another sample of skin and hair to replace the one that was lost. An Apatosaurus by Any Other Name In the mid-1970s, around the time Chatwin left on his six-month journey, scientists finally proved that there had never been any such thing as a brontosaurus. For nearly a century, a skeleton of a dinosaur known as the apatosaurus had been displayed with the skull of an entirely different animal, the camarasaurus. This odd combination of bones never should have been given a unique name, but the error has persisted to this day in popular usage, even decades after all references to “brontosaurus” had been wiped from paleontological texts. Chatwin may not have known this at the time, but he did at least discover before his journey that the skin fragment in his grandmother’s house belonged to another, more recent (but still prehistoric) creature: the mylodon, or Giant Sloth. The last mylodon expired perhaps 10,000 years ago, but some mylodon flesh was indeed preserved in a cave in a remote area of Patagonia. It was this creature whose remains his grandmother’s cousin Charley had found. Nevertheless, Chatwin’s grandmother hadn’t been entirely off the mark. Argentina had, at least, been home to numerous large sauropods, the suborder of dinosaurs to which the apatosaurus and camarasaurus both belonged. In fact, just a couple of years before Chatwin’s death in 1989, an Argentinean rancher discovered some sauropod fossils that would soon be very big news in the world of dinosaurs. In 1993, paleontologists Rodolpho Coria and Jose Bonaparte classified the fossils as belonging to a hitherto unknown dinosaur, which they dubbed Argentinosaurus. It was the largest dinosaur—in fact, the largest land animal of any kind—to have been discovered at that time. Thinking Big The Argentinosaurus, which lived about 90 million years ago in the Upper Cretaceous period, weighed up to 100 tons and measured between 30 and 45 meters (100–150 feet) in length. As a plant-eater, it was not the most fearsome creature, but I still wouldn’t want to meet one in a dark alley. Although only a small percentage of a full skeleton has been recovered so far, paleontologists have a pretty clear idea of what the entire creature must have looked like—enough to assemble a full-scale replica of the skeleton, which was recently installed in Atlanta’s Fernbank Museum of Natural History. (By law, dinosaur fossils cannot be removed from Argentina.) Humongous dinosaurs turn up with remarkable frequency in Patagonia. This is also where the fossils of a gigantosaurus, the largest known carnivore, were found. A few years ago several vertebrae were unearthed belonging to a still-unidentified dinosaur that may well challenge Argentinosaurus for the record of largest lizard ever. Be that as it may, there’s no question that this creature was immense. At a museum of paleontology in Trelew, the rear leg bones and one vertebra of an Argentinosaurus are affixed to a wall inside a painted outline of the body, giving visitors a dramatic picture of how tall this animal would have been—far too large, the staff said, for an entire skeleton to fit inside the museum. Before we entered the museum, our guide had warned us, delicately, that what we would be seeing was a scientific presentation based on evolutionary theory. We all thought that disclaimer was pretty funny—what else would you see in a paleontological museum? I can only guess that earlier tourists with strong fundamentalist religious beliefs had taken offense at the suggestion that life as we know it evolved over billions of years. Personally, I lack the faith to accept a timeline that would have involved Argentinosaurus tromping around Patagonia a mere few thousand years ago. If they had, we might easily discover one, flesh intact, in the nearest glacier. I’ll be the first to lay a skin fragment on Bruce Chatwin’s grave. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/21/Argentinosaurus-1.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/21/Argentinosaurus.fab092daea38.mp3"
	},
	{
		"title": "Megaplumes",
		"text": "Like every other literate adult on the planet, I've contributed to Dan Brown's fortune. I read Angels and Demons and then, of course, I had to read The Da Vinci Code. When I realized that his first four novels were all bestsellers, naturally I felt compelled to buy the other two as well: Digital Fortress and Deception Point. Brown writes page-turners—on this point, everyone agrees. Some people fault him for his literary style or lack thereof; others take issue with his interpretations of history, his scientific descriptions, or his religious views. As for me, when I pick up a novel, I understand that it's fiction—no matter how many facts may have been thrown in to make it believable. I put myself into willing-suspension-of-disbelief mode, enjoy the story, and then come back to reality. I don't allow some fictional character's beliefs to affect me one way or the other. Nom de Plume Occasionally, though, I do wonder—just a bit—if there's any element of truth to some of the more outrageous scientific “discoveries” that make such convenient plot devices. Take, for example, a phenomenon described in Deception Point that sounds much too sci-fi to be real: an oceanic occurrence known as a megaplume, which Brown describes as a sort of massive vortex, capable of sucking huge ships helplessly down to the ocean floor. The vortex, according to one of his characters, is caused by a magma dome that superheats ordinarily cold water near the ocean floor, resulting in powerful convection currents. And this unusually warm current, in turn, attracts massive numbers of bloodthirsty hammerhead sharks. Sounds very James Bondish, doesn't it? But I thought, just for laughs, I'll look up “megaplume” and see if there's any such thing. Allow me to cut to the chase: megaplumes do exist, and although Brown took some liberties in his descriptions, they are nevertheless a fascinating phenomenon. What is a megaplume? Why, a giant plume, of course! In its geological sense, plume is defined as “An upwelling of molten material from the earth's mantle.” But the term can also be used to describe a column of hot water ascending from the ocean floor, and a megaplume is an exceptionally large pocket of unusually hot ocean water. Precisely what heats the water is the subject of some debate, and while it could be more or less what Brown describes—a dome of magma bubbling up just below the ocean floor—the usual geological explanations are quite a bit more complicated, and frankly, beyond me. But one way or another, the heat does clearly come from tectonic activity. Going for a Spin Although hydrothermal vents—discharges of a hot, mineral-rich water solution from the ocean floor—are well known, megaplumes have been likened to a huge initial “belch” of hot water that may occur when such a vent forms. The hot water forms itself into a free-floating lenslike shape that can be more than 12 miles (about 20km) in diameter and more than half a mile (about 1000m) deep. When the water closer to the surface—which is now colder than the water beneath—begins to sink, it contributes to the formation of powerful but slow-moving whirlpool-like currents. But the whirlpool is not anchored in one spot; like a tornado, the entire megaplume can move horizontally—sometimes hundreds of miles over a period of months—before dissipating. However, because the ocean is relatively deep in areas in which megaplumes are known to exist, the whirlpool is far below the surface, making it difficult to detect. The first megaplume was discovered in 1986 on the Juan de Fuca Ridge, which runs roughly parallel to the coast of the U.S. Pacific Northwest, about 300 miles (450km) west of Oregon. Since then, only a handful have been observed. I have read no reports of megaplumes attracting hammerhead sharks, but they do certainly bring with them a wide variety of interesting creatures, including some rare microbes that flourish in the superhot waters of hydrothermal vents. Moreover, megaplumes can transport both minerals and animal life to areas far outside the range where they would normally be found, giving researchers no end of unusual things to study. Only in novels do megaplumes swallow boats, but in this case, truth is more interesting than fiction. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/21/Megaplumes.123e3af85cdc.mp3"
	},
	{
		"title": "Tsunami Warning Systems",
		"text": "At the end of December 2004, I was among the millions watching the endless hours of TV coverage of the Indian Ocean tsunami. As I watched the huge death toll rise by the hour, I remember thinking, naïvely, “How could so many people not have known what was coming?” After a bit of reflection, I had a worse thought: “How could they possibly have known?” Living in the U.S., I’ve become accustomed to having instant information about everything. When something newsworthy occurs anywhere in the country, television crews materialize out of nowhere and broadcast the story to a nation of information junkies. And if the TV or radio isn’t on, I’m never far from a cell phone or a Web browser. If I think I feel an earthquake—not an uncommon occurrence here in San Francisco—I can check a Web site that tells me its strength and epicenter within minutes. The notion that something cataclysmic could be occurring without my knowledge, whether in my neighborhood or across the continent, is almost unfathomable. And yet, when I fantasize about a dream vacation, the picture in my mind is invariably that of a tiny, picturesque island out in the middle of the ocean somewhere. Maybe I’m even in a bungalow built on stilts over the water. I’ve left all my gadgetry behind, and have nothing to worry about but finishing the next chapter of my book and maybe taking a quick swim before dinner. I’m not thinking about staying connected to the rest of the world; that’s what makes it a vacation. And that, tragically, is exactly the situation many tourists found themselves in when the tsunami struck. Of course, even locals with phones and televisions were not warned, because the existence of the tsunami was largely unknown before it hit. Since then, while the governments of every coastal nation in the world have talked about the urgent need for a global tsunami warning system, I’ve been wondering exactly how that could happen. On the one hand, I want to know why it isn’t trivially easy (Don’t we have satellites? ), and on the other hand, why it isn’t immediately dismissed as impossible (What about all those people on the remote islands without communication equipment? ). Although I knew that a lot of money was being spent on sensors and radios, I didn’t understand just how this proposed system would work. So I decided to look into it. Little Things Mean a Lot Tsunamis usually begin with strong earthquakes, and there is already a global network of sensors that can adequately detect and measure seismic activity. But not all strong earthquakes that occur in the ocean produce tsunamis, and even when they do, seismic data gives few clues as to the direction or speed of the waves. So although some regional tsunami warning systems are based on seismic data alone, such systems are notorious for false positives. The only way to know for sure if a tsunami is coming is to observe the waves as they move. But perhaps “observe” is not the right word; tsunami waves appear quite small at the surface when far out at sea, even near a quake’s epicenter. With a height of sometimes as little as a few centimeters, they look like ordinary waves from a boat or plane. Only as they approach land do they swell to dangerous sizes. This characteristic makes detection a tricky business—requiring high-tech equipment and computerized analysis. The first method used to supplement seismic data was taking readings from tide gauges. Although some tide gauges are quite sophisticated, many are simple mechanical devices that measures the height of a float protected from waves by an enclosure called a stilling well. Because tide measurements require a fixed point of reference, tide gauges are normally installed on or near a coast. Thus the data they provide is more useful for landmasses farther out from the tsunami’s starting point. A more direct way of detecting tsunamis is to measure changes in pressure on the ocean floor. The Deep-ocean Assessment and Reporting of Tsunamis (DART) program, already in use in the Pacific ocean, uses bottom-mounted sensors to detect changes in water pressure consistent with a tsunami. The sensors relay the information via sonar to a buoy floating on the ocean’s surface; the buoy, in turn, transmits the data to a satellite, which relays it to ground-based stations for processing. DART greatly increases both the speed and accuracy of tsunami warnings, but the sensors and buoys are prone to failure and must be serviced or replaced frequently. And there are at present far too few of them in place to monitor all the world’s oceans. Although tsunamis out at sea are not visible to the naked eye, radar satellites, if they happen to be pointed in the right place at the right time, can detect them. The problem with satellites, apart from knowing where and when to look, is that the data they produce must be processed back on Earth; the time required—currently several hours—is generally too long to be of use for warnings. Future generations of satellites, however, may overcome these limitations. The Challenge of the Last Mile But even if and when the world’s oceans are populated with perfectly functioning tsunami sensors, the truly phenomenal challenge will be getting the information from the scientists who operate the equipment to the people living in the coastal areas where the tsunamis will hit. For one thing, tsunamis move incredibly fast—up to 1,000 km/h (about 600 mph). So land areas must be at least a few hundred kilometers away from a quake’s epicenter to have even a small chance of receiving a warning in time. Once the warning does come, the nation must have the infrastructure to relay it rapidly to coastal areas at any hour of the day or night. Although telephones, television, radio, and the internet can be used for such purposes, residents need something that can wake them in the middle of the night—such as a siren—to be assured of having maximum time to react. While such warning systems may be feasible in densely populated coastal towns, it’s inconceivable that every remote beach in the world is ever going to have a tsunami alarm. Then, of course, there’s the little matter of preparedness. If someone told me right now that a tsunami was going to hit my house in 15 minutes, I wouldn’t know what to do—where to go, what to take with me, how to be as safe as possible. Every child attending school in California learns what to do in the event of an earthquake, but not, in general, how to cope with sudden giant waves. This is all the more true in many other parts of the world. No matter how great the technology is, there’s no substitute for education. All that to say: if the world’s leaders keep their promises, spend enough money, and encounter no significant technological barriers, global tsunami detection could very well be a reality in a few years. Will we then—or ever—have the ability to effectively warn everyone of an impending wave? Absolutely not. But with diligent attention to education and civil preparedness, we can certainly hope to reduce the risks dramatically. I learned long after the fact that some friends of mine had been very close to some of the tsunami zones when the waves hit, but all of them returned safely. This made the tragedy seem more personal, and the need for a warning system more urgent. Even knowing what I know now, I still long for that idyllic island getaway. I may, however, pack a cell phone on my dream vacation—just in case. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/19/tsunami.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/Tsunami.e877b5f66da2.mp3"
	},
	{
		"title": "Memetics",
		"text": "Several years ago, a friend of mine gave me a book for my birthday called Thought Contagion. I had not heard of the book or its subject matter, the science of memetics, but I was fascinated by what I read. Author Aaron Lynch explained, concisely and convincingly, how some of the most significant beliefs in society came to be as popular as they are. By the end of the book I felt I understood, for the first time, a great many things that should have been obvious all along. I was even more surprised to discover that the things Lynch was saying were considered novel, and even somewhat controversial. What he described, simply and elegantly, is a compelling theory about the way beliefs spread. What Memes May Come The fundamental term in memetics is meme, which means a self-propagating idea. The term was borrowed from sociobiologist Richard Dawkins, who coined it in his 1976 book The Selfish Gene. Roughly speaking, memetics applies the principles of evolution by natural selection to beliefs. In conventional evolution, genes that improve an organism's ability to survive endure in future generations and spread throughout a population; those that hinder survival eventually disappear. By analogy, memetics says that ideas are subject to natural selection as well; those that most effectively promote their own survival multiply and spread, while those that don't, don't. In memetics, it is misleading to think of a person as having a belief; instead, it is more accurate to think of beliefs as acquiring people. Memes propagate from person to person in a manner analogous to the way viruses spread. A meme is passed from one person to another through one form of contact or another, and in some cases must mutate in order to continue surviving and spreading. Thus memetics is sometimes described as an epidemiology of ideas, investigating them in much the same way as a researcher might study the way a disease spreads throughout a community. This is not to say, of course, that all ideas that spread are negative ones, as the analogy to disease might suggest. Memetics itself is neutral with regard to the value of beliefs, and the principles apply equally to positive, useful beliefs as to destructive ones. Being Fruitful and Multiplying Just as a virus can spread by floating through the air, by skin contact, or through exchange of bodily fluids, there are a number of different mechanisms whereby beliefs spread. One of the most common and effective means of spreading a meme is simply having children, because children more often than not serve as hosts for the same memes as their parents. Thus memes that encourage procreation directly (“your biological clock is ticking”) or indirectly (“abortion is murder”) serve to propagate themselves to the children of the meme's host. Similarly, memes that make it more likely that parents will pass a belief on to children (such as “children should respect their parents”) encourage their own propagation. Another common mechanism of meme propagation is proselytism. Consider the meme “those who do not believe in Religion X will spend eternity in hell.” This meme aids its own propagation, because holding the belief increases the likelihood that it will be transferred to other hosts. A person who considers belief in Religion X crucial to eternal happiness will be motivated to influence its adoption by friends and even strangers (not to mention offspring). This meme also illustrates other methods of propagation, such as discouraging hosts from dropping the belief (persistence of the belief, especially at the time of death, is regarded as crucial to its effectiveness) and resisting efforts of competing memes (such as “all religions are equally good”) to displace it. Gimme Some Truth (or Not) Of the other methods of meme propagation, surprisingly, one of the least effective is for a meme simply to seem true. The sheer force of logic can and does cause memes to spread (as in “Earth revolves around the Sun”). But more often than not, competing memes with other methods of propagation win out over those that depend solely on truth or plausibility. In particular, political and moral beliefs (which typically spread by offspring production, proselytism, and dropout prevention) usually displace beliefs whose only mechanism of reinforcement is objective fact. This could help to explain, for example, how a nation might muster public support for a war in the absence of objective evidence of danger from an enemy. The basic principles of memetic theory that describe the ways in which beliefs spread, persist, and recede, can account for the rise and fall of numerous widespread beliefs, including economic trends, pro- and anti-abortion movements, terrorism, racism, diet fads, and hundreds of other memes. It can explain how TV programs or radio talk shows gain and lose popularity, why less effective technologies win in the marketplace over more effective ones, and how public opinion can shift rapidly on many major issues. My predominant thought while reading Lynch's descriptions was, “Well, of course that's why so many people believe such-and-such. It's obvious. How could it be any other way?” And yet, that is precisely what's interesting about memetics: it points out and explains things that should have been obvious all along, but weren't. Although Thought Contagion is written for a general audience and therefore avoids complex mathematics, memetic theory is in fact a very serious science, backed up by increasing amounts of highly technical analysis. Very few professionals currently consider themselves full-time memeticists, but that is certain to change, thanks to the rapidly spreading meme, “memetic explanations rock.” —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/Memetics.e6f090d61629.mp3"
	},
	{
		"title": "Sea Monkeys",
		"text": "I recently went to a toy store with my son, and found myself marveling at how little had changed since I was a kid. Alongside all the miracles of modern toy science were dozens of items that I remembered seeing on toy store shelves 25 years or more ago, and they looked exactly the same—except for the price. Slinkies. Magic Rocks. Ant Farms. Silly Putty. Nerf balls. And, of course, Sea Monkeys. I vividly remember the ads in comic books and magazines promising “Instant Life—Just Add Water!” The ads pictured anthropomorphic sea creatures with tails, smiling faces, and crown-like protuberances on their heads. These intelligent and fun-loving creatures could be your new pets for just a few dollars. I never managed to prevail upon my parents to spring for the Sea Monkeys, but I always wondered just how close the real thing would be to the hype. A couple of years ago, when Morgen bought a Sea Monkeys set as a present for a friend, I got to see them in action. The little critters were, unsurprisingly, not terribly impressive as pets. However, in terms of both biology and marketing they are a marvel every bit as interesting as those ads implied. Brine Shrimp Deluxe Sea Monkeys are a variety of brine shrimp. Unlike the common species Artemia salina, Sea Monkeys were engineered as a larger and longer-lived hybrid variety the manufacturer calls Artemia nyos (NYOS stands for New York Ocean Science Laboratories, where the breed was developed). But like all brine shrimp, Sea Monkeys lay eggs encapsulated in a cyst shell. These cysts have the unusual capability of remaining viable over long periods of time when completely dehydrated—effectively maintaining a state of suspended animation. This state, known as cryptobiosis, is also seen in some plant seeds, insect larvae, and crustacean eggs. When the eggs are re-hydrated in a saline solution, they continue with their development and hatch soon thereafter. Sea Monkeys have other interesting characteristics, such as the fact that they have one eye when they hatch but later grow two more. According to the official Sea Monkeys literature, the animals also breathe through their feet—I'll have to take their word for it—and the females can reproduce either sexually or asexually. Just Add Hype But when you get right down to it, these creatures, which rarely grow longer than half an inch (about 15mm), are not that interesting as pets go. Brine shrimp are often sold as food for other fish, and their low status on the food chain says something about not only their size but their neural capacity. Compared to even the most ordinary tropical fish, the translucent Sea Monkeys are rather tedious to watch—if you can spot them at all—as they swim around in their little tanks. That brine shrimp could ever be conceived of as pets is nothing less than a stroke of marketing genius. The man behind it was inventor Harold von Braunhut, who was also responsible for such kitschy fads as the X-Ray Spex, which got me in trouble when I tried to wear them during class in sixth grade. Von Braunhut began working with brine shrimp in 1957, and in 1960, his first simple kits went on sale. The fact that the eggs could be shipped easily, stored indefinitely, and brought back to life within a couple of days suggested the name “Instant Life,” which was how the product was first sold. When von Braunhut realized the creatures themselves needed a more marketing-friendly name, he began calling them Sea Monkeys, reportedly because of their tails. (Any actual resemblance to monkeys is purely in the mind of the beholder. ) Von Braunhut died on November 28, 2003. But in recent years, his invention—along with its innumerable variations and spin-offs—has sprung back to life as a retro fad. For about US$10 (rather than the original $0.49), you can get a plastic tank, water purifier, egg “crystals,” food, and accessories—including a handbook whose main purpose is to convince you to buy still more supplies to keep your new pets alive as long as possible. Sea Monkeys come with a two-year “growth guarantee,” but owners seldom maintain their interest in keeping the creatures alive for more than a few months. As pets, they make great fish food. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/19/Artemia_salina.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/Sea_Monkeys.da51086f2995.mp3"
	},
	{
		"title": "Sinkholes",
		"text": "As a San Francisco resident, I have experienced my fair share of earthquakes. They're unsettling (literally and figuratively), and yet they're something we have all come to accept as a normal occurrence in this part of the world. We like the climate, the views, the culture—in other words, the whole vibe of the area—and we simply accept that it has its faults. We stockpile emergency supplies, buy earthquake insurance, and perform seismic retrofitting on our buildings to reduce the risk of damage…and then go on with our lives. Each time a truly devastating earthquake hits—such as the one in 1906 or, more recently, the Loma Prieta quake in 1989—we learn some important new lessons, and soon thereafter feel much safer about the future. Sometimes that safety is illusory. On December 11, 1995, the ground moved in a very small area of San Francisco's Seacliff neighborhood, swallowing Howard Billman's $1.5 million mansion. In this case, however, the cause was not an earthquake, but a giant sinkhole measuring 200 feet (60m) across and 40 feet (12m) deep. Sometimes sinkholes are natural occurrences; in this case, however, the culprit was an old sewer tunnel that had deteriorated. The tunnel itself, of course, was much smaller than the resulting hole. That bit of surprising geometry is just one of the things I find interesting about sinkholes. The mechanisms by which they form, and the abruptness with which they appear—often without warning, and in seemingly unlikely areas—make them even more fascinating, in a rather grim way. Feeling Depressed and Empty? Generally speaking, a sinkhole is a depression in the ground formed when the top layer of earth collapses into an empty space below—a process also called subsidence. (If there were no empty spaces—only layers of earth, rock, sand, and water—the ground would remain solid.) The natural question is where those cavities came from in the first place, and the usual answer is that they were always there—unnoticed until the ceiling of stone above them gave way. So what causes a layer of stone to collapse? Sinkholes are most often found in areas where the bedrock is limestone or another relatively porous stone. Water can dissolve limestone—especially if the water is slightly acidic (due to natural or artificial causes). If acidic groundwater seeps through small cracks in a layer of limestone and into an empty cavity beneath, it can carry away the dissolved rock; the cracks eventually become wide enough that the entire layer weakens and caves in. This type of process is responsible for many of the sinkholes found in Florida and Texas. Throwing Out the Basement with the Bathwater But sinkholes can occur for other reasons too. In some cases, the loss of groundwater (due to pumping for municipal water supplies, say) creates new cavities large enough and near enough to the surface that sinkholes result, even though the soil or rock above the cavity was not compromised. Even more interesting, though, is the way damaged sewer pipes or other tunnels, such as the one in Seacliff, create massive underground cavities. In a typical scenario, an old sewer pipe fills to capacity after a rain storm, and due to a blockage or collapse, begins leaking excess water into the surrounding soil. When the water begins to recede, it drains back into the sewer pipe, but now saturated with minerals that have eroded from the adjacent areas. Repeat this process often enough, or with a large enough volume of water, and the empty spaces formed where the soil has eroded away become large enough to turn into sinkholes. Yet another cause of sinkholes is salt mining—though not always for the reason you might think. Abandoned salt mine shafts can and do collapse, but some sinkholes have a more indirect cause. In Cheshire, England in the late 1800s, salt was produced in great quantities by drying brine that was pumped out of the ground. This brine was a saturated salt solution that had formed by the contact of groundwater with layers of rock salt over many years. Because the solution was saturated, it could not cause further erosion of the salt, and therefore left in place naturally occurring salt pillars that supported the earth above. However, salt producers pumped out the brine so quickly and recklessly that the salt concentration began to decrease rapidly as fresh groundwater came in. The fresh water quickly absorbed the salt that formed the supporting pillars, and the ground collapsed, forming a great many sinkholes. But because the sinkholes were located far from the sites where the pumping took place (in some cases, several miles away), it was impossible for people who had lost their homes to the subsidence to pin the blame on any particular salt producer. None of this is in any way reassuring. Regardless of the geological and topographical features of the ground you're walking on, there's always the chance that some unknown empty space—whether natural or artificial—lurks below, waiting to envelop you in a sinkhole on your very next step. It happens with tragic frequency, though usually not on a scale sufficient to merit widespread attention. But then, you can't really prepare for a sinkhole the way you prepare for an earthquake, so maybe ignorance is bliss. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/18/sinkhole.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/Sinkholes.c698167d2b04.mp3"
	},
	{
		"title": "Spotted Handfish",
		"text": "My earliest memory of fish was watching them swim around in an aquarium at the dentist's office. They had been strategically placed so that patients could see them while undergoing dental procedures; presumably this was expected to have a calming or at least a distracting effect. However, my predominant memory of those dental visits was that of pain. I'm sure the dentist never imagined he was causing his young patients to associate pretty tropical fish with discomfort, but let's just say I never developed much of an interest in fish—other than as food. But of course no subject is outside my curatorial domain these days, and I'm often quite surprised to learn about what I've been missing. For example: a fish that walks. Limping Along The spotted handfish (Brachionichthys hirsutus) is found only in a small region of the lower Derwent Estuary near the city of Hobart, in southeastern Tasmania. It's a small, colorful, friendly-looking fish that lives in shallow waters. Adults grow to be no more than 15cm (about 6 inches) in length, and are covered with a distinctive pattern of dots that can identify individuals as uniquely as fingerprints. But what makes this fish truly unique is its pectoral fins, which look for all the world like arms and function as legs: although the spotted handfish can swim, it usually walks (or “gallops”) along the sandy sea floor using both its pectoral and ventral fins. My first tendency, of course, would be to assume that a fish that can walk on arm-like appendages is climbing the evolutionary ladder. I have this mental image of a handfish, after a few more generations of random mutations, pulling itself up onto a beach to take a look around, and eventually adapting to life on land. But it turns out that just the opposite is the case: the spotted handfish is in dire danger of extinction. In 1996, the spotted handfish had the dubious distinction of becoming the first marine fish to appear on Australia's endangered species list. Although the species was known to be abundant just a few decades ago, there are at present only three known colonies, each with fewer than 200 adults. Getting Stepped On by Stars Although no one can say with complete certainty why their numbers are dwindling, three factors are mentioned repeatedly. First, the considerable development in the Derwent Estuary area has caused a lot of silt runoff, clouding the waters and reducing the fish's habitat. Second, heavy metals may be contaminating the waters, acting as a poison. But the most likely reason the spotted handfish is in trouble has to do with a predatory starfish known as the northern Pacific seastar, which was introduced into local waters accidentally and which has multiplied at an astonishing rate. The seastar does not feed on the spotted handfish themselves, and apparently does not eat their eggs either. What it likes to munch on is a marine animal known as the ascidian, also called the sea squirt. Adult ascidians like to affix themselves permanently to a rock, and the spotted handfish lay their eggs on the ascidians—actually wrapping the eggs in a sort of interconnected web around the ascidian's body. So if the seastars eat all the ascidians, the handfish have nowhere to lay their eggs. Conservationists have been studying the spotted handfish carefully to find solutions to this problem, and some hopeful progress is being made. For one thing, spotted handfish have been successfully bred in captivity and reintroduced to their native habitat. For another, biologists have discovered that spotted handfish are happy to use an artificial spawning substrate made out of plastic—even in the wild. This is all good news, but without a great deal more help, the ongoing dangers from development and hungry starfish may leave the spotted handfish with nowhere to run. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/18/handfish.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/Handfish.b41a3840a0e2.mp3"
	},
	{
		"title": "The Oropendola",
		"text": "I'm not much of a bird watcher, but on my first visit to Costa Rica I kept hearing this strange sound, almost like one bird trying to laugh while another one is whistling. That made me look up, and when I spotted the bird that was making the sound, I started to laugh. I had the distinct impression that it was putting on a show just to entertain the tourists, and it immediately became one of my favorite rain forest animals. The bird is called the Oropendola (often, and understandably, misspelled as “Oropendula”). It's a largish bird that looks black from a distance but is actually dark brown, with bright yellow tail feathers. There are two species of Oropendola: the Crested Oropendola (Psarocolius decumanus) and the Montezuma Oropendola (Gymnostinops montezuma). Oropendolas are native to Central America, with some found as far north as southern Mexico and some as far south as Ecuador and Brazil. In the parts of Costa Rica I've visited, the Montezuma Oropendola is more common. Swingers Both species of Oropendola share a unique and rather silly characteristic, as hinted at by the bird's common name (roughly, “gold pendulum”) and the Latin genus name Gymnostinops. A male Oropendola stands on a thin horizontal branch, with his claws wrapped most of the way around it. Then the bird spreads his wings and swings around the branch so that he's hanging upside down, his yellow tail feathers prominently displayed above him. Sometimes he reverses the motion and springs back to the top, and sometimes he flips all the way around the branch like a gymnast on the horizontal bar. At the same time, the bird lets out its loud, goofy call [click here to listen]. During mating season (January to May), this goes on pretty much all day, every day. Scientists will tell you this behavior serves a purely utilitarian purpose. When a male displays his tail feathers and makes the distinctive mating call, it attracts females, end of story. (In a typical Oropendola colony, there are five females for every male, so the males keep busy.) Like most scientific explanations, this one is sensible and descriptive—but also dull and unimaginative. Thousands of bird species manage to mate without such an elaborate ritual, even if they don't have yellow tail feathers. I have an alternative explanation for both the swinging behavior and the call: Oropendolas flip around branches because it's fun, and the call can be translated directly into English as “Wheeeeeeee!” Watch these birds for a few hours and you'll probably come to the same conclusion. The name Oropendola is also suggestive of the bird's unusual nest: a long, narrow woven basket one to two meters in length. Each nest holds just one adult female and her offspring. They hang from the highest branches of tall trees, sometimes in clusters of dozens or even hundreds. The Birds and the Bees As with other rain forest creatures such as sloths and leaf cutter ants, Oropendolas participate in some interesting symbiotic relationships. I've read two very different accounts, both involving the cowbird, which does not build its own nest but lays its eggs alongside those of the Oropendola. According to one source, Oropendolas like to nest in trees where hornets are found, because the hornets keep away the cowbirds; Oropendolas, in turn, protect the hornets from bees. Other sources say the cowbirds are a desirable neighbor, and that Oropendolas like hornets because they attack botflies, the real enemy. Botflies like to lay their eggs directly on newly hatched Oropendolas, and the botfly larvae feed on the birds. But cowbird eggs hatch before the Oropendola eggs do, and the young cowbirds feed on the botflies, thus protecting the Oropendola. Oropendolas are not the largest or most colorful birds; most tourists in Central America's rain forests are really looking for the Resplendent Quetzal, with its absurdly long, bright green tail. But what the Oropendola lacks in sheer flashiness it makes up for in style. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/18/112.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/Oropendola.c2ce6a9ef683.mp3"
	},
	{
		"title": "Perpetual Motion Machines",
		"text": "I distinctly remember learning the laws of thermodynamics in a science class—it must have been around eighth grade. After explaining these laws, the teacher added, “…and that is why perpetual motion machines are impossible.” So this fact has been firmly implanted in my brain for a very long time. What I did not realize back then is that over the centuries, hundreds—if not thousands—of hopeful inventors have dedicated their lives to disproving these laws by building machines they believed would run indefinitely with no input of energy. Patent offices around the world became so inundated with designs for alleged perpetual motion machines that they now routinely dismiss such submissions without so much as a glance. But although every such design ever attempted has failed, the pace of research to find that subtle trick that results in perpetual motion has, if anything, accelerated. While doing some research on another topic, I stumbled upon a Web site listing an incredible number of current or recent projects. And sadly, many of these are not merely futile but fraudulent, as their developers convince investors to fork over large sums of money to pay for something that is just not possible. That said, the books and Web sites created to debunk claims of perpetual motion technology are equally numerous—and equally passionate, if not more so. As obsessed as true believers may be in proving their claims, the skeptics are just as obsessed with disproving them, and greater enthusiasm from one camp is met with renewed fervor from the other. Whether this self-reinforcing feedback loop itself constitutes perpetual motion is a question better left for philosophers. The term perpetual motion is perhaps a bit misleading, since technically, nothing about the laws of thermodynamics prohibits something from moving forever. Arguably, the motion of planets in space and electrons in atoms is, in some sense, perpetual. But the point of building a perpetual motion machine is typically not just to get something to stay in motion, but to do work of some sort—propel a vehicle, power a mill, heat your coffee, or run your computer. Any output of energy (whether in the form of heat, electricity, motion, or whatever) that goes beyond the input minus what the machine itself uses is what conflicts with the laws of thermodynamics. Nowadays, designers are concerned less with producing motion than with producing excess energy in the form of electricity or heat, so terms such as “free energy” and “over-unity” are often applied to devices, moving or not, whose energy output ostensibly exceeds their input. Laying Down the Law For those of you who haven't been in eighth grade recently, here's a quick review of the laws of thermodynamics. The First Law of Thermodynamics, also known as the Law of Conservation of Energy, states that energy can be neither created nor destroyed. Thus, the total energy within a system is a constant; although a system can turn one form of energy into another (say, electricity into motion), the net output can never be greater than the net input. The Second Law of Thermodynamics, also known as the Law of Entropy, states that heat cannot be turned into other forms of energy with 100% efficiency. Or, to put it more generally, in any system involving the conversion of energy (per the First Law), some amount of energy will be dissipated into the environment in the form of heat. (There's also a third law and a zeroth law—no kidding—but those are not usually applicable to perpetual motion machines.) A machine could achieve perpetual motion only by violating one or both of the first two laws of thermodynamics. For example, if there were some sort of motor that spun on its own forever, that would be a violation of the first law, because it would produce energy output without energy input. And if there were a device that converted electricity into motion, and then used that motion to drive a generator producing more electricity (to keep the cycle going indefinitely), that would violate the second law, which predicts that eventually the loss of energy due to inefficiency would cause the machine to stop. Running on Empty So the question most perpetual-motion and free-energy enthusiasts start with is, “Who says I can't break those laws, anyway?” Surely, the inventor says, there must be some way to exploit gravity, magnetism, or other natural forces in such a way as to produce a machine that will run forever. And the attempts over the years to do so have been nothing if not creative. Some devices are purely mechanical; others depend on water, gases, or chemical reactions; still others have no visible moving parts, operating at a molecular or even quantum level. And yet, each design that has actually been built—large or small, simple or complex—has eventually stopped producing energy (if in fact it ever worked at all), just as the laws of thermodynamics said would happen. Of course, there is a nagging problem. The standard scientific definition of a perpetual motion machine is “a machine that violates one or more laws of thermodynamics.” But this sounds suspiciously like an attempt to define such machines out of existence—it allows skeptics to say, “Whatever it is you've designed, it can't be a perpetual motion machine because we define such machines as ones that can't possibly exist.” It's rather like saying, “I define a flying saucer as an imaginary spacecraft. Therefore, whatever you saw in the sky, it could not by definition have been a flying saucer.” However well justified scientific skepticism may be, this is a rhetorically unfair tactic. And it has only spurred free-energy proponents to work harder to prove they're right. So Near, and Yet So Far In a typical scenario, an inventor has an idea for a novel design. When the machine is actually constructed, it seems to work for a while but then stops, prompting the inventor to conclude that with further refinement, it would keep going. Or a device appears to produce excess energy, until it is discovered that the measurement technique was flawed, and that energy from another source was in fact being applied to the system. Because it's possible to make extremely efficient machines that run for a very long time with just a small initial injection of power, it's tempting to believe that a truly perpetual solution is just around the corner. The only problem is, the distance between “a very long time” and “forever” is infinite. Despite the best efforts of scientists, engineers, and crackpots alike, the laws of thermodynamics have held their own and show no signs of being breakable. Several large cash prizes have been offered for people who can construct a working perpetual motion machine and prove its capabilities under rigorous test conditions. The prizes lie unclaimed so far. But for someone to offer such a prize is not merely a statement of confidence in the laws of science—it's a dare. And I think that deep down, many skeptics hope someone eventually proves them wrong. Free energy is something we all wish we could believe in, like world peace—and entropy makes one as elusive as the other. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/18/Perpetuum1.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/Perpetual.e56bc20e8f3.mp3"
	},
	{
		"title": "Ultrasonic Mosquito Repellers",
		"text": "I like to think that I'm a reasonably open-minded person—neither credulous nor unduly skeptical. When a friend of mine told me he saw ghosts, I didn't try to convince him he was hallucinating; I believe that he had some sort of genuine experience for which the terminology and imagery of “ghosts” provided an appropriate description. I would reserve judgment as to whether these were really spirits of the departed, but then, I have no reason to rule out that possibility a priori either. Things are frequently not what they seem; lacking solid evidence one way or another, there's no point in being dogmatic. There are some things, though, that lots of people persist in believing in the face of serious counterevidence. I am speaking, of course, of the decades-old meme that you can keep mosquitos away by using a little electronic gadget that emits ultrasonic sound. Let me get straight to the point: they don't work. They have been scientifically proven not to work again and again over a period of quite a few years. Yet somehow manufacturers keep making them and people keep buying them, because the claim that they should work seems so plausible. As a public service, then, in these waning days of summer, I'd like to tell you the truth about ultrasonic mosquito repellers. Animal Magnetism I have always been popular with the girls—female mosquitoes, that is. I don't know if it's my charming demeanor or the irresistible smell of Earl Grey tea on my breath, but somehow, if there is a single mosquito buzzing around a crowd of a hundred people, it always manages to find me. My skin is very sensitive to mosquito bites, too; they turn into big, ugly, insanely itchy welts that don't go away for days. Fortunately, I live in an area where there are very few mosquitoes, but when I'm in, say, Costa Rica in the winter or Saskatchewan in the summer, mosquito avoidance is always a top priority. If I'm staying put, tactics like mosquito netting, citronella candles, or mosquito coils work well, but when I'm moving around there's no good choice but to cover myself with some sort of mosquito repellent. DEET-based repellents, while very effective, are greasy, smell horrible, and supposedly find their way into your bloodstream quite quickly, where they can't be especially healthy. Newer, more natural alternatives are safer and less offensive to the senses, but it's still no fun to smear the stuff all over my exposed skin (and keep reapplying every hour or so). So one summer, I bought myself an ultrasonic mosquito repeller. The package claimed this tiny, battery-powered device was “safe and effective,” and I figured it was worth finding out if I could get relief without all the chemicals. When I took the device out of its package, the first thing I noticed was that it had not only an on-off switch but a frequency dial. I thought that was odd; wasn't it supposed to be some very precise frequency that drove mosquitoes away? But perhaps I was just not thinking about the device in a technologically sophisticated way. I took the repeller outside, and went to an area that I knew to be popular with mosquitoes. I flipped the switch, and within a few seconds a mosquito approached me, hovering about a foot away. I slowly turned the dial from one frequency extreme to the other; the mosquito was unfazed. I thought it was perhaps a question of range, so I held the device as close as I could to the mosquito. Even an inch away, it had no effect. Finally the mosquito landed on the little black box in my hand and I decided the experiment had been definitively concluded. Sales Pitch The U.S. Environmental Protection Agency and numerous universities have performed tests to determine if or how well various ultrasonic repellers work. In most cases, the tests showed no difference between using the device and using no protection; in the least successful experiments, use of ultrasonic devices increased the number of bites. So what makes people think they should work, and why don't they? Some animals are sensitive to sounds pitched higher than the range of human hearing; ultrasonic whistles are used when training dogs and circus animals, for example, and bats use echolocation to navigate and hunt. The theory behind ultrasonic mosquito repellers is that there is some frequency, or range of frequencies, that mosquitoes can hear—and find distasteful enough to stay away from. For example, some manufacturers claim their devices mimic the sound made by a male mosquito's wings, the theory being that females who have already mated would try to stay away from them. (Though it turns out they do not.) Others say their devices emit sounds at the same frequency as the wing beats of dragonflies or bats, the mosquitoes' natural enemies. Unfortunately, the sounds made by dragonflies and bats have no effect on mosquito behavior in the real world. They don't prevent mosquitoes from becoming lunch for their predators, and they don't protect you from becoming dinner for the mosquitoes. Ultrasonic mosquito repellers do one thing remarkably well, however: survive. They have maintained their uncanny ability to transfer money from the pockets of consumers into manufacturers' bank accounts in the face of terrible odds. Alas, this is a meme that deserves to die. Save your money and rent a copy of The Sixth Sense or The Mosquito Coast. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/18/Ultrasonic_Mosquito_Repellers.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/Mosquito.3ba01730b6d4.mp3"
	},
	{
		"title": "Furlongs Per Fortnight",
		"text": "The official Interesting Thing of the Day style guide stipulates that within reason, all measurements expressed in American or British units (pounds, gallons, miles, etc.) should also be given in S.I. (metric) units. We do this partly because many of our readers are located in other parts of the world, and partly because metric units just make so much more sense. And yet, all units of measurement are ultimately arbitrary, and however convenient calculations may be with systems based on the number 10, there are always other ways of looking at things. Faster than a Speeding Snail When I was in high school, for example, I heard someone use the expression “furlongs per fortnight,” an odd juxtaposition of measurements that struck me as very funny. I thought it would be interesting to figure out how to express the speed of light in furlongs per fortnight. It turned out to be a huge number, over 1.8 trillion (1,802,617,500,000, to be exact). A furlong is of course defined as 40 rods, a rod being an equally obscure unit of length measuring 16.5 feet. Thus you can also express a furlong as 220 yards, 660 feet, 201.2 meters, or 1/8 of a mile. (The only people who normally work with furlongs are those who design race tracks for horses—clearly, an animal whose height is measured in hands needs a special term to describe how far it runs.) A fortnight is 14 days (or nights, as the case may be). So something moving at the speed of one furlong per fortnight (f/f) would be moving very slowly indeed. Interestingly enough, though, 1 f/f is almost exactly equal to 1 centimeter per minute; therefore, furlongs per fortnight would be a good unit of measurement for a snail's pace, which ranges from a bit less than 1 f/f to about 30.5 f/f. Engineers like to use the term “furlongs per fortnight” when they encounter an unknown unit of measurement or can't figure out what the best unit is to express some value. Because this term has come into common slang use in a few academic fields, it often shows up in tongue-in-cheek questions on exams in physics, math, and engineering. For example: “Determine the velocity of projectile x at time t. Express your answer in furlongs per fortnight.” A Googol of Possibilities “Furlongs per fortnight” has also famously appeared in Google's under-publicized calculation feature. If you need to do a calculation or convert one type of unit into another, you can type what you want into Google's search box (or the Google search field in your Web browser, if it has one). Google can work with almost any conceivable unit of measurement. Here are some examples: * Enter 315+412 and Google returns 727 * Enter 4 tablespoons in milliliters and Google returns 59.1470594 milliliters * Enter 65 miles per hour in kilometers per hour and Google returns 104.60736 kilometers per hour * Enter 35 miles per gallon in rods per cup and Google returns 700 rods per US cup * Enter 4 cubits per fathom in feet per yard and Google returns 3 feet per yard * Enter speed of light in furlongs per fortnight and Google returns 1.8026175 x 1012 furlongs per fortnight The possibilities are endless. And the point of all this is…well, I'll need to think about that. Give me a few microcenturies, and I may be able to come up with one. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/18/furlong.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/Furlongs.288980c7a264.mp3"
	},
	{
		"title": "The Kepler Mission",
		"text": "Editor’s note: The transcript to the audio starts three paragraphs below, see the three ***. Among the many things that interest me are some that have—how can I put this delicately?—dubious claims to authenticity. Fortunately, this is not “Interesting True Fact of the Day,” and I don’t think anyone would dispute that the word “thing” could be applied fairly to unicorns, flying saucers, or pots of gold at the end of the rainbow. Today’s topic, the astrological interpretation of a perfectly commonplace phenomenon called Mercury retrograde, is perhaps in the same category. But the story of Mercury retrograde’s alleged effect is quite interesting—so much so that I’m tempted to believe in it, common sense notwithstanding. The word retrograde simply means “moving backward” or “retreating.” In its astronomical usage, a planet is said to be retrograde when, from the viewpoint of Earth, it stops and then moves backward in its orbit. The effect has been likened to driving down the road watching a moving car beside you—if it slows down or your car speeds up, the other car appears to be moving backward. A change in speed has nothing to do with a planet going retrograde. The illusion of backward motion occurs because the angle of a planet’s orbit relative to Earth’s orbit changes at certain points in their respective cycles. Three or four times a year, for a period of 20 to 28 days each time, Mercury exhibits this effect. It’s All a Big Misunderstanding Astrologically speaking, Mercury is associated with communication—the god Mercury, after all, was the winged messenger. By inference, if Mercury is moving backward, that implies difficulty communicating. Specifically, Mercury retrograde periods are said to be characterized by misunderstandings, confusion, and indecision. Delays in communication (for example, a misdirected package or a failure to return a call) are common, as are distractions and a frequent need to rework or redo things you create. Mercury retrograde is also blamed for malfunctions of every kind—cars breaking down, computers crashing, and answering machines going kaput for no apparent reason, and with greater frequency than usual. ***Ever since I was a kid, I’ve been a fan of Star Trek in its various incarnations. I have no trouble suspending my disbelief in the seemingly incredible technology of the future, and I can even accept that somehow, mysteriously, humanoid beings all over the galaxy speak English. But there are some recurring Trek themes that boggle the mind because they seemingly defy the laws of statistics. For example, we viewers are expected to believe that upon encountering any alien race, there is a 35% probability that some hot alien chick will fall in love with the captain of the Enterprise within an hour. Well…I don’t know that the probability is 35%, but it’s certainly a few orders of magnitude higher than what common sense tells me. Likewise, when our heroes encounter a new planet, almost without exception they observe with feigned surprise that it’s a “Class M” planet—Trek shorthand for “able to sustain human life.” Of course, any planet on which human actors are going to be filming a TV show would pretty much have to support human life, wouldn’t it? But in the real universe, it’s hard to imagine that there would be very many worlds so similar to Earth that humans (or human-like beings) could live there comfortably. After all, a lot of very specific criteria would need to be met. The atmosphere must have just the right mixture of gases—and must provide protection from stellar radiation. The temperature must be within the range humans can tolerate. The gravity must be strong enough that we stick to the surface, but not so strong that we can’t walk. There will have to be some liquid water somewhere on the planet. And there must be no environmental toxins or hazards that could cause us serious harm. In short, there are a lot of variables that have to be just right, and you’re not going to find that winning combination just anywhere. You need, in fact, to find a planet that’s very, very similar to Earth in terms of its size, distance from its sun, rotational speed, and so on. So what are the odds, really, of finding other planets like that? The Kepler Mission, a project currently in development by NASA and the SETI Institute, aims to find out. This Little Light Planets outside our solar system reflect far too little light to be seen from Earth. So we only know of their existence inferentially. For example, a technique called Doppler spectroscopy measures the apparent shift in a star’s color when a large planet’s orbit takes it directly between the star and Earth. Using this technique, astronomers have been able to detect more than 100 gas giants (similar to Jupiter) orbiting other stars. However, smaller planets (on the order of Earth’s size) cannot be detected this way because the color shift is too slight. What we can measure, however, is the tiny decrease in brightness as a smaller planet passes in front of a star. Or we could, if we paired an extremely sensitive digital sensor with a powerful telescope—and put it in space, where our atmosphere wouldn’t interfere with the readings. This technique is called transit photometry, and that is what the Kepler Mission is designed to do. The Kepler Mission is currently scheduled for launch in 2007. For four years, it will unblinkingly watch a field of about 100,000 stars, looking for those characteristic dips in brightness. This is tricky business—the decrease in brightness has been compared to that caused by a gnat flying in front of a car’s headlight. And of course this temporary dimming must be observed at regular intervals (say, once a year) to prove that it really was caused by an orbiting planet. Planes and Planets There’s another problem too. Even if a planet exactly like Earth were orbiting a certain star, there’s no guarantee that the plane of its orbit would be in alignment with the Kepler telescope. Astronomers estimate that for any given star, there’s a 1 in 200 chance that a planet’s orbit will be just right to be detected using this method. Statistically speaking, it should be possible to detect small planets—if they exist—in about 500 other solar systems. Needless to say, not all stars are expected to have Earth-like planets in orbit around them, but the Kepler Mission’s designers hope to find at least 50, and possibly hundreds, of potentially habitable planets. Still, all this will really tell us is whether there are stars with planets of roughly the right mass and orbit. Transit photometry can’t tell us anything about a planet’s atmosphere—a crucial part of its habitability. For that, we’ll have to wait until at least 2012. Another of several proposed NASA projects, called the Terrestrial Planet Finder, would use multiple spacecraft with much larger telescopes and more sophisticated techniques to collect detailed data on the atmospheres of potentially habitable planets in other solar systems. Even if one of the missions succeeds, we still won’t know if those planets have any hot alien chicks, but we have to leave something for Captain Kirk to discover a few centuries from now. —Joe Kissell Permalink • email icon Email this Article • • Categories: Science & Nature, ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/18/Keplerpacecraft.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/Kepler.dde5baad321a.mp3"
	},
	{
		"title": "Mercury Retrograde",
		"text": "Among the many things that interest me are some that have—how can I put this delicately?—dubious claims to authenticity. Fortunately, this is not “Interesting True Fact of the Day,” and I don't think anyone would dispute that the word “thing” could be applied fairly to unicorns, flying saucers, or pots of gold at the end of the rainbow. Today's topic, the astrological interpretation of a perfectly commonplace phenomenon called Mercury retrograde, is perhaps in the same category. But the story of Mercury retrograde's alleged effect is quite interesting—so much so that I'm tempted to believe in it, common sense notwithstanding. The word retrograde simply means “moving backward” or “retreating.” In its astronomical usage, a planet is said to be retrograde when, from the viewpoint of Earth, it stops and then moves backward in its orbit. The effect has been likened to driving down the road watching a moving car beside you—if it slows down or your car speeds up, the other car appears to be moving backward. A change in speed has nothing to do with a planet going retrograde. The illusion of backward motion occurs because the angle of a planet's orbit relative to Earth's orbit changes at certain points in their respective cycles. Three or four times a year, for a period of 20 to 28 days each time, Mercury exhibits this effect. It's All a Big Misunderstanding Astrologically speaking, Mercury is associated with communication—the god Mercury, after all, was the winged messenger. By inference, if Mercury is moving backward, that implies difficulty communicating. Specifically, Mercury retrograde periods are said to be characterized by misunderstandings, confusion, and indecision. Delays in communication (for example, a misdirected package or a failure to return a call) are common, as are distractions and a frequent need to rework or redo things you create. Mercury retrograde is also blamed for malfunctions of every kind—cars breaking down, computers crashing, and answering machines going kaput for no apparent reason, and with greater frequency than usual. It's oddly appropriate that even the name of the phenomenon is often not communicated correctly. I have frequently heard people say, “Mercury's in retrograde.” My inner grammarian obliges me to point out that this doesn't make sense, any more than saying, “My car is in green.” Retrograde is an adjective, so Mercury can't be in retrograde, it's just…retrograde. I'll Get Back to You in a Few Weeks Conventional wisdom in astrological circles says that one should never make an important decision during Mercury retrograde. There are also some who say—though there's disagreement on this point—that Mercury retrograde is a bad time to travel, since a breakdown, lost reservation, or other mishap will be harder to deal with away from home. But because of all the other things that can go awry, a great many people become tentative or even paralyzed with apprehension during Mercury retrograde. Whatever can be said of the astrological effect, the psychological impact of the astrologers' claims is strong indeed. So is there anything real to Mercury retrograde? Certainly the astronomical phenomenon as such is not in dispute. Every planet spends some time in a retrograde state relative to Earth during the year, and this is nothing more than a quirk of geometry. But what about the supposed manifestations in daily life? Well, astrologers eagerly point to major world events that occurred during Mercury retrograde periods and purportedly show the hallmarks of its influence. Notably, the 2000 U.S. presidential election—which was without a doubt a profoundly weird case of confusion, delay, and difficulty in making decisions—occurred during Mercury retrograde. There are hundreds of other examples, but it's difficult to evaluate them without carefully comparing them to events that occurred when Mercury was not retrograde. By its very nature, the effect is so subjective that it would be impossible to pin down definitively. Even astrologers allow that Mercury retrograde—or any astrological configuration, for that matter—doesn't cause anything as such; it's rather an indication, a sign, a symbol. The positive spin is that because communication difficulties tend to occur during these times, it's a good opportunity to meditate, to reexamine priorities and projects, to give special consideration to your interactions with others. Nothing that happens is truly the fault of Mercury retrograde; instead, it's an indicator of where your awareness and attention should be. Retro Is In Several years ago, I picked up a book on Mercury retrograde, intending to give it to a friend as a joke. The right situation never presented itself, however, and I ended up keeping the book. One day I thought I'd read a bit just out of curiosity, so I skimmed the first few chapters to get an idea of what sorts of claims were being made. Then I put the book aside and forgot about it. Months later, I experienced a striking number of inexplicable miscommunications, malfunctions, and delays within a period of a few days, and the character of these events reminded me of what I had read. On a whim, I checked the calendar in the back of the book. Sure enough, Mercury was retrograde. I thought that correlation was mildly interesting—a curious coincidence. But a number of months later something very similar happened, and once again, I discovered that Mercury had been retrograde at that time. That, as they say, makes me go “Hmmmm.” I would be the first person to point out that anecdotal evidence of a positive correlation between a spike in miscommunications and a change in apparent planetary motion is hardly a smoking gun. It doesn't prove a cause-and-effect relationship, or even that it's not imaginary. And, to be sure, I've had lots of things go wrong when Mercury was not retrograde, and lots of great experiences while it was. Still, the frequency with which the claimed effects of Mercury retrograde do in fact occur nags at me. I don't know what, if anything, to make of it, but I certainly notice it. There are a lot of people who claim not to believe in astrology but who nevertheless check their horoscopes daily, “just for fun.” Not me; the whole notion of sun-sign horoscopes strikes me as self-evidently absurd, and it feels like an insult to my own intelligence to read that stuff even for its entertainment value. My opinion of horoscopes, like tarot cards, palm reading, and crystal balls, is that they're just like an ink blot test: by themselves they mean nothing, but you can read into them whatever your predispositions suggest. A belief in their predictive power can turn them into self-fulfilling prophecies, proving nothing. Yet having said all that, there's something about Mercury retrograde that gives me pause. I don't plan my life around it and I don't put off important decisions just because it's that time of year. I do, however, tend to slow down and give more thought and care to my plans, and I try to be a little more gracious and understanding when glitches occur. That, at least, is a very positive effect of Mercury retrograde. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/18/Mercury.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/Mercury.aa92ad020000.mp3"
	},
	{
		"title": "Mantle Convection",
		"text": "Many years ago I read an article in which the author jokingly referred to something called the “International Stop Continental Drift Society.” Believe it or not, ISCDS was an actual organization in the early 1980s that produced a tongue-in-cheek newsletter for geologists. If it were still around, I'd join in a second: stopping continental drift, like any number of other futile and pointless endeavors, is a cause I could really get behind. Besides, given the complex subject matter, I'd probably learn a lot more from a humorous article than a dry textbook. In our family, I'm the science guy; my wife tends more toward arts and literature. But she also took a college class that covered plate tectonics, a subject I knew very little about. It gave me a warm feeling in my heart to hear her excitedly talking about continental drift and what happens when the edge of one tectonic plate dives below another one. That's the kind of stuff we should find interesting, especially since we get plenty of firsthand experience with seismic activity here in San Francisco. But one topic from Morgen's class stuck out as being particularly interesting: the theory of mantle convection. Passing the Mantle The mantle is the thick layer of rock below the crust of the earth. It's not quite molten, but it's softer than the crust, and because of the enormous pressure it's under, it behaves almost like a very thick liquid, with the tectonic plates “floating” on top. The big question that has confronted geologists and seismologists since the existence of tectonic plates was postulated is why they move. And the most reasonable theory to explain that at the moment is that the mantle is fluid in a way—though moving extremely slowly. How slowly? Think in terms of hundreds of millions of years for a given portion of the mantle to circulate from its lowest point to its highest point and back. And that appears to be exactly what's happening: an unfathomably slow but powerful circular movement within the mantle. You may be familiar with the term convection to describe water or air currents. The idea is simply that hot portions of a fluid rise, and as they cool, they sink back down. The hot bits going up and the colder bits going down need to stay out of each other's way, so a somewhat circular motion builds up. It isn't perfectly uniform, though; watch a Lava Lamp for a while and you'll see the unpredictable convection currents in action. The theory of mantle convection says that a layer of the earth 1,800 miles (3,000km) thick is doing exactly that: responding to heat from the molten core below, moving upward, then cooling and sinking back down. This movement in turn causes the plates above to shift, accounting for many earthquakes and volcanoes, not to mention the formation of some mountains. Moving Pictures Sci-fi adventures notwithstanding, no one has been able to dig under the crust and explore to find out exactly what's happening down there, but seismological data and computer models give us a fairly good picture of the currents beneath the earth. Not good enough to predict earthquakes—at least not yet—but that problem is analogous to predicting the movement of a piecrust resting on a boiling cherry filling. Tricky, to say the least. What the theory of mantle convection can give us insight into, though, is how and why some features of the planet's topography came to be the way they are. And with time, I'm sure it will lead to a solution to that whole continental drift thing. Or at least a good movie or two. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/18/mantle.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/Mantle.4488514b987d.mp3"
	},
	{
		"title": "Helioseismology",
		"text": "Although in general I have tremendous faith in science, there are a few concepts I've always had some trouble grasping. For example, textbooks have told us for decades—with great certainty—details about the interior of the Earth. We know how thick the crust and mantle are, what the core is made of, and how hot it is (among many other facts), even though no one has managed to dig or drill even halfway through the crust—the thinnest and outermost layer of the planet. How do people figure this stuff out? Yes, I know it's all about earthquakes. When the ground shakes, sensitive instruments all over the world make detailed measurements. By carefully analyzing the way vibrations move from one point to another, scientists are able to infer a great deal about the planet's structure. Although I accept that this is true, the actual physics and mathematics involved are so far beyond me that I can't help harboring a slight doubt. Maybe the core is really made of flubber or, say, chocolate pudding, rather than iron. If I wonder at proclamations about the composition of our own planet, you can imagine how I felt when I read that astronomers are now making claims about the interior of the Sun. Not only that, these claims are based on measurements of sound, which I am reliably informed does not travel through space. After a few minutes of eye rubbing and brow furrowing, I began the long, slow process of trying to wrap my brain around the emerging science of helioseismology, the study of vibrations that occur within the Sun and what they tell us about its interior. Light Music Helioseismology is a branch of the more general science of asteroseismology, which is not limited to our Sun in particular. But as the Sun is conveniently located much closer to Earth than any other star, it gives us the best opportunity for detailed study. Observers have noticed periodic changes in the brightness of the Sun and other stars for centuries, but a more detailed study in 1960 showed that the Sun's surface has a very complex pattern of oscillation. In 1970, astronomer Roger Ulrich theorized that the oscillations were due to sound waves traveling through the interior of the Sun. Further research in the decades that followed has confirmed that hypothesis. How exactly does one observe oscillations on the surface of the Sun? By measuring the Doppler shift of light coming from a given location on the Sun's surface using specially designed spectrometers, astronomers can tell whether that spot is moving inward or outward, and at what rate. This data can be used to create computer models that graphically depict the waves on the surface. And this information, in turn, reveals what's going on under the surface of the Sun. Some people liken helioseismology to a sonogram: using sound waves to “see” inside a body—in this case, a celestial body. In the case of the Sun, the vibrations are affected by temperature, density, and convection, meaning that by studying the patterns of sound waves, astronomers can create surprisingly detailed, dynamic maps of the interior of the Sun—not just its surface. Weather Forecast: Sunny Helioseismology has produced some interesting results. For example, astronomers now know that the Sun contains plasma “rivers” or “jet streams”—massive convection currents that produce what you might think of as solar cyclones thousands of miles below the surface. In addition, the research has shown that the Sun has a number of layers that rotate at different speeds, contributing to the formation of powerful magnetic fields. And helioseismology can even detect sunspots on the far side of the Sun—quite a neat trick if you think about it. All this information can help scientists evaluate theories of stellar evolution. Of more immediate practical concern, helioseismology is the best tool currently available for predicting solar weather patterns. The solar flares and coronal mass ejections that often accompany sunspots can disrupt satellites in Earth's orbit and damage electrical grids. The more we know about the timing and location of these events, the better we can prepare and adapt. The moral of the story? Although you should never look at the Sun, you should always listen to it. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/18/Helioseismology.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/Helioseismology.cc5054c788b7.mp3"
	},
	{
		"title": "White LEDs",
		"text": "Thirty years ago, the most interesting thing I knew of was the digital watch. Never mind that digital watches were harder to read than analog watches, that they went through a set of batteries every few weeks, that they cost a small fortune. These things were not important. What was important was cutting-edge style. You could now wear a computerized device on your wrist that, at the press of a button, would display the time in glowing red LED numerals! How cool was that? When my dad got his first digital watch—a huge, clunky thing—I was deeply envious that he had the best toy in the house. Just a few years later, though, digital watches had moved into the mainstream. I distinctly remember, as a nine-year-old in 1976, saving my allowance to buy my very own $20 digital watch. I was the first kid in my school to have one, the envy of all my friends. (Yes, my geek roots go way back.) It would be a few years yet before liquid-crystal displays (LCDs) became common; in the meantime, I was thrilled to have a status symbol courtesy of LEDs. Since their commercial introduction in the 1960s, LEDs (light-emitting diodes) have become common components of every imaginable household product. Your phone, TV, answering machine, clock, and possibly even your kids' shoes have LEDs in them. LEDs are popular largely because they're inexpensive and use very little electricity. Compared to ordinary incandescent bulbs, LEDs also produce less heat, last many times longer, and are less sensitive to shock and changes in temperature. These are all wonderful attributes, but until relatively recently, there was one major limitation: color. Your choices were limited to red, amber, and green; anything further along the spectrum just didn't exist. The invention of the blue LED was groundbreaking, but the white LED that soon followed was cooler by an order of magnitude. A Little Light Science To understand why white LEDs are so cool, you need to know a little bit about the technology behind LEDs generally. A diode is a very simple semiconductor device that allows electricity to flow in just one direction. If you apply current in that direction (called forward-biasing), the diode produces light as a side effect. For ordinary diodes, that light is infrared, invisible to the naked eye. By varying the materials used in the diodes, scientists were able to produce diodes that made visible light—red at first, and later, other colors. The physics behind LEDs dictates that whatever light is produced is of a single wavelength (that is, a single color). But for a long time, nobody could figure out how to make colors with shorter wavelengths than green—at least, not at any reasonable level of brightness. Among the people trying to solve the blue LED problem was Shuji Nakamura, a researcher at Nichia Chemical Industries in Japan. Nakamura thought he had determined just the right type of material (indium gallium nitride, if you care) to use for blue LEDs. The problem was that the existing manufacturing processes did not produce material of sufficient quality. So he had to invent a new process as well. In 1993, after years of research, Nakamura finally produced the first commercially viable blue LEDs. Now with Extra Whiteners This achievement alone would have earned Nakamura a place in electronics history. But the real genius was in his next step. He applied a special type of phosphorescent coating to a blue LED. The blue light excited the molecules in the coating—much like the way a fluorescent lamp works—and produced bright white light. So white LEDs are actually a clever spin-off of blue LEDs, and without Nakamura's insights, neither would have been possible. A white LED is brighter than a comparably sized, conventional incandescent bulb. However, it's not as bright as a high-output Krypton or Xenon bulb, such as you'll find in fancy flashlights. In addition, white LEDs cannot be made arbitrarily large, as incandescent bulbs can. So if you want to replace the bulb in your Mag-Lite or kitchen light fixture, you must use a cluster of LEDs. A good LED flashlight will typically have three or more bulbs; for residential lighting, much larger clusters are used—for example, a 36-LED fixture will replace a 30-watt bulb; to replace a 90-watt bulb would require over 100 LEDs. Apart from the issue of sheer luminosity, an important reason for using LED clusters is the pattern of light they produce. With incandescent bulbs, the light is omnidirectional, which is why flashlights and lamps usually have reflectors to concentrate the light in a certain direction. LEDs, because of their built-in lenses, produce much more directional light. This can be either a blessing or a curse, depending your needs. If you want to create a “Walk” sign at an intersection, an array of white LEDs will give you just what you're looking for: bright light with a fairly narrow viewing angle. If you want to illuminate a room, however, that directionality is a problem. LED fixtures that need to disperse light more broadly rely on a combination of varying angles for individual LEDs and light-diffusing coverings. The Price Is White Although red and amber LEDs can be purchased for just a few cents each in volume, blue LEDs, which are harder to manufacture, typically cost about ten times as much, and white LEDs are more expensive still. You might imagine that a 100-LED fixture to replace your hall light would be quite costly, and you'd be right: at current prices, that sort of light will run you well over US$500. Of course, over its lifetime, which will probably be decades, you will save quite a bit of money in both electricity and replacement bulbs. This is precisely why they are attractive to municipal governments, which are rushing to replace conventional bulbs in traffic lights (and in some cases streetlights) with LEDs. Until economies of scale bring white LED prices down to more reasonable levels, their biggest appeal for ordinary consumers will be in products such as flashlights, bike lights, and headlamps used for caving. It's in applications like these that the LEDs' low power consumption makes a profound difference. A Krypton flashlight might run for three hours on a set of alkaline batteries, compared to thirty or more for a flashlight using white LEDs. The extra convenience, not to mention the cost savings, can be enormous. This Little Light of Mine A bit of additional circuitry can extend the life of LED-based products even further. For example, I bought a white LED flashlight called an EternaLight. It has a built-in microprocessor that flashes the LEDs very rapidly—so fast that the human eye cannot detect it. Because the LEDs only use power when they're actually on, this technique stretches the battery life to as much as 700 hours—you could leave the flashlight on for a full month. After about three years of frequent intermittent use, I decided to change the batteries simply on principle because I was going on a trip, but for all I know they could have lasted another three years. There are many reasons to like white LEDs, but for me, the sheer cleverness of the idea tickles my fancy. The novelty has already worn off, but I'll always be impressed by the creativity and hard work that made them possible. And when some pseudo-retro designer gets the idea to make a white LED digital watch, I'll be first in line to buy one. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/18/LED.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/White_LED.2835f2cbc97f.mp3"
	},
	{
		"title": "Red Tide",
		"text": "In the mid-1990s, I was living in San Diego. Because the place where I worked was near the ocean, barely a day went by when I didn't walk along the beach or at least drive by it. One day, something looked a bit different—the water, normally greenish, had taken on a bit of a red hue. I heard a few people talking in passing about something called a “red tide,” as though it were a common occurrence that anyone who had lived there for more than a few months should be familiar with. It didn't sound like anything I should be either worried about or especially interested in—just some random marine phenomenon, the details of which I was content not to know. Light Waves But driving home from work late that night I glanced at the waves breaking on the beach again and did a double take. I could have sworn I saw light coming from the water. Maybe it was just a reflection of the moon, I thought, or someone playing with a flashlight. I kept looking, and every few seconds I saw another glow of greenish light that lasted for just a second or two and then faded away. I pulled over and walked down to the water to take a closer look. Sure enough, every time the waves broke, the leading edge of the wave emitted a faint green glow. I stood there and stared at the water for the longest time—I thought it was one of the strangest and most beautiful things I'd ever seen. Later I asked around about the glowing water and someone said, “Oh yeah, the red tide. It's caused by a phosphorescent plankton.” Glowing organisms were familiar enough; where I grew up—far from the ocean—fireflies were common. But though I never thought twice about seeing a sparkling field or lawn at night, glowing water seemed incredibly foreign and exotic. Years later, though, living in British Columbia, I sometimes saw warnings against collecting bivalve mollusks (such as oysters, clams, and mussels) due to something that was also called a “red tide”—but never a mention of glowing waters. Was the phenomenon that had entranced me years earlier in southern California actually a toxic danger? The Tide Turns The answer turns out to be somewhat complicated. First the easy part: the red color of the water in a red tide is indeed caused by a type of plankton, specifically one of quite a few species of dinoflagellates, single-celled organisms that have characteristics of both plants and animals. Dinoflagellates, like other phytoplankton, create their own food through photosynthesis, a plantlike behavior. However, they don't have roots, stems, leaves, or seeds, and they do have the ability to move (thanks to a pair of hairlike appendages called flagella)—thus making them more like animals. Although the dinoflagellates are often found in ocean water in very small quantities, sometimes the conditions of heat, sunlight, salinity, water currents, and so on are just right, and the organisms multiply extremely rapidly, creating a reddish or brownish algae bloom. All dinoflagellates are not created equal. The variety that causes the glowing waters in California is Noctiluca scintillans, which by itself is relatively harmless. However, it often appears together with the less colorful but more toxic Gonyaulax catenella. The latter, along with other non-bioluminescent species of dinoflagellates such as Gonyaulax tamarenis (which appears in the Atlantic Northeast) and Karenia brevis (which appears in the Gulf of Mexico), are responsible for the dire warnings; they produce toxins that can cause illness or death if consumed. Red tides not only make shellfish unsafe for humans, they kill fish, manatees, dolphins, and other marine life. Because of the negative impact of red tides (at least in some areas), research is underway to determine the exact conditions that cause them and what can be done to prevent or destroy the blooms—or at least reduce their toxic effects. I'm all for protecting marine life, but I'd be sorry to see the disappearance of Noctiluca scintillans. I'd gladly give up shellfish for a few weeks to experience another evening of glowing waves. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/18/Red-Tide.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/18/Red_Tide.108562f33af2.mp3"
	},
	{
		"title": "Traveler's Palms",
		"text": "One of the reasons I like to travel is to be reminded how interesting seemingly ordinary things can be. On a trip to Costa Rica last year, I had many such opportunities. Just walking into a local market made my eyes widen when I saw Tang in no fewer than eight flavors (Lime, Mango, Apple, Peach, Mandarin, Pineapple, and Strawberry—in addition to the original Orange). To someone who sees this selection every day, it would seem completely normal, but to me the thought of Mango Tang was exotic and exciting. Most of the interesting things I found in Costa Rica, however, were natural ones. In the middle of a long drive from San Jose to the Caribbean town of Puerto Viejo, our group stopped at a restaurant for lunch. In front of the building, just a stone's throw from the edge of the rain forest, was a tall plant that caught my eye. It looked exactly like a fan, with each of its long branches terminating in a single broad leaf. Not only was it nearly two-dimensional, it was completely symmetrical. It looked so perfect I wasn't sure it was real. Our guide told us it was called a Traveler's Palm. A Tall Drink of Water Later, while visiting a botanical garden, a botanist shared some fascinating details about this striking plant. For starters, the Traveler's Palm (sometimes called Traveler's Tree) is not really a palm at all, although the trunk gives it that appearance. It's closely related to bananas (as you might guess from the shape of the leaves) and in the same family as the Bird-of-Paradise Flower. It gets its name from two distinctive characteristics. First, the leaves collect water and channel it into the base of the plant, so a thirsty traveler could cut a hole in the soft trunk and get a significant amount of drinkable water—about one liter per branch. Second, Traveler's Palms tend to grow in an east-west direction, with each new branch turning either toward or away from the sun. So it can also serve as a sort of compass, to put you back on track after quenching your thirst. The Traveler's Palm, which goes by the scientific name Ravenala madagascariensis, is native to Madagascar, but can be found in tropical and subtropical regions all over the world. If you live in an area with the right climate and enough space, you can even grow your own. Its major requirements are sunshine, water, and protection from freezing and high winds. The trees can grow to be as tall as 60 feet (18.3m), so they'll be much happier outside than inside. Open Your Palm and Make a Wish A few Web sites claim that there is a saying, “If you stand directly in front of a Traveler's Palm and make a wish in good spirit, it will come true.” As far as I can tell, that saying exists only on the Web—I haven't been able to locate evidence that this is a genuine part of any culture's folklore. On the other hand, a small biotech company called Shaman Pharmaceuticals investigated substances produced by Traveler's Palm as a potential treatment for adult-onset diabetes, with very promising preliminary results. That would certainly be a wish come true for many people. Unfortunately, the company has now gone out of business, and as far as I know, no one has yet picked up where their research left off. Whether or not Traveler's Palms can grant wishes or stabilize your blood glucose level, they are beautiful plants with extremely useful yet hidden properties. Explorers who have lost their way in the rain forest may like to look at a Traveler's Palm and think of the spreading fan shape saying, “West is this way.” I like to think of the branches as forming an arrow pointing inward and saying, “Interesting things inside.” —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/17/palm.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/17/Travelers.52112ee6c4af.mp3"
	},
	{
		"title": "Oil Sands ",
		"text": "For the last few years, I've led a blissfully car-free (though not carefree) life. I've been vaguely aware that the price of gasoline has gone up quite a bit, but not having to buy it myself, I haven't felt much of a personal impact. I am, however, keenly aware of the many lives lost in the name of oil, not to mention the environmental problems to which it contributes—air and water pollution, global warming, and so on. And oil is destined to become more expensive still as the planet's finite reserves are depleted. Call me naïve, but it seems to me that any reasonable person would have to conclude we should all do whatever we can to reduce our need for, and use of, the stuff. So when I learn about yet another potential source of oil that could keep our cars running a few more decades, I must confess my first thought is not, “Great! Less dependence on foreign oil!” Instead, I'm thinking, “Drat! Another blow to solar and wind power, another step backward environmentally.” That rather large disclaimer aside, I do find one particular source of oil increasingly interesting, not least because obtaining the oil requires some impressive feats of engineering. I'm referring to the vast amount of tar-impregnated sand in the Canadian province of Alberta, which some experts are hailing as the world's largest and most important oil reserve. A Sticky Situation The first of many problems with this stuff is what to call it. In Canada, the term oil sands is most often used to describe the deposits, while in the U.S. they are more commonly known as tar sands—a bit of a misnomer since technically, tar is an artificially manufactured product. In any case, it's a thick, sticky, and smelly mixture of clay, sand, water, and bitumen—a naturally occurring mixture of liquid hydrocarbons, or crude oil. Once separated from the sand and minerals, the crude oil is sometimes referred to as heavy oil, though that term is often used interchangeably with “oil sands” or “tar sands” as well. Where did the oil sands come from? The sand itself was undoubtedly deposited by ancient rivers. As for the oil, the prevailing theory is that it began as a lighter oil that formed deep underground some distance away and was pushed by geologic pressure to its current location. After being absorbed into the sand, it gradually thickened due to bacterial action. The sheer quantity of oil sands in Alberta is staggering: the equivalent of an estimated 1.6 trillion barrels of oil, of which at least 300 billion barrels are recoverable—considerably more than in, say, Saudi Arabia. But getting the oil from the ground to your car is a mammoth undertaking. Because the oil sands contain less than 20% bitumen, it takes about two tons of oil sand to yield one barrel of oil. And this oil doesn't squirt out of the ground for your convenience. Oil and Water Most of the oil sands are not on or near the surface of the ground; workers must sometimes dig 200 feet (61m) or more to reach the deposits. Because the oil sand is both heavy and sticky, even more effort is required to bring it to the surface. Furthermore, extracting the oil from the sandy mixture is no mean feat. Because the tarry substance is much too viscous to flow through pipes, it has to be shoveled out and carted away in gigantic dump trucks. Before it can be used, the bitumen must be separated from the sand. There are several techniques to achieve this, but all of them involve large quantities of water and elaborate equipment. To oversimplify somewhat, oil companies blend the oil sand with water, and sometimes solvents, until the mixture becomes thin enough that the sand and the bitumen can separate (sometimes with the help of a centrifuge). The reliance on water makes the process all the more challenging in winter, when temperatures of –40° (C/F) in Alberta are not uncommon. Once the sand and water are removed, the bitumen must be processed further under high heat to remove impurities and break it down into a more useful and smoother-flowing oil. Even then, it must go through multiple refinement stages to become fuel. Given all the time, effort, and equipment needed to recover usable oil from oil sands, the cost of production is quite high—about three times that of drilling for oil. However, this is a tremendous improvement over the situation a few decades ago, when production costs far outweighed the value of the oil recovered. Improvements in technology are slowly but steadily making the process even more cost-effective. One technique, for example, involves forcing steam into a deep well to melt the bitumen so that it will flow to the surface—without the sand. Besides reducing transportation and refining expenses, steam extraction also provides access to bitumen that's too deep for conventional mining. Slippery Slope As challenging as it is to extract oil from oil sands, Alberta is already producing upwards of 600,000 barrels a day, a figure that's likely to triple within a decade. Oil sand deposits in several other parts of the world—notably Venezuela—are being exploited with equal success. And yet, even as output increases and costs decrease, other problems loom large. Most conspicuously, the mining operations are often devastating to the landscape and vegetation. The separation and refining process requires a great deal of heat, which usually comes from natural gas—consuming one natural resource to get access to another. And the equipment used to extract and process the oil sands also creates a significant amount of air pollution. Still, if I were the type of person who invested in new methods of energy production, I'd bet heavily on oil sands to make a fortune in a few years. Then just think how much solar energy research I could fund! —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/17/OilSands.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/17/Oil_Sands.91b6cf016ea7.mp3"
	},
	{
		"title": "Microclimates",
		"text": "BaliI have lived in many different parts of North America, but for the past decade or so, all of the places I’ve lived have been on the west coast, no more than a few miles from the ocean. There are many things to like about the west coast, but I’m especially fond of the weather. Each city has its specialty—San Diego is famous for sun, San Francisco for fog, and Vancouver for rain. But what this entire strip of land has in common is a relatively temperate climate year-round. Summers are rarely hot, and snow is almost unheard of. Some of my friends complain about the lack of seasonal variation, but not me. I figure, I can go and visit the snow or the sun for a week or two every year if I really miss it—and that’s enough for me. Besides, we do have seasons, just not the same kinds of seasons as the rest of the continent. Here in San Francisco, the months of June through August are usually cool, especially near the ocean; the hottest month is October. Tourists invariably get this wrong, shivering in shorts in the summer and sweating in the fall. But our generally mild climate has another interesting twist that makes it difficult for me to give a meaningful answer when someone from another part of the world asks me how the weather is. Artificial and Natural Diversity San Francisco is not a large city. Located on the tip of a peninsula with the Pacific Ocean on the west and the San Francisco Bay on the east, the city is only about 7 miles (11.3km) square. The famously steep hills contribute to an illusion of greater size—as if what the city lacks in width, it makes up for in height. Although it is nicely compact, San Francisco is composed of numerous distinct neighborhoods that are often profoundly different from each other in terms of architecture, culture, ethnicity, and overall demographics. Chinatown, for example, is just steps away from North Beach (our version of Little Italy), yet the local vibes of the two areas could not be more different. But as you move around San Francisco, you may notice something even more striking than the varying neighborhoods: major shifts in weather. San Francisco is often held out as a textbook example of microclimates. A microclimate is a weather pattern that’s localized in a small area and different in some significant way from the weather of nearby areas. The variation can be one of temperature, humidity, rainfall, wind, or any combination of these. For example, there are parts of San Francisco that barely see the sun all summer long; along the coast, especially, it’s frequently cold, foggy, and windy. In other parts of the city, though, fog is virtually unknown; it may be sunny and 10 or even 20 degrees hotter than spots just a mile or two away. In all, there are about 30 well-defined microclimate regions within the city, and even more when you travel slightly farther away. When I was commuting to work just south of the city, I often drove out of rain and into sunshine or vice-versa, but nearly always found the southern parts of the peninsula much warmer than San Francisco. You Don’t Need a Weather Man to Know Which Way the Wind Blows There are many reasons for microclimates, but they all boil down to three main causes: water, hills, and concrete. Large bodies of water affect the climate both by increasing the humidity and by stabilizing the temperature in the immediate area. But even small ponds or pools, in the right location, can have a noticeable effect on the climate. This is especially true if there are large hills nearby. Hills block wind and redirect air currents, holding in both moisture and pockets of cool air. (This is also why temperate rain forests are able to thrive even when the greater region in which they’re located is too dry.) The concept of “city heat,” too, is well known; large expanses of concrete and stone absorb heat in the day and release it at night, making the average temperature in a city warmer than in adjacent areas. All these factors in combination with the area’s patterns of topography and vegetation contribute to the formation of microclimates. Although San Francisco’s microclimates are numerous and conspicuous, the phenomenon is by no means unique to this area—it occurs, to varying extents, just about everywhere there are hills, large bodies of water, or other topographical features that can influence temperature and humidity. Depending on your point of view, they can be a curiosity, an aggravation, or a blessing. Weather forecasts for San Francisco are often misleading if not meaningless, because there’s so much variation throughout the city. On the other hand, in some areas microclimates make it possible to grow certain plants that could not survive just a few blocks away. San Francisco’s microclimates don’t reach the extremes of seasonal variation in the northeast part of the country, so I still have to drive or fly if I need a real season fix. But as long as I don’t feel the need to shovel snow or rake leaves, nearly any weather I could want is just minutes away. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/17/Jungle.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/17/Microclimates.f22d622bf6e3.mp3"
	},
	{
		"title": "Nyepi",
		"text": "It’s a familiar scene to most of us: high noon in a deserted town, the streets empty of people and vehicles, with only the low buzz of insects and faint birdsong breaking the silence. If this were a John Wayne movie, the hero would turn to his companions and quip “It’s quiet—too quiet,” suggesting that the unnatural absence of noise and activity may bode ill for him and his posse. While my introverted nature takes exception to the thought of a situation being “too quiet,” it is unusual to actually find myself in the middle of such an environment. However, there is one place, on one day, where it is perfectly normal for everyone to experience this absence of noise and activity. Known as Nyepi, the celebration of the new year in Bali, Indonesia is a day during which the entire island shuts down, retreats indoors, and maintains almost absolute silence. Saka to Me Nyepi is the first day of the Saka calendar, a twelve-month lunar cycle that usually begins in March or April, around the time of the vernal equinox. (In 2007, Nyepi falls on March 19.) The Saka calendar originated in South India in A.D. 78, and was brought to Indonesia around A.D. 465; it is therefore offset by roughly 78 years from the Gregorian calendar (2007 marks the beginning of Saka year 1929). Bali also uses the Gregorian calendar for business and government purposes, as well as the Pawukon calendar, a 210-day system introduced from the island of Java in the 14th century, which determines the proper days for religious rituals to take place. Whenever the new year is celebrated, most cultures see the changing of the year as a chance to let go of the past and to move forward with renewed energy and optimism, as is the case with making New Year’s resolutions. (For more examples of New Year’s rituals, see Eight New Year’s Rituals from Around the World on SenseList.) It is no different in Bali, where the Hindu symbolism of Nyepi lies in the act of spiritual cleansing, both of the self and of the outer world. As part of this, in the three days leading up to Nyepi, the Balinese observe Melasti, a time when sacred objects and effigies are brought to local rivers to be ritually cleansed. The day immediately before Nyepi, known as Tawur Kesanga, has more of a Mardi Gras-like atmosphere, with revelry sometimes lasting well into the night. However, all revelry stops before sunrise, when Nyepi begins. Bali Hide Observed from 6 a.m. until 6 a.m. the next morning, Nyepi is a day reserved for self-reflection and as such, anything that might interfere with that purpose is restricted. The main restrictions are: no lighting fires (and lights must be kept low); no working; no entertainment or pleasure; no traveling; and for some, no talking or eating at all. The effect of these prohibitions is that Bali’s usually bustling streets and roads are empty, there is little or no noise from TVs and radios, and few signs of activity are seen even inside homes. The only people to be seen outdoors are the Pecalangs, traditional security men who patrol the streets to ensure the prohibitions are being followed. Although Nyepi is primarily a Hindu holiday, non-Hindu residents of Bali observe the day of silence as well, out of respect for their fellow citizens. Even tourists are not exempt; although free to do as they wish inside their hotels, no one is allowed onto the beaches or streets, and the only airport in Bali remains closed for the entire day. The only exceptions granted are for emergency vehicles carrying those with life-threatening conditions and women about to give birth. On the day after Nyepi, known as Ngembak Geni, social activity picks up again quickly, as families and friends gather to ask forgiveness from one another, and to perform certain religious rituals together. Quiet Riot Although we do have celebratory gatherings with friends and family to mark the New Year in North America, in every other way Nyepi stands in stark contrast to our own rituals. Instead of silence and inactivity, the sounds of loud music, cheering, horns blowing, and friendly chatter more closely describe our typical New Year’s Eve experience. Being interested in quieter pursuits, I am drawn to the type of New Year’s celebration that involves more periods of silence and reflection, and fewer moments of drunken gaiety. I’m sure there are others out there like me, people who would rather sit and talk quietly, perhaps over a glass of wine, with other like-minded individuals. And when midnight rolls around, you’ll know who we are; we’ll be the ones off to the side, standing perfectly still and observing a celebratory moment of silence. —Morgen Jahnke ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/17/Bali.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/17/Nyepi.a70a41af6bcf.mp3"
	},
	{
		"title": "Zeno's Paradoxes",
		"text": "Do you ever have one of those days when you just can’t seem to get yourself moving? Or maybe, no matter how hard you try to get caught up, you always seem to lag behind? I have those kinds of days all the time—and so, apparently, did ancient Greek philosophers. One of them, Zeno of Elea, devised an ingenious set of philosophical statements that amount to “proof” that motion is impossible, despite all evidence to the contrary. These statements are known as Zeno’s Paradoxes (or sometimes, collectively, as Zeno’s Paradox), and they continue to vex philosophers to this day. I first became aware of Zeno and his ideas while working on my undergraduate degree in philosophy. I was reading Douglas Hofstadter’s Pulitzer-winning Gödel, Escher, Bach: an Eternal Golden Braid, in which philosophical issues are frequently presented in hypothetical dialogs between Achilles, the Greek warrior legendary for his swiftness, and a Tortoise. Lewis Carroll had used the same pair of characters, but it was Zeno who first put them together—in the fifth century B.C. In Hofstadter’s retelling of the story, Zeno himself makes a guest appearance in order to explain to Achilles and the Tortoise that motion is not merely impossible, it “unexists.” The story is based on one of Zeno’s eight so-called paradoxes, of which only three or four are usually mentioned. Allow me to give you a very brief taste. Achilles and the Tortoise: Imagine that Achilles meets a Tortoise, who challenges him to a foot race. Achilles is amused when the Tortoise asks merely for a modest head start. But then the Tortoise explains that by agreeing to this demand, Achilles has already lost! The logic, says the Tortoise, is that if he starts ahead of Achilles at point A, Achilles will have to run to point A before he can overtake the Tortoise (which is, of course, obvious enough). Meanwhile, the Tortoise will have moved ahead slightly to point B. Again, Achilles must advance to point B before he can push ahead, by which time the Tortoise will have traveled farther (if only by inches), to point C. And so on. Although with each successive point in the race the Tortoise moves smaller and smaller distances, Achilles never quite catches up, always remaining one segment behind. And thus, says Zeno, the faster can never overtake the slower. The Dichotomy: Another variation on the same theme is called the “dichotomy paradox” (or sometimes the “bisection paradox” or “race course paradox”). Suppose you want to cross a room. In order to get to the other side, you must first get to the halfway point, which will take you some finite amount of time. And before you can get halfway, you have to cross half of that distance, at which point you’d be a quarter of the way across. And before that, you’d have to cross half of a quarter, and so on infinitely. Each of these steps must take a finite amount of time. And yet, you have to cross an infinite number of distances to walk across the room—or indeed any distance at all. And since one cannot travel an infinite number of distances in a finite period of time, motion itself is impossible. The Arrow: Just when you think motion is completely done for, Zeno makes matters even worse. Think of an arrow in motion, he says. At any particular instant during its flight, the arrow occupies just one position in space, which is how we define an object that’s at rest. So the arrow must, at that point, be at rest. At the next instant, whatever position the arrow is in, it’s also in just one spot, and thus, still at rest. Therefore, by definition, anything in motion is actually at rest! Now, I know what you’re thinking: this is all very silly. A logical “proof” does not mean that motion is impossible, and whatever Zeno may have conjectured about such things at the office, he still certainly walked home at the end of the day. That is true. And yet, at some level, you have to admit that he does have a point, of sorts. Trying to tease apart Zeno’s logic from common sense has occupied a great many philosophers and mathematicians over the centuries. And if you’re willing to wrap your head around a bit of calculus, you can find some rather definitive mathematical explanations for why we can move after all. But that, say some people, is missing the whole point. In the first place, there are philosophers who deny that these little stories are truly paradoxes. For example, it’s true that one can, in principle, divide a finite distance into an infinite number of points, but so what? They still add up to a finite distance. Meanwhile, the same is true of time: you can subdivide hours, minutes, seconds, and so on as much as you want, but that doesn’t make time grind to a halt. Both motion and time are, in reality, continuous. So if you don’t believe in the fiction that motion must occur in discrete steps of both distance and time, there’s no paradox at all. That, say critics, takes care of at least the first two statements; as for the arrow…you can define motion as a state that exists over successive points in time, which would mean Zeno’s idea of “rest” is fundamentally mistaken. However, it may be that all the effort to debunk the paradoxes is misguided; by themselves, they’re nothing more than intellectual exercises that Zeno himself may not even have believed. Zeno, who lived from roughly 490 B.C. to 430 B.C., was a student of Parmenides, founder of a group of thinkers known as the Eleatics. Parmenides believed that the universe is fundamentally unchanging. Since everything is ultimately one, any motion or change must be merely an illusion. Although Zeno’s statements can be taken as defending Parmenides at face value, their intention was to do so in a more subtle way, using a logical technique known as reductio ad absurdum—reduction to the absurd—also known as proof by contradiction. In other words, if a logical argument yields an absurd conclusion, one of its premises must be wrong. So it’s not that Zeno believed motion in the everyday sense was impossible; he was trying to demonstrate, by way of these absurd stories, that time and distance are in fact not divisible—and in that way, support the claim that the universe is an unchanging whole. Ultimately, though, no one will ever know for sure exactly what Zeno was getting at, because none of his writings survived. We know about Zeno only because later philosophers, such as Plato and Aristotle, mentioned his writings in their own works—and not, I should point out, in a very complimentary way. Although some philosophers still aren’t convinced that the paradoxes are resolved, most people believe now, as in Aristotle’s time, that Zeno was too clever for his own good. And personally, I just don’t find his stories moving. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/17/paradox.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/17/Zeno.ab06b037f7e2.mp3"
	},
	{
		"title": "Voodoo",
		"text": "On my first walking tour of New Orleans, our guide promised us chilling stories of ghosts, vampires, pirates, horrific murders, and all the other dark elements of the city's past—some real, some fictional. And as if to show that these dark forces were still alive and well, he said that our very last stop would be a genuine, functioning Voodoo temple. At that point, everything I knew about Voodoo had come from bad films and TV shows. I gathered that it had something to do with black magic, curses, and sticking pins in dolls. So a chance to meet real Voodoo practitioners seemed a bit exciting and a bit scary. To Grandmother's House We Go When we finally got to the temple, it was a bit anticlimactic. The building was just a converted house, the rooms were bright and cheery, and there wasn't the remotest suggestion of any evil undercurrents. Yes, there was the smell of incense in the air; yes, there were a bunch of altars piled high with offerings and candles; and yes, there were a lot of unusual images on the walls. But then, the same could be true of a Buddhist temple. Wasn't Voodoo supposed to be, like, wackier? Then we met the resident clergy, Priestess Miriam. In retrospect, the Voodoo priestess reminds me of the Oracle in the Matrix films—friendly, down-to-earth, maybe even grandmotherly, and not what I was expecting. She gave a short talk and answered all our questions. Her mild manner and warm smile seemed to say, “Sorry if you were expecting animal sacrifices and gibberish. I get that a lot.” Most educated westerners are familiar with the world's major monotheistic religions, at least in broad strokes. But Voodoo holds a much different place in the public awareness, because sensationalized fictional accounts of Voodoo practices are so common. Even the word “Voodoo” has become slang for “scary,” “silly,” or “nonsensical.” Unfortunately, what books and films say about Voodoo is mostly misleading if not downright false. Zombies, devil worship, and human sacrifices all make for a scary story, but they have nothing to do with Voodoo as practiced by 60 million people worldwide. Voo Who? The term “Voodoo” is an unfortunate Americanization of a word that originally was more like “vodu”; alternate spellings, each of which is championed by one group or another, include Vodun, Vodoun, Voudou, Vaudoun, Vodou, Voudoun, and probably quite a few more. The religion as practiced in Haiti, where it has the largest number of adherents, is usually spelled “Vodou” (pronounced “vo-DOO”). Voodoo (under one name or another) is practiced in several Caribbean countries and is the official religion of Benin in western Africa, but also has a large following in the United States. New Orleans seems to have earned a reputation as the unofficial Voodoo capital of America. Far from being a set of evil practices, Voodoo is actually a complex religion with a rich set of beliefs and rituals. Although there are many different varieties of Voodoo (comparable, perhaps, to the variety of Christian churches), they share in common a belief in a single God, called Bondye (from the French Bon Dieu, “good God”). This God is, however, remote and normally inaccessible, so interaction with the spirit world is generally by way of contact with lesser spirits called Lwa (or Loa), pronounced “l'wah.” The Lwa, of which there are many, are often referred to as a “pantheon,” but that term is a misnomer because Voodoo practitioners think of the Lwa as more like saints than gods. In any case, the spiritual business of Voodoo—healings, prophecies, blessings, prayers, and so on—requires contact with the Lwa, who often possess or “mount” worshippers during ecstatic rituals. Another central tenet of Voodoo is veneration of one's ancestors. Their spirits are believed to influence one's life, so proper respect and sacrifices (of food, generally) are seen as important to stay in their good graces. The Beat of a Different Drummer Rituals play a large part in the practice of Voodoo; most are presided over by a priest or priestess in a local temple. Drumming, singing, and dancing are almost invariably part of Voodoo rituals, and in the versions of Voodoo practiced in some areas, animal sacrifices do occur regularly to appease the Lwa. But the main focus of Voodoo rituals is on positive desires such as healing, prosperity, and protection. As in any religion, most practitioners seek a harmonious relationship with other people as well as with the forces of the unseen world. But as is also true of other religions, there are smaller, more extreme groups of believers who practice a darker and more violent version of Voodoo. Even that version doesn't quite live up to the Hollywood picture, though. And what about the infamous Voodoo dolls? They do exist—but mainly as souvenirs for tourists. There are some Voodoo practitioners, particularly in the southern United States, who use Voodoo dolls in their rituals, but generally the idea is not to make an enemy cry out in pain by sticking a needle in a doll's eye. Rather, the dolls are used as a symbolic proxy for attracting good things and dispelling bad things from one's life—your own or someone else's. Animism Meets Catholicism Voodoo as a modern religion evolved in the second half of the 18th century in Haiti. Yoruba slaves from West Africa developed a system of religious practice based on animistic beliefs that can be traced back thousands of years. But in the 19th century, a series of crackdowns by the Catholic church drove Voodoo underground. Since Voodoo could not be practiced openly without serious repercussions, worshippers began to associate Catholic saints with Voodoo Lwa. In other words, while they appeared to be praying to, say, St. Patrick, they were really just calling the snake Lwa Dumballah by another name. There is some disagreement as to whether this mapping amounts to syncretism; it's not so much an absorption of Catholic beliefs as an openness to alternative terminology. Nevertheless, distinctive ritual elements of Catholicism and various African religions are easily found in Voodoo—particularly in the variety practiced in the southern United States. And in Haiti, despite the fact that Voodoo is no longer outlawed, a large percentage of the population practices both Catholicism and Voodoo with equal earnestness, and without feeling there's any tension between the two belief systems. Voodoo doesn't fit neatly into the categories of modern religions. It doesn't have a bible or other set of universal codes. It gives the appearance, at least, of mixing and matching elements from other religions. And it has, let's face it, a funny-sounding name. But when you get right down to it, Voodoo beliefs are no more (or less) wacky than those of any other religion. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/17/124.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/17/Voodoo.3387887b42e9.mp3"
	},
	{
		"title": "Phenomenology",
		"text": "About halfway through college, I decided I was going to major in philosophy. I was one of only four or five philosophy majors in my class, and most of my friends simply couldn't comprehend why I chose such a field. For one thing, philosophy was obviously the most boring subject in the world, and for another, there didn't seem to be anything you could do with a degree in philosophy. My classmates would say things like, “I'm majoring in psychology, which means I can become a psychologist. I can have an office and an ad in the yellow pages and people will pay to come talk to me. But there aren't any philosophers in the yellow pages—look it up. How do you expect to earn a living as a philosopher?” I had no good answer to that question. I didn't think I wanted to teach philosophy, which is the usual way philosophers make money. But I wasn't worried about long-term career options or marketability. All I knew was that of all the subjects I'd studied in the past two years, philosophy was the only one that interested me enough to take seriously. It seemed important in a way that, say, history or even science did not—it was a search for answers to the Big Questions: Is there a God? What is the nature of existence? What does it mean to be human? How do we determine right and wrong? I couldn't imagine wasting my time on lesser questions. It was not long, of course, before we began talking about Descartes, who in the early 17th century famously said, “I think, therefore I am.” This was not an idle comment; Descartes was looking for a starting point for his philosophical inquiries, some basic principle that, no matter what, could not be doubted. He decided to start by tossing out any belief that could conceivably—even under the unlikeliest conditions—be doubted. For Descartes, it was impossible to doubt his own existence. One could be mistaken about the interpretation of sensory data, but not, he felt, about the experience of thinking. Putting Descartes Before da Husserl (sorry) Descartes has been extremely influential in the study of philosophy ever since, and though he has as many detractors as fans, there has never been a satisfactory resolution to that seed of doubt he planted: Just what sorts of information can we trust? People frequently believe things that are not true, for any number of reasons. One of the tasks of philosophy is to figure out what kinds of things exist out there in the world. But is that even knowable? Can we trust our senses to give us an accurate representation of the world—especially when we all know that scientific facts often contradict the common-sense interpretations of our experience? Almost three centuries later, in the early 1900s, a German philosopher named Edmund Husserl found himself worrying about just these kinds of questions. He felt that a lot of philosophy was entirely too subjective, that philosophers took too much for granted about the way the world works. Husserl began developing a method of philosophical inquiry that would be immune to the hermeneutical baggage that prevented true objectivity. In his 1913 book Ideas Pertaining to a Pure Phenomenology and to a Phenomenological Philosophy he first used the word phenomenology to describe this new way of philosophical investigation. Experiencing Phenomenology Phenomenology is not an easy subject to get your brain around, even if you studied it in college and grad school, even if you wrote your Master's thesis on it. (Just speaking hypothetically here, of course.) For example, as I was skimming through half a dozen books and innumerable Web sites to collect background information for this article, I was repeatedly struck by the complete absence of any definition of the term that is both concise and useful. Among the definitions of phenomenology you may encounter are “the science of experience,” “the study of apparent phenomena,” and “the systematic description of pre-theoretical experience.” Great, so…what is it? Those definitions are concise, all right, but they don't tell you a whole lot. In a nutshell, phenomenology is an attempt to study experience itself objectively and scientifically. That may seem contradictory—isn't experience, by its very nature, subjective? Husserl was looking for a rigorous method of describing experience that in fact did away with subjectivity. His motto was, “To the things themselves!” By this he did not mean that he wanted to study things as they exist objectively out there in the world, but rather that he wanted to study the experience of things—as they present themselves to the observer—without any assumptions, predefinitions, interpretations, or prejudice as to why or how they exist (or even whether they “really” exist at all). Bracket This The phenomenological method is involved and time-consuming, but here's a brief outline. The first step is to consider the memory of a very recent experience—phenomenology is not normally done in real time—and subject it to a process known variously as epoché, bracketing, or phenomenological reduction. Much like the Cartesian method of doubt, epoché is a temporary suspension of any external beliefs, placing one's focus solely on the “raw” experience itself. The goal is to ignore empirical data—along with intuitions and judgments—and simply describe your experience in detail. To take a fairly trivial example, a phenomenological description of eating ice cream would not include a list of ingredients, information about fat and calories, or the likely impact on one's waistline. Instead, your description includes details about the flavor, temperature, texture, color, and so on. In other words, you don't concern yourself with what appears, but rather, with a thing's way of appearing. After this, you perform a further process known as eidetic reduction. This involves taking certain features of the bracketed experience and imagining variations on them, as freely as you can. For example, if I am focusing on how a cup appears to me, I may perform free variation on the feature color, changing it to different hues, or attempting to remove the feature completely. The purpose of this exercise is to arrive at the features that are essential to the object in question. Thus I should discover, for example, that while no one particular color is essential to a cup's being a cup, it is essential that it have some color. This is an essential feature of a cup in my experience; whether someone else would find it so is not for me to say. But the phenomenologist hopes to learn, in this way, how to describe any experience with complete objectivity. It'll Drive You to Drink Husserl's phenomenological method changed significantly over the years, and other philosophers have taken it in very different directions. Martin Heidegger, for example, who was both a student and a critic of Husserl, doubted whether the epoché was useful or even possible, while still rigidly adhering to the “describe, don't explain” model of inquiry. Other famous phenomenologists have included Jean-Paul Sartre, Maurice Merleau-Ponty, and Paul Ricoeur, all of whom put their own spin on Husserl's basic principles. Besides being an independent branch of philosophy, phenomenology is applied with increasing regularity to other fields, including science, literature, and the arts. But it's also becoming excessively trendy—you may hear something like “the phenomenology of consumer-oriented marketing,” which means, approximately, nothing. But I can't complain too much. At least now if someone asks me what I plan to do with my degree in philosophy, I can say, “phenomenological obfuscation.” —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/17/Phenomenology.73ffce7fba38.mp3"
	},
	{
		"title": "Complaints Choirs ",
		"text": "The acoustics in my apartment are lousy. I have too many work deadlines. The dollar-to-euro exchange rate is depressing. It always rains when I want to go for a walk. It's not hard to come up with things to complain about, but who wants to listen to someone else complain? The surprising answer: just about everyone, as long as the complaints are set to music and delivered in four-part harmony by a choral ensemble. In the past few years, musical groups called complaints choirs have sprung up all over the world, drawing sell-out crowds (and Internet fans by the hundreds of thousands). Let's Give ‘Em Something to Complain About The idea was the brainchild of a Finnish couple, performance artists Tellervo Kelleinen and Oliver Kochta Kalleinen. They were discussing the Finnish term Valituskuoro, which literally means “complaints choir” but refers to a situation in which numerous people are complaining about something at the same time. Tellervo and Oliver thought it would be interesting to make an actual choir of complainers. They circulated flyers and posters in Birmingham, England in 2005 and soon got together a small but enthusiastic group of participants. Each one contributed some random complaints, the list was set to music, and the resulting performance was an instant hit (both in Birmingham and around the world, thanks to YouTube). The couple proceeded to organize similar choirs in numerous other cities, including Helsinki, St. Petersburg, Jerusalem, and Melbourne. In each locale, group participants create their own litany of complaints in their local language and with a unique vocal arrangement. Some complaints choirs are quite theatrical, while others stick to traditional choral performances in black gowns and suits. But the end result is invariably funny. Grievances A-plenty What do these musical complainers complain about? Anything and everything, ranging from the trivial to the profound. In fact, it's the very randomness of the complaints that often makes the performances so funny. A few examples… In Birmingham, the catchy chorus begins, “I want my money back. My job is like a cul-de-sac. And the bus is too infrequent at 6:30.” The St. Petersburg choir complains, “Yesterday the waitress was so rude to me.” “Shoe shops never sell size 35.” “My heart is so full but my wallet is empty. And anyway she wouldn't love a poet like me.” In Chicago, the complaints include “I can't stop thinking about sex,” “airport security took my mouthwash,” and “only tourists like deep-dish pizza.” The Jerusalem Complaints Choir sings, “”My bags don't open and there's passionfruit in everything.” “Bananas are never in the right state of ripeness.” And “football players only date models.” In Helsinki, they sing, “Old forests are cut down and turned into toilet paper, and still all the toilets are out of paper”; they also gripe that “our ancestors could have picked a sunnier place to be.” In addition, the Helsinki choir expresses my very favorite complaint: “Ringtones are all irritating,” sung several times in a row to the tune of that hideous default Nokia ringtone that we all know and hate. If You're Going to Complain, At Least Do It in Tune The choirs organized so far have ranged in size from fewer than a dozen to nearly 100 members. In some cities the singers are all experienced and the compositions are top-notch. But in most cases, participants aren't turned away for being tone-deaf as long as they have something to complain about. The Penn State group, for example, seemed to have an interesting concept but was just too painful for me to listen to. But hey, if I ever decide to start my own complaints choir, that'll be the perfect thing to complain about. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/15/Complaints.7cdf99f8453e.mp3"
	},
	{
		"title": "Quiet PartiesQuiet Parties",
		"text": "On our way home from the theater after seeing the most recent X-Men movie, Morgen and I kept finding ourselves surrounded by unusually noisy people—in the lobby, on the street corner, in the subway station. We were attempting to discuss the film, but we could barely hear each other. Every time this happened, I tried to move away to a quieter spot; noise has its place, but when I'm trying to think or carry on a conversation, I prefer relative silence. As we reviewed some of the fictional mutants and their super powers, I said, “If I were a mutant, they'd call me Silento. My super power would be the ability to create a large bubble of silence all around me.” In my book, that beats being able to throw balls of flame or have metal claws pop out of my hands. I have always been baffled at the fact that people so frequently go to noisy parties, bars, clubs, and restaurants with the apparent intention of getting to know each other or spend quality time together. How is that supposed to work? How can you have a worthwhile conversation with someone when you must yell over loud music, not to mention all those other people yelling their own conversations at each other? Perhaps my telepathic powers are insufficiently developed, but as an ordinary human, it seems more sensible to me that if you want to talk to someone, you'd go to a place where you can hear and be heard. So I was delighted to learn of a relatively recent phenomenon sweeping the world: quiet parties, where the only rule is “no talking.” These Go to Zero The idea for quiet parties came from two New Yorkers, artist Paul Rebhan and musician Tony Noe, who got frustrated trying to find a bar where they could have a quiet conversation in 2002. They invented the quiet party partly for practical reasons and partly as a sort of participatory performance art. Despite—or perhaps because of—New York's reputation for ubiquitous noise, the parties were an instant hit. Loud music, yelling, and cell phone use are prohibited at quiet parties; sometimes there's soft music in the background and sometimes not. Whispering is allowed in designated areas, and occasionally, quiet parties even permit the exchange of text messages and email. But on the whole, participants rely on written notes, mime, and body language to convey their messages. Once partygoers get over the initial discomfort of writing instead of talking, they often find that passing notes makes it easier and less intimidating to approach strangers. And it's often quite entertaining: there's no rule against giggling or gasping. You Had Me at “___” Quiet parties that are officially sanctioned and promoted by Rehban and Noe take place at a venue that has been specially reserved for the evening, with hosts who explain how it works, pass out pens and paper, and enforce the “no talking” rule. These events, which have been held around the world in cities including New York, San Francisco, Houston, Washington, D.C., and Beijing, have tended to attract mainly singles; those looking for love at a quiet party are said to be practicing silent dating. The organizers are quick to point out that their events were never intended exclusively for singles, but that seems to be the angle that's received the most press. Of course, anyone throwing a private party, of whatever sort and for whatever audience, can choose to follow the same format, and informal quiet parties have been gradually catching on. I think I can safely say that no one has ever had to yell to be heard at one of my parties, but I'd certainly be game to try complete silence. Perhaps one day in the future, when silent parties are the norm, the world will no longer need Silento. I'll be only too happy to hang up my cape. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/15/silence.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2009/03/03/ITotD-570-Quiet.afcd592643c0.mp3"
	},
	{
		"title": "Stewart/Gaskin",
		"text": "In 1985 I was attending college in New York, and in the great tradition of young people wasting the best years of their lives “experimenting,” I developed an addiction—to synthesizers. I bought what was to be the first of many keyboards and spent countless hours tweaking sounds when ordinary people my age were busy getting drunk and forming bad social habits. I wasn't very interested in writing songs; what fascinated me most was the process of creating interesting timbres. I subscribed to Keyboard Magazine, which encouraged my habit in two different ways. First, each issue convinced me that I absolutely needed the latest electronic musical gadgets, thus ensuring a state of perpetual credit card debt. But the magazine also taught me a number of practical skills for making music. One of the magazine's features at that time was called a Soundpage—a tear-out plastic phonograph record. Each month, some well-known keyboard player would put together a special recording, along with an article describing the music and the techniques used to create it. These Are the Daves I Know Dave Stewart was the featured artist in the December 1985, issue. The Soundpage article began: “Dave Stewart insists that the other Dave Stewart, co-founding member of the Eurythmics, is not related to him, even though they're both British, play keyboards, accompany female vocalists, and wear glasses.” (This Dave Stewart had been in the bands Egg, Hatfield & the North, and Bruford; vocalist Barbara Gaskin was once in Spirogyra.) I listened to the recording of “Henry and James” and was instantly hooked. Though the style could be called “synth-pop,” I had never heard music like this. The instrumentation was entirely electronic, but the sounds had been crafted with such skill and care that you could easily forget that fact. In contrast to the prevailing custom, synthesizers were used to maximum musical effect, not to call attention to the fact that the artist was using the latest gear. Meanwhile, Barbara Gaskin's vocals were hauntingly beautiful, utterly obscuring the song's rather odd subject matter: two dronelike office workers. I played the single until it was nearly worn out. Naturally, I had to have more. But their first album, Up From the Dark, was available only on CD. I didn't have a CD player or even know anyone who did, but I decided I'd buy the CD anyway and figure out how to play it later. I looked in record stores for the next five years and simply couldn't find it anywhere. Once a store said they'd special-order the CD for me, but it never arrived. I wondered if I would ever hear more of Stewart/Gaskin. Then, in 1990, I casually mentioned Up From the Dark to a friend of mine in Texas. “Oh yeah, I have that,” he said. “It has the ‘Siamese Cat Song' on it; I bought it for my kids.” I was flabbergasted: my quest had ended. After listening to a cassette copy for a few months, I finally tracked down the CD in a used record store. Shortly thereafter, Stewart/Gaskin released another album, The Big Idea, followed by Spin in 1991. Extended Coverage The music on those three albums (along with several singles) is very diverse. Many of the songs are extremely inventive covers—including such strange bedfellows as “Subterranean Homesick Blues” (Bob Dylan), “Amelia” (Joni Mitchell), and “Leipzig” (Thomas Dolby). It was also on Stewart/Gaskin CDs that I first heard “8 Miles High,” “Walking the Dog,” and “It's My Party,” their version of which became a #1 hit in the U.K. But Stewart's original compositions, like “Henry and James,” “The Cloths of Heaven” (based on a poem by Yeats), and “Golden Rain,” are my favorites. Although the styles of music vary, the masterful orchestrations, clever interpretations, and luscious vocals give it all a distinctive coherence. Stewart and Gaskin refer to their work as “pop music for grown-ups.” That's a terrifically apt description. The songs' subject matter is sometimes serious and sometimes silly, but it never degenerates into the meaninglessness of most commercial pop music. Stewart/Gaskin's unique mixture of intelligent lyrics and interesting music results in a distinctive style. I think of it as the musical equivalent of gourmet macaroni and cheese: familiar and comforting, yet rich and sophisticated—skillfully made with quality ingredients and adorned with subtle garnishes. The songs tend to have the overall structure, rhythm, and length of pop songs, but an entirely different texture, if you will—one that especially appeals to people who appreciate technical excellence in musical composition, performance, and yes, synthesizer programming. After the major labels dismissed Stewart/Gaskin's music as “too uncommercial,” they started their own label, Broken Records. The lack of commercial pressure allows them an unusual level of artistic integrity and creative freedom. Unfortunately, they've released no new music as a duo since 1991, despite assurances on their Web site for the last seven years or so that a new album is in the works. But along with the many fans who keep their site's Visitors' Book busy, I remain hopeful that I haven't heard the last of Stewart/Gaskin yet. Godspeed, guys: my MP3s are wearing out. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/15/Dave_Stewart.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/15/StewartGaskin.5269ec666d34.mp3"
	},
	{
		"title": "The B-52's",
		"text": "Most people who have heard of the B-52's know them as a dance band from a couple of decades ago, the group behind “Rock Lobster” and “Love Shack.” Their music is often regarded as lightweight and disposable, made memorable only by its quirkiness—Fred Schneider's shouted or chanted vocals; Kate Pierson's and Cindy Wilson's outrageous wigs and luscious harmonies; the signature licks of guitarists Keith Strickland and Cindy's late brother, Ricky Wilson. But this group of friends from Athens, Georgia, who named themselves after the local slang expression for a beehive hairdo, are icons who were once iconoclasts. As recently as 1996, I knew nothing at all about the B-52's. I was vaguely aware that there was a band by that name, but I had no idea what sort of music they played and couldn't name a single one of their songs. Then a friend loaned me one of their CDs and I was immediately hooked. I thought it was the cleverest and most inventive music I had heard in a long time—funny, articulate, and very, very strange. Detour Through Their Minds Most of their music is upbeat and danceable, but not the kind of cookie-cutter pop produced by many of their peers. It might be called “alternative,” except that it doesn't take itself as seriously as most alternative music. The thing that makes it alternative is that the music has never been about fitting into a mold. For the B-52's, music is all about having fun. B-52's songs were generally group efforts that sprang from stream-of-consciousness jam sessions. It turned out that audiences had as much fun listening to their unusual music as the band did creating it, and their commercial success was largely accidental. In their music, as well as their costumes, videos, and concerts, the band presented an unabashed “different is OK” attitude. Music wasn't serious business; it was about enjoying yourself and the company of your friends. Even so, their songs show tremendous creativity and musical skill. The subject matter is sometimes absurd, yet the lyrics always sound like they were crafted with great care to produce the maximum artistic (or comedic) effect. This is perhaps best shown on the band's 1986 Bouncing Off the Satellites album. This album never got much recognition, because Ricky died just before it was released and the band could not bring themselves to promote it. But the tunes on that album showcase the best of the B-52's: intelligent, quality music that works because the band's only concern is being who they are. The B-52's—all four surviving members—are still around and still touring. In fact, I've been fortunate enough to see them in concert three times in the past six years. In concert, they still please the crowds, if not quite the same way they once did. Keith seems strangely ageless, and to watch him play, you could believe he's still 30. But Fred is certainly not as energetic as he once was, and Kate and Cindy—who can no longer hit all those high notes—have, shall we say, supplemented their formerly svelte figures considerably. More importantly, the performance appears almost rote—they just sing the old songs the same way they always have. The band acts almost like a parody of themselves, doing the same “Rock Lobster” dance they did 20 years ago. Songs for a Future Generation A year and a half ago, I wrote about the B-52's here, saying that although I love them dearly, they seemed to have lost their mojo. I said this not because of their uninspired concert performances but because they appeared not to be innovating anymore. They weren't writing new songs together or pushing the envelope of style or creativity as they once did. And their recording career had stalled. The group's last real album was 1992's Good Stuff; the last one with Cindy was Cosmic Thing in 1989; and the last one with Ricky was Bouncing Off the Satellites in 1986. Since 1992, they've released only compilations and remixes, except for two songs (“Debbie” and “Hallucinating Pluto”) the quartet recorded for their 1998 Time Capsule collection. And those two songs—critically praised though they were—don't have the original spark, don't show the group having fun the way they used to. Now comes the news that they're actively working on a new, full-length studio album, for release in summer, 2005; they also plan a tour to support the new album. I can hardly wait; but then, only time will tell if the band's latest effort lives up to the standard they set when they were much younger. I missed the B-52's during their heyday, and I miss them still, even when I'm listening to them in concert. I wish I could experience the freshness and novelty of the band as it was in the late 1980s and early 1990s; I would love to see more creativity from the people who created “Theme for a Nude Beach” and “Channel Z.” And now, finally, perhaps I will. I'd like to think there's still time for the B-52's to recover their mojo and give us more of that Good Stuff. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/15/B-52s.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/15/B-52s.a7e3827bf373.mp3"
	},
	{
		"title": "Anechoic Chambers",
		"text": "When I began making audio recordings of Interesting Thing of the Day articles, I immediately realized that my office was not acoustically appropriate. There were too many extraneous sounds—fans, hard drives, and so on—and my fancy new microphone picked them all up perfectly. So I decided to set up a little recording studio for myself in a closet. The closet door nicely blocked out the sounds of the room, as well as most of the sounds from other parts of the house, traffic outside, and so on. The problem was that the recordings sounded like I was in a closet, or maybe a bathroom—the flat walls and ceiling added an unpleasant reverberation to my voice. In professional recording studios, the walls are usually covered with special acoustic foam to absorb most of those reflected sounds and give the sounds being recorded a more pristine character. I didn't have any acoustic foam handy, so I covered the walls with old blankets instead. That did the trick: now my voice sounds correct, and I can always add reverberation or other effects later if I feel the need. Recording studios are generally designed both to keep outside sounds from being heard inside the room and to keep sounds generated inside the room from bouncing around enough to be picked up by the microphones—and they invariably do a better job at both than my makeshift studio-in-a-closet. However, they're still far from soundproof or acoustically “dead.” A noisy motorcycle or heavy truck coming down the road outside might still be heard inside, and the surfaces inside the room still reflect a bit of sound. Is There an Echo in Here? If you're recording a CD, these minor imperfections in the room's acoustic quality are no big deal. But if you're trying to perform delicate, highly accurate measurements of the dynamic response of a microphone or the frequency range of a speaker, any reflections or unintended sounds at all can invalidate your tests. So you need a heavier-duty soundproof environment than a recording studio: you need an anechoic chamber. The word “anechoic” means, as you might guess, “without echoes.” Naturally, an ordinary room is going to reflect sound less than a canyon or a concert hall, but making a room completely immune to sound reflections is surprisingly difficult. The first step is to consider the angles of the surfaces in a room. Flat, hard surfaces reflect sound best, and when you have more than one such surface—especially when they're parallel—you're guaranteed to have some sort of echo. Then you have to consider the composition of the walls, floor, and ceiling. A given material (think of the blankets lining my closet walls) may absorb certain frequencies of sound effectively, while reflecting higher or lower frequencies. In addition, sound volume comes into play: materials that absorb relatively quiet sounds may nevertheless partially reflect louder sounds. So most anechoic chambers have all their interior surfaces lined with thick wedges of fiberglass (or in some cases polyurethane) foam. The wedge shape traps sound waves by reflecting them onto another part of the wedge rather than back into the room. The foam itself then absorbs the vibrations (turning them into heat). The deeper the wedges are, the lower the frequencies of sound that can be absorbed. To absorb all sounds within the range of human hearing requires immense wedges, shrinking the interior space of the room and adding to its cost. Meanwhile, it's equally important to prevent sounds from the outside from entering the room. The walls themselves (behind the foam wedges) must be quite dense and thick; in addition, anechoic chambers are generally isolated from the rest of the building by “floating” them on a set of large springs. The Cone of Silence I've never been inside an anechoic chamber myself, but my friend Darren has. Darren is a record producer, and he uses his considerable audio engineering talent to turn my raw voice recordings into the polished programs heard every day by our audio subscribers. He once visited an anechoic chamber used for testing microphones at the Peavey Electronics headquarters in Meridian, Mississippi. Darren described the experience as being just like walking into Cerebro, the psychic amplifier created by Professor Xavier in the X-Men comics and movies. Because the floor, ceiling, and even the door of an anechoic chamber must be kept as free as possible of reflective surfaces, the working area is a small stage suspended in the very center of the room, accessed by a long walkway. The walkway and stage included handrails because people inside the chamber frequently become disoriented. Although we are not normally conscious of it, the tiny reverberations from sounds hitting the walls, floor, and ceiling of ordinary rooms are picked up by the inner ear and used to enhance our sense of balance. Without these cues, it's harder to know which way is up. Darren described the experience of utter silence in the room as being very strange. Because there was no ambient noise at all, the smallest sounds—a whisper, the sound of breathing, or even a shoelace flapping—seemed astonishingly loud. But the important thing for the technicians testing audio equipment in the chamber is that if they're measuring the sensitivity of a microphone or the output of a speaker, they can be certain that only the sounds they deliberately generate inside the room have an effect on their test equipment. Other Other Echoes Echoes Although anechoic chambers were originally designed as places free of sound echoes, the term “anechoic chamber” is also used to describe a type of room specially designed and shielded to prevent the reflection of radio waves and other electromagnetic radiation. Manufacturers use such chambers for testing antennas, radar equipment, and other electronic devices that produce radio waves, to ensure that their measurements do not include any reflected signals. The materials and designs used to prevent the reflection of radio waves are different from those used in conventional anechoic chambers, but the basic principle is the same: absorb, don't reflect. Interestingly, though, some anechoic chambers designed for electronics actually have surfaces that reflect sound quite well. Being a city dweller, I'm accustomed to a certain amount of background noise 24 hours a day. At the same time, I can do without the more obnoxious sounds of traffic, loud music, shouting, sirens, and so on. Even though the absolute silence of an anechoic chamber sounds delightful for a meditative retreat, I imagine the novelty would rapidly wear off. If the sound of my own breathing became distracting, I may be on my way to a padded room of another kind. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/15/Anechoic_chamber.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/15/Anechoic.5b6935aa3ac0.mp3"
	},
	{
		"title": "Array Microphones",
		"text": "It all comes back to Star Trek. Whenever I have a complaint about the way technology works—or doesn't—a little voice in the back of my head says, “They don't worry about this on Star Trek.” One of the things they don't, apparently, worry about aboard starships a few centuries hence is being understood by computers. Keyboards and mice, we are led to believe, are relics of the distant past, and voice recognition has been perfected. That's a rosy and probably overly optimistic future, but one small aspect of the Star Trek computer interface is closer than many people realize. Have you ever noticed that when giving spoken commands to the onboard computer, Enterprise crewmembers never worry about where the microphone is located? Somehow, the entire ship manages to listen to everything that's spoken, and intelligently pick out particular voices—as well as determining what words should count as commands. While we're not quite there yet, technology has taken a meaningful stride in that direction, thanks to devices called array microphones. The Inglorious Legacy of Speech Recognition But first, a story. In late 1993, I was working as a computer graphic artist for a major electrical equipment manufacturer. My friend David was in charge of maintaining the group's network of Macintosh computers, and one day he invited me into his office to see the company's latest acquisition: a brand new Quadra 840av computer. David was grinning proudly because he got to play with it before anyone else, and he was eager to see my reaction to the machine's highly touted voice-recognition capabilities. Apple had included a special digital signal processing (DSP) chip in the computer whose main purpose was to make voice recognition fast enough for day-to-day use. Having read the reviews already, I knew that I should be able to speak any menu command and have the computer execute it without getting anywhere near the keyboard or mouse. So I stood near the microphone and said, “Computer, open Microsoft Word.” It did. Now I was grinning too. “New. Paste. Select All. Text to Table.” I rattled off a bunch of commands and the computer dutifully executed every single one, instantly and perfectly. I was in geek heaven. The Quadra ended up on the desk of one of my coworkers, a guy named Ken. He, too, was very excited about the new technology and eager to play with it. He named his computer Brancusi after the sculptor, and that was the word he used to trigger new commands. Unfortunately, in the real-world office environment, Ken's success with voice recognition left a bit to be desired. We'd hear him plead with his computer. “Brancusi, open Photoshop.” A pause. “Brancusi!” Another pause. “Brancusi, what time is it?” Nothing. “Brancusi, WHAT TIME IS IT?” Ken was not amused when we called his attention to the clock on the wall. The point was, the machine refused to understand him, and before long he gave up and turned off the speech recognition feature altogether. Over the past decade, speech recognition software has certainly improved. Where once you were restricted to a very limited vocabulary of commands—or dictation software that required you to pause after every word—now you can buy applications that will, with a fair degree of accuracy, transcribe normal, continuous speech. But speech recognition is still a very imperfect undertaking for a variety of reasons. Not least is the way microphones work. The Ears Have It It's tempting to think of microphones as being something like human ears, but ears have a couple of very important advantages over microphones. First, they generally come in directionally optimized pairs. And second, they make use of a sophisticated signal processor known as a brain. It's actually the brain that does the bulk of what we consider listening—sorting out which sounds deserve to be focused on, distinguishing one speaker from another, and following a conversation even when the speaker is moving around. Conventional microphones lack any intelligence and so simply pick up whatever is around them—the sound of computer fans, telephone calls, nearby conversations, music, or traffic. They have no way to discriminate and give you just the particular sounds you want. In terms of speech recognition, this causes some serious problems for your computer, which can't figure out which sounds are meant to be understood as commands and which should be discarded as noise. The usual way to “solve” these problems is to wear a headset microphone, which puts a highly directional pickup very close to your mouth. At such a close range the gain (or input volume) doesn't have to be very high, so extraneous noises are usually avoided. Headset mics do provide pretty good results, but most people don't really enjoy wearing a contraption on their heads just so they can talk to their computers—even if the headset is wireless. Creating a Digital Ear An array microphone does for microphones what your brain does for your ears. It gives them some intelligence. The general idea is that you take a set of microphones—which could be two, or eight, or thousands—and add a DSP chip with some sophisticated logic. The array microphone's processor continuously figures out where the primary speaker is in the field of audio input it's receiving, and selectively adjusts the output so that most of it is coming from the microphone that is getting the best signal. This amounts to “focusing” on a certain direction and distance so that the speaker's voice, and little or no other noise, actually reaches the output. (Some array microphones are actually much more sophisticated than this, doing advanced noise cancellation and other tricks. ) The implication of this is that in principle, with an array microphone on the desk, a speaker can walk from side to side, or move backward or forward—and maintain the same level of accuracy in speech recognition as with a headset mic. But that's in principle. Just as ordinary microphones vary in quality and sophistication, so do array mics. Some work well only at close distances; some cancel out certain kinds of noise better than others. As with anything, you get what you pay for—there are array mics that cost less than US$50, and those that cost $3,000. But even the most expensive array mics are only designed to pick a single speaker out of a background of noise; the all-important Star Trek tricks they can't do—at least not yet—are distinguishing one speaker from another and intelligently distinguishing commands from conversation. An Array of Uses Array microphones are used in numerous applications besides computer speech recognition. They are sometimes used in recording audio for films and TV shows—where extraneous noises are a no-no—or to amplify the voices of performers in a play. Some hearing aids use an array of miniature microphones to help wearers focus on a single speaker in a noisy environment. You may also find array microphones in cars, where they're used for hands-free phones. Home automation enthusiasts have been known to use microphone arrays—sometimes separate arrays in each room—so they can speak a command from anywhere in the house (“Turn kitchen lights on,” “Activate force field”) that will be carried out by equipment attached to a central computer. Array microphones have been around for decades, but in the last several years, advances in digital signal processing have made them much more sophisticated. A few centuries more, and we may have the other speech recognition issues ironed out for good. Then we can move on to that whole warp drive problem. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/15/array_mic.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/15/Array.b19c3106ceb.mp3"
	},
	{
		"title": "The Hurdy-Gurdy",
		"text": "Guest Article by Jackie Chappell In 1996, I bought an album I knew next to nothing about, by an artist I had never heard of before, on the strength of the album being issued on Peter Gabriel's excellent Real World record label. The album was “Big City Secrets” by Joseph Arthur, and from the very first track I knew that I had made a good purchase. However, I really sat up and listened when I got to track 3, “Mikel K.” In the background of the song there was a really odd-sounding instrument. It sounded a bit like a violin (or a folk-style fiddle) played with a never-ending bow, and had a bagpipe-like drone note in the background. As if that wasn't enough sonic complexity for one instrument, there was also a rhythmic buzzing sound, slightly reminiscent of a kazoo. What in the world was it? A quick check of the liner notes revealed only one instrument that I hadn't heard of before—a hurdy-gurdy. Don't They Usually Come with a Monkey? The first image that popped into my head was of a kind of barrel organ, where a handle is turned to drive bellows which force air through organ pipes, and which is also usually accompanied by some kind of simian assistant. I was so fascinated by the sound that I did some research, and found that my misconception was a common one. The hurdy-gurdy (or vielle à roue, as it is known in France) is played by turning a handle, but the resemblance to a barrel organ ends there. The body of the instrument can be box-shaped or with a rounded back like a lute, and many examples are beautifully decorated with inlaid wood. The handle turns a wheel covered in rosin, which vibrates the strings; the hurdy-gurdy functions like a violin with an endless bow, so that there is no pause in the sound at the end of a bow stroke. Instead of sounding notes using the fingers, the musician presses sliding, un-sprung keys which make contact with the strings and shorten them to make a sound of the required pitch. The drone comes from one or more strings which do not get pressed by the keys, and therefore sound the same notes continuously. The final part of the puzzle is the moveable bridge, or chien (French for dog), which supports one of the drone strings and can be manipulated by a skilled player so that it vibrates against the body of the hurdy-gurdy during playing, making a rhythmic buzzing noise. The whole ensemble has a driving, continuous sound, with its own percussion produced by the chien; it is impossible not to tap your feet along with the music. The Golden Age of the Hurdy-Gurdy It should therefore come as no surprise that the heyday of the hurdy-gurdy was in the medieval period, when it was used to accompany dancing. However, between the 14th and 16th centuries, the complexity and range of the popular music of the day increased beyond the capabilities of the instrument, and it fell out of favour with professional musicians, while remaining a firm favourite in rural areas with folk musicians. There was a bit of a hurdy-gurdy revival in the 17th to 18th centuries, as the instrument was improved and much new music was written for it. Oddly, this was partly due to its former association with the rural peasantry. The French court of Louis XIV started a fashion for what might be called “peasant chic”: the King was fascinated by his own idea of the simple, rural life (of course, this was a somewhat rose-tinted view, ignoring all the harsh, unsanitary, and downright unpleasant aspects of peasant life), and the hurdy-gurdy fitted in with this fashion perfectly. Eventually, the fashion changed, and by the French Revolution, the hurdy-gurdy had been returned to the rural working people. Today the peculiar sound of the instrument has a great affinity for all kinds of modern music, as I discovered. It makes an interesting acoustic counterpoint to largely electronic music, and the Celtic/Middle-Eastern feel of the sound complements world and folk music equally well. In my opinion, there are few pieces of music that aren't improved by the addition of a hurdy-gurdy—but perhaps I'm a bit biased. The Sad and Seedy Side The hurdy-gurdy also has a dark side to its history, which can be traced back to Hessen, Germany in the 1800s. Poverty was rife in rural areas because of increasing family sizes and the division of inherited land, so farmers started to make brooms and fly whisks in the winter which they then sold in the summer as pedlars. Initially, they sold their goods locally, but their trade soon spread to other areas of Europe, and as far as Britain and Russia. Being shrewd folk, they realised that brooms are not the most fascinating of household commodities, and that they would gather more of a crowd of potential purchasers if some form of entertainment was included. This took the form of pretty young “hurdy-gurdy girls” who danced and played music. Inevitably, the girls became more of a draw than the brooms, and before long, young girls were being persuaded by “soul-merchants” to leave their homes and families to play and dance in seedy music halls for sailors, miners, and other groups of men bereft of female company. The girls performed as far afield as gold-rush California, Cuba, and Australia. Some were drawn into prostitution, and while a lucky few became rich from their trade, most led miserable lives and returned home poor and ill. For many years, the trade was a public secret, with officials turning a blind eye (or even profiting from it) but eventually it changed from public secret to public scandal, and was finally outlawed in 1865 by a government edict. Hurdy-Gurdy Gurus So who is the Jimi Hendrix of the hurdy-gurdy scene? My vote would go to Nigel Eaton. His father, Chris, also makes the instruments, which must be handy if he has a Pete Townsend moment at a gig, and smashes up his hurdy-gurdy. Nigel has formed numerous groups centered around the hurdy-gurdy, including Blowzabella and Ancient Beatbox, as well as playing as a session musician with performers as diverse as Led Zeppelin and Joseph Arthur. In fact, this is where I came in—Nigel Eaton was playing on the Joseph Arthur track I mentioned at the start of this article. Like the rosined wheel of the hurdy-gurdy, I have come full circle. —Jackie Chappell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/15/hurdy_gurdy.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/15/Hurdy-Gurdy.684fb33fd906.mp3"
	},
	{
		"title": "The Theremin",
		"text": "As an amateur synthesist, I have always been intrigued by electronic means of creating sounds. Normally I work with buttons, sliders, and keys on modern digital equipment, every parameter conveniently shown on an LCD panel or computer screen. Long before computer-based, programmable synthesizers, though, there were analog synthesizers that were “programmed” by stringing patch cords across a panel that looked like an old-fashioned telephone switchboard and fiddling with dozens of twitchy knobs. But these early modular synthesizers were still not the beginning of electronic music. Go back a few decades further and you find a device with such a stunningly elegant user interface that it could be played without even touching it. Meet the theremin, the world's first electronic musical instrument. Just a Bunch of Hand Waving The theremin was invented by a Russian engineer named Lev Sergeivitch Termen (whose name was later anglicized to Leon Theremin). Termen was doing research involving vacuum tubes for the Russian government. At one point during his experiments, in which he happened to have headphones hooked up to his measuring equipment, he noticed that his own proximity to the tubes affected the pitch of the sound he was hearing. Although this was completely tangential to his research, the effect interested him; as a trained cellist, he soon found that he could play tunes on his laboratory apparatus simply by changing the position of his body. Termen began to explore not only the theory behind the capacitive sensor he had just stumbled upon, but also the mechanisms for creating musical tones electronically. He began building machines whose sole purpose was to translate gestures into sounds. Accounts vary as to when the first prototype instrument was created, but it was some time between 1917 and 1920, with the first public demonstration held in 1921. Termen received patents for his device in both Russia and the United States, and in 1929 RCA began production of the first commercial model, then known as a “thereminvox.” The original theremin looked like nothing so much as a lectern: a sloped wooden box on a pedestal. Protruding from the left side of the box was an oblong loop of metal tubing that functioned as an antenna; a second, straight antenna rose vertically from the upper right corner of the box. Sound came from a built-in speaker. The player stands a few feet away from the theremin with arms outstretched—one near each antenna. To play it, one simply changes the proximity of the hands to the antennas. The horizontal loop controls volume—move your left hand closer, the volume decreases, move away, the volume increases. The vertical antenna is responsible for pitch. Move your right hand closer, the pitch goes up; farther away, the pitch goes down. By making subtle, carefully synchronized movements, players can produce all sorts of effects to enhance the basic tones. Sounds From the Ether The basic sound of a theremin has been described as being similar to a musical saw, a flute, musical wine glasses, or even a human voice. In reality, the classic, unmodified sound is pretty close to a plain sine wave, but skillful manipulations of pitch and volume produce effects that can sound like the soothing vibrato of a mellow voice, a harsh shriek, or anything in between. In any case, the sound is monophonic—just one note plays at any given time—and it is a continuous sound, always sliding upward or downward in pitch rather than jumping discretely from one note to another. So it's impossible to play staccato notes on a theremin, though expert theremin players can move between notes so quickly and smoothly that the portamento effect is not noticeable. The theremin's sound has an ethereal, spooky quality, which made it ideal for soundtracks of science-fiction and horror shows during the middle part of the 20th century. Though the original RCA theremins have been out of production for decades, Moog Music, the company founded by legendary synthesizer inventor Robert Moog, still sells several compact, solid-state theremin models. A few years ago they also sold (for about US$5,000 each) fully digital theremins equipped with MIDI (Musical Instrument Digital Interface), meaning they could be used as controllers for other sound sources such as synthesizers or samplers—or, conversely, produce sounds when triggered by a keyboard, guitar, or other controller. This model is no longer available, but there is reason to hope Moog will create new MIDI-capable theremins in the future. Strange Music Fills the Air You're not very likely to hear an all-theremin concert, but there are modern classical pieces written for theremin (in some cases, along with a piano or even an orchestra), so theremins do pop up in serious concert halls on occasion. In addition, numerous bands and other performers use theremins in their acts from time to time. Last year we saw magicians Penn & Teller in Las Vegas, and as part of the show Teller (the one who doesn't speak) played a theremin solo from the side of the stage. If you'd like to play a theremin yourself, you may be lucky enough to find one on display at a science or art museum, or—more rarely—at a large music store. For a few hundred dollars or so you can buy a modern electronic model for yourself (the original wooden, tube-based theremins are extremely valuable antiques). There are also plans and kits available from numerous sources if you want to build your own. Of course, having a working theremin is no different by itself from having a working piano—although anyone can walk up to it and make some noise, it takes a lot of training and practice to become proficient. But even though the theremin is unsophisticated by today's standards, there is still something deeply satisfying about making music just by moving your hands. Whether you like pretending to be a conductor or a sorcerer, a theremin gives your gestures a fascinating soundtrack. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/15/Leon_Theremin_Playing_Theremin.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/15/Theremin.a7c7570b14fe.mp3"
	},
	{
		"title": "The Right-to-Quiet Movement",
		"text": "When I was in high school, I had an alarm clock that I truly hated. It was not merely loud, it was hideously, harshly loud. It sounded pretty much exactly like a smoke alarm, and had precisely the same effect: it scared me senseless every time it went off. I'd wake up, all right, but in such an anxious state that I came to associate the early morning with feelings of terror. Knowing a thing or two about electronics, I decided to perform surgery on the clock and modify it so that instead of making noise, it would flash a bright light in my face when the alarm went off. My modification worked—at least in the sense that the light flashed at the appointed time. What I hadn't thought through was the fact that at the time the alarm went off, my eyes would be closed (and, more often than not, turned away and buried in a pillow), so while the light flashed merrily away, I kept on sleeping. My invention merely swapped the stress created by a noisy alarm clock for the stress created by being late for school. Whether due to this adolescent trauma or for more mundane reasons of genetics or environment, I have had an aversion to noise almost as long as I can remember. My idea of a good time is visiting a library, cathedral, or desert location where the loudest sound is that of a page turning or wind blowing; my idea of torture is trying to write while someone is operating a leaf blower outside, being stuck on a plane next to a screaming child, or trying to hold a conversation on a noisy train. If you were to plot my stress level on a graph alongside a graph of the ambient sound level, you'd probably find significant correlations. I used to think my preference for quiet was abnormal if not pathological, until one day I typed “quiet” into Google and came up with Quiet.org—the Right to Quiet Society, one of numerous organizations dedicated to the promotion of quiet. There is in fact a rather large and diverse anti-noise pollution movement afoot, and being a fan of quiet, I find this notion extremely interesting. Now Hear This Broadly speaking, there are two main types of what is commonly called noise pollution: low-level, continuous background noise, and extremely loud but intermittent noise. Examples of background noise include radios or TVs left on all the time, appliances such as refrigerators and air conditioners, computers and other devices with cooling fans, and traffic sounds. Loud intermittent noises are things like planes flying overhead, leaf blowers, sirens, vacuum cleaners, and PA systems in clubs and concert venues. Typically the anti-noise groups focus on the second type of noise, citing extensive research on noise-related health concerns: hearing damage from extended exposure to high levels of sound, sleep loss, psychological trauma, and increased stress levels resulting in high blood pressure, aggressive behavior, and even suicide. But there is also a significant drive to reduce background noises, because even though they may not result in hearing loss, the cumulative long-term effect of low-volume but persistent unwanted sounds can have significant impact on one's mental health and stress level. It can be tricky business drawing the line between “sound” and “noise,” and even the most ardent anti-noise activists agree that context plays a significant role in determining what should be considered noise or, more specifically, noise pollution. Very loud sounds, however sonorous they may be, can cause hearing damage after a period of time, so it would be fair to call a Bach cantata “music” at 80 decibels but “noise” at 130. Likewise, I may enjoy listening to loud music at a dance club, but the very same music at the same volume would be noise pollution if it's occurring in the next room when I'm trying to sleep. On the other hand, there are loud noises that would not be called “pollution.” I want to be disturbed by noises like sirens, back-up alarms, or gunfire when they are necessary to alert me to danger. So the generally agreed-upon definition of “noise” is sound that is unwanted or distracting, and “noise pollution” is the term used for unnecessary, excessive environmental noise. Crying For Silence Anti-noise pollution groups have a wide variety of aims. Some concern themselves exclusively with aircraft noise in residential areas, for example; others seek more broadly to regulate any noise (factories, motorcycles, lawnmowers, watercraft, etc.) that threatens the peace and tranquility of the population. There are also movements to regulate workplace noise, to set and enforce safe standards for sound at concerts and clubs, and to reduce or eliminate background music at shopping malls, medical offices, and other public places. The overall message is that second-hand noise is a lot like second-hand smoke: it's one thing if you want to damage your own health, but quite another to inflict noise on other people nearby who cannot escape it, and yet suffer because of it. There are more examples of noise pollution than I can possibly list here; more appear every time I turn around. The problem is that most people have become so accustomed to constant noise that they simply don't notice it anymore. You've probably seen signs asking you to turn off your cell phone in a museum or refrain from talking during movies—these requests must be made explicitly because otherwise it would simply never occur to many people that such sounds might be offensive. The biggest aim of the anti-noise pollution organizations is therefore simply to bring the dangers and annoyances of noise into the public awareness, at which point, they hope, a majority of people will be outraged enough to do something about it—either voluntarily or through legislation. I wish them, of course, the best of luck, though I can't help noticing the irony of the squeaky-wheel effect: those who complain the loudest tend to get heard, and loudness is precisely the opposite of what anti-noise pollution activists stand for. Epilogue: The Noisy American I have traveled to many parts of the world, and based on what I've witnessed, I have developed a nearly foolproof metric for identifying Americans: the volume of their voices. English is not intrinsically louder than any other language, but Americans, as a group, tend to speak more loudly than any other nationality I've encountered in my travels—even if they're speaking the local language. I've asked people in several other countries if this has been their experience as well, and so far, everyone has agreed with me. This is, of course, a gross overgeneralization, a completely unscientific and unfair one. But I have to wonder: could it be a simple matter of habitually compensating for what has become an incredibly high ambient noise level? How's that? Oh, I said, “I HAVE TO WONDER…” —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/15/Quiet.4af8e99089d6.mp3"
	},
	{
		"title": "Moxy Früvous",
		"text": "When I went to my first Moxy Früvous concert in San Francisco in 1998, the sum total of my knowledge about them was: (a) they're Canadian; (b) they had written an interesting song about the (first) Gulf War; and (c) a couple of my friends liked them. This was not much to go on, and consequently I approached the concert without any expectations at all. The band consisted of four guys in their late 20s or early 30s, who mingled with the audience in the club before the show as though they were close personal friends with all 400 or so of us. Then, as the music started, I noticed something that hardly ever happens at concerts: I could actually understand all the words. This shouldn't be remarkable, but you know how it is at concerts. The fashionable idea of a good live mix is to have every channel turned up all the way, which guarantees that the instruments will drown out the vocals. Not so here: the music was loud, sure, but nicely balanced. This was my first clue that these guys took their art seriously. The next thing I noticed was that the lyrics I was hearing so clearly were both thoughtful and hilarious. Songs about renting videos, love lost and found, politics, and the profligacy of pop culture…every topic treated incisively and with finesse. The songs were not all funny, but they were uniformly well written—clever and edgy, yet folksy, without any hint of commercial pretense. The band members displayed the kind of cutting humor that can only come from being intelligent and well-read; I daresay their knowledge of history, politics, and current events put nearly everyone in the audience to shame. After the first song or two, the four musicians rearranged themselves on stage and switched instruments. The bass player took over on drums, the drummer picked up a guitar, the banjo player (yes, I said banjo) strapped on an accordion (yes, I said accordion), and the guitar player stepped up to a keyboard. They acted like this was the most normal thing in the world. All four took turns on lead vocals as well, and yet every song managed to have the same distinctive Früvous sound. I thought to myself: these are real musicians. Cool. The Lowest Highest Point Perhaps the most entertaining part of the concert was the banter between songs. It was like a highly intellectual improv comedy show thrown in for free. This clearly met with the approval of the audience. I was surrounded by a bunch of rabid Früvous fans—who, I was later to learn, call themselves Früheads. The audience seemed every bit as involved in the show as the musicians, and once or twice the band threw together an impromptu song on the spot in response to some comment from the audience. The band's rapport with their audience was legendary. For about a year and a half, Moxy Früvous used a clever marketing tactic to draw people to their concerts. Attendees received “Frühead Cards,” which were stamped once at each concert. Fans received prizes for accumulating various numbers of stamps. Collect six stamps, get an autographed T-shirt; 18, and the band will write and record a song just for you; 24, an all-expense-paid bowling trip with the band, and so on. But the decision to nurture groupies in this way was a mixed blessing. By the time they finished fulfilling their commitments to cardholders, the band had recorded 41 fan songs for Früheads who had earned 18 or more stamps. The fans were, of course, thrilled, but the additional work of fan maintenance was clearly taking its toll on the already overworked band. Stuck in the '90s In late 2000, Moxy Früvous announced that they were taking a “hiatus” from touring. Fair enough: life on the road can be brutal. They never claimed to be disbanding, but the members have all become involved in other projects and don't show any signs of reconstituting the band. After all this time, Früvous fans generally assume this hiatus was intended to be permanent but the band didn't want to come right out and say it. That would hurt too many feelings: Früheads have an enormously proprietorial attitude toward their beloved band. It seems I have a knack for discovering great bands just as they fade into retirement or, shall we say, an extended state of nonproduction. And yet, the fact that you can no longer see Moxy Früvous in concert in no way diminishes the appeal of their music. The full canon of Früvous recordings—seven CDs produced between 1993 and 2000, plus a rare 1992 cassette-only release—can still be found and enjoyed, and many of the one-off fan reward songs can be heard on the band's Web site. With or without the band, the Früvous legacy lives on. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/11/Moxy_Frvous.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/11/Fruvous.f6b64aaf7066.mp3"
	},
	{
		"title": "Polyphasic Sleep",
		"text": "I've been thinking a lot about sleep lately. It all started when I saw the movie Into Great Silence, which depicted the lives of Carthusian monks who get by on about six hours of sleep per night, divided into two segments (see The Grande Chartruese). More recently I've been testing software called pzizz that's supposed to facilitate power napping. And the publicist for a sleep researcher I mentioned in my article about sleep debt offered to send me a book on improving the quality of one's sleep. So sleep has been very much on my mind, especially when I'm downing my third cup of coffee for the day, frantically trying to meet some deadline or other and wishing I could be dreaming instead. In fact, now that I look at how many articles I've written that have something to do with sleep, I'm frankly shocked. Clearly sleep is one of my favorite hobbies. On the other hand, I always have projects stacked up months deep and never seem to have enough time to finish everything on my day's schedule. So I was intrigued to read about a concept called polyphasic sleep, in which you sleep for several short periods of time each day, rather than one long period as you would in ordinary, or monophasic, sleep. (By the way, if you sleep for a long stretch at night and then take an afternoon nap, you're practicing a form of biphasic sleep—a schedule I personally enjoy.) Proponents of polyphasic sleep claim that it reduces your overall need for sleep to as little as two hours per day, while keeping you just as alert and healthy as you'd otherwise be. Critics say it's a dangerous practice that can shorten your lifespan and lead to physical, psychological, and social problems. But lots of people have tried it, and I've found it intriguing to read about their experiences. Nothing But Nap Although polyphasic sleep could take many forms, the one most frequently mentioned, sometimes by the name Uberman's sleep, is a schedule in which a person sleeps for approximately 20 minutes every 4 hours. For example, one might take naps at 2:00, 6:00, and 10:00 (a.m. and p.m. ). If the naps each last 20 minutes, you get 2 hours of sleep per day; if they last 30 minutes, you get 3 hours of sleep. Other variants include fewer, but longer, sleep cycles or a single stretch of 3–5 hours of sleep at night along with two or more brief naps during the day. I've read numerous accounts of people who have successfully adapted to one or another of these schedules for periods ranging from weeks to months, though I'm not aware of anyone who has made the change permanent. Most reports indicate that the initial several days are the most difficult, as the body struggles against the new schedule, after which it finally accepts the alternative sleep pattern. What's it like to live with polyphasic sleep? I can't speak from personal experience, but from what I've read, polyphasic sleepers invariably enjoy having 6 or more extra hours per day to get stuff done; some of them also report increased alertness, more vivid dreams, and even weight loss. But many of them say they have to cheat (or “reboot”) every so often, when their bodies simply tell them they're too tired and they have to sleep for a longer period of time. When folks trying out this alternative schedule go back to monophasic sleep, as they inevitably do, they cite various reasons, but a recurring theme is that it's just too difficult to keep a different schedule from everyone else in the world. Selling Sleep Short Among people who say polyphasic sleep is a good idea, there's an oft-repeated meme that once you get used to this sort of schedule, you can achieve deep, REM sleep almost immediately; the presumption is that as long as you get enough REM sleep each day, your brain and body get all the benefits of a single long stretch of sleep. Although solid clinical evidence about what happens during polyphasic sleep is almost nonexistent, some research suggests that this hypothesis is mistaken, and that a prolonged course of polyphasic sleep amounts to a form of sleep deprivation. Similarly, polyphasic proponents often mention a long list of famous scientists, inventors, and artists who allegedly followed such minimalist sleep schedules, but in most cases there's little or no documentation to back up these claims. On the contrary, it may be that although one can indeed be awake and alert for 22 hours per day, creativity and mental agility suffer as a result. However, almost everyone who's written about polyphasic sleep agrees that the technique has its place—for limited periods of time—when people are faced with a serious situation that demands the maximum possible number of waking hours per day. Frequently cited examples are long solo yacht races, space missions, military operations, and civil or medical crises. And, perhaps it would also be worth trying if you're an author who absolutely must get two book manuscripts, three articles, and a dozen Web posts done by the end of the week. I happen to be someone whose work and social schedules could probably accommodate polyphasic sleep, and maybe one day I'll give it a try. But ultimately, I know that I enjoy sleep a lot more than I enjoy work, and trading the former for the latter somehow doesn't seem like a very good deal. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/11/liquid_sleep.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/11/Polyphasic.6d91d412ff8b.mp3"
	},
	{
		"title": "The Grande Chartreuse",
		"text": "Last Sunday afternoon Morgen and I went to a local theater to see the film Into Great Silence. We expected to be pretty much the only ones there—how many people could really want to sit through a three-hour-long documentary about a group of monks in the French Alps who live in almost complete silence? Especially on a Sunday afternoon, a traditional nap time if ever there was one! But the line stretched halfway down the block, and we were lucky to get seated before the film began. The documentary contained no music except for a few scenes in which the monks were chanting, no voiceover, very limited dialog, and in fact hardly any sounds at all. I'll admit, in fact, that we both dozed off once or twice (it pays to go with someone who can nudge you when your eyelids droop). But we also left the theater agreeing that we'd just seen one of the coolest things ever: an intimate glimpse into the lives of the Carthusian monks who live at the Grande Chartreuse monastery near Grenoble, France. That we should be drawn to the story of monks living in silence probably comes as little surprise; the themes of quiet and solitude have come up repeatedly here at Interesting Thing of the Day. But we were frankly shocked to discover that life at the Grande Chartreuse, as depicted in the film, seemed completely at odds with our image of what has been called one of the most ascetic monastic orders in the world. The monks' cells looked quite comfortable and reasonably spacious. The monastery's setting in the Alps was simply breathtaking. Even the food looked amazing—no shortage of fresh produce and delicious-looking bread. We also saw a few moments of monks at play and got a small taste of their sense of humor. They seemed, to me, quite comfortable, well-adjusted, and serene—yet intensely focused on their work. I turned, as usual, to the Web to get more details about the monastery and the order of which it is a part. Chartered for Silence The Carthusian order was founded in 1084 by Saint Bruno. The first monastery—at the site of what is today the Grande Chartreuse—was established in the Chartreuse Mountains in southeastern France. Over the centuries, the monastery has burned down and been rebuilt several times, its occupants have been displaced by wars, and various other catastrophes have occurred. The structure as it exists today was built in 1688, and is one of 24 such monasteries, or charterhouses, around the world; the word charterhouse and the name Carthusian both come from the same root as Chartreuse. Nineteen of the Carthusian monasteries house monks, while the remaining five house nuns; with minor differences, the day-to-day lives of the 450 or so members of the order are the same, regardless of gender. Although the monks do not take a vow of silence, they limit speaking to times when it's strictly necessary so as to focus all their attention on contemplation. Each monk spends most of the day alone in a cell—in this case, typically a two-level apartment with space for sleeping, eating, work, and prayer, along with a garden area outside. They gather three times a day for prayer services, once a week for a shared meal followed by a recreation time, and on other special occasions. Every hour of every day is rigidly scheduled, and only about six hours per day is allowed for sleep—in two segments, separated by a long service in the middle of the night. Habit Forming Becoming a Carthusian monk involves a multi-stage discernment process that can last as long as eight years before taking the eternal vows; during this time, the monks-in-training can choose to leave or be asked to leave if the other monks feel they don't fit in or have not chosen their vocation correctly. Only a small percentage of those who set out to become monks ultimately stay. The order distinguishes between fathers, who have taken the vows and who live in almost complete solitude, and brothers, who spend more of their time working to maintain the monastery, preparing the meals, and so on, rather than focusing entirely on contemplation. Of the brothers, some are full monks while others are laypeople who have a sort of volunteer arrangement with the monastery and are therefore given more leeway in the use of their time and their interactions with each other. The Grande Chartreuse is a huge complex situated on some prime real estate, and despite the simplicity of the lifestyle practiced there, the monks do require some income to pay for things like the electricity bill, building maintenance, fabric, and any food they can't grow for themselves. One source of income is the sale of the eponymous Chartreuse liqueur. Only three monks at any time are privy to the drink's secret recipe, which reputedly contains extracts from 130 plants. The herbs are mixed at the monastery and then sent to a distillery in the town of Voiron for processing and bottling. Other monasteries have their own sources of income so as to be self-sustaining as much as possible, and those monasteries with greater income share with the ones that have less. Half a Monk The monastic lifestyle depicted in Into Great Silence produced surprisingly mixed feelings for both of us. On the one hand, the silence, the solitude, and the simplicity of their lives held great appeal. On the other hand, the intense schedules, the lack of variety, and the inability to travel would probably drive us mad. Not to mention the little fact that we aren't actually Catholic, and don't accept many of the beliefs that are central to the monks' daily practices. However, I'd be thrilled to see a secular version of the Grande Chartreuse: no scripture chanting, shaved heads, midnight chapel services, or eternal vows, but the same combination of solitude and community, the same silence, the same blend of contemplation and work. Sure, I'd still want periodic doses of the outside world, but even getting halfway to what the Carthusian monks have seems heavenly to me. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/11/Grande_Chartreuse.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/11/Chartreuse.56643ce03317.mp3"
	},
	{
		"title": "Proxemics",
		"text": "Before we embarked on our recent trip to Indonesia, we did as much research as we could to prepare ourselves for what we would encounter. Along with other social customs, such as forms of greeting and what is considered appropriate to wear, we learned that the idea of personal space is very different in Indonesia. In addition to tropical heat, large bugs, and infectious diseases, I thought of this as just another challenge to be faced as part of our adventure. I wasn't prepared for how much this difference would affect me. We did experience searing heat, spiders the size of coasters, and a few bouts of minor illness, but surprisingly these discomforts paled in comparison to our discomfort in navigating crowded streets and markets. It wasn't just the huge numbers of people in a small space that got to us, because we have faced similar situations in the large North American cities we've lived in. It was partly the way people frequently came into close proximity even when there was plenty of space around and there was therefore no need to do so. In addition, we couldn't remain invisible; even people who kept their distance were constantly asking us to buy something or just noticing us. While for these folks there was nothing out of the ordinary in these interactions, some instinct in us registered these approaches as invasive. Don't Stand So Close To Me In 1966 anthropologist Edward T. Hall coined the term proxemics to describe the study of how people perceive the proximity of others. Hall's work was inspired by an animal study conducted by Swiss zoologist Heini Hediger, who found that animals maintained various boundaries depending on whether they were preparing to escape, to attack, to communicate with members of another species, or relating to a member of their own species. Based on these insights, and after conducting his own research, Edward Hall developed the idea of a set of expanding circles, called reaction bubbles, that described how humans manage the space around them. The innermost circle he identified as Intimate space, reserved for those we are closest to, and usually measuring 6 to 18 inches (15 to 45cm) in radius. The next level up he dubbed Personal space, the distance we are comfortable maintaining with close friends, about 1.5 to 4 feet (0.5 to 1.2m). He used the term Social space to indicate our preferred proximity to acquaintances, about 5–12 feet (1.5–3.6m), and Public space for the distance we need for public speaking, 12–25 feet or more (3.6–7.6m). This sounds very specific, but Hall himself acknowledged that these distances vary from culture to culture. While those from less-populated countries, or countries where individualism and privacy are highly valued, are more comfortable with larger spaces between themselves and others, in other cultures maintaining what is considered excessive distance can be perceived as rude or unfriendly. Ignorance is Bliss Because in certain situations it is not always possible to keep our preferred distance from others—for example in crowded subway cars or elevators—we learn coping mechanisms to deal with our discomfort. Psychologists observe that individuals in these circumstances often avoid eye contact as a way to minimize the forced intimacy of close quarters. Another strategy we employ, according to psychologist Robert Sommer, is to dehumanize those around us, imagining them as inanimate objects in our personal space instead of the more anxiety-producing fellow creatures they are. I think these strategies are in play in most large cities and in other situations where it's is too threatening to acknowledge the close presence of others. My own discomfort is assuaged by passing others anonymously on a crowded sidewalk, or keeping to myself in a cramped airplane cabin. Of course, the illusion of space is shattered when I'm approached on the street, or when the passenger behind me starts kicking my chair. At these moments I feel my blood pressure rise, my stomach clench, and my temper grow short. While this reaction might be appropriate in truly life-threatening situations, nothing is at stake most of the time. Maybe knowing that I am responding only to a perceived threat to my safety will help me to remain calm the next time this happens. Then again, maybe not. —Morgen Jahnke ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/11/Reaction-bubble.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/11/Proxemics.dfe5b61b14eb.mp3"
	},
	{
		"title": "Power Napping",
		"text": "I recall being unenthusiastic about taking naps as a child, much to the consternation of my parents. Fortunately, as with so many other childhood dislikes, that attitude disappeared as I got older. By the time I was in college, I had realized naps were among the most wonderful things in life, right up there with chocolate and computers. Ever since then, I’ve indulged in naps as often as possible. It hasn’t always been easy. For a number of years, my job involved sitting behind a desk in an office all day, and my employers would have frowned upon my spending any portion of the workday asleep. And so I conquered the early-afternoon sleepies with caffeine instead. But I always felt that countries where siestas were common had it right: people tend to get drowsy soon after lunch, and when they’re drowsy, they’re less effective at their jobs. If, instead of suppressing the urge to sleep, we give the body what it wants, we end up being more alert and more productive. So I’ve been delighted in recent years to notice that this message is finally getting through to businesses in industrialized countries. All it took was a change in terminology. No longer do we take catnaps; instead, we take power naps. Unlike “dozing off,” which is presumably involuntary and thus a sign of laziness, power napping is deliberate and thus a sign of responsibility. People take power naps to enable them to get more work done and endure longer work hours, things employers tend to like. Although I’m not a fan of long workdays either, I’d certainly rather work long hours with a nap than without. Nap Time The term “power nap” was coined by James Maas, a psychology professor at Cornell University. In his 1997 book Power Sleep, Maas made the case for napping as a legitimate tool for enlightened businesspeople, parents, and anyone else with a busy schedule. Numerous studies in recent years have shown that napping can be amazingly effective in improving alertness, memory, and overall cognitive performance, not to mention one’s mood. However, opinions among sleep researchers differ when it comes to the ideal length for a power nap. Twenty minutes or so seems to be a popular length—it’s long enough to be demonstrably effective without allowing you to fall into deep, REM sleep, from which it can be harder to awaken. On the other hand, some studies suggest that an hour-long nap, including a REM phase, may be much more effective, proportionally speaking, than a half-hour nap. But if you awaken during a particularly deep part of the sleep cycle, the nap can have the opposite of the desired effect, making you feel groggy for hours afterward. And if your nap is too long, it can also prevent you from sleeping properly at night. The solution is to experiment and find the nap length that works best for you. Ideally you’d time yourself so that you wake up at the end of a natural sleep cycle, but because most of us can’t precisely control the moment at which we fall asleep, this is tricky to do without the use of expensive monitoring equipment. (Personally, I’d find a 20-minute nap break almost useless, because it often takes me nearly that long to fall asleep in the first place. ) Power napping can help to overcome sleep debt, making it feasible for some people to sleep fewer hours at night than they normally would. However, experts warn that napping shouldn’t be considered a substitute for a solid night’s sleep. While any given person may need more or less than the 8 hours dictated by conventional wisdom, even power naps can’t keep a person healthy and sane with only a few hours' sleep per night. Putting the Power in Power Naps Nothing could be more natural than sleeping, but judging by the numerous power-napping gadgets that have appeared on the market, you shouldn’t try this without technological assistance. You might start with CDs containing soft music and soothing voices guiding you into, and out of, your nap. Or, move up to audio with embedded binaural beats, which help to coax your brain into quickly achieving a restful state. You can buy software that creates audio sleep sessions you download to your iPod, or even a stand-alone, pocket-sized device designed exclusively to play power nap-inducing audio. And if your office chair isn’t comfy or private enough for a nap, you may be able to find a nearby MetroNaps pod—a sort of lounge chair with a large bubble over the head to reduce outside noise and light. Slip into the chair, put on the noise-cancelling headphones with soft music playing, and you’re all ready for a 20-minute power nap. Of course, this nap will cost you more than lunch, but just think how much more money you’ll make with a clear head. As for me, when I decide to rest in the afternoon, it usually turns out to be a literal catnap. That is to say, as soon as I lie down on the couch, my cat cuddles up with me. After licking my neck for a few minutes, she’ll fall asleep, and shortly thereafter, so do I. When she’s decided I’ve slept long enough, she starts meowing. It’s an admittedly low-tech approach, and the cat’s snooze alarm feature is unreliable. But there’s just nothing like a power catnap to improve my energy level and my spirits. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/11/nap.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/11/Napping.e09d8a05f5a4.mp3"
	},
	{
		"title": "DNA Fingerprinting",
		"text": "Guest Article by Rajagopal Sukumar From high-profile trials to popular TV shows, numerous events have imprinted on our collective psyche the fact that DNA evidence can be used to solve crimes. But the technique has extensive uses that go far beyond forensic science. You may even owe tonight’s dinner, in part, to DNA fingerprinting. My curiosity about this subject was piqued when I came across a recent newspaper report that talked about how DNA fingerprinting is being used in India to identify different varieties of basmati rice. The report mentioned a hotel that buys around 200 tons of basmati rice per year. The hotel’s chefs found it difficult to cook the rice properly because each type of basmati rice has different soaking times and cooking properties. A visual inspection is of limited use because all the varieties look nearly the same. They decided to solve this problem by working with the rice’s producer to certify each bag of rice using DNA fingerprinting; the chefs then use the information to help them determine the proper cooking parameters. How Does It Work? DNA sequences are extremely long, and comparing an entire DNA sequence with another would be hard to do. Fortunately, though, about 99% of human DNA is identical from one person to the next. The 1% that’s different includes several frequently repeating sequences; the number of repeating sequences in any given position on a chromosome is different for each person. Therefore, in DNA fingerprinting, fragments of DNA are extracted and a collection is created that is unique for each person. There are several techniques for doing so; they differ mainly in how the fragments are extracted and how they are converted into a form that can be analyzed for identification. While human DNA fingerprinting has numerous uses in law and forensics—from verifying paternity to identifying murder suspects—this technique also applies to other organisms. Plants, animals, and even bacteria have unique DNA fingerprints. An increasing range of applications makes use of this fact. For example: * Fighting Disease: The big problem in treating bacterial infections using antibiotics is the fact that, over time, bacteria become resistant to the antibiotics, thereby making the treatment ineffective. DNA fingerprinting is being used to identify antibiotic-resistant strains. This helps doctors to select an antibiotic other than the one to which the bacteria are resistant, or consider a different type of treatment altogether. The Centers for Disease Control (CDC) has been using DNA fingerprinting successfully for controlling the spread of tuberculosis (caused by Mycobacterium tuberculosis) for the past few years. * Fighting Foodborne Illnesses: E. coli is a type of bacteria that lives in the intestines of humans and animals and is generally harmless. However, there are a few strains of E. coli that are quite dangerous—such as O157:H7 (sometimes found as a contaminant in beef), which produces a powerful toxin and can cause severe illness. By using DNA fingerprinting, this harmful strain can be identified easily if it’s present in food. After a major outbreak of this E. coli strain in 1993, the CDC created PulseNet, a national network of laboratories that performs DNA fingerprinting on food-borne bacteria. PulseNet has been instrumental in stopping outbreaks by quickly identifying the strain in contaminated food after comparing it against known patterns. * Fighting Fraud: How do you know that the contents of the bottle of wine or the bottle of medicine you are about to consume is authentic? Wine producers are using DNA fingerprinting to ensure that the correct grapes have gone into the making of the wine, thereby guaranteeing its authenticity. Pharmaceutical manufacturers are working on using DNA fingerprinting for labeling medicines so that counterfeits can be detected more readily. Experts now think that DNA fingerprinting, when combined with rapid detection methods, can give rise to better authentication tools than the ones in use today. * Genography: Not to be confused with geography, genography (or genetic anthropology) studies the migration patterns of humans over long periods of time. The National Geographic Society has embarked on an ambitious 5-year project that will use DNA fingerprinting to map the journey of human beings since prehistoric times as they migrated to various parts of the globe. They are relying on the fact that some parts of the DNA, called “genetic markers,” are passed down generation to generation without modification. Using these markers, the project attempts to trace the movement of humans over the ages and the path of human evolution from their prehistoric roots in Africa. As the field of genetic engineering increases in popularity, the range of applications for DNA fingerprinting is likely to widen. Just as with conventional fingerprinting, there is always some margin of error, and ethical questions abound, particularly when humans are involved. But the evidence so far suggests that the potential benefits far outweigh the risks, and the future of DNA fingerprinting looks bright. —Rajagopal Sukumar Guest author Rajagopal Sukumar lives in Chennai, India and serves as the Chief Knowledge Officer (CKO) of a software consulting company that specializes in the global delivery model. You can read his personal blog at www.sastwingees.org. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/11/fingerprint.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/11/DNA.55bbdd4d8864.mp3"
	},
	{
		"title": "Bee Venom Therapy ",
		"text": "My experience may be exceptional, but I’ve found the several bee stings I’ve received over the years to be rather unpleasant—even after remembering my favorite things, I still felt pretty bad. So when a reader wrote to tell me about a treatment for such conditions as arthritis and multiple sclerosis (MS) that involves voluntarily stinging oneself with bees, I must admit I found the whole idea rather creepy and off-putting. Although this alternative therapy has not yet proven itself in widespread clinical trials, quite a few people swear by it, insisting that the benefits far outweigh the pain. And even some doctors are trying it with their patients. I feel obliged to insert the usual “don’t try this at home” and “your mileage may vary” disclaimers, but though the jury is officially still out, an increasing body of evidence suggests that there just may be something to this weird notion after all. A Little Jab’ll Do Ya Numerous poisons can—in small enough quantities and under the right conditions—produce beneficial effects. So it’s entirely plausible that the same is true of bee venom, or at least some of its components, even though its main purpose is to protect the bees by inflicting pain. Bee venom therapy is a subset of apitherapy, the medicinal use of any substances created by honeybees—including royal jelly and honey, each of which is already known to have some health benefits. Researchers have discovered a number of very interesting substances in bee venom—most prominently, melittin, a powerful anti-inflammatory agent. This gives some credence to the anecdotal reports that beekeepers who were stung repeatedly experienced a reduction in the pain and swelling of arthritis. Perhaps the most interesting application of bee venom is in treating the symptoms of MS. Some patients have reported startling improvements in their condition, and although doctors are quick to point out that bee venom is not a cure, patients frequently exhibit increased stability and mobility, as well as reduced spasms. In addition to arthritis and MS, bee venom therapy has also been used with some reported success in treating a wide range of other conditions, including post-herpetic neuralgia, fibromyalgia, Chronic Fatigue Syndrome, tendonitis, high blood pressure, scarring, asthma, post-operative pain, and even hearing loss. No Pain, No Pain Relief But let’s be clear about this: bee venom therapy, as usually practiced, hurts. The standard procedure is to remove a live bee from its hive (or a bottle) with a pair of tweezers, hold it next to the skin, wait for it to sting, and repeat. (Sometimes ice or a local anesthetic is used to reduce the pain a bit.) Depending on the condition, patients may receive multiple stings at a time, several times a week, for weeks, months, or in some cases, years. The sites of the stings normally turn red, swell up, and become itchy, just as you’d expect. And although some patients find this a minor annoyance compared to the more serious symptoms that are relieved, others have to discontinue the treatment because it’s just too painful. In order to deal with both the pain and the inconvenience of keeping and handling live bees, bee venom has also been made available in numerous other forms, such as an injectable solution, ointments, capsules, and drops. From what I’ve read, injectable bee venom approaches live stings in potency but also in pain; other forms appear to be somewhat less effective. Stinging Criticism Despite the cottage industry that has sprung up around bee venom therapy and reports from a great many satisfied stingees, the medical establishment in the United States considers it an unproven—and possibly dangerous—practice. Most seriously, about 1% of the population has a severe allergic reaction to bee stings that can, in extreme cases, result in death. When bee stings are administered by lay practitioners, the danger is increased, and yet relatively few doctors are willing to perform the procedure. A few small studies are underway to determine the safety and effectiveness of bee sting therapy for specific conditions. But one of the problems in performing a proper, rigorous, double-blind study is that a placebo must be used in a control group, and it’s difficult to find an inert substance that causes the same pain and skin reaction as bee venom. Still, some of the preliminary test results are encouraging, and everyone’s hope is that the particular substance or substances in bee venom that produce the desirable effects can eventually be isolated and administered without serious pain. In the meantime, people with treatable conditions but a low tolerance for stings must ask themselves: “To bee, or not to bee?” —Joe Kissell. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/11/bee.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/11/Venom.a199f6546fae.mp3"
	},
	{
		"title": "The Milgram Obedience Experiments ",
		"text": "As a teenager, I never thought of myself as someone who had a problem with authority. I may not have liked what I was being told to do, and I may have complained, but it was not in my nature to say no. I had my first crisis of authority when I was 16. I was learning to drive, and I’d already failed my driving test—twice. (The first time, I couldn’t parallel park and I ran into a cone; the second time, I didn’t come to a complete stop at a stop sign.) After several more weeks of practicing and diligently studying the driver’s manual, I was taking my third and final test. If I failed that, I’d have to apply for a learner’s permit all over again and endure embarrassing months of being the only person my age without a license. So the pressure was on. With the examiner, a police officer, in the passenger’s seat and sweat on my brow, I carefully completed the entire course—and I thought I did well. At the very end, the officer told me to pull over at a certain spot and park the car. And I had a moment of complete panic: the spot he’d indicated was just a few feet from a stop sign, and I remembered from the driver’s manual that it was illegal to park so close. Was this one last test? If I obeyed, I thought, I could be failed for breaking the law. So I hesitated and said, “Isn’t that too close to the stop sign?” The officer became furious and started berating me for my arrogance, reminding me that the manual said, “…unless directed otherwise by a uniformed officer of the law.” Tugging at his sleeve, he ranted, “What does this look like, my pajamas?” He went on and on until I was about ready to shrivel up and die, but in the end, he passed me anyway. Strictly speaking, my dilemma was not a matter of whether to obey an authority, but rather which authority to obey—the police officer or the written law. Nevertheless, the fundamental conflict was between doing what I thought was right and doing what I was told. As stressful as I found that experience (I still cringe at the thought, more than 20 years later), it pales in comparison to a series of famous (or, perhaps, infamous) experiments performed in the early 1960s. The experiments' goal was to determine just how far people will stray from their ethical comfort zone in order to obey an authority. Do As I Say Stanley Milgram—the same psychologist whose research led to the six degrees of separation notion—was teaching at Yale University several years before he began working on social networks at Harvard. At that time, the world was still coming to grips with the trial of Adolf Eichmann, who was convicted in 1960 of crimes against humanity for his role in the holocaust; his defense had been that he was “just following orders.” Meanwhile, troops were being sent to Vietnam and public anxiety was high about whether, or to what extent, soldiers might again commit atrocities simply because someone in authority told them to do so. Milgram designed a series of psychological experiments to shed some light on this question. Milgram placed ads in a newspaper offering volunteers $4.50 for an hour of their time if they came to Yale to participate in an experiment about learning and memory. When a volunteer arrived at his scheduled time, he was met by an experimenter and a second volunteer. The experimenter explained that they were conducting a test of how physical punishment (in the form of electric shock) affected one’s ability to learn. One volunteer would be chosen randomly to be the “teacher,” and the other would be the “learner.” The learner was strapped into a chair with electrodes attached to his wrist; the teacher was seated in front of a console with a series of switches that controlled a shock generator. The switches were labeled with voltages ranging from 15 volts to 450 volts and descriptive terms for each (“Slight Shock” at 15v up through “Danger: Severe Shock” at 420v and “XXX” at the last two settings). The teacher was given a sample shock of 45 volts (mild discomfort) so that he’d know what the learner would feel. Then he was told to read a series of word pairs to the learner; the learner had to memorize which word came second in each pair. Next, the teacher was to read the first word in one of the pairs and wait for the learner to respond with the second word. If the learner got it right, nothing happened; if the learner made a mistake, the teacher was instructed to throw a switch to deliver a 15v shock. With each successive mistake, the teacher was to increase the voltage of the shock by 15v. As the shocks became more and more severe, the learner would first groan, then complain loudly, then scream in agony, demand to be released, and eventually, stop responding altogether. When a teacher expressed reservations about continuing (as they nearly always did at one point or another), the experimenter insisted that the experiment must be completed and urged the teacher to keep going—assuring him that the shock was merely painful, not harmful. If the teacher became even more distressed, the experimenter reiterated that he would take full responsibility for the outcome and that the teacher would not get in trouble. By the end of the hour-long experiment, a great many of the volunteers were reduced to tears, and virtually all showed signs of considerable distress. Only after the experiment was finished—when the teacher had administered the maximum possible shock, or flatly refused to comply—would the volunteer be told that the shocks weren’t real; the “learner” was an actor and the “teacher,” who was not chosen randomly after all, was the real test subject. The Shocking Truth The initial experiment showed something Milgram wasn’t expecting: despite their reservations, anxiety, and protests, 65% of the subjects administered the maximum possible shock of 450v, and none of them dropped out before 300v. Milgram then performed numerous variations on the experiment with hundreds of test subjects. These further experiments confirmed his original findings and also revealed some interesting details. For example, the subjects were less likely to deliver strong shocks when they were nearer to the “learner” or when the “experimenter” was not physically in the room (giving instructions by telephone). Subjects were more likely to deliver strong shocks if an actor posing as a second volunteer provided encouragement; conversely, if other “volunteers” disobeyed, so would the test subject. Perhaps most tellingly, though, when the subjects were given the freedom to choose shocks of any intensity, they nearly always chose the lowest settings (though a couple of people did administer the strongest shocks). Although the “learners” weren’t shocked, other psychologists were—not because of Milgram’s results, but because of his methodology. His peers criticized him harshly for years afterward for causing such severe stress to his test subjects. Nevertheless, other researchers around the world have conducted comparable tests in the decades since, invariably yielding similar results to the ones Milgram obtained. But while academics debated the ethics of traumatizing volunteers, the public latched onto the troubling implications of Milgram’s findings. Basically, in a huge majority of cases, humans will obey an authority figure (though often under duress)—even if they firmly believe that doing so means causing someone else serious harm. And yet, despite the fact that this principle has become common knowledge, most people (whether in a corporate environment, the military, or anywhere else) still believe that “I’m just doing my job” or “I’m just following orders” are valid excuses for inexcusable behavior. I’m certainly no anarchist, but I have to wonder how many injuries, deaths, acts of terrorism, and even wars might have been prevented had their perpetrators found the courage to choose humanity over following the voice of authority. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/10/Milgram.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/10/Milgram.3c3d56d066d3.mp3"
	},
	{
		"title": "InterPlay",
		"text": "There's an old joke that I've heard attributed, in one form or another, to numerous religious groups. It goes: “Why do Baptists (or Methodists, or Mennonites, or Jews, or whatever) prohibit premarital sex? Because it could lead to dancing.” The implication, obviously, is that the group's taboo against dancing is so strong that it overshadows the moral principle that gave rise to it in the first place; dancing becomes not just a potential path to evil but an evil in and of itself. One of the theological views that sometimes motivates this position is that the body (or “flesh”) is inherently sinful or corrupt, and must be ruthlessly subjugated to the purer values of the spirit. This was certainly the view of the religious tradition in which I grew up. Any activity that even suggested carnal pleasure outside strictly delimited boundaries was an immoral concession to humanity's fallen nature. Although this sort of thinking may be an extreme example, it's indicative of a broader and older cultural trend, which some people refer to as the “mind-body split.” Whether you trace this trend back to Cartesian dualism, the early days of Christianity, or some other source, it amounts to a belief that the body is somehow an ontologically separate entity from the mind (or “soul,” or “spirit”). Perhaps the two are even in competition or conflict with each other. Even if, as adults, we recognize that by implicitly accepting this split we've become disintegrated and unbalanced, it's difficult to reprogram ourselves to recover that sense of being a single, unified whole. A practice called InterPlay exists to encourage that process by helping people to rediscover and express one of their most basic, primal needs: play. Play Time Children, of course, have no trouble playing, and kids seem to engage in play with their whole beings—what InterPlayers refer to as “mindful presence.” That, in a nutshell, is what InterPlay seeks to restore to adults who have lost all sense of how easy it is to have fun. As we grow older, we tend to take ourselves more and more seriously. Although that is useful in some respects, InterPlay is a reminder that we never outgrow the need for play. What does InterPlay mean by “play”? Not the things adults usually mean—sports, board games, gambling, and so on. In a sense, play can be anything that's enjoyable, but some of the specific activities that make up InterPlay are deep breathing, telling stories, singing, stillness, hand movements, and yes, dancing—all done with a relaxed (and often goofy) attitude. InterPlayers realize that the people who most need to learn how to play sometimes have mental blocks about the very idea of dance, or perhaps even resistance to more basic notions like movement or touch. So their practices are carefully designed to put participants at ease and ensure that everyone feels safe as they learn gradually to “let go.” You may think you're making a fool of yourself, but so is everyone else; the freedom for each person to be equally silly without judgments or comparisons is part of InterPlay's basic philosophy. InterPlayers learn to identify judgments they may have unconsciously made about themselves and release them. Since other participants are not judging you, you learn to silence your inner critic as well. So taking part in InterPlay activities is something like a cross between group therapy and improv comedy. InterPlay teaches participants to become more spontaneous and creative, to better handle stress, change, and uncertainty, and to be more effective collaborators. Playground as Church Although many InterPlayers become involved out of a desire to free themselves of certain religious baggage, the practice itself has no religious (or anti-religious) agenda. Instead, it espouses the viewpoint that spirituality is a subset of play, and that to the extent we can discover our true selves, we become better equipped to experience deeper levels of reality. Those who feel a spiritual path must be one of great seriousness and asceticism are challenged to think about spirituality in a more relaxed, light-hearted way. InterPlay creators Cynthia Winton-Henry and Phil Porter met while attending seminary in Berkeley, California in the late 1970s. They have collaborated ever since. After developing the basic philosophy of InterPlay, they formed a nonprofit organization called Body Wisdom to provide a structure for teaching InterPlay and training other leaders. InterPlay groups have sprung up all over the world; the activities are also taught in such diverse settings as corporations, churches, hospitals, and prisons. Body Wisdom's new headquarters, called InterPlayce, opened in downtown Oakland, California in 2004. I have several friends who practice InterPlay, including one who's on Body Wisdom's board of directors. Although I myself am not an InterPlayer, I've noticed that simply by interacting with people who are, I've gotten sucked into the wonderful vortex of playfulness that they embody. And that's exactly what InterPlay is all about: spreading the benign contagion of play. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/10/InterPlay.f5691c67bed6.mp3"
	},
	{
		"title": "Sleep Debt",
		"text": "My life is full of contradictions, as is true for many of us. For example, if you asked me what my top five favorite things in life are, sleep would certainly be high on that list. I love to sleep—it's not merely a necessity, it's a joy. Circumstances permitting, I'd sleep 12 hours a day if I were physically able to. On the other hand, my actions don't bear out this enthusiasm for sleep. I drink outrageous amounts of caffeinated beverages. I'm usually still awake and working at 2 or 3 a.m. And frankly, I prefer a lifestyle that's at least partly nocturnal—stay up late, wake up late. This in itself doesn't result in a contradiction; if I went to bed every morning at 3 and woke up at noon, I could enjoy a nice long stretch of sleep and still maintain my desired schedule. But it generally doesn't work that way. There are too many things to do—deadlines to meet, appointments to keep—and the rest of the world doesn't conform to my schedule. So I end up getting out of bed after only six or seven hours of sleep (which is far too little for me) and feeling tired most of the day. I recognize that this is a problem. When I'm sleepy most of the time, I can't think clearly, and I am much less effective at my work. I don't like this situation, and I sense that it may be taking some toll on my physical and mental health. So my New Year's resolution this year was to get plenty of sleep. I think I kept it for about a week, but hope springs eternal: maybe I'll sleep next month or, if not, the one after that. Sooner or later, though, something's got to give, because the effects of too little sleep are cumulative—what sleep researchers refer to as sleep debt. Racking Up Debt Sleep debt is defined as the difference between the amount of sleep you need and the amount you actually get. So if you need 8 hours of sleep per night and get 7, you accumulate 1 hour of sleep debt for that night. And if you get 7 hours of sleep every night for a week, you've accumulated 7 hours of sleep debt. Of course, the amount of sleep required per night varies from person to person—and for a particular person, it changes with age. Some people, like me, operate at peak efficiency with 9 or more hours of sleep; others function perfectly well with 5 or 6. But whatever that amount is, sleep debt accrues when you get too little. Casually speaking, say experts, if you feel drowsy during the day, you probably have some sleep debt. This is more than a mere annoyance; besides making you grumpy, drowsiness can negatively affect your productivity, reduce reaction time, increase the risk of traffic accidents, and even contribute to weight gain. Various studies have suggested that anywhere from 50% to 90% of Americans experience, and suffer the consequences of, sleep debt. One major cause, according to some people at least, is the alarm clock—or, rather, rigidly defined schedules that demand its use. When you awaken every day before your body says it's ready, you add to your sleep debt. At Least There's No Interest Until recently, some sleep researchers claimed that sleep debt could be accumulated indefinitely—that, like financial debt, it simply never goes away until it is repaid. If this were the case, I would probably be in the red for about a year's worth of sleep. Current research suggests that this notion is a mistake, and that the body's maximum sleep debt is under 20 hours, no matter how many consecutive nights you've had too little sleep. Be that as it may, the only way to “repay” sleep debt, so the experts say, is to sleep more—and there are limits, both practical and physiological, to how much one can sleep. If I had, say, a month off with absolutely no obligations or distractions whatsoever, a perfectly dark, quiet bedroom, a great deal of motivation to repay my debt, and some really boring reading materials—even then, with the optimal conditions, my body simply wouldn't stay asleep 24 hours a day, or even 12. On those lazy weekends when I've had every hope of repaying a week's worth of sleep debt, I still couldn't stay asleep more than 10 or 11 hours at a time. So to the extent that sleep debt really is like a financial debt, my body appears to disallow anything other than a minimum payment of an hour or two at a time. Of course, unlike financial debt, sleep debt isn't rigorously tracked in a database somewhere. Sleep specialists can perform tests to determine one's propensity to fall asleep, which gives a rough indication of sleep debt level. But there is no test that will tell you exactly how many hours or days of unpaid sleep debt you have, so the claim that it's strictly cumulative is ultimately just an educated guess. Still, the claim that it exists is generally accepted, and certainly borne out by my own experience. In fact…(yawn)…I think I need to go make a deposit. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/10/A_child_sleeping.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/10/Sleep_.77c1a0b8aba6.mp3"
	},
	{
		"title": "Fire Breathing",
		"text": "As is clear from the many email messages I receive, readers of Interesting Thing of the Day are, on the whole, intelligent, educated, and clear-thinking individuals. You are not prone to careless or reckless behavior, and you have more than a fair measure of common sense. So I felt it unnecessary to point out, for example, when writing about coffee, that it is a hot beverage that could burn you if you are not careful. I did not have to mention that if you enter a wife-carrying contest you should lift with your legs, not with your back. And I felt no need to caution you against saying “My, how lovely you look today” when speaking Klingon. You are smart enough to figure all these things out on your own. And yet, after reading many Web sites about fire breathing—each of which begins with a stern warning and disclaimer in large bold letters—I feel strangely compelled to point out that actually attempting to breathe fire is an incredibly bad idea. However impressive it may appear, and however many circus performers may have done it all their lives, I must urge you in the strongest possible terms to resist any temptation to bring fire, or indeed flammable substances generally, into proximity with your mouth. If you fail to heed this warning and in so doing suffer disfiguring burns, cancer, loss of important body parts, or death, well, don’t say I didn’t warn you. A Breath of Fresh Fuel Fire breathing is just one of several terms for a stunt most of us have seen at one time or another. A performer puts a small amount of fuel in his mouth and, after a deep breath, sprays it forcefully past a torch that’s held in front of his face. The flame ignites the fuel into a huge, bright, and noisy ball of fire that vanishes almost instantly. This is not to be confused with fire eating, an altogether tamer practice (though nevertheless still dangerous and not recommended) in which the performer places a flaming torch in his mouth, thus (usually) extinguishing it. I’d always had the idea that fire breathers used lighter fluid or gasoline, but as every source I consulted on the subject pointed out, these are among the worst possible choices (along with alcohol). Fuels such as these have a low flash point and easily ignitable vapors; these are both dangerous attributes that make an already risky activity downright foolhardy. (They also, reportedly, taste terrible.) A better choice is kerosene, a petroleum-based liquid that’s known in most parts of the world as paraffin and sometimes used as fuel for lamps and lanterns. Kerosene not only has a higher flash point than gasoline but is reputedly less carcinogenic (for what little that’s worth). But because it does not burn quite as readily, it must be atomized—turned into a really fine mist, with no large droplets—and performers apparently must practice for quite some time to develop just the right kind of spray. Backfiring One thing fire breathers take care to avoid is a steady stream of liquid exiting the mouth, because the fire could travel back on the stream and into the performer’s mouth or even lungs—a decidedly unhappy event. Fire breathers tend to avoid long hair (including facial hair), which can burn easily, as well as clothing made of synthetic fibers, which has the nasty tendency to melt into one’s skin when burned. They also, as a rule, have safety equipment nearby (such as a wet blanket, fire extinguisher, and first aid kit), as well as an assistant trained to deal with emergencies. But even with care, an unexpected gust of wind, a hiccup, or any number of other random mishaps can (and sometimes does) result in serious injury. And, of course, anything flammable enough to burn so spectacularly can also do spectacular damage to your mouth, teeth, and digestive system. As a result, many fire breathers have seen their health and careers go up in flames (as it were). Why do so many jugglers and street performers include such a dangerous procedure in their acts? Probably for the same reasons people go over waterfalls in barrels, walk across tightropes, or do other “daredevil” stunts—these things are crowd pleasers, they produce an enormous feeling of achievement, and can make the performers look incredibly appealing (assuming they survive). Fire-breathing can also, of course, result in higher-paying gigs (or more generous donations) than an act would produce otherwise. I have never tried fire breathing and have no intention of doing so. Once, however, when I was a kid, a friend of mine held a lighter in front of an aerosol can of WD-40, creating a similar effect. (This, too, I must emphasize, is something you should never, ever do.) It was impressive, sure, but it also scared the living daylights out of me. If I want to live dangerously, I’ll go to Las Vegas, play some nickel slots, and eat a 3/4-pound (1/3 kg) hot dog. Once again, that’s something you definitely should not try at home. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/10/fire.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/10/Fire.a884e7d55789.mp3"
	},
	{
		"title": "Freediving",
		"text": "Lifeguards at public swimming pools don't like it when you disregard the signs that say “Walk, Don't Run!” But they like it even less when you don't move at all. As a lifeguard is scanning the pool, the last thing he or she wants to see is a body floating face-down and motionless in the water. I remember getting yelled at for doing exactly that when I was about 10 or 12 years old. I couldn't understand what the problem was. I wasn't bothering anyone, I was just enjoying the sensation of holding my breath, floating, and staring at the bottom of the pool. But the lifeguard reprimanded me: “You have to keep moving. Otherwise I won't know if you have drowned.” I thought that was unfair, because kicking around in the water isn't as relaxing or serene as just floating there, but ever since then, as a courtesy to those who could not discern my state of consciousness from a distance, I have refrained from floating face-down. Little did I realize that what I was doing would soon be a major competitive sport. Kicking the Breathing Habit Serious breath-holders would call what I was doing Static Apnea—just one of several categories of the sport of freediving. The current world record for Static Apnea is held by Czech diver Martin Stepanek, who floated in a swimming pool while holding his breath for eight minutes and six seconds. That is, if I may say so (and pardon the pun), an unfathomably long time. But it's just the tip of the iceberg. Freediving is all about pushing the limits of physical and mental endurance, defying common sense all the way. Freediving is the name for a class of activities that involve holding one's breath underwater for an extended period of time. In its simplest form, freediving is a low-tech alternative to recreational scuba diving. Although freedivers can't stay submerged as long as divers who use tanks and regulators, they can move much more quickly and freely without the drag caused by the equipment. It's a quieter experience too, and with fewer bubbles there's less chance of scaring off fish. The only equipment required is a mask, wetsuit, and extra-long fins, making it a less expensive pastime than scuba diving as well. The Length and the Breath But when you start talking about competitive freediving, it begins to sound like a sport that could only be appreciated by someone whose brain had been deprived of oxygen a bit too long. Static Apnea is all well and good, but serious freedivers consider that just the first step. Dynamic Apnea ups the ante by requiring the diver to swim horizontally underwater; the idea is to cover as much distance as possible without taking a breath. Separate categories exist for divers using fins and those without. But then things start getting really interesting. In the other major forms of freediving, a rope (with markings to indicate depth) is dropped to the sea floor, and the objective is to follow the rope as deep as possible before returning to the surface. In a Constant Ballast dive, divers must descend and ascend under their own power; they can optionally use a weight to help them descend but they must carry the same weight on the way back up. Free Immersion is similar, except that the diver can pull on the rope to assist in the descent and ascent. Then there's the Variable Ballast dive, in which a weighted sled takes the diver farther down into the water; the diver then leaves the sled to ascend under his or her own power. If that's not challenging enough, a No Limits dive uses the same weighted sled to go even deeper, at which point the diver inflates a lift bag to facilitate a speedy ascent. Diver Tanya Streeter currently holds the world record in both of the most challenging freedive categories. On August 17, 2002, she made a record No Limits dive of 160m (525 feet), and on July 21, 2003, her Variable Ballast dive went to 122m (400 feet). But freediving is intensely competitive, and records are set and broken with astonishing frequency. The endless push to go deeper and longer is, not surprisingly, very risky, even for extremely well-trained divers. In October 2002, world-renowned freediver Audry Mestre died in an attempt to break Streeter's record with a dive of 170 meters. A combination of equipment malfunction and human error prevented her from ascending fast enough, despite the numerous safety measures that are always taken during dives of this sort. But this tragedy seems to have had a galvanizing effect on the freediving community, inspiring them to push themselves even further as a tribute to their lost comrade. If you think about other mammals that hold their breath to make extended dives—whales, seals, and sea lions—freediving doesn't sound all that crazy. Human physiology is quite a bit different, but research has shown that with training, almost anyone can develop the ability to hold their breath for three or four minutes. Still, there's a big difference between holding your breath on the surface of a nice, safe swimming pool and doing the same thing under hundreds of meters of water. That requires stamina, guts, and probably a little insanity. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/10/diver.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/10/Freediving.d256e84c4311.mp3"
	},
	{
		"title": "Throat Singers",
		"text": "I’m not normally one to lose sleep over missed opportunities; we all make the best decisions we can and life goes on. But about a decade ago, I made a truly stupid choice and I’ve been kicking myself for it ever since. I was doing graduate work in linguistics at the University of California, San Diego, and a musical group called Huun-Huur-Tu (or the “Tuvan Throat Singers,” for most of us) came to town and put on a concert at the university. I saw the posters, noticed that my classmates excitedly anticipated the concert, and seriously considered going…but for some unfathomable reason, I decided not to. The next day, and for a week or two afterward, that was all anyone could talk about: this amazing, surreal event—and, for linguistics students in particular, the complex vocal mechanics behind it. It had been, apparently, an almost religious experience for those who went. In the years since, I’ve yet to cross paths with the Tuvan Throat Singers again, and when two different people suggested they might qualify as an Interesting Thing, it was with a certain sense of shame and self-pity that I agreed. Singing Double What could be so special about a style of singing—don’t all singers use their throats? Not like these folks. The simplest way of explaining what throat singers do is that they can sing two notes at the same time. In fact, not just two notes—some throat singers can produce as many as four distinct tones simultaneously. The effect is truly weird and chilling. The Tuvan Throat Singers hail from Tuva (logically enough), an autonomous Russian republic just north of the Mongolian border and a bit west of Irkutsk. (The capital of Tuva, incidentally, is Kyzyl, which looks and sounds very slightly like “Kissell.” Coincidence? Definitely.) Although Tuvans are the best-known throat singers, similar vocal techniques are used by some Tibetan Buddhist monks, as well as Mongolians and other residents of central Asia; the technique is also known among the Inuit in North America and Siberia. Xhosa-speaking women in southern Africa also practice a form of throat singing. Whistle While You Sing The combinations of notes you hear in throat singing aren’t really chords in the conventional sense; even the best throat singer can’t sing a melody and counterpoint at the same time. Instead, the sound is more like a bagpipe, with a constant-pitched drone under a higher melody with a different timbre. There are in fact several very distinct forms of throat singing. One sounds rather like a digeridoo, with a flute- or whistle-like melody. Others resemble a low growling sound, a bird call, or rolling water, to give just a few examples. But in every case throat singing sounds like it could not possibly be coming from a human being—especially not a single human. Throat singing is closely related to vocal techniques known as overtone singing, harmonic singing, and multiphonic singing. Whether these techniques amount to the same thing, or whether one is considered a subset of another, depends on whom you ask; there are no precise, widely agreed-on definitions. But all have in common a way of changing vocal sounds so that multiple distinct tones are perceived at once. Deep (in the) Throat Ordinary vocal sounds that are made by vibrating the vocal cords consist of a fundamental tone and a number of higher-pitched harmonics or overtones, faint pitches that are mathematically related to the fundamental and help to determine the overall quality, or timbre, of the sound. Some harmonics are more prominent than others, due to resonances caused by the shape of the throat and mouth; these emphasized harmonics are known as formants. What throat singers do is to select a fundamental pitch at which certain formants will naturally be strongest, and then manipulate their vocal tracts in such a way as to reinforce individual harmonics even further. By careful movements of the jaw, lips, tongue, and throat, they can vary the frequency of the formants, thus affecting which harmonics receive the greatest “kick.” The net result is that you get a steady low-pitched fundamental, but a shifting series of emphasized harmonics forming a melody. If that makes your head spin, it gets even weirder. Your vocal cords (known to linguists as “vocal folds”) are not the only structures in your throat that can vibrate enough to be heard. There’s another pair of tissues slightly higher up in the throat known as the false folds; these, along with various other protrusions of cartilage and tissue, can be manipulated, with practice, to make other pitches in addition to the one produced by the vocal folds. So not only can accomplished throat singers combine a single fundamental with an overtone melody, he can actually create two or three simultaneous fundamentals. I get a sore throat just thinking about it. Tuvan Fever Although Huun-Huur-Tu is the best-known group of traditional Tuvan Throat Singers, there’s another Tuvan who has taken the art down a different path. A singer named Ondar combines Tuvan throat-singing techniques with modern instruments and pop stylings that sound familiar to western ears. While some critics feel he has corrupted a beautiful art form, a more charitable view is that he has helped to make throat singing more accessible and understandable to an audience that would otherwise not accept it. Ondar was featured in the documentary Genghis Blues, and has music available on Apple’s iTunes Music Store—a sure sign of popular acceptance. Scientific research has shown that there’s nothing unique to the anatomy or physiology of Tuvans' vocal tracts; anyone, given the proper training, can learn throat singing. It is, however, very challenging, and not likely to win you a lot of votes on American Idol. But there are some things in life that are worth experiencing for their sheer wonder. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/10/singer-1.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/10/Throat.aa9a0657ecc6.mp3"
	},
	{
		"title": "Leeches Reconsidered",
		"text": "I'm not particularly squeamish at the sight of blood. Needles, on the other hand—or, let's say, any sharp objects that could be used, intentionally or otherwise, to put a hole in my skin—give me the creeps. I can deal with injections and blood tests and so on as long as I don't have to watch, but that sensation of having something poking under my skin…well, it gets under my skin. I'm also not crazy about slimy or wriggly things—food, plant, animal, or otherwise. (This was not always the case. When I was very young I loved to play with earthworms. Once I accidentally, uh, broke one, and I was terribly upset. I took the pieces to a neighbor who was a nurse and insisted that she put the worm back together with a band-aid. She did. Poor woman. Poor worm.) Thus it should come as no surprise that leeches—by virtue of being slimy, wriggly, and putting holes in the skin—are very high on my “icky” list. Teaching an Old Leech New Tricks I cringe when I read old stories about bloodletting and other medical practices that, by today's standards, would be considered insane. Although doctors of centuries past surely felt their logic was sound, they were working from incorrect assumptions, and such tactics caused untold suffering. Stories of the medicinal use of leeches, in particular, always disturbed me. It's one thing to use a medical device to remove blood from someone's body, but applying a blood-sucking creature just seemed hideously wrong. I've never heard of mosquitoes being put to therapeutic use, never heard of a surgeon suggesting that a shark might be handy for performing an amputation. So I've always been grateful to live in the age of sterile instruments, antibiotics, and other modern marvels. But over the past few years I've been seeing more and more articles about leeches being used, once again, in medicine. I saw live leeches on display at the Pharmacy Museum in New Orleans, and I've seen them used on several TV shows (both reality and fiction). After decades of living in disdain on the general public's “icky” list, leeches are once again gaining respectability for their medical applications. Only this time it's not bloodletting to cure a fever, a headache, or any other random ailment; it's a precise medical procedure to solve some very specific problems. This Animal Really Sucks Medicinal leeches (Hirudo medicinalis) have a sucker on each end with which they attach to a host. Their tiny mouths, located inside one of the suckers, have three jaws arranged in a Y shape—each with about 100 microscopic teeth. When these jaws bite into the flesh of a human or other animal, they create tiny, precise incisions that give the leech access to a steady supply of blood, which it then ingests. But just as interesting is the leech's saliva, which contains among other things an anesthetic (making the bite virtually painless), a vasodilator (which expands the small blood vessels near the bite), an anti-clotting agent (which can cause the wound to keep bleeding for many hours after the leech is removed), and even antibiotic agents to prevent infection. So as animals go, there are worse things to be bitten by. Leeches suck in up to 10 times their body weight in blood—about 15–20 grams, or 3–4 teaspoons—and then drop off. A feeding lasts about 30 minutes to an hour, after which the leech doesn't need to eat again for six months. The modern medical application involves procedures such as skin grafts, reattachment of body parts, and reconstructive surgery in which blood flow must be directed to a new piece of skin. Getting blood to a piece of tissue is relatively easy, but siphoning the used blood away from the tissue is trickier. As a result, blood sometimes pools under the skin where it has just the opposite of the desired effect—it prevents oxygen from reaching the tissue. In such cases, what the patient needs is a very tiny incision, constant negative pressure to draw the excess blood out, a way to expand the blood vessels for maximum blood flow, and a way to prevent the opening from clotting until proper circulation has been established. This turns out to be a perfect match for the leech's résumé; it can accomplish all this much more efficiently, precisely, and safely than using conventional medical equipment. As a matter of fact, the U.S. Food and Drug Administration formally classified medicinal leeches as medical devices. Now they are being used daily, by the thousands, in well-equipped hospitals all over the world. Like used syringes, “used” leeches must be disposed of; reusing them on another patient could transmit diseases found in the first patient's blood. I have not been able to ascertain how the leeches are normally disposed of, or whether such disposal raises the hackles of animal-rights groups. Medicinal leeches are, after all, considered a “near threatened” species in the wild. But as much as I like animals, I'd have trouble feeling sympathy for a euthanized leech, even if it did just save my skin. Leeches are not the only slimy critters being put to medical use. Maggots, for example, are becoming a popular choice for debriding major wounds because they eat only dead flesh, leaving the healthy tissue intact. I'm all in favor of “natural” cures, and I'd like to think that if I ever experienced an injury for which leeches or maggots were an appropriate treatment, I'd have the grace and fortitude to suppress my “ick” reflex. All the same, the researchers working to create a mechanical substitute for medicinal leeches have my complete support. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/10/leeches.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/10/Leeches.2d56cd8ee1b0.mp3"
	},
	{
		"title": "Oxygen Bars",
		"text": "As much as I enjoy visiting Las Vegas, I can't say it's the healthiest place in the world for a vacation. The local culture encourages excessive and continuous consumption of alcohol and food (not necessarily of the highest quality). And given the large numbers of smokers, the air quality, at least inside the casinos, leaves a lot to be desired. Plus, since visitors are encouraged to enjoy the city's entertainment late into the night, it's rare to get as much sleep as you need. I figure these things are just part of the bargain and I don't normally go to Las Vegas for its health benefits. But several years ago when I was there for a trade show, a friend suggested we try a new and unusual kind of diversion: an oxygen bar. It sounded like an interesting experience, so we got together a group of people and went. The Oxygen Bar Experience At that time, oxygen bars had not yet appeared in every casino and mall, so we had to take a taxi to the distant suburban outskirts of town. We arrived at an inconspicuous storefront in a shopping center that looked like a café. In front of each seat at the bar was a small apparatus with several plastic cylinders filled with colored liquids, and a small control panel with a series of dials. The friendly bartender (if you can call him that) explained how the system works. You pay for oxygen based on a fixed period of time—most people choose US$10 for 10 minutes or $20 for 20 minutes. Each customer gets a nasal cannula (a thin plastic tube that goes over the ears and has nozzles that fit loosely into each nostril). This is attached to the apparatus with the cylinders, each of which contains scented water. Oxygen is fed through the liquid and then into the cannula; you choose which scent or combination of scents you'd like using the dials—choices included scents like eucalyptus, lavender, and lemon. We decided to go for the full 20-minute sessions. And so we began breathing. Oxygen smells just like ordinary air, and were it not for the added aromas, we might never have known the difference. Because the nasal cannula doesn't completely block the nostrils, you end up breathing in about half oxygen and half room air. The first thing you notice when you start a session in an oxygen bar is that you and all your companions look rather silly wearing tubes in your noses. There is a certain etiquette, certain social conventions that apply in a bar; people automatically know how to look at each other and carry on a conversation. But those rules don't seem to apply at an oxygen bar; it feels very unnatural to have a casual conversation with someone when you're both tethered by the nose to a bubbling machine. What exactly are you supposed to do? Just sit there, close your eyes, and meditate? We tried reading the health magazines lying on the counter, but that seemed antisocial. For lack of a better strategy, we ordered fruit juice so we could have something in our hands that would allow us to pretend we were in a familiar social setting and thus be able to interact more naturally. Getting Sober at the Bar When our 20-minute sessions ended, we left, taking our disposable nasal cannulas with us as souvenirs. As we walked outside, we compared notes. The general consensus was that we all felt pretty good—clear-headed, alert, content—pretty much the opposite of the way we would have expected to feel had we just left an ordinary bar. The effect was subtle, to be sure, but pleasant. In fairness, it could probably be said that a similarly tonic effect could have been achieved simply by having 20 minutes away from the smoke and noise of the casinos, breathing in fresh desert air. How much of the effect was real and how much was imagined, I can't say. I think, though, that the mere process of breathing deeply and deliberately for 20 minutes played a large part in making us feel better. Oxygen bars are springing up left and right in major cities and suburban shopping malls all over the world—especially in places where high levels of pollution produce a widespread desire for a breath of fresh air. It's relatively inexpensive to purchase or lease the equipment to run an oxygen bar, and particularly for proprietors of existing cafés, juice bars, and similar establishments, adding oxygen equipment is a good way to boost profits. Patrons feel they're getting something valuable, and many health-conscious customers would rather spend their money on oxygen than alcohol. To Breathe or Not To Breathe On the other hand, oxygen bars are coming under attack from a growing number of critics. One criticism is that oxygen can be toxic if inhaled at too high a concentration for an extended period of time, and even more so if one is suffering from certain illnesses such as emphysema. Technically, the U.S. Food and Drug Administration considers oxygen a drug that can be dispensed only by prescription, and while most states do not enforce that rule, it could be argued that oxygen bar operators are unqualified to judge patrons' medical tolerance for oxygen. Others worry about the solutions used to add scents to the oxygen, wondering if they might in some way damage the lungs. But the biggest criticism is simply the claim that oxygen bar treatments provide no real benefit apart from a placebo effect. Healthy people already have the maximum possible concentration of oxygen in their blood, the argument goes, so adding more cannot possibly have any physiological effect. My own feeling is that while oxygen bars may provide only minor benefits, the criticisms are a bit silly. If someone wants to pay for a few minutes of air with higher-than-normal concentrations of oxygen, whether or not that has any objectively measurable effect, it seems ridiculous to object. One could say that water should never be administered without a prescription because it can lead to drowning if used incorrectly, or that baseball bats should be licensed as deadly weapons. But people don't say these things, because they defy common sense. Oxygen bars serve up what amounts to a 40 or 50 percent concentration of oxygen for very short periods of time; even the American Lung Association says, “…there is no evidence that oxygen at the low flow levels used in bars can be dangerous to a normal person's health.” So while oxygen bars should perhaps not make claims of any specific medical benefits, it is certainly hard to dispute that breathing clean air for 20 minutes is better than breathing polluted air for the same period of time. And if a visit to an oxygen bar means time not spent consuming alcohol and breathing smoke, that's undoubtedly a healthy choice as well. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/09/Ozone.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/09/Oxygen.55719a72f65e.mp3"
	},
	{
		"title": "Spontaneous Human Combustion",
		"text": "As a kid, I always wanted to be a mad scientist or inventor of some kind. So I taught myself just enough about chemistry and electronics to be dangerous, and I often had some sort of project or experiment underway. Around age 16 or 17, I was hard at work on my latest contraption—using my bed as a workbench since my desk was perpetually covered with junk. This project involved some soldering, a task at which I was moderately skilled. However, as I was leaning over my work, trying to steady myself by resting my elbow on the mattress, my arm slipped and I fell forward onto the bed with the soldering iron sandwiched between my forearm and the bedspread. Apart from the initial shock, the first sensation I recall experiencing was the smell of burning flesh and hair, followed by the realization that I had ruined my bedspread, and then very shortly thereafter, a good bit of pain. Any number of lessons could be learned from such an experience—for instance, “Don’t solder in bed.” It’s also a reminder that there are any number of ways to generate dangerous levels of heat in close proximity to one’s body. Fortunately, this incident did not set me on fire. But if conditions had been just right, could this run-in with the soldering iron have reduced me to ash? This is just the sort of question pondered by those who investigate the phenomenon known as Spontaneous Human Combustion (SHC). Up in Flames Let’s start with some science. Spontaneous combustion, in and of itself, is a well-known phenomenon—and though perhaps surprising, it’s not in any way mysterious. The term is used when something erupts into flame without any apparent exterior cause (such as a spark). One classic example is the pile of oily rags. Some types of oil undergo a fairly rapid oxidation when exposed to air; it’s a straightforward chemical reaction that happens to produce some heat. If the heat cannot escape (by being dissipated into the air), it may eventually build up to a temperature above the flash point of the oil, at which point it will begin burning—just as it would if someone had dropped a hot coal onto the rags. A similar type of spontaneous combustion can occur in a pile of hay, due to the heat produced by bacteria that feed on the hay. Mechanics and farmers know all about these phenomena and generally take appropriate precautions to prevent heat from building up to dangerous levels. But for centuries, stories have circulated claiming that a comparable process can set a human being on fire. What’s the source of this belief? Could it possibly be true? And if so, how does it happen? Is It Hot in Here, Or Is It Just Me? Picture this: you walk into a room and find the charred remains of a person, with only a few identifiable body parts left intact—a leg, perhaps, or maybe the skull. The area immediately surrounding the spot where the person breathed his or her last is also heavily charred, but the fire never spread to the rest of the room. It looks as if the person somehow caught on fire, but then burned up so rapidly that the fire was unable to spread. There being no matches or other apparent source of ignition nearby, it’s extremely easy to conclude that the origin of the fire must have been internal. Hence spontaneous human combustion. What I’ve just described may sound unbelievable, but such scenes have been reliably documented hundreds of times in the last few centuries. (It’s also been fictionalized—for example, by Charles Dickens in Bleak House.) The question is not whether the bodies burned, it’s how they burned. Light Me Up Human fat—of which there’s usually an ample quantity even in thin people—does in fact make a good fuel. If heated sufficiently (and able to ooze out of the body), it could certainly burn quite well, perhaps using the person’s clothing as a wick like an inside-out candle. And plausibly, by the time all the fat in a body had burned, nothing would be left but ashes—not unlike cremation. But how would the fat get that hot in the first place? Some believers in SHC posit a heretofore-unidentified chemical reaction in the body that could produce a buildup of heat much like the one in the pile of oily rags. But so far, no direct evidence of such a reaction exists, and scientists remind us that combustion itself cannot take place inside the body anyway due to a lack of oxygen. In addition, there have been cases where the skin burned and not the internal organs, but no cases in which it was the other way around—weakening the theory that the source of the heat was internal. Other investigators have pointed out that no strange chemical reaction is necessary, that mundane sources of fire such as a cigarette, candle, or maybe even a spark from static electricity could potentially set fire to a person’s clothing and thus produce the required heat—consuming the “evidence” in the process. Wouldn’t a person who has just caught on fire tend to notice that fact and do something about it? Advocates of the SHC theory generally claim that the heat is so intense and sudden that the victim is consumed before having the chance to do anything. Critics say that in fact a lower temperature of combustion explains the evidence better—that the bodies appear to have slowly smoldered over a number of hours, and that the smaller amount of heat kept the fire from spreading. And a person may not react if, for example, he or she was already dead—or maybe just drunk or drugged. All that to say: the (rare and tragic) phenomenon of human combustion is not in question, but its spontaneity is. Even in the few cases where the victim survived or witnesses attested that there was no apparent external source of flame, there is no scientific need to imagine a mysterious internal source of heat—and no reason you should lose sleep worrying that you didn’t drink enough water today and therefore might suddenly burst into flames. All the same, I recommend doing your soldering on a nice solid table. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/09/Combustion.257da1e7549.mp3"
	},
	{
		"title": "White Noise",
		"text": "During the summers when I was growing up, my bedroom had an air conditioner mounted in the window. I loved the hot nights when I got to turn it on, but only partially because it cooled the room. What I liked best was the sound, which I found to be very soothing. Years later, when I was in college, I had a classmate everyone made fun of because he couldn’t go to sleep without having a radio on next to his bed—playing static. For some reason, the sound of static on a radio seemed goofy in a way that the sound of an air conditioner did not, but they amounted to roughly the same thing: white noise, which has a well-known ability to promote sleep by masking other sounds. Most of us have seen white noise generators or CDs of white noise that are sold as sleep aids—sometimes especially for infants. A different class of white noise generator is used for testing and calibration of pro audio equipment. But what exactly is white noise, how does it work, and why is it called “white”? Pure Noise If you think back to elementary-school science classes, you probably learned that white light is a combination of all the other colors of light; using a prism, we can separate it into its component colors. By analogy, “white” noise is composed of sounds of every frequency within the range of human hearing—roughly 20 to 20,000Hz (cycles per second)—with each part of the frequency spectrum equal in amplitude (volume). It’s called “noise” instead of “sound” because it is random in nature. Rather than simply generating a fixed tone at 20Hz, 21Hz, 22Hz, and so on all the way up to 20,000Hz, a white noise generator creates a constantly changing mixture of tones such that all frequencies have an equal probability of being audible at any given moment. To human ears, white noise sounds like a hiss—sounds such as a waterfall, an aerosol can, and static are all very similar to white noise. Although all frequencies are represented, we perceive white noise as being relatively high-pitched—partly because higher octaves consist of a greater range of frequencies than lower ones (giving the higher-frequency sounds proportionally more energy), and partly because our ears are more sensitive to higher-pitched sounds. White noise is good at masking most other kinds of sound because it effectively overloads or “numbs” our auditory systems. Just as it’s difficult to hold a conversation at a crowded restaurant, it’s difficult for your brain to identify any one sound or voice when you’re already hearing sound at every frequency. So it’s not the white noise itself that promotes sleep as much as the fact that it reduces audio clutter, drowning out other sounds that may distract you and therefore keep you awake. The Color of Sound If “white” noise includes sound at every frequency, you might imagine it would be possible to create other “colors” of noise by emphasizing certain ranges of frequencies over others. And you’d be right. There is such a thing as pink noise, as well as red, orange, green, blue, purple, gray, brown, and even black noise. Of these, pink noise is the most common—and the most clearly defined. Whereas white noise has equal energy at every frequency, pink noise has equal energy within each octave—in other words, the amplitude at higher frequencies is reduced to make it sound more balanced to the human ear. Pink noise is used for, among other things, calibrating speaker systems. The term “pink” signifies that it’s like white, but “tinted” or weighted toward the lower-frequency (and therefore longer-wavelength) sounds. However, not all of the so-called noise colors map onto the visible spectrum so clearly—and in any case, the color names are nothing more than a convenient metaphor to describe white noise that has been filtered in various ways. Many of the products claiming to produce white noise are recordings or simulations of wind, waves, and other sounds that are in reality quite a bit more complex than white noise. Not that there’s anything wrong with that—the sound of rain on the roof can be very soothing and can have most of the same masking benefits as white noise. And just as the term “white noise” can be stretched somewhat in meaning to include what you might call “off-white” noise, it also can have a more metaphorical sense, as in “meaningless chatter.” But what I’d like to hear is a recording that sounds just like my old air conditioner—complete with the hum that the compressor made every time it came on. For me, that would beat a melatonin tablet washed down with a glass of warm milk. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/09/White-noise.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/09/White_Noise.1ed907013a8d.mp3"
	},
	{
		"title": "Cochlear Implants",
		"text": "Today's article was going to be a pretty straightforward technological exposition. I was going to describe a procedure that can improve hearing in ways that conventional hearing aids cannot, mention some of the limitations and risks involved, and pretty much leave it at that. Then I got an email from a friend wondering if I was planning to cover the political issues cochlear implants raise for the Deaf community. Um…political issues? I hadn't known there were any. But after a bit of research, I discovered that the controversy surrounding this procedure is at least as interesting as the procedure itself, which has been called everything from a miracle cure to genocide. Can You Hear Me Now? First, a bit of background. There are many different types and causes of deafness. Some kinds of hearing loss can be compensated for very adequately with just a bit of amplification—namely, a hearing aid. However, if there is a defect or damage in the inner ear, a hearing aid may do no good. Our perception of sound results from the vibrations of tiny hairs lining the cochlea, a spiral, fluid-filled organ in the inner ear. When the hairs move, the hair cells convert the movement into nerve impulses, which are then sent to the brain for decoding. If the vibrations never reach the cochlea, or if the hair cells themselves are damaged, no neural stimulation occurs and deafness results. However, if most of the underlying nerve fibers themselves (and the neural pathways to the brain) are intact, they can be stimulated electrically, producing a sensation interpreted by the brain as sound. A cochlear implant places a series of electrodes inside the cochlea to do just that; a wire connects these electrodes to a small receiver with its antenna placed under the skin. Outside the skin, a device that looks somewhat like a hearing aid picks up sounds with a microphone, digitizes them in such a way that they produce meaningful signals for the electrodes, and transmits them via radio waves to the receiver. The net result is the perception of sounds picked up by the microphone, but because this apparatus completely bypasses the eardrum and middle ear, it's really an artificial ear rather than a hearing aid. The technology was developed by Dr. Graeme Clark at the University of Melbourne in the 1960s and 1970s; the first implant was performed in 1978. Although any number of technological innovations have occurred in the decades since, cochlear implants are still by no means perfect. They vary greatly in their effectiveness, depending on a large number of variables. And the effect they produce, while auditory in nature, is not identical to what would be experienced with a fully functional ear. In addition, patients with cochlear implants require months or years of training to associate their new perceptions with sounds as they are usually known. In the most successful cases, implant recipients can eventually understand someone talking on the phone—but there is no guarantee of that level of hearing. Still, tens of thousands of people around the world have received the implants, and the procedure is rapidly gaining in popularity. You Will All Be Assimilated To a hearing person such as myself, all this sounds very rosy and optimistic. Of course, the surgery is rather delicate and carries with it the usual risks associated with putting holes in one's head; plus, the cost of the procedure and rehabilitative therapy is quite high. But these are not the primary concerns of the Deaf community. Although the controversy has diminished greatly in recent years, cochlear implants—particularly for children—were strongly opposed by many deaf people for some time because of a fear that they would destroy the Deaf culture in general and the use of sign language in particular. On the surface, this argument may seem sort of silly to hearing persons. But the Deaf community has a unique culture and language that they rightly consider quite valuable; the thought of losing such a culture to technology is understandably offensive. One of the key beliefs of the Deaf community is that deafness is simply another perfectly valid way of life, not a problem that needs to be fixed. So the intimation that deafness is a “disease” for which cochlear implants are a “cure” smacks of assimilationism: “You must all be like us.” Even detractors of cochlear implants allow that this must be an individual decision, and that implants may be a reasonable choice for people who have lost hearing later in life (and who therefore may not have integrated themselves into the Deaf community). But when it comes to implants for children, the story is different. If a deaf child does not receive an implant, he or she is likely to learn sign language easily and adopt the Deaf culture. With an implant, the child is more likely to be treated as a hearing child. However, the imperfect nature of “hearing” provided by the implants may make it difficult to learn spoken English; meanwhile, because the parents have little incentive to raise the child as a deaf person, the child may never learn sign language. The result is that the child has less ability to communicate than if the implant had not been performed. In addition, if the child has partial hearing, the implant may eliminate any possibility of later using a conventional hearing aid by impeding normal functioning of the cochlea. On the whole, decades of experience with cochlear implants in thousands of children have not borne out these worries, so resistance to implants in children is decreasing somewhat. Conventional wisdom holds that someone with a cochlear implant is still deaf, and many people with implants—children and adults alike—continue to learn and use sign language, participating actively in the Deaf culture. If cochlear implants, in a roundabout way, can promote both bilingualism and biculturalism, that may be their most compelling advantage. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/09/Cochlear_implant.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/09/Cochlear.90e45eedb0c4.mp3"
	},
	{
		"title": "Binaural Beats",
		"text": "Regular readers may recall an article here several months ago about brain machines—electronic devices that use flashing lights to promote relaxation. The idea behind these machines is that brainwaves have a tendency to fall in step with stimuli of certain frequencies—a phenomenon known as entrainment. So by flashing lights at the same frequency as one's brainwaves would have during, say, deep meditation, a machine should be able to induce a meditative state artificially. It's a fascinating concept, and there are numerous gadgets that use light or sound and light together to induce sleep, improve learning and creativity, and perform any number of other feats. In the course of my research for that article, I noticed that there were also products that claimed to produce exactly the same effect using sound alone. Somewhat skeptical, I put on some headphones and listened to one of the sample recordings. The next thing I knew, I was waking up, wiping the drool from my keyboard. A half hour had gone by and I never knew what hit me. Whatever happened, the effect was as surprising as it was impressive. Beat It I decided to investigate further. There are, it turns out, quite a few different companies selling CDs, tapes, and electronic gadgets based on the basic notion of binaural beats. Although they come in many different forms and have different claims, they all exploit an interesting quality of the brain. If you were to listen to two musical instruments playing the same note, but slightly out of tune with each other, you may perceive a sort of warbling or vibrato effect. These cyclic pulsations are called beats, and within a small range of tunings, they get faster the farther apart the two notes are. (If the instruments are perfectly in tune, the effect is absent, and if they're really far out of tune, then you simply hear two different notes.) It turns out that you can get exactly the same effect if you play a tone in one ear and a very slightly lower- or higher-pitched tone in the other ear. Listen to either sound individually, and it sounds normal—but listen to both together and you perceive the beats. In other words, this effect is not an acoustic one, but is produced by the brain. The human auditory apparatus can hear sounds with a pitch as low as about 20Hz (Hertz = cycles per second), give or take a few Hertz. However, the frequency of brainwaves—particularly those associated with states of relaxation and sleep—can go much lower, even below 1Hz. So a recording of a sound at, say, 4Hz would be inaudible and would have no effect. However, if you pitch two sounds exactly 4Hz apart (say, one at 100Hz and the other at 104Hz) and play one in each ear, the brain “manufactures” a 4Hz beat. And, all things being equal, the brain will then strongly tend to fall into sync with that frequency, producing the same sort of subjective sensation as sleep. Conveniently, the range of frequency differences that can produce an audible beat corresponds roughly to the range of frequencies dominant in the brain during the sorts of relaxed states most of us enjoy. Mixed Notes Of course, plain out-of-tune tones aren't especially interesting to listen to, so most publishers of binaural beat CDs mix in other sounds such as rain, waterfalls, bells, gongs, and so on. In some cases, these extra sounds completely hide the beats so that the listener is unaware of them consciously, but they still register in the brain and have the same effect. It's not at all difficult to record these sounds on a CD—perhaps in a progression from faster to slower beats—and numerous companies do. There are also computer programs you can download that do the same thing, and even a keychain-sized electronic gadget that looks like a digital music player but actually produces binaural beats. These recordings and devices are sold as aids for meditation, relaxation, or self-hypnosis—and even as a legal “digital drug.” The prices range from almost nothing to thousands of dollars for a multi-year program of customized recordings. Although each company puts a unique spin on its particular method or formula, it's virtually impossible to make fair comparisons because what you have to judge is ultimately a subjective experience. That US$15 CD might produce an effect that, for you, is just as good as what you'd get by spending several hundred dollars—then again, it might not. It's reasonable to expect better and more reliable results from larger companies that employ neuroscientists and psychologists and do actual testing of their products' effects on human brainwave patterns. I have invested only a little time—and no money—into a few limited experiments on myself with binaural beats. My results have been modest at best—perhaps I get what I pay for. Still, my experience suggests that this technology has a lot of potential. And it's certainly a lot less goofy-looking than sunglasses with blinking LEDs mounted on the inside. So the next time you see someone on the train wearing headphones and apparently zoned out, remember: you might be looking at a great spiritual master in training. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/09/brain-1.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/09/Binaural.f5682004d2c0.mp3"
	},
	{
		"title": "Push Hands",
		"text": "Most people who have heard of t'ai chi know it as a gentle, flowing set of movements that senior citizens do in the park on Sunday mornings. At first glance, it doesn't even appear to be a martial art, in that each person is doing the same movements without coming in contact with anyone else, like some sort of slow-motion, silent line dance. The solo form, however, is just one aspect of t'ai chi. This sequence of postures is designed to strengthen the legs, improve posture, balance, and circulation, and teach the basic principles of shifting weight, relaxing, and remaining rooted. For all its benefits, though, this aspect of t'ai chi is just the beginning for serious practitioners. What many t'ai chi enthusiasts find most interesting about the art is a two-person exercise known as push hands (sometimes referred to as “pushing hands,” as it sounds more grammatical in English). Resistance Is Futile Push hands is sort of like a gentle, cooperative game, or perhaps a cross between dancing and sparring. The basic idea is to maintain your balance while causing your partner (not “opponent”) to lose balance. However, the one who loses balance is actually the “winner” in the sense of learning more. By being pushed off balance, you become aware of areas of tension in your body, so the whole challenge of push hands is to identify and correct those areas—to relax completely. Counterintuitively, a person who is completely relaxed will be nearly invincible at push hands, because you can only unbalance someone who is tense or resisting in some way. This is much harder than it sounds, because it feels extremely unnatural to yield to, or blend with, a push rather than resisting it or fighting against it. Unlike sparring in karate or even other “internal” martial arts such as aikido, push hands typically involves very little movement. There are no kicks, punches, or throws, and it is quite rare for anyone even to fall to the ground. (When you have successfully unbalanced your partner, it is considered good form to grab his hand to keep him from falling.) Sometimes accomplished players can push someone halfway across the room with a minimal amount of energy, but this serves little purpose other than to show off. The point is not to pin or disable your partner, but rather to help him or her to relax. Becoming a Pushover What does push hands look like? In general, players stand facing each other with their hands in light contact with each other's arms. As one person's arms move, the other person follows the movements, keeping both hands in contact at all times. A player may push against the other person's arms, chest, shoulders, or waist; the person receiving the push yields by turning the waist and redirecting the pusher's arms in a variety of ways. Pushing and yielding continues in a circular fashion until one person is “uprooted,” with one or both feet losing contact with the floor; then the cycle continues. If you were to watch two skilled push-hands players in action, you may see virtually no movement, as each person gently feels for a point of tension in the other person's body to push against. All at once, someone's hand will move, the other person will stumble, and the two partners will smile and begin again. Although it doesn't look like much to someone who's never tried it, push hands is strangely addictive. Often when two strangers meet and discover they are both t'ai chi players, they will spontaneously begin pushing hands; it's almost like the t'ai chi secret handshake. At t'ai chi workshops, conferences, and retreats, it's as common to see people pushing hands as standing around having a conversation (and often both happen at the same time). Strangely, the more you get pushed over, the more you want to keep going until you've identified your area of weakness. Of course, you don't get better by trying harder; you get better by doing less—by relaxing more. You Put Your Right Foot In, You Put Your Right Foot Out Although there are many varieties of the t'ai chi form, push hands looks quite similar wherever it's taught, so students of, say, the Yang style short form can push hands with students of the Guang Ping Yang style, Wu style, or Chen style, without feeling they're playing by different rules. Nevertheless, there are a few different forms of push hands. The most common variety, especially for beginners, is fixed-step push hands (or tui shou in Chinese), in which both players must keep both feet planted in the same position the entire time. There's also a moving-step push hands (san shou), which can either follow a set, choreographed pattern or be done freestyle. The main point of doing push hands is to become more relaxed, rooted, and self-aware, not to prove your superiority over another player. There are, however, push hands competitions, in which players receive points for unbalancing their partners (or, in the case of moving-step push hands, causing the partner to step outside a marked area on the floor). Some t'ai chi teachers discourage participation in competition because they feel it's missing the point; other teachers encourage it on the grounds that it gives students exposure to more partners and styles than they would otherwise have, and promotes diligent practice. With or without competition, however, skill in push hands only comes after months or years of consistent practice. In some schools, push hands is taught along with the solo form; in other cases, teachers prefer the students to spend six months to a year learning the form and strengthening their legs before beginning to study push hands. Training usually begins with partners performing circular patterns of movement over and over—first with just one hand, then with both. After the basic moves and principles are learned, students begin doing freestyle push hands, in which both partners are free to move in various ways and push on any part of the other person's upper torso. Pushing with a variety of partners gives participants the chance to work on many aspects of their technique, as each person presents a new set of challenges and opportunities for improving one's relaxation. Pushing Your Leg There are several t'ai chi books that discuss push hands, but trying to learn push hands (or any martial art) from a book is like learning to dance from a book. Without someone to demonstrate in person and correct your mistakes, you're unlikely to get very far. I should also mention that push hands requires very strong leg muscles; it may not be enjoyable at all until you've worked at it for several months and built up both strength and flexibility. In my opinion, though, the most interesting thing about push hands is what it teaches on a metaphorical level. You may never use push-hands techniques to win a street fight, but learning how to yield to, blend with, and redirect energy without losing your balance is useful in any sort of conflict. That is, in fact, the ultimate goal of push-hands training: to achieve a level of relaxation and rootedness that will enable you to keep your “balance” in any situation. It's also part of what makes t'ai chi so powerful as a martial art: the ones who prevail are those who know the secret of meeting strength with softness rather than resistance. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/09/push_hands.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/09/Push_Hands.eb06c1fcce65.mp3"
	},
	{
		"title": "The Egely Wheel",
		"text": "In Chinese, it's called ch'i (or qi). In Japanese, it's ki. Variously translated using terms like “vital force” and “internal energy,” it is the name for a type of invisible power that circulates through the human body. It can be stimulated through acupuncture or ch'i kung (qigong) exercises, blocked by bad posture, enhanced with a proper diet, and depleted by stress, illness, and negative emotions. You can't see it, nor is it visible indirectly to the tools of modern medical science, but many people consider it every bit as real as air or blood. I've been aware of this concept for many years, and it's mentioned at least a few times in every t'ai chi class I take. Although my teacher may talk about ch'i as though it's tangible, I've always thought of it as a metaphorical way of discussing a bundle of abstract concepts—a useful fiction, in other words, just like “spirit” or “love” or “peace.” No one claims to be able to locate someone's spirit physically within the body, but it's nevertheless a handy word for talking about certain notions that are not quite covered by more mundane terms such as “brain” or even “mind.” The Ch'i Tricorder Imagine my surprise and bewilderment, then, when at a t'ai chi retreat several years ago, the instructor pulled out a small, strange-looking plastic box with blinking LEDs and told us, matter-of-factly, that it was a device that measures ch'i. On the top of the box was a gearlike wheel, giving the device the overall look of a miniature, high-tech phonograph. Supposedly, when you bring your hand near the device, this wheel spins faster or slower depending on the amount of ch'i you have. It's called an Egely Wheel, and for a mere US$150 or so, you too can have your very own. During a break, I tried the machine out myself. I tried holding each of my hands in turn near the device, but the wheel did not spin. I tried concentrating, mentally directing energy at the device…still nothing. Then I tried relaxing and casually intending the wheel to move. Again, nothing. Various other people tried it too—sometimes the wheel moved, sometimes it didn't, even for the same person. But no one appeared to be able to spin the wheel very fast, regardless of their apparent proficiency in t'ai chi. One explanation, of course, is that our ch'i wasn't very strong. The more tempting explanation is that the device doesn't actually measure anything. The Spin Doctor The Egely wheel is the brainchild of Hungarian scientist Dr. George Egely. According to Egely, he discovered that small objects (such as a small strip of foil) floating in a bowl of water rotated when someone's hand was held nearby. He initially attributed this effect to heat radiated from the bodies or small air currents generated by breathing, but found that even when shielded from heat or wind, the floating strip exhibited the same effect. His conclusion was that some other, previously unmeasurable energy was causing the motion—namely, ch'i. Egely realized that because the effect was so subtle, it could only be shown by something with extremely low friction, so he developed what he calls a Vitality Meter based on a very lightweight wheel with a specially designed low-friction pivot. As for the electronics, those are used to provide a visual and/or audio indication of the wheel's speed; if you actually look inside the case you'll see that there's no motor—in fact nothing connecting physically to the wheel at all. Now, supposing for the moment that this principle really does represent a display of ch'i, it's not at all apparent to me how a $150 gadget is better than a toothpick floating in a bowl of water. Money aside, though, I can't say I'm convinced that such motion—to the extent that it does occur with subjects who are obviously more talented than I am—isn't caused by something quite simple. If not heat or air currents, my guess is that the wheel is responding to vibration. Because it has such low friction, even a tiny amount of vibration (from someone walking nearby, say), could conceivably cause it to move. Any number of devices, from self-winding watches to perpetual-motion machine wannabes, are simply clever machines that convert lateral or vertical vibration into rotation. Quite plausibly, even a vibration too weak to be felt by a person could produce motion in a wheel; nothing mysterious there. When you get right down to it, I can no more prove that ch'i isn't moving the wheel than that there's no such thing as a unicorn. But I really don't buy it. If there is even such a thing as ch'i, I have no particular reason to expect it would cause an object nearby to rotate. On the other hand, if I needed some way of assessing my mental or physical health other than introspection, there are any number of gadgets I could buy for that same $150 that would tell me things I find genuinely useful, such as my body temperature, blood pressure, skin resistance, or brainwave activity. And saving money definitely enhances my ch'i. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/09/egely_weel.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/09/Egely.c08199ac6fce.mp3"
	},
	{
		"title": "Quantifying Despair and Depression",
		"text": "Sometimes I make jokes about the exact extent to which some event has affected my mental state. For example, my wife will walk into my office with a plate of freshly baked cookies, and I’ll say, “Wow, I’m now 7% happier!” Of course, the reason it works as a joke is that happiness (or the lack thereof) is not only subjective, it’s multifaceted—I may be ecstatic about the cookies, yet still quite unhappy about my taxes. Doctor, It Feels Like I’m Treading Water All joking aside, I wondered whether there might be some way of measuring despair. We can certainly tell if it exists or not, and whether it feels severe. But surely psychiatrists have some sort of semi-objective scale of measurement, I figured. I couldn’t imagine one doctor saying to another, “My 10 a.m. is a Venti, but with some Prozac I’m sure we can get him down to a Tall.” So I began searching for references of scales used to measure despair or depression. The first test I found was called the Porsolt Forced Swim Test (FST). This test was created in the mid-1970s by R.D. Porsolt et al., and it has been used ever since to measure despair in mice and rats. Antidepressants often affect rats in the same way they affect humans, so before human trials begin with any new antidepressant, this is one of the tests likely to be performed in a laboratory. The FST is one of the more reliable tests of an antidepressant’s effectiveness. It’s simple, if somewhat disturbing. Essentially, you put a rat in a cylinder of water for a given period of time, and measure how much of that time the rat swims compared to how long it remains immobile. The rationale is that a rat will give up trying to swim when it feels despair; rats with less despair swim longer. The test will be repeated with a given animal before and after administering an antidepressant; when a rat keeps swimming longer after treatment with a drug, this is taken as a sign of the drug’s effectiveness. If You’re Happy and You Know It, Check This Box Needless to say, the FST would not be considered an appropriate test for human subjects. Although I’m certainly no authority on the matter, one of the diagnostic tools that appears to be popular among mental health professionals for assessing one’s level of depression is called the Beck Depression Inventory (BDI). This is a straightforward 21-question test, with each question having four possible answers. For each question, the answers range from a score of 0 (no indication of depression) to 3 (strong indication of depression). Add up your score, compare it to a scale, and the doctor can get a reasonably good picture of how depressed you are. Of course, this is just one of many tools, and no responsible clinician would rely solely on the results of this test for a diagnosis. (Nor, by the way, do I recommend using it on yourself without professional interpretation. Caveat lector.) Interestingly, a “perfect” score of 0 on the BDI only indicates that you’re not depressed (or, perhaps, in denial); it says nothing about how happy you are. In fact, I haven’t been able to find any tests that purport to measure happiness with the same degree of rigor and repeatability as the BDI, probably because happiness is not normally a condition doctors need to diagnose and treat. But if you say your happiness increases by 1% for every article you read at Interesting Thing of the Day, I’ll take your word for it. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/09/depression-1.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/09/Despair.c2fce0f38312.mp3"
	},
	{
		"title": "T'ai Chi Ch'uan",
		"text": "There's nothing like a good action film, especially if it involves martial arts. Explosions and chases are all well and good, but I like kung fu better. I'll eagerly watch Jackie Chan, Chow Yun Fat, or even Keanu Reeves give the bad guys a whomping using no weapons other than physical skill and a sharp mind. In the real world, though, I find the best kung fu not in the flashy, Hollywood-friendly jumps and kicks, but in a discipline your grandmother may well practice: the slow, gentle movements of a martial art called t'ai chi ch'uan. For a westerner, the first challenge in learning about a Chinese martial art is figuring out how to pronounce it. There are several systems for representing Chinese sounds using the Roman alphabet. These varying transliterations have led to numerous spellings (“tai chi chuan,” “t'ai chi ch'uan,” “taijiquan,” etc.) and pronunciations. I'll leave the details for another article, but if you want to avoid ambiguity it's best to use the pronunciation “tai ji,” because the chi in “t'ai chi” is not at all the same thing as ch'i (or qi), a Chinese word usually translated as “internal energy.” Supreme Softness T'ai chi is based on the principles of Taoism, and its invention dates back about a thousand years. According to legend, a Taoist monk named Chang San Feng was watching a crane trying to catch a snake. Every time the bird struck with its beak, the snake would gently slide out of the way, and this defense was so successful that the crane eventually gave up. Chang remembered Lao Tzu's words in the Tao Te Ching: “The soft overcomes the hard.” This image led him to develop a fighting art based on softness, yielding, and flexibility, rather than brute force. The name “t'ai chi ch'uan” literally means “supreme ultimate fist,” a reference to the fact that it was considered the most advanced, and deadliest, form of boxing. For centuries, t'ai chi was a closely guarded secret, taught only to the members and close associates of a few powerful families. A variety of distinctive styles emerged, taking on the names of the families from which they originated. The earliest form was Chen style, which later evolved into Yang, Wu, and Sun styles, among others. Each style has distinctive movements and emphases—some are more athletic and explosive, others more gentle and flowing; some emphasize martial applications, while others focus on health, softness, and the internal movement of energy. T'ai Chi Basics The differences, however, are less important than the similarities. All forms of t'ai chi follow several basic principles, including relaxation, rootedness, separation of weight, and smooth, continuous movement from the body's center or tan t'ien. A t'ai chi student spends months or years learning the solo form, a series of interconnected postures designed to teach these basic principles, improve balance, and strengthen the leg muscles. (Depending on the style, the number of movements ranges from less than ten to more than a hundred.) Although most schools of t'ai chi don't include sparring in the manner of karate or judo, it is crucial for students to understand the martial applications of each of the form's postures. A two-person exercise called push hands—to many, the most compelling aspect of the art—helps to serve this purpose. In push hands, partners help each other identify areas of tension by trying to push the other person off balance while maintaining their own. T'ai chi training often also includes ch'i kung, exercises that develop healthy breathing skills and attention to the flow of one's energy. T'ai chi is often referred to as one of the “internal” martial arts, or neijia. In contrast with the so-called external martial arts—karate, jiu-jitsu, taekwondo, and so on—internal or “soft” martial arts focus on the movement of energy within the body. Internal martial arts do not rely on muscular strength, so hard kicks, punches, and blocks are not commonly employed. Instead, a minimum of external energy is used, and skilled practitioners blend with, rather than block or deflect, their opponents' energy. Other internal martial arts include pa kua, hsing-i, and aikido. Judging Your Progress Each school and teacher takes a slightly different approach to t'ai chi. There are no ranks or belts as there are in many martial arts, as it is considered more important for an individual to assess internal growth than to take an objective measure of skill or fighting ability. Besides, t'ai chi is a very subtle art that takes most people quite a long time to master. (As one my teachers is fond of saying, progress in t'ai chi is measured in decades.) Nevertheless, t'ai chi tournaments and competitions are quite popular. In some cases, judges grade an individual's execution of the solo form, based on adherence to the basic principles. Push-hands is also done competitively, with points given for causing one's opponent to lose balance. T'ai chi tournaments tend to have a much greater spirit of camaraderie and respect than most competitive sporting events. People take up the practice of t'ai chi for a variety of reasons. For many, health and fitness are the primary motivations. And without doubt, t'ai chi is an excellent way to reduce blood pressure, improve circulation, strengthen muscles and bones, and develop balance. Because the movements are slow and gentle, people of any age or level of fitness can participate and benefit. Other people study t'ai chi for its martial applications, and still others like to think of it as yoga in motion—a sort of moving meditation. My Two Left Feet When I first started studying t'ai chi in the mid-1990s, I didn't know anything about its history or applications, and certainly wasn't interested in learning how to fight. My initial motivation was much more mundane: I simply wanted to learn how to move my body gracefully. I had never learned to dance or been involved in sports of any kind, and I felt clumsy and out of touch with my own body. T'ai chi certainly gave me what I was looking for. I began to develop much better balance, posture, and flexibility. And as I learned more about what it feels like to move in a deliberate and graceful way, dancing and other types of movement began to feel much more natural too. The surprising thing, though, was that the most important lessons I learned from t'ai chi had nothing to do with physical movement at all. For one thing, I learned to relax much more easily than I could before, and by relaxing I developed a greater sense of equanimity and flexibility in dealing with other people. I found myself unconsciously applying the principles of softness and yielding to my conversations, and this frequently improved the outcome of arguments and other tense situations. Don't get me wrong: studying t'ai chi hasn't turned me into some sort of enlightened master exuding radiant bliss. It's just that, on the whole, I'm calmer and more agreeable than I used to be, and, I can hope, moving further in that direction. Don't Try This at Home If you're interested in learning t'ai chi, let me offer just one word of unsolicited advice: find a good teacher. Do not attempt to learn t'ai chi by reading a book or watching a video. There are many fine books and videos, of course, and these can supplement or enhance your training. But they can never correct you when your posture is incorrect—which, I can almost guarantee, will be most of the time for the first many months. No matter how hard I try to follow my teacher's instructions and example, I often find that I'm doing something wrong, usually because the wrong way is more comfortable than the right way. The tendency to do the comfortable thing rather than the right thing is even stronger when no one is watching. (No proverb intended.) In some ways, practicing t'ai chi has fed my appetite for contradiction. It's an exercise I enjoy even though I hate exercise, and it's a martial art I believe in despite my pacifist leanings. And yet, somehow, it all makes sense. T'ai chi is, after all about balance—yin and yang, inner and outer, negative and positive. Cultivating these contrasts gives me a deeper appreciation of what lies at the center. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/08/tai_chi_yang_sabre.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/08/Taichi.26e09a83dd48.mp3"
	},
	{
		"title": "The Charles Atlas Dynamic-Tension Fitness Course ",
		"text": "I’m not what you’d call a “fitness freak.” I’ve spent enough time in gyms to know how the machines work and experience the sensation of building up a sweat, and I like to do t’ai chi. I also live on a San Francisco hill, so I get an aerobic jolt just walking home from the subway. But working out for its own sake is not really my idea of a good time. My disenfranchisement with exercise goes way back. All throughout school, I was the kid who got picked on in phys. ed. classes—the last one chosen for teams, the slowest in races, the kid who couldn’t do a chin-up if his life depended on it. The shared trauma of phys. ed. embarrassments from high school strengthened my bond with my wife. When we were first dating, I asked her how she felt about exercise, and she replied, “My motto is: ‘no pain, no pain. '” A woman after my own heart. A few years ago I stumbled across an ad that made me laugh: it was one of those Charles Atlas comic-book ads from the 1930s. You know the basic idea: the skinny 97-pound weakling gets sand kicked in his face at the beach, but he can’t stand up to the bully so he loses the girl. Then he sends for Mr. Atlas’s program and one frame later, he’s admiring his new body in the mirror. He goes back to the beach, decks the bully, and gets the girl. The ad then goes on to show a photo of a smiling Charles Atlas with the caption “The World’s Most Perfectly Developed Man.” The reason I laughed at the ad was not just that it reflected a long-forgotten advertising style or that Atlas looked goofy in his leopard-skin briefs; I laughed because the ad was on a Web site, and after almost 70 years, the program was still being sold. Curiosity got the better of me and I sent in my US$50. Pages of History What I got in the mail about two months later was a slim three-ring binder with about 60 photocopied pages inside: the 12 lessons in the original Atlas program, intended to be worked through at the rate of roughly two lessons every two weeks. These could have been exactly the same pages sent out to skinny kids 30 or 40 years ago, except for the URL and e-mail address at the tops of the pages. For $50, I would have expected a slightly more modern and professional presentation, but I figured, I’m not just paying for exercise instructions, I’m paying for history. Charles Atlas was born Angelo Siciliano in 1892 and immigrated to the U.S. from Italy in 1903. He was the kid who got sand kicked in his face at the beach. He decided to do something about it, and got the idea for his special brand of isometric exercises while watching lions stretching at a zoo. After building his own physique, he saw a statue of the Greek god Atlas at Coney Island and decided to change his name to “Atlas” to reflect his new image. Several years later, he met entrepreneur Charles Roman and the two designed the formal exercise program (and its advertising campaign). Atlas died in 1972, but his company has continued selling the instructions to this day. And just what do the instructions say? The core of what Atlas is teaching would now be called Isometric Contraction—exercises in which you put tension on muscles without using machines or free weights. Instead, you’re relying on opposition from other muscles. Along with isometrics are some isotonic exercises (pushing or pulling on a weight, though in this case, all the weight comes from your own body, as in push-ups). None of this is rocket science: as you increase the amount of resistance, you build muscles, and as your muscles strengthen, you further increase the amount of resistance you’re able to supply. Atlas also talks about things like breathing, posture, and proper nutrition—though some of his diet recommendations are a bit suspicious by modern standards—and he has an entire lesson on avoiding constipation. Weight and See Fitness experts who have seen the Atlas program typically say it’s fine as far as it goes. Of course, there are some muscle groups it doesn’t address, and aerobic fitness is basically ignored. Arguably, the use of machines or weights could yield similar results more quickly or permit someone to advance further, but for people wanting to build muscles on a budget, it’s a very reasonable program. The only real problem—and the reason my arms still don’t look like Atlas’s—is that the exercises are hard. Or, perhaps I should say, they’re no easier than any other kind of exercise. Naturally, they work only if you practice them diligently over an extended period of time. When I first got the Atlas program in the mail, I did make an honest effort to follow the instructions—for about a week. Then I gave up, due to laziness, sore arms, and a lack of time and motivation. Every once in a while I think to myself, “I should actually go all the way through the program…just to see.” Perhaps one day I will. Of course, I never, ever wanted to have the bodybuilder physique; I just don’t find that body shape appealing. And for me, written instructions and the promise that I’ll be able to beat up a bully some day are not strong motivators; if I wanted to build serious muscles, I’d probably sign up at a gym with a personal trainer. Still, for all its anachronistic campiness, the Atlas program is really a pretty good idea—good enough to keep selling by the tens of thousands more than 70 years later. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/08/charles_atlas.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/08/Atlas.2570500d4939.mp3"
	},
	{
		"title": "Silent Retreats",
		"text": "In The Hitchhiker's Guide to the Galaxy by Douglas Adams, one of the main characters is an alien named Ford Prefect from a planet near Betelgeuse. Although he looks, talks, and acts more or less human, there are many things about earthlings that puzzle him, such as the fact that they seem to talk all the time—even if only to repeat the obvious. Over the course of several months, he comes up with a number of theories for this behavior, one of which I found particularly insightful: “If human beings don't keep exercising their lips, he thought, their brains start working” (p. 49). I've frequently noticed, on the one hand, that many people like to surround themselves with sound all the time (making their own if all else fails); and on the other hand, that contemplation is a foreign and uncomfortable concept to most of us. An increasingly popular way of overcoming the sound habit, at least briefly, is to go on a silent retreat. All Action and No Talk The idea of a silent retreat is simple: you go somewhere relatively quiet and don't talk—for a day, a few days, or even longer. Silent retreats usually involve a group of people, so the significant part is not so much that you yourself aren't speaking but that others aren't speaking to you. In addition, most other artificial sounds—radio, TV, music, and so on—are avoided, so that for the most part, participants don't hear any words for long periods of time. What exactly is the point of going without words for a few days? You get to hear yourself think. Other people use different language to describe this: meditation, listening to your inner or higher self, hearing the voice of God, and so on. However you wish to think about it, you are avoiding the influences of other voices in order to focus your attention inward. Just as you might step away from a crowd to have a private conversation, a silent retreat provides an extended period of time during which your thoughts can be strictly your own. Silent retreats recall the monastic tradition of vows of silence, which are still practiced today in many contemplative orders. In that context, a period of avoiding speech—which for some monks can last months, years, or even a lifetime—is a sign of humility as well as being an aid to prayer and meditation. Some people participate in silent retreats as a religious exercise or because they have a specific problem to solve or decision to make; for others, it's more of a relaxing vacation, with no real goal attached. But it's not uncommon for people to begin a retreat without any particular expectations and later find they've had a profoundly moving experience. Sound Decisions There are no fixed rules for the way a silent retreat should be structured. Often a group will schedule one or two daily sessions during a retreat with a lecture, group prayer, discussion, or some other ritual, temporarily interrupting the silence to give participants some context or direction for their contemplation. It is also not uncommon to have individual coaches, counselors, or spiritual directors meet with participants occasionally to provide feedback or make suggestions as to where attention might be focused. Even without words, though, silent retreats can have an agenda or theme. In addition to Buddhist meditation and retreats organized by various churches, I've seen advertisements for silent yoga and t'ai chi retreats, for example. Retreat centers sometimes offer do-it-yourself personal retreats as well, with or without the services of a counselor. If you look at the comments made by ordinary people who have been on silent retreats, it's striking how often they say it was a mind-blowing or life-changing event. That the simple act of going without words can affect someone so profoundly shows how unusual silence has become in ordinary life. Even for those who make an effort to avoid extraneous noise, a silent retreat can provide a more thorough and prolonged period of silence. I participated in a silent retreat myself last spring, and found it very effective in helping me to clear my mind, organize my thoughts, and make sane decisions. I look forward to my next opportunity for an extended time of silence, and heartily recommend the experience to anyone who likes to think. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/08/lake.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/08/Retreats.733545f89e52.mp3"
	},
	{
		"title": "Lucid Dreams",
		"text": "I dream that I am standing in a very unfamiliar building. Something about the strangeness of my surroundings leads me to wonder if I might not be dreaming. I decide to perform a little experiment to determine whether it really is a dream or not. There is a short flight of stairs ahead of me going down to a lower level. I know that if I jump off the top step and find I can fly, it must be a dream, whereas if land normally, it isn’t. So I jump, and sure enough, I float down to the next level. “Cool!” I think, “I am dreaming—that must mean I can do anything I want!” But I can’t decide what to do next. I try walking through some people but that doesn’t work, and after a few minutes I slip back into the unconscious world of regular dreams. Nevertheless, the experience is fascinating and exhilarating. Being able to consciously influence the course of my dream is a wonderfully novel sensation. A lucid dream is simply one in which you realize that you are dreaming. The dream I just described happened about a year ago—and it happened spontaneously, without any effort or intention on my part. Since then, I’ve read about and practiced a variety of methods for inducing lucid dreams deliberately. Although I can’t yet dream lucidly on command, my success rate has gradually improved. For me, this is a purely recreational activity, but for centuries lucid dreaming, in one form or another, has been practiced with great seriousness in certain religious and philosophical traditions. Tibetan Buddhism, in particular, has an ancient discipline of meditative techniques designed to encourage not just lucid dreaming, but a continuously unbroken state of consciousness, while sleeping and awake. Lucid Reasoning What’s so great about lucid dreaming? For one thing, it’s lots of fun. If you’re aware that you’re dreaming, you can do things that are impossible in waking life, such as flying, becoming invisible, or traveling to distant times or places. But on a more practical note, interacting with dream characters in a lucid state can help the dreamer to interpret the meanings of dreams in real time. Lucid dreams can also enable the dreamer to find creative solutions to problems, work through difficult emotional issues, and promote physical and mental healing. Many people believe lucid dreaming is a path to, or at least a necessary step toward, a form of enlightenment, and it also forms part of the training for some forms of shamanism. A researcher named Hervey de Saint-Denys introduced the notion of lucid dreaming to the Western world in his 1867 book Dreams and How to Guide Them. But the term lucid dream itself was coined by Frederik Willems Van Eeden in his 1913 paper “A Study of Dreams.” The best-known modern figure in lucid dreaming is Stanford professor Stephen LaBerge. For nearly three decades LaBerge has been studying lucid dreaming in a laboratory setting, and he proved that subjects can be taught to dream lucidly, using a technique he calls Mnemonic Induction of Lucid Dreams (MILD). To use this technique, you form a habit, in waking life, of asking yourself, “Am I dreaming or awake?” every time you encounter some common stimulus. Sooner or later you’ll encounter the same thing in a dream, and if you ask the question while dreaming, you’ll probably figure out that you’re really asleep. (Carlos Castaneda wrote extensively about lucid dreaming—though he didn’t use that term—in his books about his alleged training as a sorcerer under don Juan Matus. His trigger for lucid dreaming was his hands. He developed a habit of looking at his hands as often as possible so that he’d be likely to do that in a dream as well; on seeing his hands, he’d be reminded to consider whether he might be dreaming.) Other methods include exercises performed right before going to sleep to focus one’s attention on having lucid dreams, meditating on certain symbols or sounds, and listening to specially designed audio recordings while falling asleep. Blink and You Won’t Miss It There’s also a sophisticated, high-tech way to promote lucid dreaming. In the course of his research, LaBerge developed an electronic gadget—somewhat reminiscent of a brain machine—called the NovaDreamer. The NovaDreamer includes a soft mask that you wear to sleep; sensors above the eyes detect when the wearer enters REM sleep, the state in which dreaming occurs, and then activate a flashing light or a sound. The idea is that the user will notice the light or sound inside the dream, remember what it means, and enter a lucid dreaming state. This device is apparently quite effective—as well it should be, considering its price of US$500. Regardless of the details of one’s approach, anyone who tries to incubate lucid dreaming will end up wondering, on increasingly regular occasions, “Is this real? Could I be dreaming?” And this is what so many people find fascinating about the notion of lucid dreams: if dream reality is as convincing as waking reality, how do we really know that waking reality is not itself a kind of dream? Of course, we don’t: this has been one of history’s great philosophical questions from the time of Plato through The Matrix. But learning to influence the course of your dreams can lead to skills that may help you to exert similar influence in waking life. Whether that turns out to be yet another dream or not, a little extra awareness and control surely can’t hurt. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/08/Hypnos_and_Thanatos.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/08/Lucid.36095df5ce57.mp3"
	},
	{
		"title": "Iris Scans",
		"text": "How many passwords do you have? For the average computer user, the number can range from dozens to hundreds. It seems like every time I turn around another Web site asks me to come up with a password; I need them to get access to bank accounts, utilities, discussion boards, travel reservations, and countless other services. Security experts tell us that you should never use the same password twice, that passwords should never contain words found in a dictionary, and that they should include combinations of upper- and lowercase letters, numbers, and special characters such as punctuation. Wow. I try to follow this advice for the most part, but the more secure and diverse I make my passwords, the harder they are to remember. A forgotten password is useless, and if I write it down, I take a risk that someone will find it. As long as someone can guess or steal my passwords, my money and important data are vulnerable. The same goes for PINs used to get money from ATMs or codes used to unlock doors and gates. A few months ago I needed to make a deposit into a bank account I rarely use, and although I had my card with me, I had forgotten my PIN and had to return home to look it up on the notice my bank sent me way back when. My money was safe, all right—even from me! The basic question a password attempts to answer is: Are you who you claim to be? I can walk up to a bank teller with a name and account number, but if the teller doesn't know me personally, he has to have some way to confirm my identity. Photo ID and signatures are often used for this purpose—on drivers' licenses, passports, credit cards, and checks. But photos and signatures are relatively easy to forge, and they do little good when conducting business over the Web. This is why, increasingly, companies and governments are turning to biometric data—measurements of some aspect of the body—to solve problems of identification and authentication. The best-known form of biometric data is the fingerprint. Fingerprints are unique from person to person, and therefore a good indicator of one's identity. Fingerprints can be scanned electronically, too, so it should be fairly easy for a machine to use a fingerprint to identify someone. Unfortunately, some fingerprint scanners can be fooled in one way or another, and although newer models run additional checks to make sure the finger is—ahem—alive and attached to a body, there is always going to be a certain fear of password amputation. Furthermore, a cut or burn on your finger can throw off a fingerprint scan, and a small percentage of people have no readable fingerprint at all. For these reasons, other means of biometric identification are being developed. Fingerprints, after all, are not our only unique features. Hand geometry, facial structure, voice patterns, and other characteristics can be measured by a machine to help identify a person. But the latest word in biometrics is the iris scanner. The Eyes Have It The human iris has more individuating characteristics than a fingerprint, meaning the mathematical probability that two people could have exactly the same pattern is much, much smaller. Your left and right irises are also different from each other, and even identical twins have distinct iris patterns. All this means that iris recognition should be, in theory, virtually 100% accurate. Perhaps just as important as accuracy is convenience. Unlike a fingerprint scanner, an iris scanner does not require contact. In some cases you can be standing several feet away. To oversimplify somewhat, an iris scanner consists of a special digital camera that focuses on your eye and snaps a picture. The meaningful patterns of iris variation are then extracted from the picture and compared against the patterns stored in a database. All this happens in just a few seconds. So instead of inserting a card, punching in a password, or flashing your photo ID, you can identify yourself almost instantly simply by looking in the right direction. Nothing to carry, nothing to remember. If this sounds like the answer to all your password problems, that could very well be the case…eventually. The current crop of iris scanners has not yet achieved anything near their theoretical accuracy, and they can sometimes be thrown off by very dark brown eyes—or even by tears, long eyelashes, or contact lenses. As developers iron out the bugs, iris scanners are likely to become much more common in banks, airports, and other businesses, not to mention desktop computers. Looking for a Bargain? However, iris scanning can also be put to more nefarious uses. As the technology improves, iris scanners will be able to identify you from greater distances—and potentially without your knowledge. In the film Minority Report, people of the not-too-distant future are bombarded by customized billboards and advertising, targeted at them based on surreptitious eye scans. This is not even slightly far-fetched. More worrying, the fictional government of the film tracks the identities and whereabouts of all its citizens by frequently scanning their eyes, leading to a creepy, Big Brotherish atmosphere that is all too easy to imagine. On the other hand, we probably don't need to worry that someone could remove one of our eyes and use it to fool a scanner. Even today, iris scanners can check for appropriate pupil contraction as a safeguard. The iris is not the only part of your eye that can be scanned to provide biometric identification. The technology to perform retina scans has been around even longer, and depending on whom you ask, is sometimes considered even more accurate than iris scans. But retina scans are harder to perform because the camera has to be very close to the eye. Retina scans also require more elaborate and expensive equipment, not to mention greater patience and cooperation from the person whose eye is being scanned. Come to mention it, “person” is too narrow a word when it comes to iris scanning. The technology is now being used as an alternative (or, in some cases, a supplement) to branding or tattooing as a means of identifying horses and cattle. Apart from the challenge of getting livestock to hold still and look at a camera for a few seconds, iris scanning is just as effective on non-human eyes. And I say it's about time: if you've ever seen a cow struggling to use an ATM, you know the importance of better accessibility. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/08/Humaniris.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/08/Iris_Scans.ff4ae63493ce.mp3"
	},
	{
		"title": "Bionic Eyes",
		"text": "As a kid in the mid-'70s, one of my favorite TV shows was The Six Million Dollar Man. When astronaut and test pilot Steve Austin was critically injured in a plane crash, government scientists decided to replace his damaged body parts with electromechanical equivalents, making him the first bionic (or cybernetic) human. The cost for two new legs, a right arm, and a left eye turned out to be $6 million, but for that price Steve Austin was able not merely to walk again, but to outrun cars, lift enormous weights, and see faraway objects with a built-in zoom lens. The decisive statement, which we heard as a voiceover at the beginning of each week's episode, was, “We can rebuild him. We have the technology.” Even though I knew the show was science fiction, I assumed we really did have the technology back then, or at least something close to it—and that the cost was the main reason people weren't being fitted with bionic limbs on a regular basis. Of course, cost aside, we didn't then, and still don't, have the ability to come anywhere near that sort of body-part replacement. Medical science has made great advances in the development of prosthetic limbs, and perhaps someday, decades from now, amputees will be able to receive something like Steve Austin's bionic arms and legs—though I wouldn't count on superhuman strength and speed. But the eye…that's another story. Even today, restoring sight to the blind seems like the province of myth and science fiction. In many ways, it's a much harder problem to solve than creating an artificial arm or leg, but researchers are making significant progress, and the reality of a bionic eye may not be so far-fetched after all. Spare the Rod In a healthy eye, the rods and cones on the retina convert light into tiny electrochemical impulses that are sent through the optic nerve and into the brain, where they're decoded into images. If the retina no longer functions correctly—due to conditions such as retinitis pigmentosa or age-related macular degeneration—the optic nerve can be given information from an artificial source. Capturing images and converting them into electrical signals is the easy part; every day a new digital camera appears that's smaller, more powerful, and cheaper than what you could buy yesterday. The much trickier part is wiring the input into a person's nervous system. Retinal implants currently being tested pick up radio signals from a camera mounted on a pair of glasses and then directly stimulate the nerve cells behind the malfunctioning rods and cones. The current state of the art in retinal implants of this type is fairly low-resolution, though, and it does require that electronic apparatus be worn whenever the person wants to see. A more advanced approach places an array of microphotodiodes—think of them as miniature solar cells—directly onto a retinal implant. When light hits them, they generate electricity, which then directly stimulates the retinal nerves. This eliminates both the camera and the need for an external power source. Several clinical trials have already taken place, with very encouraging preliminary results. Meanwhile, NASA scientists are creating a similar implant using photosensitive ceramic films. Unlike silicon, ceramic does not degrade when exposed to the fluids inside the eye, and the ceramic implants are also porous—allowing nutrients to flow through them to the cells on the other side. The Matrix Revisited But what if the eye is missing altogether, or the optic nerve is damaged? When retinal implants are not possible, one option is to implant electrodes into the brain that can stimulate the visual cortex directly. This highly experimental procedure has been performed a few times, and as brain surgery goes, it's relatively safe. It does require wires to protrude from the skull to provide power and data for the implants, but the real challenge is how to figure out which precise locations in the brain to stimulate to produce specific visual impressions. Neurons in the brain are not arranged in a convenient grid like a camera's sensor, so each patient must undergo extensive testing to figure out which electrodes should fire in response to which input from the camera. Even after all that, the net result is that the patient perceives a field of less than 100 points of light (called phosphemes). By comparison, a single character on your computer screen contains many more dots than that. Although the patterns created by those dots can help someone to avoid obstacles or identify when the light is on, they come nowhere near the point of enabling someone to read or recognize faces, to say nothing of distinguishing colors or fine detail. A much different approach to artificial sight, and one that requires no surgery at all, has been developed by Dr. Peter Meijer of Philips Research Laboratories in the Netherlands. It's called the vOICe system—the three middle letters are capitalized to stand for “Oh, I see.” This system uses a small video camera mounted inside a pair of sunglasses or on a helmet, along with a computerized processing unit. It translates visual images into sounds, which are then fed through stereo headphones. As the user comes to associate certain kinds of sounds with corresponding shapes and motions, the effect is much like an artificial synesthesia, a phenomenon in which someone's senses are crossed in such a way that stimulus of one sense causes perception in another—tasting shapes, seeing sounds, and so on. Over time, the brain comes to accept the auditory data as a substitute for visual data, although the subjective impression is still much less detailed than regular vision. None of the technologies currently in development provides even 20/20 eyesight, much less the high resolution, automatic zoom, and night vision of Steve Austin's bionic eye. But when it comes to curing blindness, something is definitely better than nothing—and we're heading in the right direction. Nowadays the most fantastic thing about the bionic man seems to be the price tag. Only $6 million? Now that's science fiction. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/08/eye.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/08/Bionic.ef9b9b8b4e27.mp3"
	},
	{
		"title": "Lichens",
		"text": "There are some things in the natural world I tend to take for granted, but that reveal true surprises when I look at them more closely. Such is the case with lichens. I've known about lichens since childhood, but it turns out I never really knew anything about them at all. I always assumed they were like mosses, vegetable-like things that grew on the ground, rocks, and trees. In fact, lichens are not even one organism; they are a delicate balance of fungi and algae (and in some cases, cyanobacteria) that coexist in the form of what we see as a lichen growth. More than this astonishing fact, a study of lichens reveals many other surprises, including examples of their extreme hardiness, the myriad of uses to which they are often put, and the fascination they once inspired in a beloved literary figure. I've learned that there is much more to lichens than meets the eye. One is the Hungriest Number On the most basic level, lichens exist to fill a need for certain types of fungus. Because fungi are unable to produce food for themselves, they have adapted to take advantage of whatever opportunities they find to gather it, either becoming parasites on other organisms or gaining nutrients from decomposing matter. In the case of lichens, fungi use the photosynthesis abilities of algae and/or cyanobacteria to access nourishment. The fungus makes up most of the bulk of a lichen, with the algae or cyanobacteria cells interspersed amongst so-called “fungal filaments.” Because these cells contain chlorophyll, they are able to convert water and carbon dioxide into fuel for the lichen. In return, the fungus acts as a protective covering for the algae and cyanobacteria. In this way, the two (or more) organisms have a symbiotic relationship. It is estimated that lichens cover about eight percent of the world's land, and can be found pretty much everywhere there is a stable surface and adequate sunlight. They often grow on surfaces that other organisms would find inhospitable, such as desert sand, bare rock, and arctic tundra. Their four basic forms are: crustose (flat, scaly growths); squamulose (pebble-like growths); foliose (resembling leaves); and fructicose (tube-like branches). Lichens grow extremely slowly, sometimes less than one millimeter per year, and for this reason are helpful to scientists trying to date glacial retreats and other disturbances in the geological record. Lichens serve as a major food source for many types of animals, including deer, caribou, and reindeer (hence the lichen that's misleadingly called “reindeer moss”). In addition, some bird and squirrel species use lichens not only as material for building their nests and burrows, but as food (handy in the winter when nothing else is available). Lichens have sometimes been eaten or brewed as tea in some cultures, but the use of lichens for their decorative and medicinal purposes has been much more common in human history. Their unique usefulness is a result of their adaptive abilities; in response to environmental challenges or to deter predators, lichens of different kinds have created more than 500 biochemical compounds. Dyes made from lichens were once commonly used in coloring textiles and continue to be used for preparing litmus paper. Some lichens have been found to have antibiotic properties, and are used as medicinal remedies in various parts of the world. Since they can be extremely sensitive to environmental conditions, lichens have even been used to detect levels of air pollution in Europe and North America. A Perfect Licheness An interesting footnote in the story is the involvement of the famous children's author and illustrator Beatrix Potter in the early study of lichens. Best known for beloved works such as Peter Rabbit and The Tale of Two Bad Mice, earlier on in her career Potter was commissioned to create scientific drawings of biological specimens, including fungi and lichens. She became so interested in these organisms that she wrote her own scientific treatises on them, and in fact was the first to propose that lichens function as a symbiosis between fungi and algae cells. While she enjoyed her study of lichens, the success of her literary works eventually overshadowed this pursuit. Lichen Strikes Again Out of all the interesting facts about lichens, I think the most impressive is their extreme hardiness in harsh conditions. For example, lichens can dry out entirely, but then be restored to their original condition once they take on water again. This ability has served them well in regions where water can be scarce, such as deserts and polar regions. Putting lichens to the ultimate test, the European Space Agency ran an experiment in 2005 that is mind-boggling in its implications. Researchers directly exposed specimens of two different species of lichen to open space for 14.6 days before returning them to Earth (the lichens were shielded during re-entry). Despite their exposure to the vacuum of space, cosmic radiation, full-spectrum UV light, and intense temperatures, the lichens survived and were able to undergo photosynthesis as before. The success of this experiment may one day help researchers discover the viability of transferring a form of life to other planets such as Mars. Lichens truly are amazing; with their incredible adaptive abilities, they have managed to thrive in the most barren of settings on Earth, and can even endure the severe conditions of outer space. The unique partnership of fungus with algae (or cyanobacteria) has benefited both organisms; in the case of lichens, two really is better than one. —Morgen Jahnke ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/08/lichens.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/08/Lichens.284dd15a0a49.mp3"
	},
	{
		"title": "Mondegreens and Eggcorns",
		"text": "One of the very first things I remember learning in school, around age five or six, was the patriotic song “My County Tis of Thee,” which all the children would sing every morning after reciting the Pledge of Allegiance. At that point, we hadn't yet been taught how to read—priorities, you know—so we learned the words by listening and repeating. That was fine, except that I was confused about the very last word of the song. The way I heard the last line was, “from every mountainside, let free dumring.” I didn't know what a dumring was, and I wondered about that, fleetingly, every time I sang the song for years afterward. Clearly it was someone, or something, that had to be “let free,” which I assumed was the same thing as “set free.” Maybe a dumring was a slave or something. I had no idea. For whatever reason, it never occurred to me that I might be singing two separate words (“dumb ring”), although that would have been equally nonsensical. I must have been well into my teens before I saw the lyrics in print for the first time, and I was utterly shocked to discover what I'd actually been singing: “let freedom ring.” In my defense, my five-year-old self wouldn't have identified freedom as something that could ring. But I certainly did feel stupid for having misunderstood those words. Greens, Eggs, and Corn I've run across numerous other instances of lyrics being misheard, sometimes with very funny implications. For example, I know someone who grew up thinking the hymn “Lead On, O King Eternal” was actually “Lead On, O Kinky Turtle”! Just a few months ago, I learned that there's a linguistic term for exactly this type of misunderstanding. It's called a mondegreen. That term was coined in 1954 by a writer named Sylvia Wright, who wrote an article for Harper's Magazine describing how as a child she'd misheard a line from a poem. The actual text was “And laid him on the green,” but she'd understood it to say “And Lady Mondegreen.” In context, that alteration significantly changed the meaning of the poem, as it implied the mysterious and undeserved death of this hitherto unmentioned woman. Thus, “mondegreen” itself started out as a mondegreen, and Wright went on to give several other examples of this phenomenon from music and poetry. Closely related to the mondegreen, yet subtly different, is the eggcorn. The term comes from a report of a woman who referred to acorns as “egg corns,” having made a reasonable but incorrect guess about the spelling of the word based on its sound and the fact that an acorn, like a corn kernel, is a kind of seed and could be considered roughly egg-shaped. In a 2003 discussion on a linguistics blog called Language Log, linguist Geoffrey Pullum suggested that the expression “egg corn” itself was as good as any to describe this phenomenon for which no other term seemed to fit. The name stuck (sometimes spelled as two words, sometimes as a single word), and already, after only a few short years, it has been mentioned on tens of thousands of Web pages. Hundreds of eggcorns have been catalogued, including “by enlarge” (or “by in large”) for by and large, “for all intensive purposes” for for all intents and purposes, “French benefit” for fringe benefit, “lack toast and tolerant” for lactose intolerant, and “tow the line” for toe the line. In most cases, the eggcorn is extremely close in pronunciation to the correct term, but it's not a mere matter of misspelling a homophone; the eggcorn's faulty etymology makes some sort of sense. For example, you might not be able to articulate what's French about a “French benefit,” but one could easily imagine that if there are French cuffs and French fries, there are also “French benefits.” Errors Aplenty There are now numerous Web sites that exist solely to collect mondegreens and eggcorns; like malapropisms, they've officially achieved linguistic fad status. But considerable confusion still exists as to what makes the two phenomena different from each other—or from folk etymology or malapropisms, for that matter. As I understand it, mondegreens are restricted to verse—either spoken or sung. So a mondegreen could conceivably be an eggcorn, but only if the mistake is etymologically defensible in some fashion. Both mondegreens and eggcorns, however, are normally thought of as mistakes by individual speakers that don't affect the language as a whole. Folk etymology, on the other hand, is a mistake in which one language borrows a word from another, but changing it in the process to reflect the new language's assumptions—for example, turning cucaracha into “cockroach.” And malapropisms are sort of the reverse of eggcorns; they're primarily unintended speech errors rather than ongoing errors of comprehension. This is perhaps an appropriate time to reiterate that although English now has yet another term that means “the wrong word,” there's still, as far as I know, just one that means “the right word.” That term is aproposism, which I coined even before the word eggcorn appeared. Sadly, although eggcorn might be an aproposism, aproposism is no eggcorn, having so far done very little to propagate itself. It's been a “tough road to hoe,” but I'm taking it with “a grain assault.” —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/08/Mondegreens.feb2e5a01268.mp3"
	},
	{
		"title": "National Novel Writing Month",
		"text": "Like many authors, I have a “vanity shelf” in my home, with copies of all the books I've written (or contributed to). Well, at least it contains copies of all the printed books I've written—a lot of what I've done in recent years has been in the form of ebooks and magazine articles. Among the 11 titles currently on that shelf are several recent books about Mac software, a bound copy of my Master's thesis, and even—no kidding—a copy of Arnold and Sam, the Two Dragons, which I wrote in October 1974 at age 7. This 12-page book was my first work of fiction, and it was as bad as you might imagine, but I was understandably proud of it at the time. My mother typed it up, my dad photocopied it, and my elementary school library even kept a copy on its shelves, with cover art hand-drawn by the author. By the time I left that school a few years later, it had been checked out nine times, only a few of which were by me. In November 2005, I made my second attempt at writing fiction. I participated in National Novel Writing Month, which has been held annually since 1999. Along with more than 59,000 other aspiring novelists, I attempted to write 50,000 words of fiction between November 1 and November 30. I was one of almost 10,000 participants who reached that goal. However, what I wrote during that month is not sitting on my vanity shelf. I've declined requests to read it even by close friends and family members, who will love me regardless of how bad my writing is. In fact, I haven't even looked at it myself since then. It's so bad that it makes Arnold and Sam look like literary genius. And I don't merely mean that it needs a few rewrites and a thorough going-over by a good editor. It is profoundly, utterly, and irredeemably awful. Humanity will be better off if no one ever sets eyes on that manuscript again. Novel Ideas And yet, say the organizers of of National Novel Writing Month—or NaNoWriMo, as it is known among its participants—I did exactly the right thing: I sacrificed quality for quantity. If you're going to write a novel in 30 days, something has to give. But even if your novel is terrible, you can call yourself a novelist. The following year, you can breezily mention that you're working on your second novel. And you can hold your head up high as you hobnob with other novelists, having accomplished a truly remarkable task—even if you accomplished it rather poorly. After all, so did most everyone else. The important thing is that you got it done, proving to yourself that you can make it through a process that has stymied and frustrated countless authors in the past. NaNoWriMo began in the summer of 1999 when Chris Baty, a freelance writer living in Oakland, California, decided for no particular reason that he needed to write a novel in a month and invited a group of friends to do so too. That July, 21 people set out to write novels, and six, including Baty, finished. By “finish,” I mean they wrote 50,000 words of fiction. Baty had decided on that figure after picking up the shortest novel on his shelf—Brave New World—and doing a rough word count. Most novels, to be sure, are considerably longer, but 50,000 words, or about 175 pages, seemed to be just long enough while being achievable for the average writer in 30 days. The following year, the event moved to November and, thanks to word of mouth, attracted 140 participants. But in 2001, after newspaper articles and bloggers started covering NaNoWriMo, participation ballooned to 5,000. The number of novelists has continued to rise each year; people from all over the world write novels, in a variety of languages, each November. The experience is oddly addictive, too; a sizable majority of participants from any given year repeat the undertaking again and again. NaNoGrams NaNoWriMo is about much more than simply sitting at your computer in a quiet corner somewhere and typing out 50,000 words; it's about being part of a huge number of people doing something challenging. In order to connect all the participants to each other, keep track of how many people are writing, and confirm reaching that magical word count, every novelist is asked to sign up (at no cost) on the NaNoWriMo.org Web site. In hundreds of cities around the globe, novelists schedule regular write-ins at cafés and bars to encourage each other as they write. In addition, online forums are abuzz all during the month as the writers seek and give advice, brag or complain about their word counts, and try to maintain enough collective enthusiasm to get everyone through the month. There are also numerous kick-off (and “Thank God It's Over”) parties, and in some places, even weekend novel-writing retreats. When you're finished with your novel—or at any point in the process—you can upload your text to the NaNoWriMo servers for a single purpose: to use its automated word count validator. You can, if you choose, post a short excerpt from your novel on the site, but no one on the NaNoWriMo staff actually reads your work. (In fact, they go to great lengths to assure your privacy.) At the end of the month, what you do with your novel is up to you. Needless to say, even highly experienced writers are unlikely to churn out anything more than a first draft in a month; further work on the novels, at one's own leisure, is encouraged. In some past years, March has been designated National Novel Editing Month, or NaNoEdMo, and thanks to the work of another group, December is now National Novel Finishing Month, or NaNoFiMo—for those writers who get on a roll and simply aren't ready to stop on November 30. In one way or another, a number of NaNoWriMo participants have gone on to hone their works and get them published; many, however, have no aspirations to be professional novelists and do the writing just for the experience of it. Light Reading Given the tens of thousands of annual participants, NaNoWriMo has evolved from an informal project managed by a few friends in their spare time to a full-blown nonprofit corporation called The Office of Letters and Light, complete with a paid staff and an actual office. The organization is funded through voluntary donations by participants; 50% of any amount over their break-even point is donated to build children's libraries in southeast Asia. In 2005, for example, the program raised $14,000 for new libraries in Laos and Cambodia. The Office of Letters and Light is even expanding into new programs, such as Script Frenzy! (a project in which participants write a screenplay in a month). Chris Baty's motivational book about novel-writing, No Plot? No Problem!, is popular among NaNoWriMo participants, stressing as it does the importance of getting through the process without worrying about whether the writing is any good. Speaking for myself, not having any notion of a plot my first time around actually was a problem. Not only did it mean I ended up with something that—let me repeat—must never again be read by anyone, but it meant that as I was writing, I found it hard to generate much enthusiasm; I simply didn't care enough about the story I was writing for it to be an interesting process for me. However, that experience also taught me some valuable lessons, and I fully expect that, armed with a clearer notion of what kind of story I want to tell, I'll participate again. And if, some day in the distant future, I'm better known as a novelist than as a technical writer, I'll have NaNoWriMo to thank for it. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/08/books-1.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/08/NaNoWriMo.bd4d0a141c.mp3"
	},
	{
		"title": "Portmanteau",
		"text": "One of the great things about language—any language, but I'm thinking especially of English—is how badly you can mangle it and still be understood. All spoken language has a certain amount of built-in redundancy, so you can figure out, for example, what would have come at the end of this sentence if I'd bothered to… And the same is true at the level of individual words. If I say “gonna” instead of “going to” or “kinda” instead of “kind of,” you'll still know exactly what I'm trying to say. What Isn't in a Word When I was studying linguistics, I ran across quite a few terms that refer, in one sense or another, to missing sounds (intentional or otherwise). Here are a few examples: * contraction: a word formed from two or more other words, as in isn't from “is not” or it's from “it has” * elision: the omission of a sound (or a syllable or even one or more words), often to make pronunciation easier, as in in ‘n' out from “in and out” or ‘cause from “because” * aphesis: the loss of a vowel sound at the beginning of a word, as in ‘bout from “about” * ellipsis: the omission of words from a phrase that are implied by the context, as in “I like wine better than beer” from “I like wine better than I like beer” (Surprisingly, I have not been able to find a term that generically refers to any case in which sounds are dropped. I believe there used to be such a term, but it was gradually shortened to the point where it has no sound at all.) But there's another linguistic phenomenon I find more interesting than any of these: the blend. A blend is similar to a contraction, except that the component words are mixed in a way that ignores the language's usual grammatical rules for contractions—and usually, gives greater importance to similar or shared sounds than to meaning. (So a blended word can't always be linearly deconstructed into morphemes, or meaningful segments.) The most common examples of blends are ones in which the beginning of one word is stuck onto the end of another, as in smog (from “smoke” + “fog”), brunch (from “breakfast” + “lunch”), and motel (from “motor” + “hotel”). Packing Up Words Lewis Carroll was particularly fond of blends, and he used them extensively—especially in his poem “Jabberwocky.” In Through the Looking-Glass, and What Alice Found There, Carroll coined a term for his special variety of blends: portmanteau. Humpty Dumpty says, “Well, slithy means lithe and slimy…You see it's like a portmanteau—there are two meanings packed up into one word.” The “portmanteau” Carroll was referring to is a type of suitcase that's hinged in the middle and opens into two equal parts; it comes from the French word porter (“to carry”) + manteau (“coat”). (The plural—I'm sure you were wondering—is portmanteaux.) Linguists, meanwhile, did not adopt this usage (since they already had a perfectly good word to describe this phenomenon) but they do use the term in a more restrictive sense. The linguistic sense of portmanteau is a single-morpheme word that substitutes for (and functions grammatically as) two morphemes. The canonical example, coincidentally from French, is the word du (“of the,” masculine singular) which is used instead of de (“of”) + le (“the,” masculine singular). You may sometimes hear portmanteau words referred to descriptively (if somewhat inelegantly) as frankenwords. Some other well-known examples include chortle (“chuckle” + “snort”), guesstimate, infomercial, edutainment, and televangelist. And even some well-known verbal blunders are cases of portmanteau (misunderestimate, anyone? ). One of my favorite examples is the word intertwingle—a portmanteau of “intertwine” and “intermingle”—which one of my editors uses when she wants to tell me that I've written a sentence or paragraph that mixes two concepts that should properly be separated. The great thing about intertwingle is that besides being a portmanteau itself, it describes a higher-level, semantic portmanteau effect. Many portmanteau words are coined with humorous or ironic intent, and later become absorbed into the language as legitimate entries in the dictionary. If it's good enough for the digerati, it's good enough for me. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/08/Rapicasso.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/08/Portmanteau.78808fdfbdc3.mp3"
	},
	{
		"title": "Tag Questions",
		"text": "People who want to make fun of the Canadian dialect of English invariably start with one of its two most idiosyncratic features. The pronunciation of the diphthong “ou,” of course, is one of them—in words like out and about, Americans exaggerate both the gliding and rounding of the vowels so that it sounds like the “ow” in power, whereas the stereotypical Canadian pronunciation is closer to oat and a boat. I know lots of Canadians who protest this characterization, pointing out that Americans butcher the language much more egregiously. They may say, “Every dialect of English has its faults, eh?” This is the second oft-ridiculed peculiarity of Canadian English: turning a statement into a question by adding the word “eh” at the end, which means, approximately, “Isn't that so?” Needless to say, not all Canadians fit the stereotype—my wife, for example, rarely uses “eh,” just as I avoid most of the influences of Pittsburghese. Some of her family members from Saskatchewan, on the other hand, say “hey” instead of “eh,” and there are many other regional variations of English within Canada, just as there are within other English-speaking countries. But whether or not one uses “eh” (or “hey”), every English speaker knows dozens of ways to add a word or a phrase to the end of a statement so that it becomes a yes/no question. Questions formed in this way are called tag questions. You're It (Aren't You?) In one of my first graduate linguistics courses in grammar, we studied English tag questions at great length, because they nicely illustrate a simple, rule-based grammatical transformation. The simplest way to make a tag question in English is to repeat the verb, negate it, and then repeat the subject. For example, “He is smart” becomes “He is smart, isn't he?” If the verb is already negative, you just make it positive. “It won't rain” becomes “It won't rain, will it?” In most cases, if a sentence doesn't use a “be” verb, tag questions are created using a form of the verb “do”: “This scarf matches my hat, doesn't it?” Depending on the verb and the context, there are numerous other variations, along with special exceptions to the rules. Every student in elementary school is taught that when speaking of yourself, you must use the awkward-sounding “Aren't I?” to form a tag question unless you're willing to phrase it as “Am I not?” Beyond these basic kinds of tag questions, though, there are many other ways of achieving the same (or very similar) result. “Don't you think?” is very common, as are “Right?” and “OK?” and sometimes even “Huh?” In certain parts of the U.S., Canada, and England, “Isn't it?” is shortened to “innit?” and used as an all-purpose tag question, even where the verb doesn't seem to match, as in “This shirt costs a lot of money, innit?” But if you think of “innit?” as short for “isn't it so?” you have a nice parallel to the all-purpose French tag question, which also shows up in English. “This foie gras is splendid, n'est-ce pas?” And oddly enough, “yes” and “no” can often be used interchangeably to form tag questions. “We're having fun, yes?” means about the same as “We're having fun, no?” Tag Questions Have Many Uses (Don't They?) What I have always found most interesting about tag questions is their many and varied uses. Ostensibly they are questions that seek agreement or disagreement with whatever the original statement was, but more often than not, they are used for reasons other than gathering information. In some regional dialects of English, tag questions occur quite frequently—every few sentences or so—with the net effect of softening the overall impact of the speaker's statements. In other words, tag questions can make speech sound more polite or deferential by implicitly suggesting, “I could be wrong about this; what do you think?” This is also one of the functions of the Canadian “eh”—just as a Canadian will often say “Sorry!” if you step on his toes, frequent use of “eh” can serve the social purpose of limiting one's impression of self-importance. Very often, tag questions are used mainly as a tool to move conversations along, to involve other participants. A tag question can invite feedback—anything from a nod to a “Yeah, sure,” to a lengthy response. But with very few exceptions, tag questions that expect a response are looking for a positive response: an agreement with the speaker's original statement before it became a question. They say: “I believe such-and-such. Do you agree?” So tag questions can exert a subtle (or sometimes not-so-subtle) pressure on the listener to respond positively, like a preacher who makes a string of bold statements followed by “Amen?” It would be unexpected, to say the least, for a member of the congregation to shout out “Not really!” So just as tag questions can be used as a means of expressing courtesy, they can also be misused as a way of controlling a conversation, inducing guilt, or expressing passive aggression. Hence the infamous “You'd never leave me, would you?” It's not easy for someone to respond, “Oh, sure I would!” Tag questions can be used to make accusations, especially when followed by an explicit demand for agreement: “And then you bludgeoned the victim with Volume XI of the Oxford English Dictionary, didn't you? Admit it!” They're also a perennial favorite among parents: “You didn't finish your vegetables, did you?” or “You need a nap, don't you?” In fact, tag questions are a veritable Swiss army knife of English constructions, with almost as many possible uses as expletives. Although tag question formation is usually taught to people learning English as a second language, the full range of uses and variations is rarely addressed, making them confusing for people who don't grasp their underlying motivations. You Don't Get It, Eh? Even English speakers don't always understand the unwritten rules for tag questions. Several times I've heard Americans try unsuccessfully to imitate a Canadian by saying something like, “Isn't it cold up here, eh?” And that's simply wrong; a tag question only works if it modifies a statement (or, in some cases, a command: “Stay for dinner, eh?”). Tag questions are fascinating, aren't they? You enjoyed reading about them, didn't you? You will keep reading Interesting Thing of the Day every day, won't you? —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/07/face_-_questions.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/07/Tag_Questions.c7a84652f291.mp3"
	},
	{
		"title": "Spoonerisms",
		"text": "One of my linguistics professors in grad school had a strange sense of humor that appealed to me greatly. He didn't see a need to divide work and pleasure; exams regularly contained jokes, puns, and strange juxtapositions, and every class session was filled with laughter. When this professor needed to make up a word in an imaginary language to use as an example, he wouldn't give it a common meaning like “mother” or “tree”; he'd instead gloss the word as “flagpole sitter,” “hubcap thief,” or something similarly odd. He constantly urged us not to take our homework too seriously and to ask annoying questions of the other professors. I think this lighthearted attitude helped us all to learn better, and it certainly brightened the classroom atmosphere. How Near This Class discussion had a remarkable tendency to stray from the planned lesson, though invariably it went in interesting (and linguistically useful) directions. One day, someone in the class mentioned the word metathesis, which is the phenomenon that occurs when two adjacent sounds are swapped (as in “aks” for “ask”). Without missing a beat, the professor said, “Oh yes, this reminds me of spoonerisms,” and proceeded to recite, rapidly and perfectly, the tale of the Mion and the Louse. We were stunned and delighted by his brilliant display of linguistic prowess. It's not easy to make mistakes like that on purpose. A spoonerism is like metathesis but instead of affecting adjacent sounds within a single word, it's spread out across two or more words (sometimes with intervening words)—for example “hat rack” becomes “rat hack”; “light a fire” becomes “fight a liar.” Some spoonerisms instead transpose vowel sounds (“I fool like a feel” instead of “I feel like a fool”). Because mistakes like this are involuntary slips of the tongue, they don't always result in real words (you might say “key tup” for “tea cup,” for instance), but the funniest and most memorable spoonerisms change the meaning of a sentence completely (as in “I'm biting a rook” in place of “I'm writing a book.”) A Speecher Named Tuner I have mentioned my hope that my name never gets distorted into an adjective or other part of speech. But if history remembers me for anything, I trust it will be for something more auspicious than a tendency to mix up my words, as was the case with the Reverend William Archibald Spooner, a member of New College, Oxford, from 1862 to 1924. Spooner was a small man and an albino. His head was disproportionately large, and he had poor eyesight. But he was kind, well-liked, and extremely intelligent—so much so that his mouth couldn't keep up with his brain. He therefore developed a reputation for frequent verbal blunders. Spooner himself was seldom aware of making these mistakes, and some people believe the quotes attributed to him were apocryphal. In any case, he is credited with such classics as “a blushing crow” (instead of “a crushing blow”), “you've tasted two worms” (instead of “you've wasted two terms”), and a toast to “our queer old Dean” (instead of “our dear old Queen”). He navigated the streets of Oxford on a well-boiled icicle, and reminded parishioners in one of his sermons that “the Lord is a shoving leopard.” By the time he was in his fifties, the term “spoonerism” had become a common noun, but as far as I can tell Spooner accepted this dubious distinction with gracious good humor. A legend in his own time, he lives on in our marts and hinds. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/07/spooner_.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/07/Spoonerisms.15c803d19a4f.mp3"
	},
	{
		"title": "Intaglio Printing",
		"text": "As I look around at the many printed items within arm's reach—books, magazines, a calendar, posters, checks, labels, boxes, and so on—I am vaguely aware that nearly all of them made their way through a printing press at some point. And, since I've used rubber stamps and stencils, I have an equally vague awareness that any printing process is based on putting ink or other coloring onto some parts of paper while keeping it off other parts. But despite having worked in the prepress field for a while, I never thought very deeply about the methods for transferring ink to paper; terms like “offset” and “lithography” had no specific meaning to me. Even after I finally grasped how laser printers work, ink-based printing methods remained a mystery. Every time I realize that I've been living in blissful ignorance about something so common, I feel sort of guilty—it's the same feeling I had when I was in high school and knew that I'd studied just enough to get through my exams, but not enough to actually understand or remember anything. So I began some remedial self-instruction in printing techniques, determined to fill in those embarrassing gaps in my knowledge. Along the way, I learned all sorts of interesting things, but one printing method particularly struck my fancy: intaglio (in-TAL-yo) printing. Making an Impression There are several major large-scale printing methods. The original printing press and its descendants (including rubber stamps) use raised letters to ensure that ink is applied only to the desired portions of the page; although an entire block of type may be covered with ink, only the raised parts make contact with the paper. In lithography, a printing plate (or stone) is moistened with water and then coated with ink; the greasy ink adheres only to the portions of the plate with the right texture (achieved in a variety of ways), while the water on the blank portions of the plate repels the ink. Although paper is brought into contact with the entire plate (directly, or, in offset lithography, via an intermediate rubber roller), only the inked portions transfer marks to the paper. Intaglio printing (from an Italian word meaning “carve”) predates lithography by more than three centuries. Like lithography, it employs full-plate contact—but instead of relying on water to keep ink where it belongs, it uses recesses cut, engraved, or etched into a metal plate (or cylinder) to hold the ink. After the ink is spread, the plate is wiped down to remove excess ink from the top surface. The paper is then applied under tremendous pressure to push it into the grooves, transferring the ink where it has made contact. One of the side effects of intaglio printing is that the inked surfaces are very slightly raised on the front and indented on the back; depending on the type of paper and ink used, this can give intaglio prints a unique texture. A variant of intaglio printing called gravure varies the depth of the recesses in order to produce a range of tones; deeper grooves hold more ink and therefore create darker colors. Show Me the Money Intaglio presses can cost ten times as much as offset presses, and an intaglio printing plate can cost hundreds of times more than a comparable plate intended for offset printing; hence the relative popularity of the latter. But intaglio printing has some important advantages. For one thing, the plates have an incredibly long life; many millions of impressions can be made before the image quality degrades. For another, intaglio printing can achieve remarkably fine levels of detail. These facts, combined with the raised surfaces of the design, make intaglio printing the natural choice for currency, passports, and other high-security documents. Virtually every banknote in the world is printed at least partially using intaglio, because its distinctive appearance and texture make it easier to spot counterfeits. Although intaglio will never replace laser and inkjet printers on the desktop, there's no better printing technique when only perfection is good enough. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/07/Intaglio_printing.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/07/Intaglio.4eb41b8884a9.mp3"
	},
	{
		"title": "The Writings of Carlos Castaneda",
		"text": "Bookstores are dangerous places for me. I invariably leave with less money—and more books than I'll ever have time to read. But I have to support my habit: I'm basically an idea junkie. I like to learn things, absorb new ideas, and challenge my mind to form connections between concepts that don't seem to go together. So I choose books not because I assume they're true, but because I expect them to be interesting or thought-provoking. When I've finished reading a book, though, I usually have a pretty strong sense of whether or not I believe it. After reading a dozen books by Carlos Castaneda—along with quite a few criticisms of his work—I could only come to the conclusion that the stories he told may or may not be somewhat or completely true. This very uncertainty is one of the things that makes his books so interesting. I have since revised my conclusion—about which more later. But first, some background. For years, as I browsed through second-hand books, I frequently came across Castaneda's The Teachings of Don Juan: A Yaqui Way of Knowledge. I'd invariably pick it up, glance at it, and put it back on the shelf. Then I read Fritjof Capra's The Tao of Physics, which had a brief quote from don Juan at the beginning, and that piqued my curiosity. Shortly thereafter, I ran across the book at a thrift shop and decided I could give it a whirl for 50 cents. Within a few pages I was hooked, and after finishing it I read all 11 of its successors. For better or worse, I was too late to be a groupie—in April, 1998, before I had finished reading all of the books, Castaneda died. Only then did I begin to realize the extent of the controversy surrounding his life and work, and the state of confusion he left behind among both fans and critics. The Sorcerer's Apprentice For those unfamiliar with Castaneda and his books, here's the short version of the story. Castaneda was studying anthropology at UCLA in the early 1960s, and during the course of his field research in Mexico, he claims to have met a Yaqui Indian named Juan Matus. Don Juan was reputed to be an expert on medicinal plants, and Castaneda hoped to use him as an informant to learn more about the use of peyote among certain groups of native Mexicans. The Teachings of Don Juan purports to be an anthropological study of the way don Juan used a variety of hallucinogenic plants as part of a system of sorcery. The research, however, was participatory rather than objective, and don Juan's intent was apparently to treat Castaneda as an apprentice, indoctrinating him into the ways of the particular brand of sorcery he practiced. The hallucinogenic plants turn out to be a red herring. In Castaneda's next book, A Separate Reality, they have a more limited role, and from there on, they're barely mentioned. The books focus on other aspects of Castaneda's training as a sorcerer, along with several other apprentices of don Juan and his fellow sorcerer Genaro Flores. Eventually don Juan reveals that he only taught Castaneda about the plants to get his attention; most of the teachings are internal, psychological. Castaneda learns how to turn off his inner dialogue, control his dreams, perceive other people as luminous energy, and behave in a manner don Juan calls “impeccability.” A lot of time is devoted to an exercise called recapitulation, in which Castaneda recalls and relives all the events of his life. At the end of Castaneda's fourth book, by which time he had been working with don Juan for over a decade, don Juan and don Genaro “leave the world,” which readers are supposed to understand not as death but as a deliberate crossing into another plane of existence. Surprisingly, the story does not end there. Castaneda returns to Mexico two years later and meets up with the other apprentices of don Juan and don Genaro, some of whom we haven't heard of yet. By the sixth book, The Eagle's Gift, Castaneda and another apprentice, a woman nicknamed “La Gorda,” discover something shocking: during the years of their apprenticeship, don Juan had frequently made them shift into a heightened state of awareness, wherein he had taught them a variety of things that they could not remember in their normal state of awareness. There follows a long reexamination of their entire relationship with don Juan. They find that most of what they thought they knew was wrong or at least irrelevant; all the most crucial teachings had been hidden, delivered as they were in this altered state. Castaneda's penultimate book, Magical Passes, covers a series of movement exercises vaguely like ch'i kung, which are supposedly a key component of the knowledge don Juan revealed—even though they're barely hinted at in any of the other books. Where Castaneda's other books were simply reporting his own experiences, this one alone is actually written as an instruction manual. Stalking Castaneda From the publication of Castaneda's first book in 1968 until today, he has been subject to harsh and relentless criticism. Entire books have been written on this subject, but I'll give you just a sampling. First, many critics question whether such a person as don Juan ever existed. Only Castaneda and his close associates seem to have met him; there is no photograph or documentary evidence to prove he existed, or even a corpse—he conveniently “vanished.” Anthropologists point out that a number of the details Castaneda gave are inconsistent with what is known about the Yaqui Indians, native Mexican sorcery, and even the geography, flora, and fauna of the places Castaneda claims to have visited. Likewise, critics have cited other sources of suspiciously similar stories, suggesting that Castaneda “borrowed” some of his material. In addition, critics say, his stories read a bit too much like novels—real life doesn't arrange itself that neatly for literary convenience, so at minimum he must have employed some artistic license in his descriptions. Then, of course, some worry that his discussions of hallucinogenic plants encourage the use of drugs. Castaneda himself refused to respond to any of his critics. He was for the most part a recluse, declining to be interviewed or even photographed. His unwillingness to defend himself or offer proof of his claims was seen as an implicit admission of guilt; on the other hand, Castaneda's own books repeatedly say that according to don Juan, a life of obscurity is absolutely essential to a sorcerer. Apologists thus counter that Castaneda was simply practicing what he preached. He did, however, conduct seminars and workshops for a select few students. One of these students, Amy Wallace, was Castaneda's lover (or one of them) for a number of years. Her 2003 memoir Sorcerer's Apprentice gives an unprecedented (though clearly biased) inside look at the real Castaneda. A fascinating read, it details the life of a man who appears by turns to be a highly evolved guru and a megalomaniacal cult leader. Wallace's bottom-line opinion: don Juan almost certainly did not exist, but Castaneda, though deeply disturbed, was a genius who believed deeply in the path he followed. This seemed to be the general consensus of those interviewed for the 2004 documentary film Carlos Castaneda—Enigma of a Sorcerer, made by another former Castaneda student, Ralph Torjan. This book and film together erased any lingering faith I may have had in the veracity of Castaneda's writings. Unlike his students, I can't take his ideas very seriously knowing what I do about him. Is The Truth Out There? What makes Castaneda's books so compelling to many is their vivid descriptions of the world as perceived through the eyes of a sorcerer (or “man of knowledge”—in Castaneda's usage, the term “sorcerer” does not carry any undertones of evil practices). Some of the experiences he reports are frightening, shocking, or simply off-putting, and they wouldn't make the average person say, “Hey, this sounds like fun, I think I'll become a sorcerer.” What they suggest, though, is that the underlying reality of the world is not at all as most people perceive it, that ordinary human awareness is, as it were, a bad habit. Castaneda's writings have attracted such a following for much the same reason as The Matrix or The X-Files: people want to believe that there's more to the universe than meets the eye, that a more fantastic world lies beyond our perception. Whether Castaneda's version of alternative reality is the right one, or even approximately correct, is the question. But whatever your opinion of Castaneda—a prophet, a fraud, or a misguided fool—his books are fascinating and thought-provoking. Even in fiction, there are kernels of truth. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/07/Carlos_Castaneda.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/07/Castaneda.25f9518acd9f.mp3"
	},
	{
		"title": "Bad Fiction Contests",
		"text": "When Morgen and I visited Venice, we made the obligatory pilgrimage (along with all the other North American tourists) to Harry's Bar. For those who have never heard of it, Harry's Bar is a very nice, though small and perfectly ordinary, restaurant near Piazza San Marco (St. Mark's Square). It opened in 1931, taking its name from an American named Harry Pickering who had donated the capital to get it up and running. There is nothing especially noteworthy about this restaurant except the fact that it has attracted a great many famous people, who in turn attracted still other famous people. So in a way, it's famous for being famous—not to impugn the quality of its fare, which is excellent. Perhaps the best-known celebrity to frequent Harry's was Ernest Hemingway. He spent so much time there he had his own table in the corner, and he mentioned Harry's in Across the River and into the Trees. There's Harry, and Then There's Harry Hoping to capitalize on the recognition of the name “Harry's,” another establishment named “Harry's Bar” soon opened in Florence, Italy. This Harry's was not owned by, or related in any way to, the original. Nevertheless, following the precept that imitation is the sincerest form of flattery, it set a precedent that would play itself out in a strange way decades later. In 1978, a replica of the Harry's in Florence called Harry's Bar and American Grill opened in Century City, California, near Beverly Hills. As an apropos publicity stunt, the Century City Harry's sponsored an Imitation Hemingway Competition. Entrants were asked to write a single page in the style of Hemingway—understood to mean a convincingly bad parody of Hemingway—with the only stipulation being that the piece had to mention “Harry's Bar” in a complimentary way at some point. The winner received a trip to Florence (not Venice) and dinner at Harry's Bar there. A huge number of entries came in that first year, and the contest proved so popular that it has continued every year since. The original sponsors bowed out after 11 years, at which point the literary organization PEN Center USA took over. PEN, in turn, handed over sponsorship of the contest to United Airlines in 2003. The airline publishes winning entries in its Hemispheres in-flight magazine, and sends the winner to Milan (not Venice or Florence). You can read past years' winning entries in a book called The Best of Bad Hemingway or, for more recent years, online. Even if you're not familiar enough with Hemingway's style to feel the full force of the parody, these entries are brilliantly funny. The winning entry in 2002, written by Kathryn Bold, was titled “The Old Man and the Flea”; runners-up included “Harry Potter and the Gimlet on Fire” and “The Old Man and the Sea of Reporters.” Faking Faulkner If Hemingway isn't quite your speed, United also sponsors the Faux Faulkner Contest in cooperation with the University of Mississippi's Department of English and Center for the Study of Southern Culture and the Yoknapatawapha Press. Like Imitation Hemingway, the contest seeks a single page of Faulkner parody that makes judges laugh. The prize is a bit less impressive, though: a trip to Memphis, Tennessee, where the entry is read at a Faulkner conference. A different and, for my tastes, much more interesting form of bad fiction contest has been running nearly as long as Imitation Hemingway. Since 1983, the English Department at San Jose State University has sponsored the Bulwer-Lytton Fiction Contest. The objective of this competition is to write the worst possible opening sentence for a novel. The sentence can be, in principle, any length, though typical entries are much shorter than the 500-word maximum for the Hemingway and Faulkner contests. It Was a Dark and Stormy Contest This contest gets its name from 19th-century novelist Edward George Bulwer-Lytton. Bulwer-Lytton's 1830 novel Paul Clifford begins with the immortal words “It was a dark and stormy night…” But it was the remainder of the sentence—and, in fact, the rest of the book—that earned Bulwer-Lytton his reputation for verbosity and melodrama. The entire opening sentence reads: “It was a dark and stormy night; the rain fell in torrents—except at occasional intervals, when it was checked by a violent gust of wind which swept up the streets (for it is in London that our scene lies), rattling along the housetops, and fiercely agitating the scanty flame of the lamps that struggled against the darkness.” Whew! And it just goes on like that. For all the fun people have had at Bulwer-Lytton's expense in the last couple of decades, he was an extremely successful and popular novelist in his day, second only to Dickens. He is best remembered for his novel The Last Days of Pompeii, and was responsible for coining the expressions “the great unwashed” and “the pen is mightier than the sword.” He also inspired some less-obnoxious parodies: “It was a dark and stormy night” was the opening line of both Madeleine L'Engle's A Wrinkle in Time and Snoopy's perpetually unfinished novel in the Peanuts comics. The most interesting entries in the Bulwer-Lytton contest can be found in a series of five books, most of which are now, sadly, out of print. The winning entries for each year, however, are still available on the contest's Web site. Winning this contest won't involve a trip to Italy, Tennessee, or even San Jose; sponsored as it is by a university English department, the main reward is simply notoriety. But contestants, judges, and all those who read the entries are amply rewarded with laughter. Bad fiction—when it is intentionally bad—can be very entertaining to read. But far from simply lampooning writers whose styles are no longer in vogue, these contests can actually help to teach better writing by calling attention to what makes bad prose bad. And anything that helps writers laugh at themselves or challenge writer's block has got to be a good thing. —Joe Kissell UPDATE: In early 2006, United announced that it was no longer sponsoring the Hemingway and Faulkner contests, and that no new sponsor had yet been found. So those two contests appear to be in limbo for the time being. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/07/book-1.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/07/Fiction.5897a8cda1b6.mp3"
	},
	{
		"title": "Demosthenes' Stones",
		"text": "It's a good thing I had never heard of Demosthenes when I was a child. I would have gotten in trouble. My mom would have said, “Don't talk with your mouth full.” And I would have replied, “Don't you want me to be a famous orator like Demosthenes? I'm training!” And then I would have been sent to my room without any more of whatever my mouth was full of. Kids, this is why grownups are always saying things like, “You're too young to understand. Just take my word for it.” It's for your own good. And if you get in trouble for talking with your mouth full, don't say I didn't warn you. Repeat After Me Even as an adult, I get in trouble over Demosthenes. A while back, Morgen and I were watching “My Fair Lady” on TV. For those unfamiliar with the story, a linguistics professor in London named Henry Higgins makes a wager with a friend that he can rid a working-class girl, Eliza Doolittle, of her Cockney accent and teach her to speak like a proper lady. In one of his many drills, he insists that Eliza fill her mouth with marbles and then read a series of phrases. So of course I said, “Oh, just like Demosthenes.” Morgen gave me one of her patented looks that means “How do you expect me to know these obscure facts if I don't read about them on Interesting Thing of the Day?” I was tempted to respond with a look that meant “Oh come on, everybody knows about Demosthenes,” but I opted instead for the path of marital concord. After all, one shouldn't look a gift topic in the mouth. Appropriately enough, Demosthenes had a name that, for many English-speaking people, is a tongue twister. I have always pronounced it “di MAHS thə neez,” which is what my trusty dictionary says. However, no less an authority than Demosthenes Spiropoulos, proprietor of the Web site WorldOfDemosthenes.com, says: “The name is pronounced: Dee-moss-sta-kness.” So take your pick; I suppose it depends on how authentically Greek you want to sound (which, in my case, is not at all). Speaker System The story is this. Demosthenes lived in Athens from 384 B.C. to 322 B.C. As a young man, he suffered from a speech impediment—which may have been a stutter, an inability to pronounce the “r” sound, or both. He designed a series of exercises for himself to improve his speech. According to legend, he practiced speaking with stones in his mouth, which forced him to work very hard to get the sounds out. When his diction became clearer, he got rid of the stones and found he was able to enunciate much more effectively than before. He also practiced reciting speeches while running and speaking over the roar of ocean waves to improve his projection. These strategies must have worked, because Demosthenes achieved fame as the greatest orator in ancient Greece. He is best known for his passionate speeches urging the Greek citizens to defend themselves against invading Macedonian king Philip II. Naturally this story is repeated often with a moral of “work hard, be persistent, and you will succeed.” Alas for Demosthenes, historical acclaim is all he got for his efforts. His speeches, though popular and well-received, did not prevent Greece's conquest by Macedonia. Shortly thereafter, Demosthenes was falsely accused of taking a bribe and sent to prison. He escaped, but remained in exile until Alexander the Great died. Demosthenes then returned to Athens and once more tried to lead a popular uprising. He failed again, but not without attracting the attention of the authorities. When he learned that he faced imminent capture and possibly death, he committed suicide by taking poison he had long kept hidden in a pen. Tragic though his end was, the story of Demosthenes' dramatic forensic achievements continues to inspire speakers to this day. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/07/demosphenes-1.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/07/Demosthenes.7991fac65746.mp3"
	},
	{
		"title": "Walloon",
		"text": "When I mentioned to Morgen that I was trying to come up with another good language-related topic to write about, she was silent for a moment, then proclaimed matter-of-factly, “Walloon.” This being a term I’d never heard of, I gave her my standard Scowl of Incomprehension, which she met with her deadly Blank Stare of Shame. This silent exchange is what we do when one of us is incredulous that the other could possibly lack some crucial piece of knowledge. Finally I broke down and said, “OK, what’s that?” Still expressionless, she said, “It’s a language spoken in Belgium.” Hmmmm. French I knew about, but not this one. Sounds really exciting. I said, “Is it interesting?” She said, “Maybe.” And that was that. It turned out, as it always does, that she was right—it is interesting. But the very first interesting fact I learned about Walloon was one she wasn’t even aware of: Belgium is not the only place where native speakers of this language are found. The other is Green Bay, Wisconsin. Special Relativity When I think of Belgium, I think of food—in particular, things like chocolate, waffles, cheese, and beer. When I think of Green Bay—which, I admit, is a rather infrequent occurrence—cheese and beer also spring to mind, along with football. I never jumped to the conclusion that there must be a Belgian connection in Wisconsin, but indeed there is. It’s the only outpost in the New World where you can find a community of people who speak Walloon. Some linguists classify Walloon as a dialect of French, but it began developing a distinct character as early as the 8th century and acquired its own name by the 16th century. The differences are significant enough that many consider Walloon a distinct language (though unquestionably a close relative of French). For example, in French, the word for “the” takes on a different form depending on the gender of the noun that follows it; in Walloon, as in English, the definite article is always the same. Walloon, unlike French, also uses a single word to mean “his” or “her.” Word order is different (adjectives usually come before the noun, whereas they follow the noun in French), and there are numerous differences in spelling, pronunciation, and vocabulary. Furthermore, Walloon itself has four distinct dialects, each concentrated in a different region of Wallonia. Where’s Wallonia? Wallonia? Yes indeed, Wallonia is the name for a region covering roughly the southern half of Belgium. Although this is home to Walloon, that is by no means the only language spoken there; French is of course the official language, and there’s also a local, “Walloonized” version of French—plus several other languages in the same family. When thousands of Walloons (as the residents are called) moved to North America in the mid-1800s, they settled in a corner of eastern Wisconsin near Lake Michigan, where there were already some French Canadian residents. By and large, the Belgian immigrants continued speaking their native language, which over the past 150 years has apparently changed less than any of the Walloon dialects spoken in Belgium. Other than Green Bay and Wallonia, the only places where you can still find communities of active Walloon speakers are Brussels and a few small villages in northeastern France. Estimates of the number of Walloon speakers vary. Most sources say there are at least a few hundred thousand people who actively speak Walloon (though virtually all of these also speak at least one other language)—with as many as a million more people who can understand it to some degree. However, it’s far more common to find active speakers among people over 60 than among children and young adults. Walloon is not considered an official language of either Belgium or Wallonia (um, not to mention Green Bay), so it’s relatively difficult to find Walloon media and educational materials. As a result, use of the language is rapidly fading—especially in Wisconsin. However, there is a movement afoot in Belgium to revitalize Walloon; part of this movement is an effort to apply a single system of spelling to the diverse dialects, which should aid greatly in the propagation of literature and Web sites. There are a number of Walloon magazines and theatrical productions, and the language is heard occasionally on television and radio. Supporters of the language want it to be taught in school as well. Although my utilitarian side sees great value in standardized languages, my conservationist side feels the same sort of grief about endangered languages as it does about endangered species. If there’s anything at all I can do to help the cause—such as buying more beer—I’m only too happy to oblige. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/07/Linguistic_map_of_Wallonia.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/07/Walloon.e8ecd188d08d.mp3"
	},
	{
		"title": "Style Guides",
		"text": "When I received the edited manuscript of one of my books from the publisher a couple of years ago, I was annoyed to find that every instance of “OK” had been turned into “okay.” Well, not quite every instance: in places where I was talking about a button on a computer screen that actually said “OK,” that was allowed to stay. There followed a lively exchange between my editor and me, she claiming that it had to be “okay” because that’s what the publisher’s style guide said, and me claiming “okay” is etymologically illegitimate, style guide or no. I couldn’t countenance the thought of having a book with my name on it include grating juxtapositions like “It’s okay to click the OK button.” I eventually got my way, though I lost quite a few other battles over differences between my style of writing and what the publisher prescribed. In cases like these, a dictionary or English textbook will be of little help. Almost any dictionary will tell you that both “okay” and “OK” are acceptable, along with “O.K.” and “o.k.,” the only difference being which is listed as the preferred spelling. But preferred by whom? Under what circumstances? And why? The question is even trickier when it comes to recently coined terms. Should there be a hyphen in “email”? Is “Web site” one word or two? Is “internet” capitalized always, sometimes, or never? And then there are questions of usage that even scholars debate. Are expressions such as “for free” and “from whence” redundant? Is it mandatory, optional, or forbidden to use the pronouns “he,” “him,” and “his” to refer to people of either gender? A Matter of Style If you want to know the preferred way to use a term for a particular type of writing, you need to consult a style guide. In high school or college, your instructors probably insisted that papers you write follow a set of rigid guidelines in order to make the writing consistent and clear. Academic style guides are often referred to by their authors, such as “Turabian” (Kate L. Turabian’s A Manual for Writers of Term Papers, Theses, and Dissertations) or “Strunk and White” (The Elements of Style by William Strunk Jr. and E.B. White). Other style guides are specific to fields such as psychology, mathematics, or linguistics. And most publishers require their authors and editors to follow a house style guide, whether writing magazine articles or technical books. Even outside the worlds of academic and professional writing, issues of usage are still quite common and quite important. English, like all languages, is constantly changing. The more frequently a given usage occurs, the more likely it is to become canonized as “proper”—even if the most frequent usage is based on a misunderstanding. This happens automatically and often haphazardly, which is why English has so many strange spellings and inconsistent rules. The further the language strays from its past conventions, the harder it will be to learn, teach, and use. For those who care about the ability to communicate clearly, choosing better usages over worse ones can be seen as a way to keep the language on the straight and narrow, so to speak. And this is exactly what style guides aim to do. The Decline of the English Language You don’t have to go far to find examples of common usages that stray from convention. Have you ever been waiting in line and heard a clerk yell, “Can I help who’s next?” You’ve witnessed a new (and, arguably, unfortunate) construction in the making. In the same way, the word “nauseous” is gradually taking on the meaning “nauseated,” even though the dictionary definition of “nauseous” is “disgusting.” The expression “going forward” no longer means “moving in the direction of your nose” but rather “from now on.” I’ve heard people use words like “dollarize” and “incentivize” without a trace of irony, even though every child learning English in school is cautioned against verbing nouns. That may be bad, but is it “actionable”? If you hear something often enough, it starts to sound right. The job of a style guide author is to figure out, for a given point in time (and usually, a specific audience), which way of saying or writing something is best—not necessarily correct. This is not as easy as it sounds. The English textbooks you read in school made it sound as if the language is ordered by sacred, inflexible rules, but in reality, there is ultimately no single objectively correct way to say anything. There are only better ways—that is, less ambiguous or more commonly used—and worse ways. So the author of a style guide has almost godlike powers to proclaim which variant is, in his or her opinion, the one that serves the language best in some particular context. To return to the “OK” example, everyone agrees on how it should be pronounced, but the spelling is another issue because there are numerous competing theories as to the expression’s origin. According to a story I heard long ago, “O.K.” came from the initials of a tongue-in-cheek alteration of “all correct” as “oll korrect.” There’s also a claim that it originated in the presidential campaign of Martin Van Buren as the initials for his nickname, “Old Kinderhook.” A number of respectable linguists think its origins are much older, from the West African language Wolof spoken by many slaves in the U.S. In Wolof, a word that sounds like “waw-kay” means “OK” (more or less), and it’s quite plausible that this was the term’s entree into English. There are probably a dozen other theories as well. The consensus seems to be that the letters O and K don’t stand for anything individually (at least, not now—even if they once did), so it would be misleading to include periods. But as to whether it should be written as a phonetic word (“okay”) or a pair of uppercase letters (“OK”), that is a matter of strenuous debate. Choosing a Guide Sorting through all these theories and opinions—for hundreds or thousands of expressions—is one of the tasks a style guide author must undertake. Style guides also provide detailed instructions for the use of punctuation and capital letters, typographical elements such as bullets and italics, and grammatical advice on such matters as split infinitives, dangling prepositions, and irregular verbs. Of course, advice is all it is or can be; no two style guides agree on everything. As a result, in choosing a style guide—and in choosing how diligently to follow it—one must consider the author’s credentials, attitude, and rationale for making decisions. Good writers must ultimately be prepared to make, and justify, their own decisions about style. A wonderful article by David Foster Wallace titled “Tense Present: Democracy, English, and the Wars over Usage” appeared in the April 2001 issue of Harper’s Magazine. Among other things, this article served as an extended review of a recent style guide: Bryan A. Garner’s 1998 A Dictionary of Modern American Usage (ADMAU). Wallace is the kind of person who would read a style guide recreationally—in other words, he’s my kind of person. And after comparing ADMAU with competing guides and dissecting Garner’s approach, he concludes that Garner is a genius for deftly and authoritatively resolving some of the thorniest issues of English usage. I picked up a copy of ADMAU myself, as well as its updated 2003 edition, now called Garner’s Modern American Usage. Garner’s advice is absolutely brilliant, and the reasoning he provides for almost all of his usage pronouncements strikes me as both thorough and reasonable. He’s detailed and strict where he needs to be; in other places, he is appropriately critical of silly, anachronistic writing rules that no reasonable person should have to follow. In other words, I trust him with my language. That’s not to say I agree with him all the time, or that he covers everything I wonder about (technical terms, for instance, are a bit sparse). But I strongly prefer his advice over that of most other style guides I’ve read, and I consulted it frequently when developing the style guide used by Interesting Thing of the Day. I like to do things right, to the extent that I can figure out what “right” is. I think I’m fairly proficient in English, but it’s still a perplexing language, and I’d be lost without a good style guide. I like to think that by choosing a guide wisely, I’m helping to keep English a little more sane. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/07/its_all_good.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/07/Style.56d44646fcad.mp3"
	},
	{
		"title": "Linguistic Categories",
		"text": "English is widely regarded as a complex language, full of unpredictable spellings, irregular verbs, and etymological inconsistencies. Many other languages are easier to learn (at least for adults) because they're more consistent. For example, people who speak both French and English often regard French as the more elegant and coherent of the two languages. But some things about French have always puzzled me—such as gender. All French nouns have a gender attribute, and your choice of modifiers and adjective forms to go along with the nouns depends on whether the noun is masculine, feminine, or neuter. But there's apparently no rhyme or reason for why a given noun has a given gender. Logically enough, the word for man is masculine and woman is feminine, yet masculinity is feminine and vagina is masculine! Likewise, I can see no reason for aphorism being masculine while platitude is feminine. If there's a logic behind French gender categories, it's not apparent to most non-native speakers. Lots of languages assign gender to nouns, and speakers tend to regard these odd inconsistencies as “just one of those things”—something one must memorize when learning a language, without trying to read too much significance into it. But nearly all languages have some implicit method of grouping certain nouns into categories, and some of these category divisions, which go way beyond the two or three so-called genders, are extremely thought-provoking. Thinking Outside the Boxes George Lakoff's 1987 book Women, Fire, and Dangerous Things: What Categories Reveal about the Mind takes this notion of linguistic categories as its starting point. Lakoff, who teaches at the University of California, Berkeley, was interested not only in a description of linguistic categories or even how they came about, but more deeply, in learning what the categories in language tell us about the nature of reason. His goal was to argue against the traditional, objectivist account of reason that says all categories in the mind must correspond to real categories in the world; if words share a category, that can only be because the things they represent share objective qualities. Lakoff wanted to show that the organizing principles behind some linguistic categories cannot be objective, but rather must be based on metaphor, imagination, and other “fuzzy” concepts. In other words, he wanted to paint a picture of reason as being a distinctively human faculty, not simply an abstract set of computational rules. The book's title comes from an Australian aboriginal language called Dyirbal. In this language there are four different categories for nouns, each of which requires a special classifier word to be used before the noun. It so happens that one of those categories includes women, fire, scorpions, the sun, and a variety of other things that might be considered dangerous. Another class includes nouns like men, kangaroos, the moon, and rainbows; a third includes fruit and other edible things, except animals; and a fourth includes everything not in one of the other three categories. What's interesting about these categories is that unlike French genders, they are not learned arbitrarily; speakers confronted with a novel object will invariably agree on which category it belongs in. This means there must be some logic or pattern to the categorization, and Lakoff spends considerable time discussing the complex inferential mechanisms humans use to form such categories. The Long and the Thin of It Another example Lakoff cites is the Japanese classifier hon, which is normally used to mark nouns in the category of “long skinny things”—pencils, candles, hair, rope, and so on. This classifier also applies to nouns that don't objectively fit that model, but which have some indirect connection. A volleyball serve is hon, for example, because the trajectory of the ball is long and thin; a roll of tape uses this classifier because it's long and thin when unrolled; telephone calls are hon because they are made using wires, which are long and thin; and TV shows are hon because of their similarity to telephone calls. There are many other examples, but what Lakoff wanted to show was that even though a volleyball serve, a roll of tape, and a TV show share no objective quality, Japanese speakers automatically group these things together because of a mental category that depends on metaphor. Even in English, we implicitly group words in classes. For example, Lakoff points out that we put time in the same category as money—it's something that can be “spent,” “saved,” “earned,” or “wasted,” even though time is an abstract concept that doesn't have any objective characteristics in common with money. Recognizing these unconscious connections can lead to rethinking one's assumptions about the way the world works. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/07/girl_sitting_reading_book_looking_surprised_.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/07/Categories.92299fe43f7b.mp3"
	},
	{
		"title": "Pittsburghese",
		"text": "The city in which I grew up is a suburb of Pittsburgh—in the southwest corner of Pennsylvania, less than an hour's drive from both Ohio and West Virginia. Decades ago, the region's economy was largely based on the production of steel. Pittsburgh was a busy, thriving, industrial city, and the residents—who sometimes refer to themselves as Pittsburghers—were by and large blue-collar working families. But the numerous coal-powered steel mills and factories were not kind to the environment. The air quality made today's Los Angeles look crystal clear by comparison, and earned Pittsburgh the unfortunate nickname “The Smoky City.” When the mills and factories began closing due to the lower prices of imported steel, Pittsburgh's air began to clear, and the ever-industrious populace reinvented the city as a center of technology, medicine, learning, and culture. Today's Pittsburgh is a beautiful city, made all the more colorful by cultural and linguistic remnants of an earlier era's working class. Modern Pittsburghers may be many things, but they are not untidy. The city has entirely shed its reputation for dirt and disorder. That's because whenever something is dirty, someone will immediately worsh it. And if the contents of a room are not neatly arranged, you must redd it up. By the time I was six or seven years old, I had worshed my face and hands and redd up my room hundreds of times. It All Came Out in the Wash It was about that time when I was learning to read and encountered the strange word “wash” for the first time. I had no idea what it meant. I had to ask my teacher if it meant something like “worsh.” The teacher took great pains to explain that “wash” was indeed the correct spelling, but sometimes in English, words are not pronounced the way they're spelled. That's true enough, but I checked in a dictionary to make sure. There, right before my eyes, was the correct pronunciation of “wash” without an “r” sound in sight, and no entry at all for “worsh.” It was a profound and defining moment for me. I was devastated to realize that my family, friends, and teachers were not speaking English the way other people did, and I determined that I would not let this happen to me. As a youngster, the most difficult thing about adjusting my language usage was figuring out which terms and pronunciations were in fact incorrect, since everyone around me spoke pretty much the same way. My friends followed professional sports, so they were always talking about the Stillers or the Pahrits. If you wanted to see the teams play in person, you'd have to go Dahntahn where the stadium was. If it was snowing, you'd need to be cautious on the slippy roads or you might slide all the way to Ahia. To ascertain whether your companions were hungry, you'd say, “Jeet jet?” If they hadn't, and wished to know if you had, they would reply, “No, jew?” In that case, you might want to pick up some jumbo (that is, bologna) to make a sammitch. Worsh it down with some pop and you've had yourself a good mill. It Had to Be You One of the most distinctive Pittsburgh expressions is the plural form of “you.” In the south, of course, “you” is singular and “y'all” is plural; this is often a very useful distinction. However, in Pittsburgh, the plural of “you” is “yoonz.” (No one really knows how to spell that—I've seen “yunz” and “yinz,” for example—but in any case, the vowel sound is more or less a schwa.) Supposedly, yoonz is a contraction of “you ones,” though I suspect most locals would be unable to articulate that etymology. The possessive form of yoonz, by the way, is “yoonz's”: “Dats nunna yoonz's bidness.” I've seen several different dictionaries of Pittsburghese, as the dialect is called, not to mention Web sites and serious analyses by researchers in fields such as English, linguistics, and sociology. There are several general principles. Phonemic parsimony is an important rule, so inconvenient consonant sounds are dropped or run together. For example, library becomes “liberry,” picture becomes “pitcher,” and something turns into “sum'in.” If an L sound appears between certain pairs of vowels, it turns into a W, so dollar is “dahwer” and skillet is “skiwet.” Diphthongs are flattened, so field is pronounced “filled,” fire becomes “fahr”, out is “aht,” and pillow becomes “pilla.” The palette of vowel sounds is also limited. A Pittsburgher would pronounce the vowels in words like bought and yacht exactly the same—they're uniformly reduced to the short o sound of toss. And quite often, terms are shortened lexically too. You'd call a rubber band a “gumban,” aluminum foil “tinfoil,” and a submarine sandwich a “hoagie.” I could go on and on, but suffice it to say that Pittsburghese is much more than a quaint drawl or a small collection of regional colloquialisms. It's really a very distinct dialect of English. Leavin' da ‘Burgh Although it's informally called “Pittsburghese,” this dialect, or variations of it, are used throughout western Pennsylvania. It's hard to say at what point one has gotten far enough away from Pittsburgh that the dialect sounds strange, but without question New York is such a place. I attended a college in New York that happened to have a large number of students from western Pennsylvania. These students were not, on the whole, any more or less intelligent or good-looking than anyone else, but they were all easily identified by their dialect, and were good-naturedly teased because of it. But all through my childhood and adolescence I had tried deliberately to avoid Pittsburghese, so my provenance was not easy to guess. Once a fellow student asked me where I was from, and when I said “Pittsburgh,” he replied, “I never would have known!” I took that as a tremendous compliment. Several years later, having finished my master's degree in linguistics, I was quite certain that I was speaking an entirely neutral, dialect-free version of English. In the early 1990s, I was doing desktop publishing for a company in Dallas. One day I was in the editorial office and I noticed that it was quite cluttered. I said to one of the editors, “This room really needs cleaned.” The editor furrowed her brow and said, “You're from Pittsburgh, aren't you?” I was aghast. I knew I hadn't said “redd up”—so what was the problem? I really had no idea what had given me away. She said, “People in the rest of the country would say, ‘This room needs cleaning,' not ‘This room needs cleaned. '” I shook my head and sighed. Apparently, despite my best efforts, I had missed a thing or two, and Pittsburghese had not lost its ahrn grip on me. Still, when someone asks me to speak an entire sentence in Pittsburghese, I can't do it. I know the individual words, but I've lost touch with the overall accent, cadence, and intonation. I'd need a lot of practice to sound convincing. When I hear a genuine Pittsburgh accent (or, better yet, an imitation by a reformed local), I can't stop laughing. It's not that I think it's silly, it's more that it reminds me of the difference between what sounded right to me as a child and what I'm used to now. Three Rivers Run Through It One of the things I find most interesting about Pittsburghese, though, is how little it's known outside western Pennsylvania. Go anywhere in the United States, and someone will be able to pick out—if not imitate—an accent from Texas, Georgia, Minnesota, or New York. But for the most part, the only people familiar with the Pittsburgh accent are those who have lived there. This is especially noticeable in films set in Pittsburgh—they may look correct, but often they don't sound correct. A notable exception is the Bruce Willis film Striking Distance, in which the actors actually do a respectable job of sounding like they're from Pittsburgh. One thing I'll say about Pittsburghese is that it sticks to you like coal dust. Well, probably a lot better than coal dust, in fact—it doesn't wash off. To this day, I keep finding minor remnants in my own speech. Now and then I catch myself rounding my L's or leaving off final consonants. And for years, my wife has made fun of the way I pronounce “umbrella”—with the emphasis on the first syllable. I never knew that was unusual before she pointed it out, and I didn't know until I saw it listed on a Web site that it's actually a Pittsburghese peculiarity. Time for another shahr. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/04/pittsburg.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/04/Pittsburghese_.bc4706e437c5.mp3"
	},
	{
		"title": "The Klingon Language Institute",
		"text": "When I was a child, I’d come home from school each day and immediately flip on the TV to watch my favorite show. The original Star Trek series—by then already well into its years of syndication—had me completely hooked. My mother used to tease me that I could summarize the plot of any episode by the time the first chord of the theme music had played. I was a serious junior Trekkie. Years later, during the run of Star Trek: The Next Generation, I rekindled my interest in the show, going so far as to attend a few Star Trek conventions. Ironically, it was the conventions themselves that started to wear down my interest in Star Trek. I was a fan, but not the sort of fan who would wear a uniform, pointy ears, or a communicator badge. Not the sort who would memorize scripts, install Star Trek sounds on my computer, or collect autographs of the stars. Just an ordinary fan. The people I saw at conventions, on the other hand—these folks, God bless ‘em, were over-the-top Trek junkies. From the way they talked, dressed, spent their money, and generally obsessed over the show, it seemed as though many of them took it way, way too seriously. I liked Star Trek, but I never confused it with reality. The fan culture actually tainted my own experience of what should have been just a very good science fiction show. Way of the Warrior One particular fan subculture revolves around characters known as Klingons. (For those who aren’t familiar with the show, Klingons are a warrior race from the planet Kronos, their culture permeated with a profound, if ruthless, sense of honor. For most of the Trek timeline, they were the “bad guys,” the archetypal enemies of the human-dominated Federation—though at various points in the mythology they have become allies to one extent or another, as more insidious foes threatened both races. Klingons have deeply creviced facial features, are always dressed for battle, and speak in a harsh, guttural language.) Many Trek fans regard the Klingons as their heroes, adopting their mannerisms, appearance, and even their language. While the extreme role-playing this group enjoys is a bit much for my taste, the language itself is worthy of note, as is the Klingon Language Institute (KLI), a nonprofit organization dedicated to the study and promotion of the language. KLI is, as surprising as it sounds, a honest-to-goodness scholarly organization. Their subject matter: an artificial language created for aliens in a TV show. In the original series, Klingons spoke English, but as sophisticated viewers began to expect a more realistic alternative universe, Paramount Studios hired a linguist named Marc Okrand to create a complete, believable Klingon language. The words and phrases Dr. Okrand came up with were used in several of the Trek films as well as in The Next Generation and later series. Okrand later published several books on Klingon, as well as audio cassettes (narrated by actor Michael Dorn) designed to help people learn the language. Alas, Poor yorIq! In the 1991 film “Star Trek VI: The Undiscovered Country,” a Klingon general (who also happens to be a Shakespeare aficionado) recites a translated version of “To be or not to be.” He then jokes that you can’t truly appreciate Shakespeare until you’ve read it in the “original” Klingon. The following year, KLI began operations, and one of its first projects was—you guessed it—producing a Klingon version of Hamlet, part of what they call the “Klingon Shakespeare Restoration Project.” As if that weren’t ambitious (and wacky) enough, KLI members are working on translating the rest of Shakespeare and, incredibly, the Bible, into Klingon. In addition to mailing lists and an extensive Web site, they produce a quarterly journal, and even offer Klingon language lessons by mail. KLI claims to have members in 30 countries and on all seven continents. Speaking as a mere fan, I don’t have any plans to attend Klingon Language Camp (yes, there is such a thing) any time soon. Still, having spent years studying linguistics, I can’t help but be impressed at the achievement of creating an entire language from scratch. And I suppose I can think of worse pastimes than translating literature into an artificial language. Who really wrote the works of Shakespeare? Perhaps it was a Klingon. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/04/kilingon.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/04/Klingon.ad4c1faa8258.mp3"
	},
	{
		"title": "Scruples and Stones",
		"text": "You may think of yourself as a scrupulous person—you may have even said indignantly when accused of some fault, “I have scruples!” But exactly how many scruples do you have? If you've recently finished a meal or taken a stroll down a gravel-covered path, chances are you have more scruples now than you did an hour ago. The calculation is quite easy to make: there are 4,900 scruples in a stone, though a single stone can also be a scruple. You may be thinking this is like saying, “4,900 angels can dance on the head of a pin, though a single pin can also be an angel.” But that's just plain silly. I don't know a single angel who can dance on the head of a pin, and besides, I must imagine that angels have much better things to do with their time. On the other hand, both stones and scruples are quite concrete, everyday things that sometimes have extended or metaphorical meanings, and in the case of this pair of terms, those meanings intersect in interesting ways. Pounding Stones I set out originally to talk about a unit of weight called the stone. When I was in England last year, I heard several people discussing matters of weight using the term “stone,” as in “That diet worked so well I lost two stone.” I gathered that this must be considerably more than a pound, but nobody I asked seemed to know for sure exactly what the weight of a stone was. They could quote me the current exchange rate between pounds sterling and the U.S. dollar, but when asked how many pounds were in a stone, most people thought for a moment and said, “probably around 15 or 20.” A stone, it turns out, is a Roman measurement equivalent to 14 pounds (6.4kg). And apart from listing all the other archaic equivalences—which, I'm sure, regular readers have had quite enough of this week—that's about all you can really say about a stone. Not all that interesting. A Rock and a Hard Place But as I was looking through long lists of obscure units of measure (you can't fathom how many I looked at), I came upon the humble scruple. The English word scruple originated with the Latin scrupus (‘sharp stone'), a diminutive form of which was scrupulus (‘small sharp stone')—in common usage, the particular sort of small sharp stone that gets stuck in your sandal, causing extreme discomfort when you walk. Both of the main figurative meanings of scruple (“a very small amount” and “reluctance due to moral misgivings”) are extremely ancient and existed in Latin as well; I was not able to determine which of them came first. But eventually “a very small amount” came to be codified as 20 grains—that is, 20 barley grains (slightly smaller than grains of wheat)—or 1/24 of an ounce (about 1.3g). This was an apothecary measure, but then, it goes without saying that pharmacists need to have scruples. I think the image of moral discomfort as a rock in the shoe is delightful. (“I'm sorry, Cindy, but I must reject your tantalizing proposal. The mere thought of it gives me rocks in my shoe.”) I also find it curious that words referring to two very different senses of “stone” came to have significance as units of measurement. And it makes me wonder: is it impossible, or obligatory, for someone with scruples to get stoned? —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/04/Scruples.14fad364f35d.mp3"
	},
	{
		"title": "Snow Crusts",
		"text": "For decades there has been a popular belief—alternately debunked and defended by various linguists and anthropologists—that there are a great many Eskimo words for snow. More specifically, the belief is that while there are lots of specific words for different kinds of snow, there is no word that can be used to refer to any type of snow generically—that is, no direct synonym for the English word snow. Some accounts claim that there are nine different Eskimo snow words; some say there are dozens; others insist there are hundreds of distinct words for snow. Critics argue that there may be just two Eskimo root words for snow (from which all other words are derived), and that in any case, English, too, has plenty of different terms for snow—flake, flurry, powder, blizzard, avalanche, and so on. I do not intend to resolve this debate here, but I would like to show that when it comes to talking about a snow crust—a thin hard layer on top of snow—English can more than hold its own. First, a brief discursus. The Snowball Effect To even begin to fathom how many Eskimo words there may be for snow, one must define what is meant by Eskimo—a term sometimes regarded as offensive when applied to people of certain ethnicities. Linguistically speaking, the word Eskimo properly refers to two language groups: Yup’ik (which consists of five distinct languages) and Inuit. Although Inuit is technically a language, it’s also a dialect continuum, meaning that dialects spoken in neighboring areas are mutually intelligible, while dialects whose speakers are separated by great distances are not. Meanwhile, some people use Inuit to refer to the people themselves while reserving the term Inuktitut for the language they speak, but this is not entirely accurate either. Depending on how you count, there are four or five major Inuit dialect groups, not all of which use the term Inuktitut to refer to their own language. And by the time you count all the individual dialects and the variety of names they use…well, you have almost as many names as you do people—the total number of people who speak any Eskimo language is less than 80,000. In any case, my point is that saying there are many “Eskimo” words for snow is sort of like saying there are many “European” words for love: trivially true but irrelevant. So let’s suppose we narrow the question down to just one particular dialect of one Eskimo language. Surely there must be one of them with lots of words for snow, right? Well, maybe. Eskimo languages are notoriously complex, and it takes someone with serious training and experience to be able to tease apart which utterances even count as distinct words. Consider that the English words snowflake and snowfall, although they appear as separate entries in the dictionary, are really just compounds based on a single root word for an underlying concept. Eskimo languages make it much harder to spot derivatives like these, and once you do find them, you’re back to making an arbitrary decision as to whether they should appear as separate entries in your snow dictionary. Eight Is Enough Interesting as this puzzle is, I would like to point out that in any case, individual Eskimo languages have only one or two words for snow crust. For example, Western Greenlandic has one word for snow crust while in the Norton Sound, Unaliq subdialect of Central Alaskan Yup’ik there are two—which, by the way, look suspiciously like derivations of the same root. How anyone can get by with so few terms I’ll never know; in English, we seem to need a lot more—eight, to be exact. And OK, they’re all two-word phrases, but still—I think they put the whole debate in an entirely new light. Here they are, courtesy of the Glossary of Meteorology at the American Meteorological Society: 1\\\\. snow crust: the general term for any hard surface on snow 2\\\\. sun crust: a crust formed when the sun melts the top layer of snow, and then it refreezes 3\\\\. rain crust: a crust formed when rain falls on snow and then freezes 4\\\\. spring crust: a crust formed when warmer weather (but not necessarily sunshine) melts the top layer of snow and it refreezes 5\\\\. wind crust: a crust that forms when wind packs down a layer of snow that has already been deposited 6\\\\. wind slab: a crust in which the wind packs the snow at the same time as it’s being deposited 7\\\\. ice crust: a crust that forms when water (from whatever source) flows onto the surface of snow and then freezes 8\\\\. film crust: a very thin ice crust Snow there. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/04/snow.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/04/Snow.31b9cd09c819.mp3"
	},
	{
		"title": "Synesthesia ",
		"text": "I have always enjoyed finding (or making) connections between things that don’t seem to go together. So I have a special fondness for metaphor—especially when it’s indirect and novel. A number of years ago, a friend suggested we go out to dinner together. I asked what kind of place he had in mind, and he said, “Oh, I was thinking we’d go to a green restaurant.” I didn’t know what relevance a restaurant’s color could have, and the usual metaphorical meanings of green (“environmentally sensitive,” “inexperienced,” “nauseated,” etc.) didn’t seem to apply. Noticing my confusion, my friend explained his unusual usage of the term. “There’s a class of restaurants,” he said, “whose décor consists mainly of antiques hung on the walls and brass railings. There’s always a central bar, a lively atmosphere, pub-style food, and an excessively cheerful wait staff. You know the type—T.G.I. Friday’s, Chili’s, Bennigan’s, Applebees…” I nodded. I knew the type. He continued, “These restaurants also typically have green awnings. Thus: ‘green restaurants. '” Ever since then, I’ve referred to this class of restaurants as “green,” even when the awnings are red-and-white striped, when there are no awnings at all, or when other details differ from the canonical example. I like that description, because it’s the most compact way I can think of to describe that type of restaurant. That Name Rings a Bell For some people, though, the word “restaurant” may literally cause them to experience the color green—or a particular texture, smell, or taste. This is just one example of a phenomenon known as synesthesia, in which senses blend together or trigger each other in one way or another. In one of the more common forms of synesthesia, a given letter or number invariably appears to be a certain color. In other cases, a certain kind of sound may cause someone to see a color or experience a tactile sensation, or a texture or color may provoke the experience of a taste. There are at least 50 different types of synesthesia, involving various combinations of senses both as the triggering stimulus and the secondary response. Some forms of synesthesia are experienced as multiple modalities of a single physical sense. For example, seeing a number might evoke a certain color for one synesthete, while in another person the same number might cause a different visual sensation, such as a pattern or shape. One sense may also trigger another, as in a tactile sensation that has a taste. But not all synesthetic experiences are restricted to the five senses. In some synesthetes, a word or sound might evoke a sensation of motion, or even a kinesthetic response, inducing the person to assume a particular physical position. There are also cases in which abstract concepts, such as days of the week or months of the year, cause the sensation of shapes, colors, or other experiences. Survey Says… Estimates vary widely as to what percentage of the population experiences synesthesia. I’ve read claims that as few as 1 in 25,000 or as many as 1 in 300 people have at least one pair of overlapping senses (in rare cases, all five senses are blended together), though everyone seems to agree that it’s more common among women and left-handed persons than the rest of the population. Synesthesia is always referred to neutrally as a “condition”—neither a “defect” nor a “gift”—because even though it’s abnormal in the sense of being rare, no one can seem to work out whether it’s advantageous or disadvantageous from an evolutionary point of view. It’s simply a trait, like having blond hair or being able to curl one’s tongue, that some people have and others don’t. There are cases in which synesthesia acts as a memory aid, and it is also associated with higher-than-normal levels of creativity. On the other hand, there are a few cases where the blending of senses is so pronounced that almost any stimulus produces a very disturbing state of sensory overload. Synesthesia is an inherited trait, although researchers have not identified the responsible gene (or genes) or the exact parameters that determine how it is transmitted. In any case, people with synesthesia experience the sensations involuntarily and consistently. There have been some reported cases in which children with synesthesia lose the multisensory associations as they grow older, but for the most part, a given stimulus always produces the same secondary response in a given person—if the number 5 is red, it will always be red; if the word “groovy” tastes like mint, it will be just as minty ten years from now. That said, though, there is little consistency from one synesthete to the next in what sensations are triggered by what stimuli. No one has yet determined exactly how the specific associations form. It’s Not Easy Hearing Green Although synesthesia has been known and documented in medical literature since 1880, it was largely ignored as a field of serious inquiry until late in the 20th century. Many people believed that those who reported synesthesia were “just imagining things,” which is a strange accusation considering that all sensory perception is, by definition, in one’s head. But if someone reported that the letter R felt cold, it was easy to conclude that the person was just speaking metaphorically, or remembering a childhood association of some kind—not really experiencing the sensation of cold. Recently, though, researchers have used several clever techniques to prove conclusively that the secondary sensations are actually experienced in the brain, not simply memories or a poetic way of speaking. In one experiment, for example, scientists filled a page with nearly identical monochrome 2s and 5s, asking subjects to tell them what pattern was formed by the 2s. Nonsynesthetes had great difficulty in picking out any pattern, because they had to look at each individual character. But for synesthetes who perceived 2s and 5s in different colors, the pattern (say, a triangle) formed by the 2s immediately jumped out. Light Me Up Having learned that synesthesia is a genuine sensory experience, researchers concocted more elaborate tests to determine what may be going on in the brain when such experiences occur. One such technique is a Functional MRI (magnetic resonance imaging) test, in which subjects are placed in a machine that can display a dynamic, real-time, 3D representation of blood flow in the brain. The parts of the brain that are activated in response to specific stimuli “light up” in distinctive colors. So in the case of someone who hears colors, showing the subject a color will cause the parts of the brain that handle auditory information to be activated, just as they would be if the person had actually heard the sound. When discussing what happens in the brain in synesthesia, it’s common to talk about “crossed wires,” and of course the phenomenon does suggest communication between parts of the brain that do not normally interact. But the image of crossed wires is probably misleading; strictly speaking, synesthesia does not appear to require a different or more elaborate set of neural connections than in a normal brain. Instead, the prevailing belief is that existing connections are simply used in a new way, or that chemicals that ordinarily inhibit this type of cross-communication are not released. This notion is supported by the fact that phenomena similar to synesthesia sometimes occur in otherwise normal people who suffer seizures, have brain injuries, or use certain kinds of drugs. But apart from physical or chemical trauma to the brain, there is no evidence that synesthesia is a trait that can be learned or acquired deliberately. A recurring theme among people with synesthesia is that they have learned by experience not to share their unusual sensations; painful tales of childhood ridicule are common. This is a great pity, because one person’s scary mutation is another person’s super power. With any luck, the combination of more generous cultural attitudes and really expensive scientific equipment will open all new doors for understanding and appreciating the unusual abilities of synesthetes. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/04/Synesthesia.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/04/Synesthesia.74dcbba65b91.mp3"
	},
	{
		"title": "Palais Idéal",
		"text": "The topic of weird, elaborate structures built by wealthy eccentrics has come up repeatedly here at Interesting Thing of the Day—think of the Winchester Mystery House, Neuschwanstein Castle, and Hearst Castle, for instance. Today we add to that list a palace constructed in its entirety by an eccentric of modest means: a postman named Ferdinand Cheval. The story begins in 1879. Cheval, then 43 years old, had been working as a rural mail carrier in the southeast of France for 12 years. Because his daily routine involved walking about 20 miles (32km), mostly in solitude, he did a lot of daydreaming. One day (perhaps while his mind was elsewhere), he tripped over a small limestone rock. He noticed that the rock was oddly and beautifully shaped, so he wrapped it up in his handkerchief, put it in his pocket, and took it home with him. The next day, he went back to the same spot and found lots of other interesting stones. He recalled a striking dream he’d had in 1864, in which he’d built a huge castle of stone. Right then and there, he decided to make his dream a reality: he made it his life’s mission to collect enough stones to construct that castle. Going Postal Cheval began collecting rocks on his rounds, eventually adding about 5 miles (8km) of walking per day. At first he kept the stones in his pockets, then moved on to baskets and, finally, a wheelbarrow as the size and quantity of the stones he collected increased. Back at home, he set to work arranging the stones into an ever-larger structure. He also made numerous figures of people, animals, and plants out of concrete and blended these into the creation, which was held together with the help of cement and wire. Despite ridicule from his neighbors, he continued working on the project for 33 years, and it became his full-time occupation after he retired from the post office in 1896. By the time he declared it finished, in 1912, it had grown to roughly 85 feet (26m) long, 40 feet (12m) wide, and 35 feet (11m) high. It was dubbed Le Palais Idéal du Facteur Cheval (or Postman Cheval’s Ideal Palace). And it looks like…well, no one can really say what it looks like. Cheval’s vision had been that of a fantastical structure incorporating elements from many different architectural styles. Part of it was intended to emulate a Hindu temple; part of it is supposed to look like a medieval castle. There are also influences from numerous other cultures from all over the world. And yet, the final product—a pastiche though it may be—has an odd sort of coherence that evokes (or possibly even inspired) Dr. Seuss. Dying for Recognition By the time the palace was complete, it had begun to draw international attention. Famous artists visited and drew inspiration from it; it was featured in media from postcards to magazines; and people came from far and wide to see this astonishing building. Public opinion about the work and its creator eventually shifted, and Cheval himself came to be regarded as an artist of some renown. However, even though Cheval had essentially put the town of Hauterives on the map, the city government denied his request to be buried, along with his wife, in the palace. Not to be deterred, he went back to work in 1914 on a second, smaller structure in the local cemetery. He spent eight years building what he called the Tomb of Silence and Eternal Rest. Two years after its completion—and just days after he finished writing his autobiography—Cheval died and was interred in this new structure. Set in Stone The Palais Idéal was declared a cultural landmark in 1969, and underwent extensive renovations from 1983 to 1993. Today, the site draws more than 100,000 visitors per year to Hauterives. An exhibition at Paris’s Musée de la Poste (Post Office Museum) in 2007 showcased artwork inspired by Cheval’s palace, and included numerous artifacts relating to its history—including the original visitors' log begun in 1905. The centerpiece of the exhibit was a detailed one-tenth-scale model of the palace (shown in the photo above). I wouldn’t call this structure a work of architectural genius, and its artistic merits (or lack thereof) have been much debated. But no one can dispute that it’s audacious, wacky, and impressive. Whatever drove Cheval to spend half his life collecting stones and building bizarre monuments, it earned him a place in history as one of only a few truly famous postmen. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/04/Palais_Idal.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/04/Palais.924b89afc4fa.mp3"
	},
	{
		"title": "The Central - Mid-Levels Escalator ",
		"text": "Traveling to other countries can often require an adjustment to new ways of doing things; there is an aspect of uncertainty in even the smallest of tasks. This is part of the joy of travel, but there are times when weary travelers appreciate any efforts to cut through the confusion. Some places handle this better than others; for example, almost as soon as I got off the plane in Hong Kong, I knew I was in good hands. I first got a sense of the efficiency of Hong Kong when I passed through Immigration, and had my body temperature scanned remotely to see if I was running a fever (important for a region trying to limit infectious diseases such as avian flu). I was further impressed with Hong Kong’s technological prowess when I discovered I could purchase a stored-value transit pass, called an Octopus card, which I could not only use on trains, buses, and trams, but could also use to buy snacks from a convenience store or food from certain restaurants. I found out later that locals can also buy rings, watches, and even cell phones that contain the Octopus chip, enabling them to simply wave their hands (or phones) over the special card readers to make a purchase. Another way in which Hong Kong tries to make life easier for visitors (and probably residents as well) is by posting numerous signs that are not only very specific, but sometimes exceedingly courteous. There are not many places where you could find a sign advising you to “Beware of sudden pushing out door” (for other examples of these signs, see My 12 Favorite Signs in Hong Kong on SenseList). While all these things are wonderful, my favorite piece of technology that makes life easier for visitors (and residents of course) is the Central–Mid-Levels Escalator. Stretching from the Central district of Hong Kong Island up to the heights of the Mid-Levels residential neighborhoods, the escalator is a godsend for footsore travelers. Escalating the Situation The Central–Mid-Levels escalator system, which opened in 1994, consists of twenty escalators and three moving sidewalks, and measures 800 meters (1/2 mile) in length, making it the longest outdoor covered escalator in the world. It takes about twenty minutes to ride the escalators from the bottom to the top (or vice versa), but it takes less than that if you walk while they move, as most people do. The escalators run from 6 a.m. to midnight, descending for the first 4 hours (bringing morning commuters down from upper levels), and then reversing direction around 10:20 a.m. to carry passengers up the hill. There are entrances and exits at each street it intersects (14 in total), making it easy to stop at whichever level you choose. Up, Up and Hooray During the time we spent in Hong Kong recently, we rode the escalators almost every day, finding them an extremely useful way to get from our hotel midway up the slope of Victoria Peak to the center of activity downtown and back again. One of the things I enjoyed most about riding the escalators was the opportunity to peek at the activity taking place on either side, from apartment life on the upper levels to the bustling bars, restaurants, and stores on the levels closer to the center of the city. While for many people who rode the escalators alongside us, it was just an ordinary commute to work, we found the journey to be a fascinating glimpse of urban life in Hong Kong. Not only that, but the ease, efficiency, and simplicity of the system made us, foreigners though we were, feel right at home. —Morgen Jahnke ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/04/Central-Mid-levels_escalator_.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/04/Escalator.8021595bae25.mp3"
	},
	{
		"title": "Hay-on-Wye ",
		"text": "As anyone who knows me can attest, I am a sucker for books. I’ve had my nose perpetually stuck in a book for as long as I can remember, and I can go absolutely stir crazy if I have to endure a two-hour flight (or ten-minute bus ride) without sufficient reading material. Although I don’t own a car, and my wardrobe may be threadbare in places, buying books (used or new) is, along with travel, one of the luxuries I will not willingly forgo. Thus it was with great joy that I discovered a place where my bibliomania would not seem out of place: the Welsh town of Hay-on-Wye, home to 1500 inhabitants and four million books. Castle Rocked Hay-on-Wye, also known by its Welsh name Y Gelli (“The Grove”), lies on the border between Wales and England, and is about halfway between the English cities of Bristol and Birmingham. Its English name is derived from the Norman word for an enclosed field (“hay” or “haie”) and from its setting on the banks of the River Wye. Earlier on in its thousand-year history, the town was the scene of immense political upheaval owing to its strategic location between Wales and England. The history of the castle at its center illustrates how tumultuous those times were. Built in A.D. 1200 by the local ruler, William de Breos II, Hay Castle replaced an older, smaller castle. After displeasing King John of England, William was forced to flee to France in 1211, and his wife and son were imprisoned. In 1231, the castle was burned by a Welsh prince, but was rebuilt by Henry III around 1233 and returned to the control of the Breos family. The Earl of Leicester, Simon de Montfort, attacked the castle in 1265 in response to local opposition to the king. In 1322, the English king Edward II again captured the castle from its rulers at the time. And during the Welsh rebellion of the late 14th century, led by nationalist leader Owain Glyndŵr, the castle was nearly destroyed by fire. The castle had various owners over the following centuries, including the local church, which used it as a vicar’s residence during the Victorian era. In 1971, a resident of Hay-on-Wye, Richard Booth, purchased the property and has since created a bookstore within its walls. Buy the Book Creating a bookstore was nothing new to Richard Booth, who first began selling books in Hay-on-Wye in 1961. Convinced that the presence of many bookstores in the town would draw in tourists and gain attention for Hay, he converted an old cinema into the Cinema Bookshop, and encouraged other businesspeople to open stores as well. He eventually sold the Cinema Bookshop, and opened Richard Booth’s Bookshop in the old town firehouse, which has now become the largest secondhand bookstore in Europe. With the example set by Richard Booth, many other secondhand and antiquarian booksellers made their home base in Hay-on-Wye, and by the end of the 1970s, the town became the world’s first “book town” with an estimated one million books in stock. The book town concept has since spread to many other countries, and the number of bookstores in Hay-on-Wye continues to grow. According to the town’s official Web site, there are now 41 bookstores serving a population of 1500, which means there is one bookstore for every 37 residents. But because Richard Booth’s vision of the town as an international center of bookselling has been realized, locals now must share these stores with the approximately 500,000 visitors it receives each year. Writers Bloc The highest concentration of visitors descends on the town during the last few weeks of May for an event that has become world renowned: The Guardian Hay Festival. Launched in 1988 by Peter Florence and now attracting some 80,000 attendees annually, this literary festival has drawn famous writers such as Margaret Atwood, Kazuo Ishiguro, Julian Barnes, John Updike, and Don DeLillo, among many others, to give readings and conduct book signings for the assembled crowd. One unique aspect of the festival is the fact that attendees are likely to run into their literary heroes in the street (or at the pub) because of the small size of the town. It’s not surprising that a town full of books has become the setting for a major literary festival; it holds out the promise of a physical location for something that usually only exists in the mind: a community of those who love the written word. I count myself in that number, and hope some day to have that same experience, whether in a small Welsh town or in another place where readers and writers gather to celebrate the joy of books. —Morgen Jahnke ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/04/Hay-on-wye-books.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/04/Hay.e9a547d80b6.mp3"
	},
	{
		"title": "Vulcan, Alberta",
		"text": "More than many other pop culture phenomena, Star Trek seems to inspire the most extreme displays of fan commitment. From Star Trek conventions, to the perennial popularity of Trek movies and TV series, on through the huge success of Star Trek: The Experience in Las Vegas (a town with no shortage of other entertainment options), Trek fans have an intense interest in replicating (so to speak) the world of Captain Kirk, Mr. Spock, and all the other distinguished members of Starfleet. A sociologist might find it interesting to study this devotion; what is it about the Star Trek universe that compels ordinary people to live large parts of their non-virtual lives in its sway? Paradoxically more adult and yet less dangerous than the Star Wars universe, one answer may be that Star Trek predicts a future that seems to make sense, with science and reason in ascendancy. And yet, this even-keeled vision of what the future may look like is at odds with the sometimes obsessive response from its fans. As the documentaries Trekkies and Trekkies 2 amply illustrate, Star Trek fans have incorporated this TV and movie franchise into their lives in surprising and sometimes disturbing ways. From the woman who refused to remove her “Starfleet” uniform when reporting for jury duty to various people who have converted homes and offices into exact replicas of portions of the USS Enterprise, there seems to be an extreme literalism at work. Instead of merely making the positive aspects of the shows and movies part of their lives, these fans work instead to make their lives as much like the shows and movies as possible. While this trend is perplexing, the vast majority of fans can tell the difference between a TV show and real life, and pursue their interest in Star Trek purely for their enjoyment and entertainment. In that spirit, the residents of a fortuitously named town in the Canadian province of Alberta have capitalized on this interest by creating a bastion of Star Trek fandom amidst the rolling wheat fields of the Canadian prairie. Going Towards the Grain The town of Vulcan, Alberta first came into being with the expansion of the Canadian Pacific Railway (CPR) into the area in 1910. Vulcan grew up around the grain elevator built to store local farmers' crops until the train came through to collect and then transport them on to other markets. At one point, the town had nine elevators, known as “Nine in a Line,” that collectively had the largest storage capacity in the country (750,000 bushels of grain) before the elevators were destroyed by fire in 1971. While the town started small, with 28 residents and 14 businesses, it has now grown to a population of 1,700. Vulcan was given its name by a surveyor for the CPR; since at that time the town sat at the highest elevation of the railroad in the prairies, he wanted to name it after one of the Greek gods from Mount Olympus. However, Vulcan is actually the Roman god of fire and volcanoes, said to live beneath Mount Etna in Sicily or under the island of Vulcano. Live Long and Prosper While the CPR surveyor got his ancient gods confused, his error has worked to the town’s great advantage in recent years. Looking for a way to boost tourism, in 1995 the residents of Vulcan decided to capitalize on their town’s link to the Star Trek franchise. In the Star Trek movies and shows, Vulcan is used as the name of both a planet and the race of people who developed there. The best-known member of this race in the shows and movies is Mr. Spock, portrayed by Leonard Nimoy. The town of Vulcan pursued two strategies for drawing tourists to the area: the creation of structures related to Star Trek and the organization of events with a Star Trek theme. The first thing to be built was a large replica of the USS Enterprise, named the Starship Enterprise FX6-1995-A, based on the airport code for Vulcan (FX6) and the year it was created (1995). Measuring 31 feet (9.5m) in length and weighing five tons, the starship sits at the entrance to the town and has a plaque on its base welcoming visitors in the English, Vulcan, and Klingon languages. The second major construction project was a visitors' centre built in the shape of a landing spaceship. The Vulcan Tourism and Trek Station opened to the public in October 1998, and provides brochures and information to visitors, as well as offering Star Trek-related souvenirs. Vulcan hosts two annual events with a Star Trek theme: GalaxyFest (formerly known as Vul-Con) and Spock Days. In 2006 these events were combined into a single long weekend of Star Trek entertainment, and featured appearances by cast members from Star Trek shows, as well as a costume contest, a Klingon Fear Factor competition, and a Galaxy Awards Banquet. All of these elements combined have made the town of Vulcan a tourist destination for avid Star Trek fans. According to a plaque greeting visitors to Vulcan, that destination is “Third Planet from the Sun, North American Continent, Province of Alberta, County of Vulcan.” Star Trek has put Vulcan on the map, so to speak, and the town has taken to heart the Vulcan mantra to “live long and prosper.” —Morgen Jahnke ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/04/VulcanAlbertaEnterpriseReplica.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/04/vulcan.80c4f9d6f377.mp3"
	},
	{
		"title": "The Marree Man",
		"text": "Previous articles here at Interesting Thing of the Day have covered some of the world’s best-known geoglyphs, or figures carved into the ground. Uffington White Horse in England and the Nazca lines in Peru are examples of huge figures that can only be appreciated in their entirety from the air, and yet date from thousands of years ago. Although scholars and UFO buffs debate how and why the figures were created, one thing seems clear: their existence is valuable. They’re impressive examples of artwork from ancient cultures and must therefore be preserved—not just for historical reasons but for aesthetic reasons. Destroying them, or allowing them to deteriorate, would be tantamount to defacing a painting in a museum. So one might reasonably conclude that if an even larger and more impressive geoglyph were discovered, similar care should be taken to preserve it for the appreciation of future generations. Just such a figure was discovered in July 1998—on barren, public land out in the middle of an Australian desert, no less—but authorities ranging from government officials and Aboriginal leaders to prominent anthropologists immediately denounced it as vandalism and graffiti. The subject matter could hardly be considered controversial: it’s a giant line drawing of an Aboriginal hunter as he would have looked in the 19th century. Only two things truly set this image apart from others of its kind. First, it’s brand new: it was clearly created during the first half of 1998. And second, rather than relying on mysterious ancient artistic methods, it was made using modern technology—tractors and GPS receivers. But as with the older geoglyphs, no one knows for sure who made this one or why, and that’s the most maddening issue. Stick Figure A pilot named Trec Smith discovered the figure while flying over the area on June 26, 1998. Located about 35 miles (60km) from the township of Marree in central Australia, the figure came to be known as the Marree Man. It’s over 2.6 miles (4.2km) in length, making it not only the world’s largest geoglyph, but the world’s largest artwork of any kind. The image shows a naked man with his hair tied back in a knot known as a chignon, which, along with a headband and a distinctive pattern of initiation scars on his chest, identifies him as an Aborigine. He’s holding what appears to be a throwing stick, which would have been used to hunt birds. But the only way to see the whole image is from the air or from space. The lines are as wide as 115 feet (35m), and they were made by carving about a foot (30cm) into the red soil. Close examination revealed that the carving was done using a plow pulled by a tractor, and because of the width of the lines, the work may have taken as many as 16 passes—over a period of up to two months. Presumably the creator or creators used a combination of satellite imagery, computer graphics, and GPS mapping to plot out a series of markers on the ground and then simply followed the path with the tractor until the lines had reached the desired width. Interestingly, had they dug just a bit deeper, they would have exposed a layer of white chalk beneath the soil (much like that seen in the Uffington White Horse), which would have made the image more visible and more durable. As it is, within months the lines had begun to fade, due to natural erosion and plant growth. They’re still visible in satellite photos, but not nearly as prominent as they once were. Marree Me? After the site’s accidental discovery, anonymous press releases began showing up giving details about the drawing. The wording of the press releases suggested that they may have been written by an American; this notion was strengthened by the discovery of several objects at the site, including an American flag, a note referencing the Branch Davidian cult, and a satellite photo of the figure. Some suspected that American soldiers stationed at a nearby base may have done the work, while others thought the American wording and objects were simply a decoy to divert suspicion from those who were really responsible—perhaps one of several Australian artists, a group of construction workers, or members of the Australian military. As media attention grew, experts publicly debated the details of the image, questioning whether the man was holding a stick or a boomerang, and whether it was an accurate representation of any particular tribe or perhaps a combination of features from two or more groups. All the while, regional officials expressed their outrage at the so-called vandalism, police followed up on clues to the perpetrator’s identity (though no crime had actually been committed), and although Marree might have benefitted from an influx of visitors, the area of the geoglyph itself was blocked off to access by tourists. Several months later, a fax sent to a hotel in Oxford, England pointed officials to a plaque buried at the site, which contained a quote from H.H. Finlayson’s book The Red Centre: Man and beast in the heart of Australia; the context of the quote helped to identify which tribe the man pictured was supposed to have been from (the Pitjantjatjara tribe) and suggested strongly that the weapon he was holding was indeed a stick. However, the identity of the artist was still unknown. Eventually the publicity, as well as the image, began to fade, and official investigations were called off. Recently, attention has focused on Australian artist Bardius Goldberg, who died in 2002. He was known to have both the skills and the resources to create a work of this sort; he had expressed an interest in creating a work of art that could be seen from space; and he apparently received a large sum of money at the time of the Marree Man’s discovery. He carefully avoided either refuting or confirming claims that he was responsible, which in some people’s minds is the equivalent of admitting he did it. We may never know for sure, but it does seem clear that no efforts will be made to preserve this artwork for the future. What a pity: the first generation with the technology to easily create and appreciate this art form ends up being the first to shun it. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/04/Marree_man.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/04/Marree.4e4d79e1a73d.mp3"
	},
	{
		"title": "Assateague Island",
		"text": "Guest Article by Jillian Hardee When I was young, my friends and their families would head out to the commercial beaches for their vacations. By “commercial beaches,” I mean the ones with oceanfront hotels, boardwalks, and a dizzying array of lights. My vacations, however, were quite different, as they were spent at Assateague, a 37-mile-long island off the coast of Maryland and Virginia. The island is owned by both states, and the state line divides it in two. Because it is a national seashore and wildlife refuge, buildings on this island are few and far between. Not a hotel, restaurant, or arcade can be found here. The beach offers a 360° view of the sea and sky, with nothing to mar the experience except for horseflies and kamikaze kites. What do you mean there’s no boardwalk? Assateague is a natural barrier island, so it is constantly battered by water and wind. Its topography changes often. Since 1866, it has “moved” a quarter of a mile inland. My vacations were spent on the Virginia side of Assateague, and as a child I remember wooden steps and walkways that would take you up and over the high sand dunes. After being away from Assateague for a few years and then coming back as an adult, I found the high dunes were gone, and smaller, less-protective dunes had taken their place. Water and sand are constantly moving on this island. Changes in landscape and scenery on Assateague are expected and accepted. Most visitors to the Virginia side of the island stay on the nearby island of Chincoteague. Because there are no hotels on Assateague itself, vacationers must drive onto the island and then out to the beach, a short 5–10 minute car ride from Chincoteague. Due to this relative isolation, you might find yourself wondering what appeal this island could have. Not for entertainment junkies, Assateague has many things to offer those who love an unspoiled beach. A short walk up or down the coast will take you away from the summer crowds and into remoteness, where you may only encounter a lone fisherman or wandering beachcombers. On the southern end of the island, 4-wheel drive vehicles are allowed (by special permit) to drive out on the sand, allowing access to the southern tip of the island and more secluded areas. Aside from swimming, sunbathing, and fishing, the island has many outdoor activities. Nature tours are diverse and can range from marsh walks to bird-watching expeditions. Canoe and boat rentals allow for more personal and scenic views of the island and its waterways. There are also a myriad of chartered excursions for inland and ocean fishing. For those who don’t have their sea legs, crabbing and clamming are popular and easy. The Assateague Lighthouse, reached by a short walk through a pine forest, is occasionally open for visitors to ascend. Additionally, there are many bike paths that transverse the marshes and forests, allowing for close views of the vast populations of waterfowl, migratory birds, and mammals. At any other beach, an encounter with wildlife usually involves a seagull stealing your sandwich. At Assateague, wildlife and nature take center stage, and humans are merely visitors just passing through. Pony Penning Although a harsh environment, Assateague has a herd of wild ponies, more casually referred to as the “Chincoteague Ponies.” These horses have inhabited the island for at least 300 years. Originally thought to have swum ashore from a wrecked Spanish galleon, it is more widely believed that settlers brought them on the island to graze. Today they survive on marsh grass and other island roughage. Two separate herds exist, one belonging to each state, and they are kept isolated from one another by a fence at the border. Although true horses, they are often referred to as ponies due to their small stature, which is most likely a consequence of their marsh diet. To keep the population numbers of the Virginia herd down, the ponies are annually driven across the channel in late July to the neighboring town of Chincoteague. Here, the horses (mostly foals) are auctioned off and the money collected benefits the Chincoteague Volunteer Fire Company. In recent years, individual horses were sold for an average of US$2,000, with the largest bid being $10,500 in 2001 for a single horse! The last few Pony Penning events have auctioned off an average of 85 horses per year. The number of horses auctioned is dictated by herd size, as the Virginia side of Assateague Island is only permitted a maximum of 150 horses. After the auction, the remaining horses swim back across the channel and resume their lives on the island. The actual pony swim officially dates to the 1920s, although some form of pony herding has occurred since the 1700s. Pony Penning is an extremely popular event, and festivities span an entire week. Large crowds of hopeful bidders as well as spectators crowd onto the island. Today, Chincoteague ponies can be found all across the United States as a result of this auction. Marguerite Henry wrote a notable series of children’s books about the horses and the annual swim. The first and most popular book, called Misty of Chincoteague, was written around 1948 and was based on a real Chincoteague family and their pony. This pony (the “real Misty”) died in 1972, and was allegedly stuffed and put on display. I don’t recall ever seeing the stuffed version of Misty while vacationing in Chincoteague, and I prefer to keep it that way. Today the ponies can be seen in a variety of places on the island at different points of the day. They usually roam in smaller herds, and it is common to see them off in the distance relaxing under a copse of trees or grazing in the marshy fields. Closer encounters occur frequently along the wildlife trails and beach road; here tourists with cameras will crowd around, snapping photos as the horses languidly amble about. Signs posted all over state that “Wild Ponies Bite and Kick,” but that doesn’t seem to stop anyone from sidling up to them. They are part of the landscape and culture of Assateague as well as Chincoteague, and they make this already fascinating area even more extraordinary. The way it should be As an adult, I still love to visit Assateague Island. Even though the nightlife is limited, and there are no boardwalks or flashy rides, a vacation here is what it should be: relaxing. There is no sense of hurry, no rush, no multilane highway packed full of cars ready to crowd the shore. It’s a shame to see how commercialized many beaches are becoming. But I guess we each have our own ideas as to how a vacation should be spent. Give me a view of the ocean in one direction, a dune full of sea grass in the other, and the possibility of ponies stomping up the shore. I want to enjoy the sun without a great big hotel looming over my shoulder. I can only hope that Assateague will always stay the way it is. —Jillian Hardee ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/03/Assateague_Island.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/03/Assateague.2d8a8f88229a.mp3"
	},
	{
		"title": "Tufa",
		"text": "In the Sierra Nevada mountains in northeastern California, about a half hour’s drive from the legendary ghost town of Bodie, lies scenic Mono Lake. (Mono rhymes with “phono,” by the way. I could tell you were wondering.) It’s a large lake, with about twice the area of San Francisco—and impressively beautiful when viewed from the surrounding mountains. Up close, however, you discover that there’s both more and less to Mono Lake than meets the eye. Mono Lake is a “dead” lake, meaning it has inlets but no outlets. As a result, the lake has accumulated a very high concentration of salts and minerals, which become even more concentrated as the water evaporates. It’s now almost three times saltier than the ocean and 80 times as alkaline. Because of the lake’s high pH level, only brine shrimp and algae can survive in the water. But tourists don’t flock to Mono Lake to see the shrimp; they go to see the tufa (pronounced “too-fah”), the strange rock formations rising from the lake and scattered along the shore. Caves Without the Cave The tufa at Mono Lake are tower-like formations that are often described as “otherworldly.” In fact, they look pretty much like giant stalagmites—some as tall as 30 feet (9m). They would look right at home in a deep, damp cave somewhere, but they are not the sort of thing you expect to see sticking out of a lake. It’s no coincidence that tufa towers look like stalagmites; they’re made of exactly the same material, calcium carbonate (commonly known as limestone). But they have a different texture, a spongy interior, and most importantly, a different method of forming. Beneath Mono lake are freshwater springs whose water is rich in calcium. When the spring water emerges through holes in the lake bed, it reacts chemically with the carbonates in the heavily alkaline lake water and forms calcium carbonate deposits around the mouth of the opening. As the water continues to flow from the spring, the deposits grow; the water pressure ensures that a channel will remain clear in the middle of the formation, like a pipe. Tufa can grow at a rate of up to 1 inch (2.5cm) per year, but because the chemical reaction depends on the lake water, tufa can only grow until it reaches the water surface. Mono Lake is more than a million years old—one of the oldest lakes in North America. Over the millennia, its water level has shifted many times, mainly for natural reasons. Every drop in water level exposes some tufa, and there are some formations high above the current lake surface that are believed to be 13,000 years old. In 1941, Mono Lake was 40 feet (12m) higher than it is today. But in that year, four of the five streams that feed Mono Lake were diverted to supply water to Los Angeles. Without that constant input, evaporation caused the water level to drop again, thus exposing huge numbers of tufa towers that had previously been submerged. The tufa towers near the new shore of Mono Lake are estimated to be a mere 300 to 900 years old. The Tourist and the Tufa It is these recently exposed tufa towers that draw most of the visitors to Mono Lake. The California Park Service has carefully constructed paths and boardwalks to protect the fragile environment along the lake shore, and charges admission to some of the more popular areas to defray the cost of maintenance. Signs and brochures warn tourists not to touch the tufa, which crumbles easily. The signs and boardwalks aren’t terribly effective, though; I’ve watched tourists climb on the formations and pick up pieces of tufa. Ironically, by doing so they’re helping to destroy the very thing that drew them there in the first place. I’ve never understood tourist logic. The tufa towers made Mono Lake much more popular as a tourist destination, and the extra water certainly helped Los Angeles. But the change in water level was not healthy for the lake or for the tufa. As the lake began to shrink, the local ecosystem was thrown out of balance, and alkali deposits left on the shores were picked up by the wind, causing concerns about air quality in the area. After many years of citizen-led efforts, the California State Water Resources Control Board issued an order in 1994 to protect the lake and the streams that feed it. This order should result in the lake level rising 17 feet (5m) over a period of 20 years. That change in water level will submerge much of the tufa that now draws tourists to the lake—perpetuating yet another interesting cycle of logic. Had the water not been diverted in the first place and the water level not dropped, many of the tufa towers would not have been exposed, and therefore the lake would not have become the great tourist attraction it now is. Had it not become a tourist attraction, support probably could not have been generated to restore the lake; once that’s happened, the existing tufa may begin to grow again, but because most of them will be covered with water, there will be little to see, and tourism will likely decrease. Makes you think. Although Mono Lake has some of the largest and most plentiful tufa towers in the world, similar formations exist in a variety of locations, especially in the western United States. But not all tufa is in the form of towers. Whenever the chemical conditions are right for calcium carbonate to form, tufa can grow. This includes lake bottoms and areas of the ocean floor, plus locations in caves, near streams, and around the mouths of hot and cold springs. As a result, not all tufa is considered rare or exotic; it’s commonly used, for instance, in gardening—certain alpine plants grow very well in or on tufa. But if you’re claustrophobic and want the experience of being in a cave without a ceiling, Mono Lake is definitely the place to go. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/03/Tufa_Mono_Lake.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/03/Tufa.d97dd31047a5.mp3"
	},
	{
		"title": "The Perito Moreno Glacier",
		"text": "When I travel, I usually make a conscious effort to avoid having very specific expectations. I plan out an itinerary, but I try to maintain a sense of equanimity about the experiences ahead. I like to be surprised—and I like to be able to experience new things in my own way, on my own terms. This sort of attitude has not only saved me some disappointment, it's helped me to approach fairly commonplace sights and events with a sense of wonder and delight. As a result—and frankly, without much effort—I found myself feeling neutral, perhaps even a bit blasé, about the prospect of visiting a glacier in Patagonia. I've seen ice; what could this be other than a great quantity of it? I expected to be cold, so I packed appropriate clothing. I expected scenic vistas, so I packed my camera. And that was about as far as I thought about it. Size Matters The trip to the Perito Moreno glacier took us more than an hour by bus from the town of El Calafate, Argentina. When we rounded a corner on a mountain road and I got my first glimpse of the glacier, I thought, “Wow. That's really big.” Later, from a much different angle, I realized what a tiny slice of one corner of one end of this glacier I'd seen earlier, and I was overwhelmed at the scale of what I was seeing. As glaciers go, I am told, this is not one of the larger ones. Yowza. Even though I took dozens of pictures, including some panoramic shots, there is simply no way to capture how big this thing looks in person. No wide-angle lens could do it justice, because it's not only impossibly wide but tall and long as well. Short of climbing a mountain or flying high overhead, there is no way to take in the whole thing at once. So, yes: a lot of ice…but that doesn't begin to tell the story. We took a boat across the lake into which the glacier drains, then hiked along the shore to a point near the edge of the glacier. There, we were outfitted with crampons for a 90-minute hike on the glacier itself. After about five minutes of climbing on the steep ice, our guides mentioned that it would become much more strenuous from here on, and two members of our group decided to turn back. The rest of us got a good workout, some extraordinary views, and a few surprises. Like all glaciers, this one begins high in the mountains—in this case, the Andes, which separate Argentina from Chile. At the source, snowfall is nearly constant, and the weight of all this snow compresses the lower layers into virtually solid ice. As the snowfall continues, gravity pushes the thick mass of ice outward—downhill in this case. So a glacier is basically the same as a river, except that the water is frozen. This river moves very slowly—about one meter per day—from its source roughly 30km (19 miles) away. As it descends, it encounters higher air temperatures and begins to melt. Some glaciers melt into the ocean; this one melts into a lake. The end of the glacier is a sheer wall of ice about 5km (3 miles) long and standing 60m (200 feet) above the water's surface. When pieces fall off—a process known as calving—they make a tremendous roar and splash. Stand and Deliver The Perito Moreno glacier also has several unique features. For one thing, it is, at the moment (according to some experts, at least) the only glacier in the world in a state of equilibrium—neither advancing nor retreating. Retreating is the norm, due to global warming—numerous glaciers have disappeared in recent decades, and many others are shrinking rapidly. The Perito Moreno glacier, however, advances at the same rate ice breaks off, and has done so for many years. Another unusual characteristic is that this glacier empties into a lake right at the point where two branches connect through a fairly narrow channel. From time to time, the glacier's face reaches all the way to the outcropping of land on the other side of the channel—sealing it off to create, in effect, two separate lakes. As the glacier continues to melt, the water level in one of the lakes rises at a faster rate than the other, causing significant flooding. Eventually, the warm water melts enough of the ice that an underwater tunnel forms between the lakes; as the tunnel expands, the water levels equalize. Before long, the tunnel becomes more of an underpass for a giant ice bridge; when this inevitably collapses, it's a spectacular sight. The last such collapse occurred in March 2004. The glacier then advanced to block the channel again, and when we visited in December 2004, a small tunnel had recently formed and the water from the higher lake was still rushing into the lower one. It's a Floor That's Also a Dessert Hiking on a glacier is like hiking on a giant snow cone—the surface is very rough, and gloves are mandatory, as you could seriously lacerate your hand if you fell. Although we were not hiking close to the face of the glacier, our guides were careful to point out that the structure was not reliably stable. We had to steer clear of numerous fissures and holes, some of them filled with water and shining with a beautiful but eerie blue glow. We noticed a thin layer of dark sediment on the ice; the guide said this was sand and dust carried by the wind, and that the water itself was the purest you'd find anywhere. This made sense; after all, the ice came from snow that fell many years ago and would not have contained any airborne pollutants—and the ice would have been an inhospitable environment for most microorganisms. “You can drink it,” the guide said. We exchanged puzzled looks at the notion that we could actually drink the glacier on which we were currently standing. I took off my gloves and tried a few sips—incredibly delicious. They should bottle this stuff, eh? Then I noticed that the picture on the bottle of water in my hand looked suspiciously like the mountains directly in front of us. Ah. Just before we went around the last wall of ice on our way off the glacier, the guide said there was a special treat waiting for us. They'd set up a little table on the ice with complimentary glasses of Scotch for everyone—on the rocks, of course. Yes, those rocks. We didn't even mind the blatant product placement—it was a delightful treat. We left tired, sweaty, sunburned, and very satisfied. And to think: all I had been expecting was a lot of ice! —Joe Kissell UPDATE: Another dramatic collapse occurred in March 2006. The event attracted hundreds of tourists who kept an around-the-clock vigil, and was major news on Argentina's TV networks. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/03/Argentina-Perito_Moreno-Glacier.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/03/Glacier.700b3224b33f.mp3"
	},
	{
		"title": "Gaiman",
		"text": "Argentina has no shortage of bookstores. In some of the busier shopping districts of Buenos Aires, it’s not unusual to see half a dozen of them in a single block—all apparently doing brisk business. We visited many of these, and showed uncharacteristic restraint, leaving with just a few books altogether. Of course, the selection of English-language books was typically limited, though you could find Spanish translations of nearly any major English book you could name. For example, I picked up a Spanish copy of Harry Potter and the Sorcerer’s Stone. On the copyright page, it said that this book was also available in Latin and Welsh translations. The Latin bit surprised me: I can’t think of anywhere other than Vatican City where Latin is still used conversationally, and I don’t expect many folks there are keen on reading stories about wizards and witches. Welsh, on the other hand—that can certainly constitute a reasonable market, especially in Patagonia. Looking for New Wales In the mid-1800s, many residents of Wales felt their territory, culture, and language were being overrun by the English. Realizing they were hopelessly outnumbered, a group of them decided to look for a place far away where they could transplant a piece of Wales and control their own destiny. Patagonia offered a familiar climate and an appropriately remote location, far from English influence. So in 1865, 159 settlers, led by Rev. Michael D. Jones, sailed aboard a ship called Mimosa and landed in a sheltered bay on the coast of Argentina known as Golfo Nuevo. They initially set up residence in a port town that came to be called Puerto Madryn, but soon thereafter most of the colonists moved about 100km (60 miles) to the south, building several small towns along the Rio Chubut—one of the few fertile regions in this part of Patagonia. Among these towns are Rawson, the provincial capital near the coast; Trelew, a hub of commerce and transportation about 20km (12 miles) to the west; and a further 16km inland along the river, Gaiman. Although Gaiman was originally founded by a Pennsylvanian named David Roberts, it eventually achieved notoriety as the largest Welsh settlement outside Wales. Today, the town’s population numbers less than 5,000, but a large percentage of these people are direct descendants of the original colonists. Public signs are in Spanish and Welsh, and the Welsh language is still taught in the public schools. Here in the heart of Argentina, it’s not at all unusual to encounter people with names like Williams, Davies, or Jones—perhaps even with red hair—who speak Spanish with a Welsh accent and not a bit of English. Locals still proudly recall a visit by Diana, princess of Wales, in 1995. Tea, Anyone? Gaiman’s biggest tourist attraction, by far, is its tea houses. Here you can have a traditional afternoon tea with a large selection of pastries. An English couple in our group couldn’t wait to tell their families about the experience, as it was something they’d never actually do at home. Other major attractions in the town include the Primera Casa, a stone house built by Roberts in 1874 (still intact but with a new, corrugated metal roof), and a brick chapel built in 1880. The town also hosts an annual festival of choral music and poetry called Eisteddfod, where you can hear both Welsh and Argentinean folk music. Of the roughly 500,000 people in the world who speak Welsh, roughly 1%, or 5,000, live in Patagonia. Of these, the vast majority are bilingual, and in fact few speak Welsh as a first language. But today, as in the earliest days of the Welsh settlements in Patagonia, a group of dedicated citizens is working hard to maintain and revitalize the Welsh language and culture in this remote area. And if that requires help from a couple of Harry Potter novels, well, it’s all in the service of a good cause. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/03/gaiman.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/03/Gaiman.c5accb686894.mp3"
	},
	{
		"title": "Caleta Valdés",
		"text": "The Argentinean portion of Patagonia comprises five provinces, of which the northernmost one is known as Chubut. You have to fly about two hours southwest from Buenos Aires to get there, yet it’s still over 1,000km (about 600 miles) from the tip of the continent—just barely into Patagonia when you consider its overall scale. This impossibly dry, windy, and desolate area is as far south as Paul Theroux got in The Old Patagonian Express. He felt he was nowhere, and it was here that he experienced his much-quoted epiphany that nowhere is a place. Although I was to discover a much more varied and inviting landscape a few days later as we traveled deeper into Patagonia, I have fond memories of the quiet, empty, and rugged steppes of Chubut. Wonders Around Every Corner Our guide had arranged for us to spend an entire day visiting one of the region’s most popular areas, Peninsula Valdés, a provincial park that is home to more wildlife than you can shake a camera at. This peninsula is really more like a large island connected to the mainland by a narrow isthmus. In certain seasons—though not when we were there—whale watching is the peninsula’s big industry, as migrating southern right whales and orcas frequent the waters just off the coast. We did see plenty of elephant seals and sea lions and a variety of birds, not to mention astonishing numbers of sheep. But the thing I found most interesting on Peninsula Valdés was the view from a rest stop. We had been driving for quite some time through an endless expanse of Nowhere on our way from Somewhere to Somewhere Else. We had a schedule to keep, but we could afford perhaps 15 minutes for a quick rest stop. As we pulled into a restaurant’s parking lot, our guide mentioned that if we walked down this trail to the right, we could see (still more) elephant seals; if we took the trail to the left, we’d be able to see a most unusual sight known as Caleta Valdés, or Valdés Creek. The left-hand trail was a 15-minute round trip, which meant that we were supposed to choose between using the restrooms and beholding a natural wonder. I opted for a hasty restroom visit and a jog down the trail on the left. Catching the Drift What we saw from an overlook at the end of the trail was a long, thin strip of land—basically an overgrown sandbar—running parallel to the coast. At the far end, about 30km (20 miles) north, this strip of silt is connected to the peninsula. Here, at the southern end, is the only inlet to the so-called creek—a channel about 150m (500 feet) wide. Less than 10 years ago, the channel was 600m (2000 feet) wide. This geological feature, known as a coastal cord, tends to trap a bit of sediment every time the tide goes out. For the past couple of years, observers have predicted that it will close up entirely “any day now.” Unless another outlet forms—which seems unlikely—Caleta Valdés will soon change from a creek to a salt lake. And given the shallowness of that lake and the area’s extremely low humidity, it could dry out completely in several more years. Caleta Valdés is thus the only spot on the continent where the coastline is growing; everywhere else it’s either being eroded slowly away or receding due to rising ocean levels. It’s almost as though this little strip of land is thumbing its nose at continental drift, growing out toward the east as the whole continent slips slowly westward. This small wonder was well worth an abbreviated rest stop. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/03/caleta.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/03/Caleta.c446d0427945.mp3"
	},
	{
		"title": "Pennsylvania Dutch",
		"text": "Pennsylvania is a state (well, commonwealth if you want to be completely nitpicky) known for its linguistic, uh, irregularities. In the western part of the state, where I grew up, many people speak an endearingly odd dialect of English called Pittsburghese. Some town names have pronunciations that utterly belie their foreign roots. DuBois is pronounced “dew boys”; North Versailles is “north ver-sales”; La Jose is “la Joes.” Then, of course, there are towns that simply have goofy names—Eighty Four, Slippery Rock, and Punxsutawney come to mind. I've Been to Pennsylvania; Ask Me about Intercourse. But to put all these oddities in perspective, western Pennsylvanians rightly consider their geographic nomenclature downright bland compared to what you'll encounter on the other side of the state. Drive four hours east from Pittsburgh and you're in Lancaster County, an area that attracts tourists by the thousands each year for no other reason than that they want to be able to say they went through Intercourse to get to Paradise. (This makes for a roundabout route, as it turns out, but that's only fitting.) Other nearby towns include Blue Ball, Fertility, Gap, Bird-in-Hand, Smoketown, and even (I swear I am not making this up) Kissel Hill. These place names seem all the more amusing because the area is known for its religious conservatism, being home to large numbers of Amish and Old-Order Mennonite folk in particular. The other thing Lancaster County is known for is Pennsylvania Dutch—a term that can refer to an ethnic group, a language, a culture, or all three. Interestingly enough, despite the proximity of towns named Holland and New Holland, Pennsylvania Dutch has nothing to do with the Netherlands. The term is a misnomer, or at least an anachronism; the Pennsylvania Dutch came from Germany. Going Dutch How did a group of German settlers in eastern Pennsylvania—and the unique dialect of German they speak—come to be known as “Dutch”? There are two main theories. Most people assume that Dutch is an accidental corruption of Deutsch (the German word for “German”) or Deitsch (the word for “German” in the Pennsylvanian dialect). But the term may have been more of a historical accident than a linguistic blunder. Until at least the 1500s, the English word “Dutch” was used to refer generically to people of Germanic descent from the regions now known as Germany and the Netherlands. It wasn't until the 17th century that the term “Dutch” came to be used strictly for people from the Netherlands, but by that time a number of German immigrants had already settled in Pennsylvania, and the old term may have stuck. In any case, the language of the Pennsylvania Dutch evolved into a distinct dialect of German, and is still spoken by as many as a quarter-million people. Eastern Pennsylvania is not the only place where you can find native speakers of Pennsylvania Dutch. Smaller communities are located in several states in the eastern U.S., as well as Ontario, Canada. Like many minority languages, Pennsylvania Dutch is slowly losing ground to the dominant regional language—English in this case. With each new generation, children are less likely to learn Pennsylvania Dutch as their first language. However, efforts are underway to preserve and promote the language through books, classes, radio shows, and other media. But the most important things Pennsylvania Dutch speakers can do to keep their language alive are to engage in conversation—and to have children who can learn the language at home. Clearly, in more ways than one, Intercourse is important to the Pennsylvania Dutch. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/03/Allentown_centersquare.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/03/PA_Dutch.6c559553d426.mp3"
	},
	{
		"title": "Pilgrimage to Santiago",
		"text": "Each year, tens of thousands of people walk hundreds, and sometimes thousands, of kilometers from various points in Europe to the town of Santiago de Compostela in the northwest corner of Spain. In this town is a cathedral built over the tomb believed to be that of the apostle St. James (Santiago is Spanish for St. James). The tomb was discovered in the ninth century, and by the 12th century, the spot had become almost as popular a destination for Catholic pilgrims as Jerusalem and Rome. Not only do people still travel this route, but the number of pilgrims has increased dramatically over the past couple of decades—over 74,000 made the trip in 2003, and over 154,000 did in 1999 (a Holy Year). For some people, the journey along the Camino de Santiago (Way of St. James) is a purely religious one; they are going to visit the relics of St. James, and perhaps (during a Holy Year) seek a plenary indulgence—a remission of sin. For others, the pilgrimage represents a less specific spiritual journey—an attempt to discover purpose in life, to practice physical and mental discipline, or to contemplate one's vocation. For a few, it's simply a themed vacation, a novel walking tour of Europe. But for most participants, whatever their motivation, the pilgrimage is much more about the journey itself than the destination. I Would Walk 500 Miles There are many routes to Santiago. Some pilgrims begin the journey relatively nearby, while others walk across several countries over a period of many months to reach their destination. Among the traditional starting points that attract many pilgrims are Paris (about 2,000km/1,200 miles away) and Arles, France (900km/560 miles away). Although most pilgrims travel on foot, some make the journey by bike or horseback. Because the trip can be quite long, it is not unusual for a pilgrim to do it in sections—for example, walking for a week or two then returning the following year to pick up at the spot where last year's walk ended. Pilgrims beginning their journey obtain a document known as a Pilgrim Record or credencial, sometimes called a “Pilgrim's Passport.” This is a record of one's path; at each stop along the way, travelers have the document stamped at a local church, bar, or other waypoint. The Pilgrim Record serves two main purposes. First, it identifies the bearer as a pilgrim (as opposed to a tourist); pilgrims are entitled to free or very inexpensive accommodations and meals at lodgings along the way called refugios. Second, it provides evidence to the cathedral that the pilgrim has met their minimum requirements for a certificate of completion, known as a Compostela. The official rules stipulate that one must walk a minimum of 100km (60 miles) or bike at least 200km (125 miles) in a single stretch to qualify for the certificate, and the Pilgrim Record validates this path over a period of several days or more. Walks of Life Stories of people who walk to Santiago are filled with blisters, sprains, and other injuries; overcrowded refugios; unpleasant weather conditions; exhaustion from the walking; and other misadventures of every description. Nevertheless, pilgrims overwhelmingly feel that the journey was among the best experiences of their lives. Beyond the efforts and hardships are psychological and spiritual rewards that cannot be captured on a suitable-for-framing certificate. The pilgrimage to Santiago does not require a great deal of money, other than the cost of getting to the starting point and home from Spain—and a very good pair of shoes. However, it does demand a significant investment of time and energy, and a lot of dedication. I sincerely hope to be able to make this pilgrimage myself some day, though I can't really say why—I suspect the answer will make itself evident along the way. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/03/santiago_spain.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/02/Pilgrimage.9584de7a5782.mp3"
	},
	{
		"title": "The Bodleian Library",
		"text": "Oxford, England is a city known for its connections to literature. It is the home of Oxford University, whose former students or faculty included C.S. Lewis, Aldous Huxley, J.R.R. Tolkien, Lewis Carroll, and Oscar Wilde, among many others. Oxford University Press is also a prestigious publisher, best known for its academic and reference books, including the gigantic and definitive Oxford English Dictionary. The city of Oxford has a number of wonderful bookstores, several shops dedicated to Alice in Wonderland paraphernalia, and tours (by bus or foot) of the former homes and hangouts of the best-known authors. The smell of old books—one of my favorite aromas—lingers in the air. In short, it is a great place for people who love books, and it was therefore an essential stop on my trip to England last year. Where Forests Go When They Die Oxford University, composed as it is of over 30 individual colleges, has many libraries. But the most impressive and well-known library on campus—indeed, one of the most impressive anywhere—is the Bodleian Library. The library, which is administered by the university itself rather than any of its colleges, traces its roots back to 1320, when the first university library was established at Oxford. In the early 1400s, the university library was so small that all the books could fit in a single chest. Then Humfrey, Duke of Gloucester made a generous donation of about 280 manuscripts, and in 1444, the university decided to construct a new library to house them. Because of the large sum of money they had to raise, construction was not complete until 1488. But 60 years later, King Edward VI, a Protestant, instituted a law designed to remove all remnants of Roman Catholicism from the English church. By the fairly broad definition of what constituted a potentially corrupting influence, the vast majority of Humfrey's books were destroyed, or at least recycled. The leather from some of the covers was turned into gloves; other books were burned, sold, or kept by the Reformers for their own purposes. Today, only 16 of those original 280 books are known to survive. By 1556 the library was emptied of its furniture and taken over by the Faculty of Medicine. Bodleian Soul In 1598, however, Sir Thomas Bodley, a Fellow of Oxford's Merton College who had married a rich widow, made a large donation to bring the library back to life. In addition to money earmarked for the restoration of the building and its furniture, Bodley donated a number of books and solicited further donations from others. When the new library opened in 1602 it contained 2,500 books. It was Bodley's innovation to store the books on their ends rather than on their sides as had previously been the custom; this not only allowed more books to fit in a smaller space but also made them more easily accessible. Over the next few decades the library's collection grew rapidly, and when Bodley died in 1613, he left money to the library for expansion of its facilities. As time went on and the collection continued to expand, further additions were built, and several other independent libraries were absorbed into the Bodleian. Because of the incalculable value of many of the library's holdings, two very strict policies were enforced from the very beginning. The first was that books must never leave the library. All requests to borrow books were summarily refused—including requests by King Charles I and Oliver Cromwell. The other policy was that no fire may be brought into the library buildings. For this reason, the library was completely unheated until 1845, when Victorian engineers installed channels in the floor to carry hot water into the building after being heated in boilers outside. The library also lacked artificial lighting until 1929. Reliance on the sun for light and heat kept the library's hours of operation quite short—as little as five hours per day during the winter. However, the library also follows another traditional policy that is considerably more liberal: scholars from any university in the world are given free access to the library as readers, and those without a university affiliation can become readers by paying a nominal fee. The only stipulation is that all readers must swear this oath: “I hereby undertake not to remove from the Library, or to mark, deface, or injure in any way, any volume, document, or other object belonging to it or in its custody; nor to bring into the Library or kindle therein any fire or flame, and not to smoke in the Library; and I promise to obey all rules of the Library.” Books by the Mile The Bodleian Library is one of several copyright deposit libraries, which means that it automatically receives a free copy of all books and periodicals published in Britain. (The library purchases tens of thousands of foreign publications each year to supplement this collection.) The library currently holds over seven million volumes, which occupy 110 miles (180km) of shelving. Each year, the collection grows by more than 100,000 books and nearly 200,000 periodicals; these volumes expand the shelving requirements by about 2 miles (3.3km) annually. Much of the library's vast storage space is in underground tunnels built in the early 1900s. A system of conveyor belts delivers volumes through the tunnels to 29 reading rooms in the various library buildings. Readers may not browse the stacks freely; each book must be requested in advance and retrieved by a librarian. The system of requesting and delivering books ensures that the library knows the exact location of every volume at all times—down to the particular chair in which each reader is sitting. Given the age and rarity of some of the library's holdings, conservation is a major concern. Light levels are kept low to prevent ink from fading; gloves are required for reading some of the older manuscripts; and for many years books were chained to the shelves. Despite these worries, though, the library maintains that it is not a museum—scholarship comes before conservation. To prevent access to the books, even though it carries a risk of damage, would be to miss the whole point of having a library. At the end of our tour, our guide was careful to point out the benefactors' register, a large stone plaque listing some of the library's most prominent donors over the last six centuries, names rendered in Latin for optimum effect. There was space left for just three or four more names. If I ever acquire a fortune, the Bodleian Library will be one of my first philanthropic targets. Donors get to sit inside and smell the books for as long as they like. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/02/Bodleian-library.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/02/Bodleian.1916fcc4ed94.mp3"
	},
	{
		"title": "Audium",
		"text": "Last night I did something I hadn't done in perhaps 20 years, and thought I'd never do again. I'm a bit embarrassed to admit this, but under the circumstances it seemed like the right thing to do. I…um…drank a cup of instant coffee. Now I realize this will come as a shock to those who know the seriousness with which I approach coffee. (I have a saying: “You can take your coffee light, but you must never take it lightly.”) But there was a method to my madness, and I hope that a few words of explanation will put my behavior in context. The scene of my transgression was a little-known San Francisco institution called Audium. It is the world's only venue devoted exclusively to the performance of pure sound. Audium is a unique and highly specialized theatre. The room where the performance takes place is actually a building-within-a-building, completely isolated from outside sounds. About four dozen chairs are arranged in three concentric circles, with 169 speakers of all shapes and sizes located around the room. Some speakers are suspended from the ceiling, or hidden behind the walls, under chairs, or beneath the floating floor. You're completely surrounded by speakers, so all seats are equally good. It's almost like being in a planetarium, except there's nothing to see—the performances take place in complete darkness. You come to Audium to experience a total immersion in sound. Sounding Out an Idea The idea for Audium was conceived in the late 1950s, when electronic music was beginning to appear. A pair of classically trained, professional musicians became interested in exploring the role space played in composition and performance. Not content with two channels of sound, they wanted to know what it would be like for sound to move all the way around, above, and below the audience—using space itself as an instrument. Composer Stan Shaff and his partner, equipment designer Doug McEachern, began a long collaboration. Shaff conceptualized the sounds and effects he wanted to achieve, and McEachern figured out how technology could bring those ideas to life. In the early 1960s the first Audium concerts were held at universities and museums in San Francisco. In 1965, the first Audium theatre was created, and after a grant from the National Endowment for the Arts in 1972, construction began on the current building. Since it opened in 1975, the current Audium at 1616 Bush St. has given weekly performances. Shaff still sits behind the console, and McEachern still maintains the equipment—now in the process of being updated for the ninth time. Everything about Audium is analog—there's not a CD player, computer, or digital effects processor in sight. Considering the vintage of the technology, the sound quality is startlingly pure. On a good night, with the controls handled expertly, there simply isn't any hiss or buzz. Every sound is bright and vibrant. Shaff said he gave a special concert last year for a group of engineers from Dolby, who were impressed by Audium's use of technology. It makes Surround Sound seem downright pedestrian. Still, the engineers said, composers and soundtrack designers would have to learn entirely new skills to be able to create sounds for an audio environment as rich as Audium. Echo of the Past Visiting Audium is like stepping back in time 30 years. The building's architecture, décor, and the performance itself are pure 1970s. When you arrive, you buy your ticket at the box office (cash only, of course) and proceed into the foyer. The first thing you notice, appropriately enough, is sound. There's a faint but steady drone that sounds like a discordant organ. As you adjust to the sound, you also adjust to dim lighting and begin to study the abstract sculptures and prints lining the walls. Meanwhile, hidden speakers on every surface play seemingly random sound effects—voices, waves, ticking clocks. On one wall, a ghostly green projection of a clock face shows the current time. The total effect is one of intriguing eeriness. But it's eerie in a very particular way: you begin to notice, almost subliminally, that the entire experience reflects the sensibilities of a bygone era. Everything around you must have seemed extremely modern when it was built, but there's a complete absence of any artifacts, sounds, or scents of the post-computer age—right down to the powdered soap in the lavatories. But the unselfconsciously anachronistic setting is quite endearing. On a small counter, next to blank index cards on which patrons could write their addresses to sign up for a mailing list, was what at first appeared to be an electric coffee urn. Then I noticed the small sign that said “Hot Water,” and before I realized I'd automatically started looking for tea bags I did a double-take and read the rest of the sign: “for Coffee.” No tea bags in sight, but there was a dispenser full of instant coffee. At first I was annoyed—this just isn't natural, especially not in San Francisco in the 21st century. But then, intuiting that this could be an essential part of the complete package, I went ahead and made myself some. If I'm going to have the sights, sounds, and smells of the 1970s, I figured, I might as well have the tastes too. The coffee was…everything I expected it to be. Pay No Attention to That Man Behind the Curtain At precisely 8:30 p.m., Stan Shaff pulled aside a black curtain and introduced himself to the 20 or so members of the evening's audience. After a few words of explanation about the performance, he led the group through a dark, twisty hall called a sound labyrinth and into the performance space. As the lights went down, Shaff seated himself behind a customized console of knobs and levers in a small control booth. He then began what he refers to as sculpting sound. While taped recordings of all sorts of sounds played, Shaff manipulated their positions, speed, and volume in real time. So although the content was fixed, the performance itself was dynamic, changing significantly from night to night. The sounds we heard were dreamlike, evoking unexpected memories and emotions. There might be children playing, an airplane taking off, a flushing toilet, or a marching band. Interspersed with the natural sounds were the textures of old analog synthesizers—not melodic for the most part, but aleatory—sometimes playfully so, other times harshly serious. The show was not a musical work in the conventional sense, but rather a sound performance in the best tradition of experimental twentieth-century composers such as Arnold Schoenberg and John Cage. Fermata The show lasted about an hour and a quarter, including a brief intermission. As the sound faded away and the lights returned, the audience simply sat there, silently, for several minutes. For some, perhaps it was simply a matter of waiting for a cue that the show was really over and it was time to leave. But I think most of the audience was still savoring the experience, pondering the strange sensations and impressions of this unique performance. I left pleasantly disoriented, having to readjust to the sounds of the city with their conventional directionality. Audium performances are held every Friday and Saturday night promptly at 8:30. Audium does virtually no advertising, so Shaff never knows what to expect. On some nights, he said, the show sells out; on others, it's just him and his wife. But he's quick to point out that it's not a commercial venture so success isn't measured in numbers. What is important is his unique art and the impressions it leaves on the audience—including, he hopes, future generations of composers who will take up the torch of omnidimensional sound sculpture. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/02/audium.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/02/Audium.a2180935d0f7.mp3"
	},
	{
		"title": "The Mega Dog",
		"text": "Author's Note: On November 17, 2005—a little more than a year after this article was published—the Westward Ho Hotel and Casino closed permanently after more than 40 years in operation. Although, sadly, you can no longer go there to get a Mega Dog or a 99¢ margarita, we'll leave this article here for its historical value. Before I visited Las Vegas for the first time, a number of people warned me that I'd hate it. To be sure, there are any number of things about the city that one may find off-putting, and it can be quite an expensive place to visit—even if you don't count money lost by gambling. But my first impression of Las Vegas was that it was like a giant amusement park. Everything was built on an absurdly large scale, but the excesses almost seemed to make fun of themselves. I found it absolutely delightful to go from one casino to the next, watching how much effort each establishment put into looking gaudier and more over-the-top than the next. Whether it's better blackjack odds, looser slot machines, a faster roller coaster, or a flashier pirate show, every business has some gimmick to convince the tourists to spend their money there. And of course, like an amusement park, everything in Las Vegas is designed carefully to make you feel that the money you're spending is well worth it; you're experiencing one-of-a-kind attractions. More is Less Down at the unfashionable north end of the Strip, older hotels cater to families and travelers on a budget. Instead of competing to be more luxurious than the place next door, the casinos lure customers with an extremely effective marketing technique: really cheap food and drink. However much common sense may try to hold you back, it's hard not to be drawn in by a sign promising a 27-ounce (0.8 liter) frozen margarita for 99¢. One of these signs is outside a nondescript hotel-casino called Westward Ho. This is as no-frills as a casino gets in Las Vegas. There are no celebrity performers or erupting volcanoes. Just slot machines, table games, and the cheapest (not to mention least expensive) food in the city. And they still think big when it comes to food. In our never-ending pursuit of kitsch, Morgen and I decided to check out Westward Ho's margaritas a couple of years ago. It took us quite a while to find the bar that sold them, and let me be frank: they were awful. In that 27-ounce glass there was perhaps one microdroplet of tequila—it was basically a very sweet slushy lime drink with a faint hint of alcohol. So when we returned this summer, we brought our own supplementary tequila, which I must say enhanced the experience considerably (while still making the price a bargain). We needed something for that drink to wash down, so we went to the deli in the back corner that features the casino's star culinary attractions. For 99¢ you can buy your choice of a shrimp cocktail or a basic hot dog. The shrimp cocktails were every bit as impressive as the margaritas: a small plastic glass filled with shredded lettuce and topped with a handful of baby shrimp and a dollop of cocktail sauce. A Matter of Size But if you're willing to splurge, $1.49 will buy you the largest hot dog I've ever seen, a 3/4-pound (1/3 kg) Mega Dog. These are no mere foot-long hot dogs; using a dollar bill as a rough measure of 6 inches, I estimated the Mega Dog to be 14 inches (35cm) long—about the size of three standard hot dogs. Last year I couldn't quite bring myself to purchase one, but on our most recent trip I decided it was one of those experiences I just had to have. The gentleman in front of me ordered his with the works—cheese, chili, and sauerkraut—and because of all the overflowing toppings it had to be cut in half just to fit on a plate. But those toppings cost extra; I was looking to get the most bang for my buck and a half, so I got a plain dog and added some ketchup and relish myself. Hot dogs are not one of my dietary staples, so I can't say with much conviction how the Mega Dog stacks up taste-wise against its more compact cousins. I didn't find it particularly objectionable, though, and certainly on a calories-per-dollar basis, you're getting more than your money's worth. Our biggest culinary disappointment at Westward Ho, in fact, was their advertised 5¢ cup of coffee—Nickel Nick's Java Shop, alas, was closed late at night when we were there. That struck me as odd, since cheap coffee would seem to be a good way to keep patrons awake and gambling into the wee hours of the morning when they've had a few too many margaritas. Westward Ho is not the only place in Las Vegas that sells extremely cheap food, but it's my favorite. Quality aside, the idea that you can get stuffed for less than $2 (and still have enough money left over to play nickel slots) is strangely reassuring in a town where money is so easy to lose. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/02/mega-dog.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/02/Mega_Dog.309f5ce189ed.mp3"
	},
	{
		"title": "Sedona’s Energy Vortexes",
		"text": "Allow me to get this disclaimer out of the way right up front: today's interesting thing might not exist. But let's be fair—I am not one to judge something by its ontological status alone. If it does exist, it's very interesting indeed, and if it doesn't, the widespread belief in its existence is equally interesting. I am referring to a natural phenomenon supposedly found in several places around Sedona, Arizona: something called an energy vortex. The town of Sedona, about two hours' drive north of Phoenix, is situated in an area of rare and stunning natural beauty. Towering rock formations and iron-rich reddish soil give the landscape an otherworldly appearance. This looks like what you imagined as the Old West, and countless films have been shot here. Kids will recognize it as the habitat of Road Runner and Wile E. Coyote. If you're looking for a scenic vacation spot, Sedona is the place to go. It's a favorite destination for romantic getaways, with a resort or a spa around every corner. Doing the Twist A large percentage of Sedona's visitors, however, come to experience something you can't see at all. An endless number of books, Web sites, brochures, and local guides proclaim the wonders of several so-called energy vortexes. A vortex, it is claimed, is an area of invisible, swirling energy emanating from the earth and producing an uplifting, rejuvenating sensation in visitors. Nearby, one often finds juniper trees with severely twisted trunks and branches—an effect attributed to the vortex energy. So powerful is this force, in fact, that it has twisted the laws of grammar in the entire region. What would in other parts of the English-speaking world be called “vortices” gets twisted into “vortexes” in the local parlance. What exactly is an energy vortex? There is no convincing answer to that question, the only common thread being that they are spots of increased energy. Some people use terms such as “magnetic,” “electrical,” or “electromagnetic” to refer to this energy, but I have heard of no scientific measurements that indicate any unusual electromagnetic activity in the area. Even if there were, it's not clear how human beings would be able to sense it directly. Others say it's nothing of the sort, that it's psychic energy of some kind, which explains why it can't be measured. But the energy is nearly always described using the term “subtle,” with the promise that you will feel it “if you are a sensitive person.” In my less charitable moments, I suspect “sensitive” is meant as a euphemism for “credulous,” but you can make up your own mind. Looking for a Sign Actual evidence for the existence of the vortexes—apart from all the footprints and cairns left by tourists—is sketchy at best. The twisted juniper trees, which are indeed quite unusual, are the only physical indication of invisible forces, and only a very few of the trees have this feature. You'll see a twisted tree right next to a perfectly ordinary one. It seems strange that a vortex would produce such a highly localized effect, and I can imagine any number of other causes for the twisted trees. Locals seem to be in agreement that there are four main vortexes near Sedona, though some claim there are a number of other smaller vortexes, and others describe the whole area as being effectively one giant vortex. Vortex experts (vortexperts?) go into great detail about how one vortex is more masculine, one more feminine, another balanced in its energy. Others speak of energy as moving upward or downward, depending on the vortex. Clearly there is more to the vortexes than fails to meet the eye. Taking Vortexes for a Spin A couple of years ago, I was in Sedona to participate in a t'ai chi retreat. I scheduled some extra time in my trip so that I could visit the vortex sites and see (or feel) for myself whether there was anything to the claims. I was prepared for—even hoping for—a significant experience. I didn't know what I was supposed to feel, but I was looking forward to finding out. Armed with vortex maps, hiking shoes, and sunscreen, my companions and I began visiting the best-known vortexes. In each location, we hiked to the spot said to be the epicenter of vortex activity and spent some time standing or sitting quietly, trying to clear our minds, relax our bodies, and allow ourselves to experience whatever was there to be experienced. At the first two or three vortexes—reputed to be the stronger ones—I had a very distinct experience of fresh air and sunshine, of perspiration from the heat and the hike, and a sore behind from sitting on the rocks. These are all powerful sensations, of course, but not particularly unusual ones. Beyond that, I just didn't sense anything. My companions spoke of feeling energized and refreshed, but I figured that was attributable to very ordinary causes. Our final stop, called the Airport Vortex, was supposedly a weaker vortex. Again we hiked to the appropriate spot (thoughtfully marked with a ring of stones by earlier groups of vortex-seekers). This time I felt…weird. I don't have a better word for it than that. There was something very unusual about the way I felt there that just made me walk around for a long time with a puzzled look on my face, trying to put my finger on it. A little tingly, perhaps? Maybe, but that could mean anything. Happy, invigorated, clear-headed? Sure, I guess, but that wasn't really it either. All I can tell you is that I felt an indeterminate but positive sensation there that I hadn't felt before and didn't feel afterward. I don't know what it was, and I don't know that it wasn't my imagination. Whatever it was, it certainly was subtle, and curiously, I was the only one in the group to feel it, whereas I had been the only one not to feel anything at the other locations. I Want to Believe I'll be the first to admit this is hardly a resounding proof. I may wear Birkenstocks, but I'm not really the crystals-and-incense type, if you know what I mean, and I have always regarded New Age beliefs with more than a bit of skepticism. That's not to say I don't find them extremely interesting. As with any meme that rests on unproven claims, my inclination is to suspect there's something real behind it, though perhaps not what people commonly believe. Maybe there really is some unmeasurable form of energy concentrated in vortexes; maybe my psychic sensitivity is too underdeveloped or my skepticism too strong for me to perceive it. Or maybe the phenomenon that has been described using “energy vortex” terminology is something entirely different but nevertheless not imaginary. This is all, of course, possible, and I'd like to believe it. I'd like to think that the next time I go to Sedona, I'll experience more than pretty rocks and fresh air. But the effect will have to be quite pronounced to convince me it's not just in my head. Vortexes or not, Sedona is a marvelous place to visit. Endless miles of hiking trails, postcard-perfect photo ops at every turn, and desert tours in a hot air balloon or pink jeep make it a memorable destination. I'll go there again, and maybe next time I'll be more attuned to the energy and have a different experience to report. See you at the vortex. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/02/sedona.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/02/Sedona.59d4e1445a4c.mp3"
	},
	{
		"title": "Tabacón Hot Springs",
		"text": "Volcanoes are generally considered rather scary, unsafe places. There was that whole Pompeii incident, of course, not to mention Mt. St. Helens. Any sensible person knows that you don’t want to be anywhere near a volcano when it erupts, and that volcanoes have the nasty habit of erupting at unpredictable and very inconvenient times. Nevertheless, dozens of active volcanoes around the world have become major tourist destinations. PR types minimize the danger, of course (“Over 27 months without a tourist fatality!”), and, statistically speaking, the odds do indeed favor a safe visit. But many thousands of tourists take the risk because volcanoes are so strange and interesting. Most of us know volcanoes only from stories that are set in faraway places and therefore have a mythological character; seeing an active volcano in person seems a little bit like seeing a unicorn—something that doesn’t seem like it could really exist. In central Costa Rica, the Arenal Volcano offers the quintessential volcano tourism experience. Practically the entire economy of the nearby town of La Fortuna is based on tourism. There are hotels, lodges, restaurants, tours, hikes, and activities of every description that cater to people who make the long drive to the area for one reason: to hear the rumble and catch a glimpse of spewing smoke, ash, and lava from Arenal. But by far the most famous (and most expensive) attraction besides the volcano itself is the Tabacón Hot Springs Resort & Spa. Forgotten But Not Gone Tabacón was once a tiny, quaint village nestled at the base of Arenal Peak. The mountain had been a volcano once, yes, but it hadn’t erupted since 1525 so its history was effectively forgotten. In 1968, a class of schoolchildren in Tabacón was given the assignment of drawing a picture of their town. When one child labeled the mountain “Arenal Volcano,” the teacher marked it wrong: “Arenal Peak is not a volcano, it’s just a mountain.” A few days later, the mountain erupted. The entire village of Tabacón and the nearby town of Pueblo Nuevo were wiped out, destroyed by ash and hot gases. Although many of the town’s residents fled when the rumbling began, 78 people died. In the years since, there have been several other significant eruptions and a few fatalities. A major eruption in 1998 forced the evacuation of nearby hotels, and lava came rolling down the hill as close as 500 feet (about 150 meters) from the resort. Arenal is still quite active, with minor eruptions many times a day. By day there are puffs of smoke accompanying the menacing rumbles, and on a clear night you can see orange streaks running down from the peak. Such is the popularity of the volcano that enterprising developers decided to erect an elaborate resort on the site of the former town of Tabacón. Where better to experience the sights and sounds of Arenal? Tabacón consists of two sites: a hotel with famously expensive views of the volcano (and an optional wake-up service for guests who want to be informed if the sky clears in the middle of the night to see an eruption), and the expansive hot springs and spa complex across the road and around the corner. The term “hot springs” is not strictly accurate, as the source of the water is an underground river, but the water is heated naturally by the volcano so the net effect is the same. The water is channeled into a series of interconnected pools where, because the hot water is mixed with cold water in varying proportions, the temperature ranges from briskly cold to 102°F (39°C). Signs next to each pool indicate its temperature, though I can say from experience that some 39° pools are hotter than others. Caution: Water May Be Hot The pools themselves, some of which include waterfalls you can sit under for a natural massage, were for the most part constructed from local stone in such a way as to look quite natural. I realized just how natural they were the first time I stepped in one. The bottom was littered with large, slippery, irregularly shaped stones. It was sometimes quite difficult to move around without slipping, tripping, or stubbing a toe. Then I began to notice there were very few handrails, no signs urging caution, and no requirement that guests sign a release form before using the hot springs. I laughed to myself when I realized that such a place could never exist in the United States; it would be either regulated or sued out of existence in a week. That made me enjoy the experience all the more—a place where adults were given credit for some common sense, where simple pleasures could be appreciated without a generic, artificially sterile environment. Imagine that. The grounds where the hot springs are located are meticulously manicured but still appear to have been carved out of a little corner of rain forest, which in fact they were. It gives you a sort of “Jurassic Park” feeling—a controlled slice of a wild environment. And despite the large numbers of tourists, it is a wonderfully relaxing place. Float Me a Loan? I had just one disappointment: a much-hyped warm pool with a swim-up bar. I had never been to one before and that sounded like great fun. Contrary to what was stated in the ordinarily unimpeachable Frommer’s Guide to Costa Rica, the swim-up bar did not offer the option of paying with a preauthorized credit card voucher; they accepted only cash. If I may say so, a cash-only swim-up bar is about the silliest thing I’ve ever heard of. Once you get to the bar and figure out you can’t pay for anything, you have to get out of the pool, go back to the locker room, get some cash, return to the pool and wade out to the bar carefully, holding bills so they don’t get wet—and with nowhere to put your change. After all that aggravation, you’re going to want a very large piña colada to settle your nerves. Fortunately, those are easily obtained. After a long day of trekking through the hot, humid rain forest, there’s nothing like a nice relaxing soak in a hot, humid spa. No, really. Strangely enough, the hot water actually feels very refreshing, especially in the evening. We didn’t plan far enough ahead to get reservations for a room at Tabacón—which is just as well since we got a better deal and a great view at another lodge down the road—but day passes are available for a modest fee, and often included as part of other tour/adventure packages. When Arenal is not busy devastating the countryside, it’s often clouded in, so you may travel halfway across the country and find there’s nothing to see. The hot springs themselves are worth the trip, but all the same, I suggest watching your step on those wet rocks. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/02/tabacon.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/02/tabacon.3f1fe2e2ad8e.mp3"
	},
	{
		"title": "Arcosanti",
		"text": "While on a business trip in Scottsdale, Arizona in the early 1990s, I took a walk down the road from the hotel one afternoon and ran into a peculiar-looking place called Cosanti. This compound, an official Arizona Historical Site, is a collection of oddly shaped concrete structures, including large domes and apses made from earthen molds. The first thing a visitor notices is the multitude of handmade bronze and ceramic windbells all over the property. These are made in the foundry and workshops on the site and available for sale in the gift shop. But Cosanti is much more than a new-agey craft center. It's the residence and studio of Italian architect and artist Paolo Soleri. As the brochures on the counter explained, Cosanti is, among other things, a prototype for a much larger and grander construction project called Arcosanti. City in the Wilderness Located about 70 miles (110 km) north of Phoenix, Arcosanti is called an “urban laboratory.” What Soleri has been testing in this laboratory for well over 30 years is a concept he calls arcology, a blending of architecture and ecology. His vision is to build a 25-acre city where 5,000 people can one day live, work, and play—comfortably, sustainably, and in harmony with nature. Soleri believes that wastefulness and urban sprawl are among the great evils of the age, and he aims to eliminate these problems with careful design. According to arcology, well-planned urban areas can use space much more efficiently and benefit from dramatically reduced energy requirements and environmental impact. This means, for example, eliminating cars, roads, and garages by putting all buildings within walking distance of each other. It also means creating multi-use spaces for maximum flexibility, and relying on solar and wind energy for most heating, cooling, and lighting. Beyond the issues of consumption and pollution that plague the world's urban and suburban areas, Soleri feels that people have become too detached from each other, and that an effective community requires more human interaction. Accordingly, Arcosanti has been designed with a large amount of shared living space (such as kitchens, gardens, and recreation areas). This seemingly benign fact sets off warning bells for Soleri's critics, some of whom see Arcosanti as an immense commune, or worse—a cult-like organization. While the project does attract its fair share of New-Age types, it also attracts many ordinary people for whom privacy does not necessarily mean a single-family house in a cul-de-sac. But if anything, Arcosanti's biggest problem is that it hasn't produced enough converts—or, to use a less loaded term, enthusiasts. A Time to Build When construction on Arcosanti began in 1970, Soleri expected it to be completed in 10 years, but less than five percent of the planned project has been completed to date. Construction is done by volunteers, who pay to live and work at Arcosanti during five-week workshops. Fewer than 100 people reside at Arcosanti at any given time, though the site receives more than 50,000 tourists per year. Much of the money used to fund the work comes from sales of the windbells and other pieces of art. But the money and volunteers are not plentiful enough to move the project along quickly. Time is running out for Soleri, who's in his mid-80s, though he intends the experiment to continue indefinitely under the auspices of the nonprofit Cosanti Foundation. Even if Soleri's experiment in the Arizona desert proves one day to be fabulously successful, it will not necessarily signal a triumph of arcology over other forms of urban planning. What works for 5,000 people may not scale up to a city of millions; what works in a hot, dry climate may fail in colder, darker, and wetter areas. But the biggest roadblock of all is not technological, it's psychological—convincing suburbanites that the cozy, interdependent community of a rural “city” is an improvement over the self-sufficient existence they've worked toward their entire lives. After all, arcology assumes that everyone will more or less like, respect, and work happily together with their neighbors. Sounds like a fantasy to me. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/02/Arcosanti.13024d6c1775.mp3"
	},
	{
		"title": "The Hearst Estate at San Simeon",
		"text": "For reasons that have never been entirely clear to me, I went through much of my life completely oblivious of certain very important icons of American culture. For example, if you were to ask 100 Americans at random to name the best movie of all time, it's a safe bet that a sizable percentage would say, “Citizen Kane,” Orson Welles's 1941 masterpiece. Even those who don't consider it a cinematic legend have most likely seen it, if for no other reason than curiosity at its fame. But I can't recall even hearing of the film until about six or seven years ago. Morgen and I were watching some old “Kids in the Hall” videos, and one very funny sketch was based on the assumption that everyone knows about Citizen Kane. Feeling that my cultural education was incomplete, I finally saw the film. I enjoyed it but utterly missed the point, having also somehow failed to accumulate any knowledge of William Hearst, on whose life the story was not-so-subtly based. Hearst, like the fictional Charles Foster Kane, was a newspaper magnate who aspired to, but never quite got, political power. Where Kane spent his fortune on a vast estate in Florida he called Xanadu, Hearst built his dream house in San Simeon, California—about 200 miles (322km) south of San Francisco. Hearst had inherited a 250,000-acre (101,172-hectare) ranch on a hill overlooking the ocean, and he used to take his family camping there. Eventually he tired of “roughing it” in a small city of tents and in 1919 hired architect Julia Morgan to design less austere vacation housing. The Art of Building a Palace These improved camping digs eventually turned into a project of palatial proportions. For decades, construction (and renovation) was almost continuous. Hearst was an avid art collector, and he and Morgan designed the estate to incorporate and display his considerable collection, which included not only paintings, sculptures, and tapestries, but entire walls, floors, and ceilings removed from castles and churches in Europe. As the art collection grew, the estate grew to accommodate it. The estate was designed for entertaining, and Hearst nearly always had guests in his home. Among his most famous visitors were Calvin Coolidge, Winston Churchill, Charlie Chaplin, Clark Gable, Cary Grant, George Bernard Shaw, and Amelia Earhart. Guests were given the run of the property but required to attend the evening meal with Hearst. Although every need was attended to—Hearst even had a complete selection of bathing suits for guests who forgot to bring their own—drunkenness was never tolerated, and rowdy guests were sent home. But an invitation to the Hearst residence was highly coveted: it meant either that you were rich and famous, or that you'd get to fraternize with those who were. San Simeon was a place where connections were made, power was wielded, and alliances forged. One Word: Rosebud When Orson Welles, at age 24, made Citizen Kane, he used Hearst as a model and—to put it generously—painted him in a less-than-flattering light. More upsetting for Hearst was the film's depiction of the character Susan Alexander, a talentless singer Kane marries. Her resemblance to Hearst's real-life mistress, movie star Marion Davies, was all too obvious. Hearst found out about the film even before it was finished and fought bitterly to prevent its release; Welles, who also had enormous power in the film industry, fought back. This much-chronicled battle damaged the reputations of both men, and prevented Citizen Kane from achieving any real acclaim until long after its original release. Welles, for his part, later claimed that the film was not intended as a reflection on Hearst's life, even if some notable character and plot points were inspired by Hearst. But now, Citizen Kane is inextricably linked to San Simeon, and the estate's current popularity as a tourist attraction is undoubtedly due, in large part, to the film. Like most lavish residences-turned-tourist attractions, what this estate has more of than anything else is…statistics: a total of 165 rooms, including 56 bedrooms and 61 bathrooms, 41 fireplaces, a 5,200-volume library, and over 90,000 square feet (8361 sq m) of floor space. The primary structures on the grounds are a main house (“Casa Grande”) that resembles a Spanish cathedral and three smaller guest houses, plus a huge Greco-Roman outdoor pool as well as an indoor pool lined with gold and Venetian glass. But wait, there's more! Hearst also had his own zoo, as well as a private airport, complete with two paved runways equipped for instrument landings. (Besides using the airport to shuttle in guests, Hearst insisted on having a daily copy of each newspaper he published—more than thirty from all parts of the country.) He also had a theater in his home that would put many multiplex cinemas to shame; legend has it that he insisted on showing a film for his guests every night. Construction on the property continued until 1947, when Hearst, in failing health and with severely depleted financial resources, moved away from San Simeon. I don't believe I'm in any imminent danger of becoming ludicrously wealthy, but I have certainly fantasized about my dream home from time to time—what kind of house I'd live in if money were truly no object. I think it would be very much on the scale of one of the guesthouses on Hearst's estate—large but not too large; lavish but not gaudy; livable and maintainable by ordinary humans. Well, OK…throw in the home theater too. You never know when you might want to have a few friends over for dinner and a movie. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/02/hearst_castle.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/02/Hearst.2e0f8d50cebf.mp3"
	},
	{
		"title": "Winchester Mystery House",
		"text": "San Jose, California—about an hour's drive south of San Francisco—is the unofficial center of Silicon Valley. Lots of high-tech companies are based in or near San Jose, and of the dozens of times I've been there, all but one or two were for a technology-related conference of one sort or another. It's an attractive small city with some excellent museums, parks, and restaurants. But San Jose's biggest tourist attraction was built long before computers made their mark on the area. About five miles (8km) from downtown, the Winchester Mystery House draws huge crowds almost every day of the year for a simple walking tour of what may be the country's strangest residential building. Everyone in the Bay Area seems to know about the Winchester House, to the extent that billboards advertising the attraction don't give any information other than its name. When I first moved to northern California several years ago, these signs puzzled me. Even after reading a brochure about the house, I didn't quite grasp what it was all about until I visited for myself. The Winchester Mystery House is undeniably interesting, though whether it lives up to its hype is another question. Our House Is a Very, Very, Very Strange House From the outside, the building appears to be nothing more than a sprawling Victorian mansion surrounded by meticulously groomed gardens, soothing fountains, and lots of tour buses. It's pretty, though not particularly shocking. But the interior of the building and the story of its construction are bizarre and fascinating. Tickets are surprisingly expensive, and there's sometimes a long wait for your guided tour to begin. But once inside, you forget all about that. You're walking through a mystery. The Winchester House has 160 rooms, with a total of more than 10,000 windows, 2,000 doors, 52 skylights, 47 fireplaces, 40 bedrooms, 40 staircases, 6 kitchens, 3 elevators, 2 basements, 1 shower, and 349.7 other impressive-sounding numerical statistics. What makes it most interesting, though, is what it doesn't have—any rhyme or reason. The entire house seems to have been randomly assembled, disassembled, and reassembled numerous times, with no master plan or design. And in fact, that's pretty much what happened. Stairs lead to nowhere; floors have doors and windows in them; doors open into solid walls. All of this and more was due to an inexplicable obsession that drove its erstwhile owner, Sarah Winchester, to keep the building continuously under construction for 38 years. Repeating Success The story begins a century and a half ago. Oliver Winchester was the co-owner of a successful shirt manufacturing business. In 1857, just before the U.S. Civil War broke out, Winchester took over the Volcanic Repeating Arms Company. The company, which would later be renamed Winchester Repeating Arms Company, was responsible for revolutionary advances in rifle design. With repeating rifles, a soldier could fire several times without reloading, and sales of the weapons soon made Winchester both wealthy and famous. His son and heir, William Wirt Winchester, married Sarah Pardee in 1862. Sarah was a diminutive woman at 4 feet, 10 inches (147cm) tall, but was reputed to be charming, intelligent, and beautiful. She gave birth in 1866 to the couple's first and only child, Annie, who died before she was two weeks old. Annie's death affected Sarah deeply, and for years she withdrew from the public and her family alike. In 1880 Oliver Winchester died, leaving his fortune to his son William. But the following year, William died of tuberculosis. This left Sarah the only heir to the Winchester fortune, an inheritance of US$20 million, plus nearly 50 percent ownership in the company, which paid her $1,000 per day. Not too shabby even by today's standards, these figures were astronomical in the late 1800s. But the fortune was no consolation to Sarah, who began to believe there was a curse on her family. History and Mystery Shortly thereafter, Sarah Winchester moved from New Haven, Connecticut to San Jose, purchased a modest farm house, and began building. This is where history ends and speculation begins. It's also an appropriate time for a brief cautionary digression. Dozens of Web sites, booklets, and brochures (and even the tour guides at the Winchester House) tell variations on the story of why Mrs. Winchester behaved the way she did for the rest of her life. Sadly, most of these stories appear to have been copied from each other and there's no persuasive evidence to support any of them. This mirrors the situation a century ago, when a fanciful tale about Mrs. Winchester would be told, embellished, and retold until it was impossible to separate truth from fiction. Thus, assume that most of what follows is apocryphal. And a word to the wise: history is slippery. What we know is that Mrs. Winchester hired builders to work around the clock, every day, for 38 years. The house was in a constant state of change, with rooms being built and modified on a daily basis. According to legend, Mrs. Winchester had visited a psychic in Boston who convinced her that she was indeed under a curse of sorts. The spirits of those who had been killed by Winchester rifles had sought revenge from her family and were now haunting her. The only way to appease the spirits and prevent her own death, by some odd logic, was to ensure that construction on her house never stopped. One version of the tale has it that the labyrinthine interior of the house, including the stairs to nowhere and the dead ends, were meant to confuse or slow down the spirits. An alternative explanation was that Mrs. Winchester, in daily séances, received plans for the next day's work directly from the dead, and simply did as she was told. Whether for one of these reasons, or simply being off her rocker, Sarah Winchester did indeed keep construction going for years on end, in what appears to be a completely random manner. This One Goes to 13 Whatever the reasoning she employed, it is certain that Mrs. Winchester was superstitious. One indication is her repeated use of the number 13 in features of the house: there are 13 bathrooms; 13 palm trees line the driveway; most of the windows have 13 panes; a sink drain has 13 holes; a chandelier that originally had 12 lights was modified to have 13; and so on. It is also frequently said that she slept in a different bedroom every night. In 1906 when the great earthquake struck San Francisco, part of the Winchester house was damaged, including the bedroom in which Mrs. Winchester was sleeping that night. Although she was unharmed, she believed the spirits were trying to tell her something. As a result she had the front portion of the house blocked off, and continued construction elsewhere. Spirit of the Winchester House Sarah Winchester died in her sleep in 1922 at the age of 82. Construction on the house stopped immediately—some stories say carpenters stopped with nails hammered in halfway. In Sarah's will—which consisted of 13 sections and included 13 signatures—the house was not mentioned specifically at all, but all her possessions were left to her niece, Frances Marriot. Marriot had all the furnishings removed from the house, a task which took more than six weeks due to the house's design, then sold it to be used as a tourist attraction. It was later declared a California Historical Landmark, and is still open daily for tours. According to some estimates, Sarah Winchester spent a total of $5.5 million building and rebuilding her house. As a tourist attraction, the Winchester Mystery House undoubtedly brings in money at a much faster rate than it was spent during the years of its construction. Appropriately enough, the reason for the house's current success is much the same as the reason it was built: many of the people who visit believe the Winchester Mystery House is haunted. (Special nighttime flashlight tours every Halloween and Friday the 13th reinforce this idea.) Tour guides will tell you stories of unexplained noises, of faucets mysteriously turning themselves on, of rooms suddenly turning cold. I've been to the Winchester House a couple of times and have never seen a ghost, but if you're ever in San Jose, I recommend a visit for the sheer weirdness of the experience. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/02/winchester_mystery_house.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/02/Winchester.74bb5a256b71.mp3"
	},
	{
		"title": "One-Log House",
		"text": "I've always wondered about the expression “famous for being famous.” It seems to denote someone or something with no intrinsic appeal but with a high level of self-replicating buzz or hype. I can think of examples of famous people and things that seemingly don't deserve to be famous, but what has always puzzled me is how that buzz about nothing gets started. In other words, how could I become famous for being famous? If it's true that there's no such thing as bad publicity, maybe it would be fun to be famous for being famous. Not “Joe Kissell the famous author” or even “Joe Kissell the famous curator of Interesting Things” but just “Joe Kissell the Famous.” Sure, all things being equal, I'd prefer to be known as smart and talented, but notoriety itself can be useful. One time-tested technique for building up unearned fame is the self-fulfilling prophecy. If you declare something to be the case, loudly enough and persistently enough, you may set in motion a chain reaction that will eventually make it true. This phenomenon is of course well-known in California, even in the quiet rural areas far from the machinery of Hollywood fantasy. A case in point: the Famous One-Log House of Garberville, California. No one can say how famous it is, or for what reasons, or among what group of people, but undoubtedly that one word on the sign has convinced hundreds of visitors to pull off the road and have a look rather than just zipping by. Big Red If you're driving through northern California to or from Oregon, the scenic route—US Highway 101—takes you through ancient redwood forests. The stuff of legend, song, and bitterly disputed logging practices, California redwoods (Sequoia sempervirens) are known for both their size and longevity. Many of the trees are over 2,000 years old, with heights of over 300 feet (about 100m) and diameters of as much as 30 feet (about 10m). Decades ago, before environmentalists started lobbying to keep these old trees alive, the redwoods were exploited not only for their lumber but also for their value as tourist attractions. It's not very exciting just to say, “I saw a big tree,” but it does sound cool to be able to say, “I drove my car through a big tree.” So a number of live trees had car-sized tunnels bored in their trunks; visitors were charged a few dollars to drive through the tree and take a picture. And yes, I drove through one of the trees too, for no other reason than to be able to say I'd done it, just like the rest of the tourists. The stretch of highway with the drive-through trees also has a number of other cheesy tourist attractions—a giant, talking statue of Paul Bunyan (along with Babe the blue ox), a larger-than-life Bigfoot carved from a redwood, and other silly gimmicks, all of which exist mainly to drive business for gift shops and restaurants. The last time I drove through northern California, I decided to throw common sense to the wind and indulge in some kitsch. So when I saw the signs advertising the Famous One-Log House, I knew I'd have to stop and see what it was all about. Home Is Where the Log Is The One-Log House is, as the name suggests, a house carved out of a single, very large redwood log. It's actually more of a mobile home than a house; the interior looks just like a travel trailer, and it's even mounted on wheels. Nevertheless, it is habitable, with a kitchen, bedroom, living room, and dining room squeezed into its interior, and a comfortable 7-foot (2.1m) ceiling. The log itself is 13 feet (4m) in diameter and 32 feet (9.8m) long, and weighs a whopping 42 tons—even with its insides removed. There are doors at either end, one of which contains two small windows—the log's only source of natural light. The One-Log House is not, from an engineering standpoint, an entirely successful design. Large steel bands encircle the tree to keep it from splitting; this is necessary because with so much of its interior gone, it has lost most of its structural integrity. The tree does have electric lights inside (only some of which were working when we visited) and a sink; details of plumbing were unclear, and there was no bathroom (unless that's what was hidden behind a locked door—it may also have been a closet). With almost no light, no ventilation, an unstable shell, and an absurdly high weight, it violates just about every sensible architectural principle and isn't very livable. Construction on the house began in approximately 100 B.C., but Art Schmock and a friend put the final touches on it during an eight-month period in 1946. As far as I can tell, it was never intended to be used as a residence; as a tourist attraction it traveled the country briefly then moved from one location in northern California to another before being sold to its current owners in 1999. Recently renovated, it's open to all visitors willing to pay US$1 (on the honor system). You can see the whole thing in about 10 seconds, but it's not about quantity, it's about quality, right? The One-Log House itself does not rate very high on the Interest-O-Meter, but the idea behind it does. In America's great tradition of weird roadside attractions, it created fame out of (almost) nothing. Here at the Famous Interesting Thing of the Day Web site, we find that an inspiration.—JK the Famous ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/02/one_log_house.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/02/One_Log.a8000d360166.mp3"
	},
	{
		"title": "Uffington White Horse",
		"text": "When I was a teenager, I once carved my initials and those of my girlfriend into a tree, something I thought of at the time as being a permanent statement of our eternal devotion to each other. When we broke up a year later, I felt obliged to return to the tree, put an X through our initials, and add the words “Null and Void.” The next time I went to find the tree, a number of years after that, it was gone. My guess is that the tree was so ashamed at having been defaced with self-contradictory graffiti that it simply fell over in an act of suicidal protest. The urge to leave one's mark on the landscape—whether in a tree, a newly poured sidewalk, or the wall of a cave—goes way, way back. One rather unusual form of ancient markings is found in the picturesque, pastoral setting of rural England. About a 30-minute drive from the city of Oxford is a large area covered with the rolling green hills and herds of grazing sheep that have found their way into countless works of literature and film. Beneath the veneer of grass and soil, some of these hills are made of chalk. And over the millennia, the landscape has become dotted with at least 50 large images made by carving through the top layers of earth to expose the chalk beneath. Of these, about a dozen are pictures of horses, and of the horse carvings, the oldest and best known is the Uffington White Horse. A Horse of a Different Color Although less famous than, say, Stonehenge, the Uffington White Horse ranks right up there among ancient and inexplicable English monuments. It is a highly stylized outline of a horse—recognizable, but not as well-defined as the other, more solid horse images. The carving is about 374 feet (113m) long, with the lines forming it ranging in width from about 5 to 10 feet (2 to 3 meters). This particular carving doesn't actually go all the way through the crust to the chalk beneath; instead, a relatively shallow trench was dug and filled in with chalk to make it almost flush with the surface. The Uffington White Horse has the distinction of being the largest of Britain's horse carvings (measured from head to tail). It's also one of only four such horses facing to the right, though no one knows for sure the significance of the horse's direction, if any. And it's the oldest horse carving, meaning it may have served as a prototype for the others. This Old Horse Scientists have determined that the carving is about 3,000 years old (give or take a few centuries), and though it is mentioned in literature dating back to the 11th century, its original purpose—along with the identity of its creators—is uncertain. It may have been a religious symbol, a monument to a victory in battle, a territory marker, or simply (perish the thought) a giant piece of abstract art. Although it has been referred to as a “horse” for at least 1,000 years, there are some who believe it was intended to represent a dragon. If so, then dragons must have been much more horse-shaped in those days. In any case, the carving has been well tended over the centuries. Every seven years, weeds are removed and the outline smoothed to maintain its original size and shape. One of the most interesting things about the Uffington White Horse is that the only place to get a good view of the whole thing is from the sky above. There are a few spots several miles away that provide a fair view of most of the outline, but the local topography is such that there is just no vantage point from which you can get a good view of the whole horse. This has, predictably, led some people to speculate that it was created as a signal to UFOs, although what exactly it would signify is a bit unclear (“Horses for sale—next exit”? ). Be that as it may, this peculiarity of perspective must have made it a challenge to carve, and it makes the horse's original purpose all the more mysterious. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2008/01/02/White_horse_from_air.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2008/01/02/Uffington.df631a1a14c2.mp3"
	},
	{
		"title": "The Tactile Dome",
		"text": "San Francisco’s Exploratorium is an immense (and immensely popular) hands-on science museum. Exhibits cover the usual range of subjects—electricity, physics, optics, biology, and so on—but with a degree of interactive friendliness that’s rare even in the best science museums (and I’ve seen quite a few). Almost everything is designed to be touched, played with, and experimented on—even by young children, whose destructive impulses know no bounds. Although I had been to the Exploratorium a number of times, there was one exhibit I’d never experienced but always been curious about: something called the Tactile Dome. This is an exhibit for which you must make an advance reservation (and pay extra), and I had never had the foresight to call ahead before visiting the museum to see if there was an open slot. On a visit last summer, when I went to purchase my ticket, I happened to notice a sign saying there were openings at the dome that afternoon. I immediately signed up—after listening to a short speech on all the medical and psychological conditions that would preclude a safe visit and consenting to the non-refundability of the ticket. A Touching Experience The Tactile Dome is a smallish geodesic dome within the museum whose stated purpose is to explore the sense of touch—taking the “hands-on” principle to its logical extreme. Inside the dome is a series of oddly shaped chambers lined with a variety of materials. The chambers are completely dark, so visitors must navigate through them—climbing, crawling, sliding, and squeezing—using only the sense of touch for guidance. In an anteroom the eight or so people who have reservations at a given time remove their shoes and any objects that might fall out of pockets and get lost. (They are quite strict about their “no-extraneous-stuff” policy; I wasn’t even allowed to take a ballpoint pen in with me, even though it was capped and sealed in a zippered pocket behind a Velcro flap. I thought that prohibition was a bit silly, but don’t say I didn’t warn you.) Then, in smaller groups (in my case, a group of one), you proceed into the dark chambers. A complete trip through the dome takes anywhere from five to ten minutes, and guests are spaced far enough apart that they won’t run into each other. The inside of the dome is not a maze; every chamber has just one entrance and one exit. An attendant in the anteroom monitors your progress by listening to the sounds picked up by microphones positioned throughout the dome. If a visitor gets stuck or panicked, a verbal request for help is all that’s needed; every spot in the dome is immediately reachable by hidden access doors. The intercom (which the other visitors waiting in the anteroom can also hear) serves another purpose, too: to discourage, shall we say, extracurricular activities that the dark and solitary environment might suggest. Each group gets to go through the dome several times during their visit. As I made my way through the dome, I found that even though sight was not available, it was not a purely tactile experience. Each time I entered a new chamber, I could tell something about its size and shape from the sounds I heard, along with the combination of temperature and airflow I could feel. Even smell played a part—the characteristic scents of carpet, wood, plastics, and the smelly socks of the person who crawled through the dome before me all contributed to a mental image. And that effect was a bit eerie—even though I couldn’t see anything, I had the distinct sensation of visual images of the rooms constructed from the other sensory data I was gathering. That impression alone made the experience worthwhile for me. Copp-ing a Feel The Tactile Dome was designed by Dr. August F. Coppola (brother of director Francis Ford Coppola) in 1971 and has been in use ever since. Not only in the choices of materials in the dome, but in its overall design and marketing, it’s definitely showing its age—or perhaps I should say, “revealing” its age. I’d love to experience a larger, more elaborate, updated-for-the-21st-century version of the dome, if one were ever to be built. By an interesting coincidence, the Tactile Dome is not the only dome-shaped, building-within-a-building attraction in San Francisco that was constructed in the 1970s and designed to be experienced in total darkness. Audium, located across town, shares all these attributes but was designed to explore the sense of hearing rather than touch. If there’s also a Smell-O-Dome lurking somewhere in the city, I’d just as soon not know. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/28/exploratorium.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/28/Tactile.ce30614e0768.mp3"
	},
	{
		"title": "Saturna Island ",
		"text": "I have a special fondness for contradiction—or more accurately, contrariety—the apparent not-going-together of things I like or believe equally. Read enough of these articles and the theme of paradox will be quite evident. For example, I love living in the city, and can’t imagine being without the energy, resources, and constant stimulation it provides. But I could say with equal conviction that I’m happiest when I’m far away from people, noise, and chaos, immersed in the solitude of nature. As a result, when planning a vacation, I’m never quite sure whether I want to “get away from it all” or experience the novelty and adventure of another urban area. Las Vegas, New York, and Paris are among my favorite places to visit; on the other hand, I also enjoy a meditative retreat, a long weekend in the desert, or a lazy trip through the countryside of Provence. But my very favorite place to go for peace and quiet is Saturna Island. Just Across the Strait Perhaps I should begin with a quick geography lesson. British Columbia is Canada’s westernmost province. Its largest city, Vancouver (where I lived for three years), is on the Pacific coast, just a few hours' drive north of Seattle. Not far off the coast—about an hour and a half by ferry—is Vancouver Island, an immense piece of land with an area about the size of Vermont and New Hampshire combined. On Vancouver Island you’ll find Victoria, the capital city of British Columbia, and about three-quarters of a million people. The stretch of ocean between the mainland and Vancouver Island is known as the Georgia Strait, and scattered along the 300-mile (483km) length of the strait are hundreds of smaller islands, only a handful of which are inhabited. The Gulf Islands, as they are called, have all the natural beauty typical of the Pacific Northwest, and a much more relaxed pace of life than the big cities. Saturna is the southernmost Gulf Island, just beyond U.S. waters (and the San Juan Islands that lie there). Although it’s one of the larger islands at twelve square miles (31sq km), it’s the least populated, with just over 300 year-round residents. It can be reached only by float plane, private boat, or ferry, and as there are no direct ferry routes from the mainland, most visitors must travel by way of Vancouver Island or one of the other Gulf Islands. By the time you get there, you already have a sense of its remoteness. And as soon as you begin to look around, you realize you’re in a wonderfully different place. Guidebooks sometimes describe Saturna in terms of what it doesn’t have. There are no camping facilities. There’s no town, either—just a few scattered businesses. There’s no laundromat, bookstore, movie theater, or pharmacy. And there’s no bank or ATM; by law, that would require the presence of a full-time police officer on the island, which it also doesn’t have. What it does have, in great abundance, is character. In this tiny rural outpost of civilization you can find not only peace and quiet, but an amazing concentration of interesting things and people. Booking a Room I distinctly remember the exact moment I got hooked on Saturna. On our first visit there several years ago, Saturna was our last stop on a tour of the Gulf Islands. We had reservations at the Breezy Bay Bed & Breakfast, a place that, from its Web site, looked very quaint and inviting. When we arrived, our host, Renie Muir, showed us to our room in the 1890s farmhouse. As we walked up the stairs, we first entered a library. I just gasped—this was the room of my dreams. Dark wood, the smell of old books, and comfy chairs all around. For me, that’s heaven. I knew I had come to the right place, and as I was to discover, that room was in a way a microcosm of the entire island: a place of contemplation, interesting ideas, and a simpler, more meaningful way of life. Outside our window was a farm—with an orchard, sheep, chickens, and a llama or two. One path led down to a small beach; another led up to the top of a hill with a beautiful panoramic view. We spent many hours relaxing, exploring, reading, and talking. The things we experienced—whether the sight of an old red tractor rusting along the side of a trail or a conversation with our host or another guest—were endlessly fascinating. You may be thinking, “That’s nice, but I can relax or talk anywhere. What’s really so special about Saturna?” The best way I can think of to put it is, of all the places I’ve visited, Saturna has consistently had the highest concentration of memorable moments. Something about the place, the environment, and the people who are drawn to the island, makes it a fertile breeding ground for interesting things. We’ve Got Rocks and Trees and Trees and Rocks and…Water For being such a small place, there is plenty to see. A few minutes away from Breezy Bay by car is Winter Cove Marine Park, with scenic hiking trails and a picturesque view of small boats anchored offshore. One of the trails leads to a narrow, rocky channel between Saturna and nearby Samuel Island. When the tide changes, water begins rushing through the channel dramatically. Watching water levels equalize may sound as exciting as watching paint dry, but I find the sight absolutely riveting. Drive to the other end of the island, and there’s an old (but still functioning) lighthouse. Trails lead through a meadow past a deserted caretaker’s residence and utility building, their state of gentle decay lending a sense of history and melancholy to the area. Along the rocky shore just below, tide pools have an abundance of small creatures, starfish are plentiful, and seals can often be seen fishing nearby. In the center of the island is Mt. Warburton Pike. At 1,630 feet (497m), the summit is the highest point in the Gulf Islands, providing a breathtaking view (along with a handy location for TV antennas). Saturna also has a large vineyard with some very respectable wines and a regionally famous bakery (the chocolate chip cookies are especially memorable). A tiny cemetery serves as the final resting place of some of the island’s earliest residents. There are also two general stores (one with a small cafe), a pub, a church or two, an upscale restaurant, and a surprising number of bed-and-breakfasts. Young children attend the island’s elementary school; after that, school requires a trip to a neighboring island by water taxi, the local equivalent of a school bus. Brushes with Greatness Saturna’s biggest claim to fame is its annual Canada Day Lamb Barbecue. Each July 1, Saturna’s population swells to over 1,000 as people flock to the island for what is essentially a community fair. I had heard a lot about this event, so Morgen and I went a few years ago. When we showed up at Winter Cove Park, Morgen seemed to recognize the woman who sold us our tickets. As we walked away she whispered to me that it was Pat Carney, one of Canada’s first female senators and a Saturna native. We listened to live music, shopped for crafts, sampled the local wine. Then we headed over to a tent to play some games. After winning at bingo I decided to move over to the blackjack table. I was doing well there too, and I was up a few dollars when the dealer had to leave. Morgen asked if I had any idea who had been dealing the cards; I didn’t. She said she was pretty sure it was Ferron, a well-known folk singer who was also from Saturna. Sure enough, moments later the erstwhile dealer got up on stage and started singing. These little “brushes with greatness” are just another ordinary part of the Saturna experience. Everyone knows everyone else, and at least for an outsider like me, there was little perceptible class distinction. Everyone is equally important, equally interesting. And that is one of the things I find so appealing about Saturna. As you walk around, people look you in the eye, smile, and say hello—a strange ritual I never experience in the city. Conversations happen easily, and you simply don’t encounter anyone without a story. Saturna’s residents are an eclectic mix of merchants and farmers, technologists and artists, spiritual seekers and environmentalists—along with, of course, a wide variety of wildlife. Even if life is not exactly idyllic, residents and visitors of Saturna Island are people who choose to be there, who trade a certain amount of convenience for the rich experience of a simple lifestyle. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/29/saturna_island.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/29/Saturna.b5e7b0545718.mp3"
	},
	{
		"title": "The Capilano Suspension Bridge",
		"text": "Every time I mention to someone that I spent three years living in Vancouver, British Columbia, I get the same response. “Oh, I've heard Vancouver is such a beautiful city. I'd love to visit there some time.” Dozens of people have said the same thing to me, almost as if reciting a line from an advertising campaign. And it's true: Vancouver is a beautiful city—whether you're talking about the mountains, forests, and ocean or the glistening modern skyline of glass skyscrapers. There's a reason so many films and TV shows are shot on location in and around Vancouver. If it's scenery you want, this is the place. Vancouver, like any other large Canadian city, also has plenty of cultural depth—an excellent symphony orchestra, live theater, cinema, folk music, improv comedy, professional sports, and museums of every kind. There are major universities, large industries, and rich natural resources, not to mention a vibrant multi-ethnic population. In short, no one needs an excuse to visit Vancouver. There are so many things to do and see there that it's a compelling tourist destination; undoubtedly this figured in the city's successful bid to host the 2010 winter Olympics. The Draw of the Bridge Having said that, I was shocked and baffled to learn that the most popular tourist attraction in the city—nay, in the entire province—is a footbridge. Incredible but true: each year over 800,000 people pay to walk across the Capilano Suspension Bridge. Now it is indeed quite a nice bridge, as suspension footbridges go. Strung high above the scenic Capilano River, it offers a lovely view. And it's an impressive feat of engineering too (about which more in a moment). But of all the things that might attract a visitor to the southwestern corner of mainland British Columbia, the enormous appeal of this bridge has always seemed quite strange to me. The current Capilano Suspension Bridge is actually the third such structure at this location. The first bridge, made of hemp rope and cedar planks, was installed in 1888 by land developer George Grant Mackay, who had purchased acreage on both sides of the river and needed a convenient way to get to and from his cabin. In 1903, the bridge was replaced with a wire cable bridge, which was then reinforced significantly in 1914. The current bridge was installed in 1956, with the heavy cables encased in 13 tons of concrete on each end. Over the course of the 20th century, ownership of the property changed hands several times, but it has always been more of a tourist attraction than a means of getting from place to place. The surrounding area has been developed as a park, with a restaurant, gift shop, and a collection of native totem poles to give it character. But you walk across the bridge solely for the experience of doing so; the only things you'll find on the far side are some short hiking trails, a pond, an observation point, and some information on the local flora and fauna. Weights and Measures The Capilano Suspension Bridge is 450 feet (137m) long and 230 feet (70m) above the canyon floor. Because it hangs freely between the supports on either end, it sways and bounces as you walk across it. This gives the illusion that it's risky, but the bridge has been designed for complete safety. The most impressive feature of the bridge is visible only on paper: its incredible capacity. How much weight can the bridge support? Apparently the number of pounds (or kilograms) is so high that a new unit of measurement had to be invented to express it: the airplane. Depending on which literature you read, the bridge can support the weight of fifty 747s or ten “heavy-duty military fighter planes,” each of which, presumably, is five times the weight of a 747—depending on the exchange rate, of course, and whether the plane is actually in flight. These statistics are intended to reassure tourists that the bridge can definitely hold as many people as can fit on it at any given time and that they, their children, and their video cameras are perfectly safe. Personally, I'd find the statement more meaningful if it said something like “can support the weight of the entire population of the city of Burnaby”—which, if my math is correct, is true. That's 200,000 people, more or less. I'm tempted to say that the Capilano Suspension Bridge is a textbook example of overengineering, like using a rivet where a paperclip would do. But whether its great strength is excessive or not, its marketing program certainly is. I've been to the bridge several times, because it's one of those things you just have to take friends and relatives to when they visit from out of town. And the reactions are predictable: “Wow, this is cool,” followed shortly thereafter by, “Is this all there is? I paid for this?” And I can't help keep thinking of the Golden Gate Bridge in San Francisco, which is many times more impressive and doesn't even come close to being the city's top tourist attraction, never mind the state's. As a couple of Vancouverites pointed out to me, there's another similar bridge not far away, called the Lynn Canyon Suspension Bridge. In addition to being free, and, I'm told, “just as nice as the Capilano bridge,” the Lynn Canyon bridge leads to some of the best walking trails in the area. But then, the real reason people visit the Capilano Suspension Bridge is to find out what all the fuss is about. And that is exactly what I find so interesting about it: the bridge to nowhere has become, for its owners, the path to fortune. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/28/capilano.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/28/Capilano.bbd04b28ec2a.mp3"
	},
	{
		"title": "The Woodwose",
		"text": "Like the Loch Ness Monster or the Abominable Snowman, I usually think of Bigfoot (or Sasquatch as he's sometimes known) as a distinctly 20th century phenomenon. However, while it's true that interest in these legendary creatures was stoked by images captured through the modern means of photography and film, the stories surrounding them actually go back centuries. From the lakes of Scotland, to the heights of the Himalayas, to the Pacific Northwest of America, locals have long attested to the presence of these elusive beings. Although little-known today, a mythical creature with striking similarities to Bigfoot was believed to exist an even longer time ago in medieval Europe. Called a woodwose, or in Anglo-Saxon wuduwasa, this wild man of the forest was a familiar figure in the literature and visual arts of the Middle Ages. Walk on the Wild Side As with Bigfoot, the woodwose's natural territory was believed to be the forest (hence the name: literally “wood-man”), and it too was said to be a hominoid covered in a heavy coat of hair. However, the woodwose was rarely described as ape-like, as Bigfoot often is. Rather, it was a creature very similar to other humans, but with a wild manner and an unusual amount of hair all over its body. Different theories have been put forward about the origin of the woodwose myth, including the medieval belief that woodwoses were people who had wandered into the woods, and as a means of survival grew hair to protect themselves from the elements. Another theory was that people born with an excess of body hair retreated from human society and led isolated lives as wild men (and women). In opposition to these ideas, some modern researchers have proposed that woodwose sightings were actually sightings of Neanderthals still living in medieval Europe. While it is unclear exactly how the image of the woodwose arose, once it entered the public's imagination it became a common motif in architecture, the visual arts, and literature. For example, woodwoses were often featured in the decoration of medieval churches, most particularly in ceiling bosses, the pieces of sculpture placed at the intersections of overlapping roof vaults. They were also depicted in works of art by such illustrious printmakers as Albrecht Dürer and Martin Schongauer. The medieval writer Geoffrey of Monmouth made mention of a “Man of the Woods” in his epic Life of Merlin, as did the writer of the “King's Mirror,” a Norwegian educational treatise dating to A.D. 1250. Great Balls of Fire Another phenomenon growing out the woodwose myth was the popular medieval custom of attending masquerades dressed as hairy wild men. The most famous story about this practice concerns an event that came to be known as the Bal des Ardents, or the “Ball of the Burning Men,” which refers to a 1393 ball organized by the then-Queen of France. In preparation for this event, the king, Charles VI and with five other men dressed themselves in costumes made out of linen soaked in highly flammable pitch to which they stuck frazzled hemp fibers to simulate hair. In addition, as part of their get-ups, the six men were chained together. Understandably, flaming torches were not allowed at the event, but the king's brother nevertheless came near the costumed men bearing a lighted torch. Tragically, one of the men caught fire, and in the panic that ensued, four of the men burned to death, although the king escaped injury. Whither Woodwose While the woodwose myth is no longer so prevalent in the public imagination, its influence can still be seen. Two relatively recent examples of this influence are a poem and book written by the British poet Ted Hughes, both titled “Wodwo” (another variant of woodwose), which were published in the late 1960s. Another reference to the woodwose is found in the writings of J.R.R. Tolkien, who called one of his fictional races of men “Woses.” Regardless of the actual circumstances that gave rise to the woodwose myth, it's clear that the image of the wild man of the woods has had an enduring resonance in works of art dating back at least as far as the Middle Ages. It's not surprising that this is this case; like Bigfoot, the woodwose can be seen as a symbol of the distance society has traveled from its primitive roots, but also of our continued attraction to the unknown and wild elements of our own nature. —Morgen Jahnke ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/28/Woodwos.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/28/Woodwose.d9cecb54b652.mp3"
	},
	{
		"title": "Tulipomania",
		"text": "In his 1850 novel The Black Tulip, French author Alexandre Dumas (père) describes a competition, initiated by the Dutch city of Haarlem in the 1670s, in which 100,000 florins (150 florins being the average yearly income at the time) would be given to the first person who could grow a black tulip. Although Dumas's story is fictional, it is based on a very real phenomenon that took place in the Netherlands in the early 17th century. Between 1634 and 1637, the Netherlands (then called the United Provinces) saw the rise and fall of many fortunes due to an intense period of tulip trading. Now described as tulipomania, it involved the wild overvaluation of certain types of tulip, leading to the eventual crash of the inflated market. It might seem strange that tulips inspired such an economic frenzy; what was it that made them so desirable? While there are solid reasons why tulips became such a hot commodity, tulipomania was ultimately driven by speculators looking to make a quick profit. In that way, it can be seen as a precursor to more modern forms of market inflation and decline, such as the dotcom bubble and historical fluctuations of the stock market. In Rare Form First cultivated in the East, tulips were brought to Europe from the Ottoman Empire during the 16th century (the name tulip is derived from the Turkish word for turban). Soon after their introduction, tulips became popular in various countries, but nowhere so much as in the Netherlands. There are many theories as to why the Dutch developed such an avid interest in tulips; in his book The Botany of Desire, Michael Pollan suggests that the bleakness of the Dutch landscape may be one reason colorful tulips were so quickly embraced. He observes that “what beauty there is in the Netherlands is largely the result of human effort…” making the cultivation of beautiful blooms an attractive pastime. Another reason for their popularity was their relative rarity. While tulips can be grown simply from seed, there is no guarantee that the resulting flowers will resemble their parent plants at all. The only way to obtain a particularly prized bloom is to grow one from an offset, which Pollan describes as “the little, genetically identical bulblets” found at the base of a tulip bulb. The process of cultivating offsets was a lengthy one, adding to the scarcity of tulips. In addition, the most valued tulips of the time were ones said to be “broken,” that is those tulips with bright flame or feather-like patterns on their petals. The most famous of this type of tulip was the Semper Augustus, a white flower marked by brilliant red strokes. These tulips produced fewer offsets, making them even rarer; although it was not known at the time, the “broken” effect was caused by a virus that weakened the plant. Gone to Seed The genesis of tulipomania is usually ascribed to the 1593 arrival in Leiden of Carolus Clusius, a plant collector and gardener. Bringing with him some tulip bulbs he had acquired while working as the director of the Imperial Botanical Garden in Vienna, Clusius proceeded to cultivate beautiful specimens from them, attracting attention from his new neighbors. However, Clusius was reluctant to part with his bulbs, refusing to sell to eager buyers. Frustrated by his refusal, thieves helped themselves to his garden, stealing many bulbs and selling the seeds they gained from them. These seeds were eventually distributed throughout all the Dutch territories, leading to the increased propagation and variation of tulips. Those lucky enough to grow a particularly beautiful bloom from seed could profit greatly from the sale of its offsets, making tulip cultivation an increasingly lucrative vocation. As the taste for certain types of tulip became more focused, prices for the most valued bulbs rose dramatically among the upper classes. At first limited to collectors and the wealthy, the large amounts of money to be made soon inspired people of otherwise limited means to sell everything they had to cash in on the trade. At the market's highest point, single bulbs sold for thousands of florins, the most famous being a Semper Augustus bulb that sold for 6,000 florins (or 40 times the average yearly income). As more people entered the trade, eventually the sale of real bulbs gave way to windhandel, or wind trade, meaning the future production of bulbs was bought and sold. This increasingly risky venture couldn't last. The tulip bubble burst in February 1637 when oversupply caused prices to drop precipitously. Very quickly, the fortunes of those unable to sell the bulbs they had purchased at the height of the market went disastrously downhill, and many were left in financial ruin. Dutch Treat Although this shift in the tulip market was awful at the time, out of that early trade came an enduring business for the Netherlands. Now the tulip is a beloved symbol of the country, and plays an important role in economic and cultural activities. It seems unlikely that anyone at the time the tulip came to the Netherlands could have predicted the enormous effect this flower would have over a nation's history and economy. It is a vivid reminder that when human nature meets Mother Nature, interesting results are sure to follow. —Morgen Jahnke ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/28/tulips.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/28/Tulipomania.7f1c341f715c.mp3"
	},
	{
		"title": "The Wallace Line",
		"text": "Back in the mid-19th century, a certain naturalist, having spent a great deal of time sailing around the world, collecting and documenting animal specimens, and thinking very hard about why certain species turned out the way they did, came up with a notion that was—and in some quarters, still is—considered heretical: the idea of survival of the fittest, or as it is more properly known, natural selection. That description may evoke the name Charles Darwin, but it could apply equally to one of his contemporaries, Alfred Russel Wallace. One could argue, in fact, argue that Wallace was the true originator of the idea for which Darwin was to become famous. The two were at least working on the same general problem at the same time though in different parts of the world, and Wallace's discoveries prompted Darwin to publish his own findings sooner than he had intended. Darwin was an honorable scholar and gave due credit to Wallace, including a mention in the second paragraph of On the Origin of Species. But because of Darwin's considerably greater influence, Wallace's contributions to the science of evolution were given far less fanfare. (Interestingly, although Wallace didn't invent the expression natural selection, there is some evidence that he coined the phrase survival of the fittest, though he was not the first to publish it, and so even that honor goes to someone else: a British economist named Herbert Spencer. ) Father of Evolution Zoogeography Wallace is, however, remembered for something that has tremendous implications not only for biology but for geology too: an imaginary line that divides what is now Indonesia roughly in half. Islands to the west of the line include Sumatra, Borneo, Java, and Bali; to the east are Lombok, Sulawesi, Timor, and many others. What Wallace noticed during his extensive travels in the area was that the islands in the western part of the archipelago had animal life similar to that found in continental Asia, while the islands in the eastern part of the chain had species resembling those found in Australia. The Wallace Line was his attempt to draw a boundary between these two regions with very different fauna. What particularly struck Wallace about his discovery was that some islands that were very far apart had the same distribution of animal species, while some that were close together had much different species. Nowhere was this more striking than between the islands of Bali and Lombok, which are separated by only 22 miles (35km) of water. And yet, numerous species of plants and animals—especially birds—that are found on Bali and other, more distant islands to the north and west were absent on Lombok, which had species found on other islands far to the south and east. Continental Drifter In 1859, when Wallace originally drew and publicized the line, he couldn't explain in any detail why these nearby areas had such different species. His theories about natural selection suggested that quite the opposite should have been the case, and Wallace speculated that ancient geological changes must have been the cause. It would be more than a century before the theory of plate tectonics was developed, but Wallace would have been pleased to know that his line closely matches the boundary between two continental plates that were once far apart. Because some of the islands on each of the plates were once connected to each other and to the mainland by land bridges, animals could freely migrate between them, but no such bridge ever existed between the two plates. It just so happens that in some spots these two geological regions have, over many centuries, moved to within spitting distance of each other. Wallace himself redrew the line with greater precision in 1863. Since then, it's been subject to a great deal of discussion, controversy, and additional refinement, as researchers have uncovered more detailed data. It's also been discovered that the zoogeographical division isn't quite as clear cut as it once seemed. But the fundamental insight that the division between areas of animal species must have been connected to massive geological shifts put Wallace far ahead of his time and remains a remarkable achievement to this day. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/28/Wallace.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/28/Wallace.b5fc1a03181a.mp3"
	},
	{
		"title": "Ethogeology ",
		"text": "On our recent trip to Indonesia, Morgen and I were reading Simon Winchester's 2003 book Krakatoa, a history of the devastating 1883 eruption of the eponymous volcano (known locally as Krakatau). A couple of hundred pages into the book, the volcano hasn't yet erupted, but we've learned about Darwin, the spice trade, Dutch colonization, and a long list of other things that, in one way or another, illuminate the circumstances surrounding that cataclysmic blast and how it affected the world at that time. Just as Winchester gets ready to describe the big bang itself, he mentions the fact that animals sometimes appear to be aware of an imminent seismic event, changing their behavior markedly just before it happens—often by fleeing, but sometimes by making noise or otherwise acting erratically. Winchester writes: “There is no firm scientific evidence that there is a connection, nor is there a true basis for a new pseudo-science called ethogeographical prediction, which seeks to forecast earthquakes by observing carefully calibrated animal activity.” He says that while some geologists concede that animals might sense changes too subtle to register on modern instruments, no one has been able to prove a connection between animal behavior and impending earthquakes or volcanic activity. Nevertheless, a good deal of anecdotal evidence supports this notion, including a particularly interesting tale of a circus elephant that seemingly “predicted” the Krakatoa eruption. I was unaware of the existence of anything called “ethogeographical prediction,” but I always enjoy learning about wacky pseudoscientific undertakings. So I consulted the usual search engines and found exactly one page on the entire Web that mentioned the phrase “ethogeographical prediction”; it was a review of Winchester's book. I then tried searching on “ethogeology” instead and found another, different page—also a review of the book. Well, now each term has at least two matches, but I'm no better informed as to who is engaged in this study or with what result. A quick scan of the book's bibliography provided no obvious clues, either, so it could be that Winchester himself coined the term or that it simply hasn't caught on widely yet. In any case, it's clear that ethogeology is a portmanteau of ethology (the study of animal behavior) and geology. Nothing to See Here Even though no one referred to ethogeology by name, I did find lots of information about how animals behave oddly before various kinds of natural disasters. The way writers often address the subject matter is by asking, rhetorically, whether this proves that animals are psychic, have E.S.P., or are in some other way supernaturally gifted. In most cases, the writers end up debunking such claims, but I find it troubling that the question is even asked in the first place. I'm pretty sure it's common knowledge that dogs have a superior sense of smell and that bats use echolocation to find their prey, to take two common examples of animal abilities that exceed those of humans. This, I can assure you, is more of the same—nothing mystical at all is going on. Unfortunately, no one can yet demonstrate by precisely what mechanism animals apparently become aware of an upcoming earthquake. One theory is that certain animals can hear ultra-low-frequency sounds generated by seismic activity just before an earthquake. Another is that they can feel tiny vibrations in the ground when a quake is brewing. Based on these theories, some researchers are trying to construct measuring devices that mimic the anatomical structures that might be picking up the noises or vibrations. If they work, they could provide some hard data that might lead to more reliable early warning systems. But that's a big “if.” I Smell a Volcano As a matter of fact, we don't currently know for sure whether animals can be aware of future seismic events at all. It seems that they can, but even if so, clearly this is true only for certain animals, in certain situations, at certain times—which is a little unsatisfying scientifically. Supposing that someone could prove this adequately, the next step would be to quantify it. What does a particular behavior of a particular animal indicate? In order to use animals to predict earthquakes, we'd need a little more to go on than “if Spot starts growling, there might be an earthquake soon.” It could also mean that Spot is hungry, for instance. Getting any truly reliable data is going to be awfully hard, because you'll never reproduce, in a controlled laboratory setting, the exact conditions of an impending volcanic eruption; nor can you interview your test subjects to find out what they hear, feel, or think. Seismic events are not the only disasters animals are said to predict. I've read stories of animals behaving strangely just before hurricanes, typhoons, and thunderstorms, for example. To study these phenomena, however, we're going to need an entirely new field: ethometeorology, a term that was, surprisingly, found on zero other Web pages before today. I predict linguistic storms in the near future. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/28/kitty.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/28/Ethogeology.9f8a15d54078.mp3"
	},
	{
		"title": "Portmeirion",
		"text": "World-famous architects like Frank Gehry, Renzo Piano, and Rem Koolhaas often make headlines for their daring and creative buildings, but the vast majority of architects spend their time on more down-to-earth projects, like schools and fire houses. Their work is dictated by the needs of their clients, and their creativity is in service to solving any problems these needs might entail. But what happens when architects are given free rein? What do architects do for fun? It is easy to imagine that Julia Morgan, the architect who designed William Randolph Hearst's estate at San Simeon, enjoyed creating that fantastical world to Hearst's specifications, or that Eduard Riedel, the architect of King Ludwig II of Bavaria's Neuschwanstein Castle, found some pleasure in recreating a medieval castle in the 19th century. But these architects were still limited by the wishes and whims of their employers, unable to express themselves fully. In comparison, the English-born Welsh architect Sir Clough Williams-Ellis (1883–1978) found a way to realize his dearest architectural dreams on his own terms. After purchasing a particularly beautiful piece of property on the northern Welsh coast from his uncle in 1925, Clough set out to create a wonderland of architectural whimsy that he called Portmeirion (after the coastal setting and the Welsh name of the local county, Merioneth). The result of Clough's work is a colorful Italianate village of cottages, towers, fountains, and cobbled streets that has drawn comparisons to Clough's twin inspirations: the medieval hill towns of Tuscany and the world-renowned Italian coastal town of Portofino. It Takes a Village When Clough bought the Portmeirion site in 1925, his vision was not to simply construct individual buildings, but to create an entire town. As The Architects Journal noted of the project in 1926, the “results of his [Clough's] scheme will be significant and should do much to shake the current notion that although houses must be designed with due care, towns may grow up by chance.” Over the next fifty years, this vision of Portmeirion began to take shape under Clough's leadership, with construction occurring in two phases: from 1925 to 1939, and from 1954 to 1976. Another part of Clough's vision for Portmeirion was that it help to prove that beautiful natural spaces could be developed for commercial use without ruining their beauty, what he called “that strange necessity.” His choice of this particular site, a peninsula in the Snowdonia region of Wales, was no accident. He wanted to draw visitors to the area, and the balmy microclimate and coastal views of Portmeirion proved attractive even when the town had not been fully developed. In fact, early on Clough raised money for the construction costs by operating a hotel out of an existing building. In this respect, it could be argued that Clough was a forerunner to the modern pursuit of sustainable development, the attempt to provide economic benefit while preserving natural resources. Clough cared deeply about environmental protection; he not only served on various councils related to this goal, but was a strong advocate for the creation of national parks in England and Wales, most especially for Snowdonia National Park in Wales. Clough's architectural credo, “Cherish the Past, Adorn the Present, Construct for the Future,” is in keeping with his passion for sustainability. At Portmeirion, Clough honored the past by salvaging old structures from demolition sites, relocating and renovating them to become part of what he called his “home for fallen buildings.” The vivid colors and enchanting streets of the town show Clough's obvious love for “adorning the present,” while his larger vision of preserving the environment by pursuing limited economic development gives meaning to “constructing for the future.” Escape to Portmeirion Portmeirion has become a prime tourist destination for visitors to North Wales; visitors can see the town during the day, or may opt to stay the night in the main hotel, individual cottages, or at the newly renovated Castell Deudraeth, a Victorian castellated mansion on the estate. Tourists are drawn by the town's legendary beauty, but it does have another claim to fame. In 1966, Portmeirion was the setting for the filming of the British TV show The Prisoner, starring the popular stage and screen actor Patrick McGoohan. Although the show only ran for 17 episodes in 1967 and 1968, it became an enormous hit, and fans continue to be interested in every aspect of its production, including where it was filmed. As part of this interest, the official fan club of The Prisoner, Six of One, holds a convention in Portmeirion every year. In these and other ways, the popularity of the town Sir Clough Williams-Ellis built lives on, nearly thirty years after his death. Although he may have created Portmeirion to satisfy his own architectural visions, he succeeded in bringing these dreams to life for the benefit of countless others. —Morgen Jahnke ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/28/Portmeirion.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/28/Portmeirion.e48646e39448.mp3"
	},
	{
		"title": "Pitcairn Island",
		"text": "The story of the mutinous crew of the British navy vessel HMS Bounty has remained a popular theme in books and movies ever since it occurred in 1789. Four major films have been made with the mutiny as their inspiration, featuring such acting heavyweights as Errol Flynn, Clark Gable, Marlon Brando, and Anthony Hopkins; one version of the film earned a Best Picture Oscar. There is a good reason for the story's popularity: the sequence of events ending with the setting adrift of the ship's captain, William Bligh, along with eighteen of his men, in the middle of the Pacific, is inherently dramatic and fascinating. The story of what happened to both the mutineers and those forced overboard may be paid less attention, but is equally fascinating. Captain Bligh, with the aid of only a sextant and pocket watch, successfully navigated the small boat to the Tongan island of Tofua, and then on to the island of Timor, a journey that took over 47 days and covered over 3,618 nautical miles (6710km) by Bligh's reckoning. Only one of those set adrift with Bligh did not survive the voyage; a crewman was killed by the inhabitants of Tofua when the group landed there. The mutineers, led by master's mate Fletcher Christian, initially sailed to the island of Tubuai, but being unable to successfully settle there, went back to Tahiti (whence the ship initially departed). Sixteen members of the crew disembarked at this point, while Christian and eight of the mutineers, along with six Tahitian men and twelve Tahitian women (who were reputedly kidnapped), set sail to find a new island where they could settle in peace. Bounty on the Mutineers Fearing capture, Christian's crew bypassed the Fiji and Cook Islands, eventually landing on the then-uninhabited Pitcairn Island in January 1790. To prevent discovery of their whereabouts, the group ran the Bounty aground, and after stripping it of its supplies, burned and abandoned it in the island's primary bay (now known as Bounty Bay). They established a settlement on the island, growing crops and raising livestock. The island, named after the boy who sighted it during the 1767 expedition of the HMS Swallow, had once been home to other inhabitants (most likely from Polynesia), but was deserted when the mutineers arrived. Measuring 6 miles (about 10km) in circumference and 2.5 miles (4 km) in length, Pitcairn Island is part of a group of four islands (now collectively called the Pitcairn Islands) that proved an ideal hiding place for the mutineers, owing to its incredible isolation in the midst of the Pacific Ocean, about halfway between New Zealand and the Americas. The early community on Pitcairn experienced considerable violence among its members; clashes between the Tahitian men and the mutineers led to the deaths of all but four of the men by 1794, and by 1800, due to further violence and poor health, only one man remained alive. This man, an erstwhile mutineer named John Adams, became the leader of the settlement—now numbering 34 (counting 10 women and 23 children)—and oversaw its development into a viable and thriving entity. The group's first contact with the outside world came with the arrival in 1808 of an American ship, but it was not until 1814 that Pitcairn became known to the wider world, when two British ships, the Briton and Tagus, landed on the island. Surprisingly, Adams was not arrested by the British commanders on board these ships, but instead helped to establish a new relationship between Pitcairn and Britain. This relationship was formalized in 1838, when a constitution for the Island was created (which included the right of female suffrage eighty years before it was adopted in Britain), and was further enhanced when Pitcairn became a British Settlement under the British Settlements Act of 1887. Throughout the 19th century, overpopulation and a lack of resources were constant problems for the islanders, leading to an exodus to Tahiti in 1831, which was reversed later that year, and a further resettlement to Norfolk Island, a former British penal colony, in 1856. This time the move was successful; the islanders became prosperous and permanently settled in their new home. However, a small group of former Pitcairn residents decided to return two years later, in 1858, and they are the ancestors of those who live on the island today. Giving it Their Own Stamp Although in 1937 the island's population reached a high point of 233, currently there are about fifty residents on the island (most of them bearing the surnames of their mutineer ancestors). Pitcairn does not have an airport, so although ships do visit on an infrequent basis, the island cannot generate much-needed revenue from tourism or trade. One attempt to support the local economy began in 1940, with the issuance of the first Pitcairn postage stamps. Now administered by the Pitcairn Island Philatelic Bureau (headquartered in New Zealand), Pitcairn issues six stamp series each year which are prized by avid philatelists. Another, more recent, economic initiative undertaken by the islanders is the cultivation of honey, flavored by the Mango, Lata, Passion Flower, Guava, and Roseapple flowers found on the island. In addition to its economic woes, Pitcairn has faced social problems in recent years. In 2004, the island came under intense media scrutiny as seven male residents (including the mayor) were put on trial facing 55 charges of sexual offenses against young girls. Six of the men, including the mayor, were eventually convicted on a total of 35 of the charges, and six other men, former residents of Pitcairn, also went on trial in 2005 in New Zealand. These trials caused major upheaval in the community, since almost all of the adult male population was implicated in them. Some residents felt disheartened by the scandal, fearing that the island's fate would be crippled by it, while others saw cause for optimism in the necessary rebuilding of the power structure on the island. This is not the first time Pitcairn has faced violence and lawlessness; from its inception the settlement has had to deal with the consequences of such actions. While to most people the mutiny on the Bounty remains an entertaining story from the past, for the residents of Pitcairn Island it is part of their daily reality, and has shaped the course of their lives and those of their ancestors. —Morgen Jahnke ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/28/Pitcairn.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/28/Pitcairn.5ec89f7d0d03.mp3"
	},
	{
		"title": "Guédelon Castle",
		"text": "For thirteen years, from 1981 to 1994, restorers worked to remove centuries of soot and candle smoke from the famous frescoes of the Sistine Chapel, including those created in the early 16th century by Michelangelo. After layers of varnish and grime covering the frescoes disappeared, the newly vibrant ceiling and walls of the chapel showed a modern world what Michelangelo's work might have looked like soon after it was completed in 1512. Not only were the colors of the frescoes revealed to be much brighter, but even individual brushstrokes were visible enough to be compared to the styles of other artists. Although restoration work of this kind can stir up controversy, as some would prefer not to risk damaging delicate artworks, or may disagree about the best method for restoring them, there is something extremely compelling about seeking to return old objects to their original states. It's not possible for us to know what it was like to stand and watch Michelangelo at his work five hundred years ago, but it is fascinating to imagine it. Of course, restoration is not limited to famous paintings; ancient buildings also often undergo painstaking restorations. One such example is the castle of Saint-Fargeau in Burgundy, France. Built in 1453 on the foundations of a fortress dating from the 10th century, the castle now draws in large numbers of visitors who view epic historical reenactments on its grounds. The man behind its restoration, Michel Guyot, has another project currently underway: the creation of an entire castle from the ground up, using the building techniques and materials of the 13th century. In the small village of Guédelon, not far from Saint-Fargeau, visitors to the castle can watch trained artisans go about their work, much as their counterparts did eight hundred years ago. Although seeing a restored castle can give you historical insight, the Guédelon project goes much further; with its emphasis on recreating the methods used to build the grand castles of the past, the experience could be likened to looking over the shoulder of a Renaissance artist, watching as he mixes his paints. I Louvre What You've Done to the Place The design of the castle was inspired by the castles built by King Philippe Auguste (or Philip II Augustus) in the 13th century. Among them is the original Louvre fortress, built to protect Paris from Viking attacks on its west side. Although the fortress was later razed to make room for a new palace, parts of its foundations remained intact (modern visitors to the Louvre can view these foundations in a special exhibition beneath the museum). Although Philippe Auguste only lived until 1223, the Guédelon project's designers imagine its beginning construction date as being 1236, when castle designs still followed Philippe's model. Having chosen to emulate this historical era, the specific plans for the Guédelon castle were developed by Jacques Moulin, the chief architect of historic monuments in France. Begun in 1997 with the laying of the foundations, the Guédelon project is not scheduled to be completed until 2023. When it is finished, the castle will consist of high fortress walls, with towers of varying sizes around its perimeter. Material Whirl Forming the backbone of the project are the 50 or so builders who quarry stone, mix mortar, and chisel rock, among other tasks, during the warmer part of the year. In summer, these workers put in 49-hour weeks, six days a week, while the site is closed in the winter. In keeping with the spirit of the project, workers wear simple tunics that would not have looked out of place in the 13th century, although they do make use of modern safety equipment such as goggles, helmets, and harnesses. Both the materials they use and the techniques they employ are limited to those used by builders of the 13th century. The area around the construction site provides all the necessary materials for the project, including sandstone, wood, iron, limestone, earth, and hemp. Sandstone is quarried near the site, using only hand tools (such as sledgehammers), and then carried by horse-cart or wheelbarrow to the area where masons wait to shape the rock with chisels and mauls. The nearby forests provide wood for a variety of uses including the production of beams, planks, levers, scaffolding, banisters, wheelbarrows, pails, and tool handles, as well as fuel for all the site's heating needs. One of those heating needs is the kiln in which sandstone is fired for two days, before producing a lump of iron ore. Blacksmiths reheat the iron in a furnace before shaping it on their anvils into nails, tools, chains, weapons, or hinges. Likewise, blocks of limestone are heated to obtain quicklime, which is mixed with sand to produce mortar. Earth is used to produce bricks, pottery and tiles, and to weatherproof walls. Lastly, the project's rope makers rely on hemp to create lifting ropes, belts, and harnesses. Build It, and They Will Come The Guédelon building site was first opened to the public in 1998, and by 2000, it was producing enough income to be self-sustaining. In recent years, as many as 250,000 people visit the site annually, and it is especially popular for groups of schoolchildren. Although the workers at Guédelon are involved in actual construction, and are not just doing demonstrations of building techniques, visitors are welcome to not only observe, but to ask questions about what they're seeing. Education is a big part of the project, and indeed, those involved in the process are also learning as they go, testing hypotheses about how medieval castles were built. To me, the most remarkable thing about Guédelon is that people are not only studying history, but are themselves experiencing what life was like so long ago. The Guédelon workers and their guests have the opportunity to feel what artisans of the 13th century might have felt, watching a medieval castle take shape beneath their hands. —Morgen Jahnke ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/28/castle-1.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/28/Guedelon.47dcb492b52c.mp3"
	},
	{
		"title": "The Dalahäst ",
		"text": "I confess that I am something of a fan of the Swedish home furnishings store IKEA, having spent countless hours wandering its shiny showrooms in three different countries (Canada, the U.S., and France). As evidence of this, you need only stand in the middle of my apartment and look around; you can't help but see an IKEA product anywhere you look. Although some may decry its mass marketing approach, I like that there is a consistency to the IKEA shopping experience. Whether I visit a store in central France or the suburbs of Vancouver, I know that I will see the same kinds of products, laid out in the same way, according to the same floor plan. This sameness might bother me in other settings, but there is a quirky charm to the world of IKEA that counterbalances the monotony. From its amusing product names to the ubiquity of kitschy Swedish foodstuffs, I always feel like I've found a tiny corner of Sweden wherever I happen to be in the world. Whether this experience is authentically Swedish or not, Swedish design is everywhere to be seen, and in ways that are not always obvious. For years I had noticed that horses, and red horses in particular, were a common decorative motif in IKEA products, whether appearing two-dimensionally on pillows or rugs, or as carved decorative figures gracing elegant bookshelves. I've only recently learned the significance of these tiny horses, and the centuries of history they represent. I thought IKEA was a popular symbol of Sweden, but the Dalahäst (or Dalecarlian) horse is a much more ancient and enduring one. Created in the Swedish province of Dalarna (Dalecarlia in English), the painted wooden horse has become a potent icon of Swedish culture. Horse Mythology Horses are an integral part of the history of Sweden, having deep cultural and religious significance. It is believed that horses were first introduced to Sweden around 2000 B.C., when Russian nomads invaded the area, overpowering the local inhabitants with their superior military capabilities—including their horsemanship. Horses soon became a valuable asset in farming and forestry for the region. The religious symbolism of the horse is long-standing in Sweden; not only was the horse the sacred animal of the As religion of the Vikings, but it was celebrated in Norse mythology as well. Horses were associated with the gods, most notably with Odin, who was said to have an eight-legged horse named Sleipner, given to him by the trickster figure Loki. When Christianity was introduced to Sweden in the 11th century, church leaders worked to discourage horse worship among the people, teaching that the horse was unclean, as were the practices associated with it: ritual slaughter and the eating of horsemeat. Although the church's efforts were mostly successful, the people of northern Dalarna, particularly those living around Lake Siljan, retained their ancient connection to the horse, refusing to demonize an animal so essential to their daily lives. The ongoing struggle between the church and local custom can be seen in two separate incidents from the 17th century. In 1624, Bishop Johannes Rudbeckius of Västerås, the diocese city of Dalarna, gave a sermon denouncing the selling of certain “articles of destruction” in the market, a list that included wooden horses. Forty years later, during a witchcraft trial in Dalarna, the parish priest accused those on trial of using a “baror,” a magic wooden object in the shape of an animal (possibly a horse), to advance the work of the devil. At the same trial, the county constable claimed that the devil himself gave wooden horses to the local children to lead them astray. Horse Trading Despite these negative reactions to wooden horses, they seemed only to grow in popularity in the following years. In the 18th century, men working in the forests of Dalarna would carve wooden horses as a leisure activity and give them to children back in the village. By the 19th century, painted wooden horses were a common item of trade, often used by traveling salesmen as payment for room and board on their journeys. Created primarily in the villages around the town of Mora, these horses were painted with a floral design, reflecting the general decorative style of the time. This pattern of decoration eventually developed into the kurbits (or ripple) style of painting, which continues to this day. Now produced only in the town of Nusnäs by two companies, Nils Olsson and Grannas A. Olsson, the Dalahäst remains a popular icon of Sweden, often given as a gift (as when the Swedish Prime Minister presents them to foreign heads of state). Crafted from premium pine timber found in the forests surrounding Lake Siljan, the horses undergo a multi-step process, from felling the tree through hand carving, various stages of hand-painting, sanding, and varnishing. The finished product is stunning, a beautiful tribute to the long and intimate relationship between horses and humans in Sweden. —Morgen Jahnke ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/27/Dalahst-horse.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/Dalahast.22d9fd1d1374.mp3"
	},
	{
		"title": "Micronations",
		"text": "I know plenty of people who generally approve of the current U.S. government and plenty who don't. But I've never met anyone who agrees with and supports every single government policy and regulation—in this country or any other. The very nature of democratic government makes this virtually impossible, and I think it's fair to say that every legislator could produce a long list of things he or she might wish to be different. We all accept certain laws and taxes in exchange for the considerable benefits government provides in the way of economic structures, a justice system, education, public works, national security, and so on. For most of us, that's a reasonable trade. But what if you could tailor a government to your exact specifications? Exercise strict control over the currency, imports and exports, immigration policies, defense programs, foreign relations, and everything else? What if you could tailor laws to support those things you care about most and disallow the things you're against? What if, in fact, you had your very own country, in which you—along with, perhaps, your family, friends, or business associates—ran the whole place from top to bottom? Numerous individuals and groups have attempted to do just that: start their own tiny countries. None of the attempts to do so in the past century has resulted in an entity that's actually recognized as a country by the world's other sovereign nations. But a number of so-called micronations around the world are run as though they're autonomous nations, their residents and leaders holding onto a faint hope that one day they may finally be legitimate members of the international community. In many cases, they even issue stamps, coins, and passports, and have a national anthem. Finding a New World The first problem you'll notice if you're contemplating starting your own country is that all the world's land is already spoken for. There's no unclaimed territory left, and for this very reason, existing countries tend to be extremely protective of their real estate. So you could declare your apartment, farm, or private island to be an autonomous territory (as others have in fact done), but seceding isn't really that easy. If the jurisdiction from which you're trying to separate doesn't change its laws to accommodate you—and crucially, if it has more guns and soldiers than you do—you're pretty much out of luck. A few groups have attempted to create land for their micronations by building artificial islands of one kind or another or by declaring a ship floating in international waters to be their territory. Apart from the logistical and financial issues of such an approach, there's still that pesky problem that if no other nation recognizes your new entity to be a country, then for all practical purposes, it isn't. Apart from those details, you've got to convince enough people to inhabit your country to make it viable. You'll need a government and security forces, naturally, but also some means of providing all the goods your population will need. If your nation can't produce enough food, clothing, transportation, and so forth from its own resources, you'll need to import it—and to do that, you'll have to have a source of income. Income could, of course, come from exported goods and services, but you'll still need resources of some sort and a reasonably large labor pool. Oh, and unless you want your citizens to go abroad for their schooling and medical care, you'd better have a well-thought-out educational system and at least one hospital. Add to that courts to punish crimes and resolve disputes; an infrastructure for electricity, water distribution, and telephone service; and a transportation system, just to name a few of the many obvious features your nation will require, and you can begin to see why more people don't start their own countries. Minor Victories And yet, despite all these complications and many more, a few micronations have managed to survive for decades without being invaded and shut down by another country. Here are a few prominent examples: * Sealand: During World War II, Britain built a large gun platform in the North Sea, just outside its territorial waters, to defend itself from German aircraft. They abandoned it after the war, and in 1967 it was occupied by Paddy Roy Bates and several of his associates. Bates declared the platform a sovereign nation called the Principality of Sealand and named himself Prince Roy I. In 1987, Britain extended its territorial waters past where Sealand sits, but although the British government doesn't officially recognize Sealand, they haven't tried to take it over either. Today, a handful of people still live on the platform; the nation's primary activity and source of income appears to be running Internet servers. * Hutt River Province: This farm in Western Australia claims to have seceded in 1970 after a long-running dispute involving wheat quotas. It's led by the farm's owner, Leonard George Casley (or Prince Leonard I to his subjects). Although it's not officially recognized as a sovereign state and its legal status is quite ambiguous, there is some evidence that Australia regarded its secession as legal. The Hutt River Province has about 20 residents, but has issued passports to thousands of people around the world. * Molossia: The Republic of Molossia comprises a small patch of land in Nevada and another in California, referred to as the Desert Homestead Province. It was founded in 1977 and still has only four citizens, but it nevertheless claims to be working toward eventual recognition as a true nation. Not in My Ocean Other attempts, though, have been less successful. Such was the case with a micronation called Minerva. In 1971, a Las Vegas millionaire named Michael Oliver decided to create his own island by dumping barges full of sand onto a shallow reef in the Pacific Ocean, not far from Fiji. The newly formed Republic of Minerva declared independence in letters sent to all the nearby nations, which soon gathered to sort out what they thought about suddenly having a new neighbor. The result of that meeting was a small military force sent by Tonga to evict the Minervans. Tonga annexed the new island, and though its ownership is still under dispute, no one is currently living there. But not all micronations are truly attempts to create geographically distinct, sovereign countries. Many people have declared some piece of land to be a micronation for comedic or artistic reasons, as a form of political protest, or to generate publicity—without ever truly intending to make it a permanent, sovereign nation. And quite a few micronations have no territory at all, but exist only on the Internet; some of these serve as virtual real estate in role-playing games, while others are themselves simulations of real societies in some fashion or another. Real or virtual, micronations feed that common but quixotic urge to make and live by one's own rules. One of them might eventually succeed, but sooner or later, a citizen of even the most idyllic micronation is bound to feel that something better can be created. Nanonations can't be far behind. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/27/Sealand_fortress.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/Micronations.e0dfccd4d9c.mp3"
	},
	{
		"title": "Polywater",
		"text": "Every once in a while, someone announces a scientific discovery that sounds too good—or at least too amazing—to be true, because it contradicts the conventional wisdom of the day. Occasionally, as in the heretical claim that Earth revolves around the Sun, the discovery turns out to be correct. Then there are the stories of perpetual motion machines, cold fusion reactors, and the like. We'd like to believe in them, and the demonstrations sure are impressive, but then someone looks a bit closer and points out that appearances are deceiving and nothing spectacular is happening after all. Sometimes the so-called discovery is an out-and-out hoax, as was the case with the famous Piltdown Man fossils. But even honest, well-intentioned scientists sometimes make mistakes, and when their claims get ahead of solid proof, it can cause tremendous embarrassment. Such was the case with polywater, a seemingly remarkable substance discovered by Russian scientists in the mid-1960s. The story begins squarely in the world of science fiction. In 1963, Kurt Vonnegut published a novel called Cat's Cradle. In the story, a scientist has discovered a new form of water, called ice-nine, which freezes at room temperature. Moreover, when ice-nine comes in contact with ordinary water, that water turns into ice-nine and solidifies too. So the dramatic tension comes from the danger that all the world's water could turn into ice-nine, which would be problematic for obvious reasons. Thicker than Water A few years later, a Russian scientist named Nikolai Fedyakin was performing experiments that involved putting water in sealed capillaries (very thin tubes made of glass or quartz). He noticed that in some of the capillaries, a second column of water formed above the water that should have been there, with an intervening layer of air. As the quantity of this second column increased, the quantity of the original water decreased. More intriguingly, though, this second column of water was thick, like a syrup. Not only did it have a higher viscosity, but it also remained liquid far below water's normal freezing point, and boiled at a much higher temperature. Fedyakin believed he'd somehow stumbled onto a new form of water—after all, what else could it be? There hadn't been anything but water in the capillaries in the first place. Another scientist, Boris Deryagin (also spelled Derjaguin), soon took over Fedyakin's research, and was also able to produce this mysterious substance. He reported his findings in science journals, and before long, began traveling abroad to present his work to other scientists. Researchers in England and the United States attempted to replicate his results, with mixed success. Those who did succeed were able to produce only tiny amounts of the substance at a time. But the U.S. Bureau of Standards examined a sample in 1969 and determined that it was indeed a new form of water. They believed that the water had polymerized, or formed long chains or rings of molecules, and dubbed the substance polywater. We Want to Believe Meanwhile, the very notion of a new form of water sparked an enormous controversy. On one side were skeptics who believed that there simply wasn't and couldn't be a new form of water. They assumed that the glassware or the water being used in the experiments must have been contaminated somehow, despite the assurances of researchers that everything had been properly sterilized. On the other side were people who trusted the experimental results they'd seen so far, came up with theories to explain what might have caused polywater to form, and also used polywater to explain away other phenomena they couldn't adequately account for. Apparently someone in this latter group had read Vonnegut's novel, because a worry arose and quickly escalated into a panic: perhaps if polywater came in contact with ordinary water, the plain water would all turn into a viscous goo too! Scientists were urged to treat polywater as a deadly substance until it was shown definitively to be safe—even though no one could make more than a drop of polywater at a time, and even though no one had ever demonstrated that polywater had any effect on plain water. The story has a happy (if anticlimactic) ending. Polywater samples were subjected to much closer scrutiny, including chemical tests and examination under an electron microscope. Every single sample showed some contamination with impurities of various kinds—in other words, polywater was nothing more than tiny particles of other substances suspended in ordinary water. When the original experiments were repeated, this time with extraordinary care given to cleaning the test apparatus, polywater could no longer be produced. By 1972, most of the world's scientists considered the case closed and moved on to new mysteries. Deryagin was somewhat more reluctant to admit he'd been wrong, but in 1973 even he conceded that polywater did not exist. He'd lost face, but there was a bright side: at least he avoided solidifying the planet's oceans. That's got to count for something. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/27/molecule.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/Polywater.d68ced62c431.mp3"
	},
	{
		"title": "Saint-Pierre & Miquelon",
		"text": "As a product of the Canadian educational system, I have always been fairly confident in my knowledge of my native country's geography and history, but I learned something recently that completely surprised me. After watching the French/Canadian film The Widow of Saint-Pierre (La Veuve de Saint-Pierre), which I assumed was set somewhere in the maritime provinces of Canada in the 1800s, I discovered that its actual setting was the island of Saint-Pierre, part of a group of islands controlled by France off and on since 1763. Other than being nonplussed about my failure to realize that the Saint-Pierre of the film title referred to a real place, what really struck me was the fact that these islands, officially called Saint-Pierre & Miquelon, are still under French control, and their inhabitants are citizens of France. It shocked me to realize that as a Canadian I would need a passport to visit these islands, located less than an hour's ferry ride from the Canadian province of Newfoundland, and that I would need to stock up on Euros before I got there. How had I missed this fact in the course of my education? It seemed amazing to me that I didn't have to travel to Europe to visit France, but could do so closer to home. I also found it fascinating that Mexico, the United States, and Canada were not alone on the North American continent; this corner of France joined the others as its smallest territory. But, although it is small in size, I learned that Saint-Pierre & Miquelon played a major role in the history of its much-larger neighbors. The Isles Have It Technically, Saint-Pierre & Miquelon is a collectivité d'outre mer, or overseas community of France. It comprises the islands of Saint-Pierre, where the main port of Saint-Pierre is located, as well as the island of Miquelon, which was once three separate islands (Le Cap, Miquelon, and Langlade) now joined by sand dune land bridges. Saint-Pierre & Miquelon's population is around 6500, with the majority of inhabitants descended from Breton, Basque, Normand and Acadian settlers who originally came to the islands as fishermen. Followers of Cod In the late 1400s, the explorer John Cabot returned to Europe with the news that he had found a rich fishing ground off the coast of North America. Now known as the Grand Banks, this series of underwater plateaus located at the intersection of the warm Gulf Stream and the cold Labrador Current just southeast of Newfoundland was home to immense numbers of fish, including the much-valued Atlantic cod. Although known earlier to the Portuguese, it was Cabot's announcement that ignited interest in the commercial potential of the Grand Banks, and there were soon many European countries sending ships to the area, including France, Spain, Portugal, and England. Because of their proximity to the Grand Banks, the islands of Saint-Pierre and Miquelon became the bases of operation for fishing fleets, most particularly those of the French regions of Brittany, Normandy and the Basque Country. By the late 1600s, French settlers had established cod salting and curing facilities on the islands. However, these settlements were short-lived; because of wars between France and Britain in the early 1700s, France ceded Saint-Pierre & Miquelon to the British as a condition of the Treaty of Utrecht. Dually Deported Throughout the 18th Century, the fortunes of Saint-Pierre & Miquelon were decided by the larger conflicts playing out across the eastern part of North America, as Britain and France (along with various groups of Native Americans) grappled for control of the continent. Over the course of two centuries, the French had built up the colonial territory of New France, which at its peak encompassed much of what is now Eastern Canada (the maritime provinces and Québec), as well as a swath of land west of the British colonies on the Atlantic coast, running from the Canadian border to the Gulf of Mexico. In 1754, a dispute about which country would control the land around the Ohio River led to a larger conflict between Britain and France which came to be known as the French and Indian War. Around the same time, from 1756 to 1763, much of Europe was engaged in the Seven Year's War, which pitted Britain, Prussia, Ireland, and Hanover against France, Austria, Russia, Sweden, and Saxony, and the conflict in North America became part of this larger war. With the British gaining the upper hand, and having captured many of the French strongholds, the conflict ended in 1763 when both nations signed the Treaty of Paris, giving Britain control of all of New France, with the sole exception of Saint-Pierre & Miquelon. However, the British attacked the islands in 1778 because of France's support of the American Revolutionary War, and deported all of their inhabitants. The French eventually took back the territory in 1783, but lost it to Britain once again in 1793 when France declared war on Britain during the time of the French Revolution. For a second time, Saint-Pierre & Miquelon's inhabitants were deported from the islands. Pierre de Resistance France gained control of Saint-Pierre & Miquelon again in 1816 after the second abdication of Napoleon, and has retained control since that time. The islands continued to play an important role as the base of operations for French cod fishing in the Grand Banks throughout the 19th Century and into the 20th. Saint-Pierre & Miquelon also briefly became the base of operations for another kind of commerce; during Prohibition in the United States, American gangsters, including Al Capone, used Saint-Pierre & Miquelon as the launching point for their liquor smuggling activities. Although it was far from the mainland of France, Saint-Pierre & Miquelon could not escape the conflict in Europe during World War II. When the Vichy government was formed in response to the German attack on France, the islands were also governed by the Vichy leaders, However, in 1941 they became part of the French resistance to the Nazis, when Rear-Admiral Muselier of the Free French forces led an attack on the islands, bringing them into the resistance movement spearheaded by Charles de Gaulle. Cod Lover Ills Saint-Pierre & Miquelon is currently facing a new challenge to its economy and livelihood. Overfishing in the Grand Banks has led to the closure of the fishing industry by the Canadian government in hopes of restoring these stocks. In response, Saint-Pierre & Miquelon is pursuing other sources of revenue, including agriculture, fish and crab farming, and tourism. I think they have a great opportunity for drawing tourists to the islands, if only to experience the novelty of visiting a European country without crossing the Atlantic, and to see first-hand these small islands that nevertheless played such an enormous role on the world stage. —Morgen Jahnke ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/27/Flag_of_Saint-Pierre_and_Miquelon.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/Pierre.a745e0a7aa5d.mp3"
	},
	{
		"title": "E Clampus Vitus",
		"text": "On our most recent long-weekend trip to northern California's historic gold mining region, Morgen and I explored some ghost towns we'd never seen, as well as several mining towns that managed to stay alive after the gold rush. Some of these towns still have a charming 1850s feel to them, with restored buildings on the original Main Street that now house gift shops catering to tourists. One such town is Murphys, which was founded as a mining camp in 1848. As we were strolling through the town's business district, we passed a building that had a long outside wall covered with more than 80 stone and tile plaques, each supposedly honoring an important figure in California's history. Called the E C. V. Wall of Comparative Ovations, it included relief images and brief biographies of not only doctors, engineers, and city founders, but also Mark Twain, San Francisco's legendary Emperor Norton, saloon dancers, and a saber-tooth tiger. Most of the plaques were made by artist William Gordon Huff in the 1970s, under the auspices of a fraternal organization to which he belonged called E Clampus Vitus (ECV). It's perhaps the world's wackiest (and least secret) “secret” society. The Society about Nothing E Clampus Vitus, a name that's had numerous alternative spellings and misspellings over the years, is faux Latin; it never meant anything. That lack of meaning is in fact a hallmark of the organization. Most of the Web sites discussing the society clearly plagiarized from each other (many, in fact, openly acknowledge that they have done so), and as you can tell by reading all these similar stories, the group prides itself on being ill-defined. But to give you a flavor of E Clampus Vitus, let me share with you a sampling of the descriptive statements I've found: * It's either a historical drinking society or a drinking historical society. * All members are officers and all officers are of equal indignity. * The society's members swear to care for widows and orphans—particularly the widows. * Their motto, Credo Quia Absurdum, is a shortened form of a Latin phrase that means “I believe it because it is absurd.” * The society's flag, always carried during parades, was a hoop skirt. Attached to it were the words “This is the flag we fight under.” * Regular meetings were required to be held at any time before or after a full moon. It's hard to say anything about the organization with great certainty, largely because its members have traditionally considered ambiguity a virtue and clarity a vice. An oft-repeated saying is that no one is ever in any condition to take minutes at a meeting, and afterward, no one can remember what happened. According to most stories, the society was started by a West Virginia tavern owner named Ephraim Bee in 1845, as a tongue-in-cheek response to what he considered overly serious organizations like the Free and Accepted Masons and the Independent Order of Odd Fellows. Over the next few years, chapters sprang up in several other U.S. cities. An ECV member named Joe Zumwalt moved to California from the midwest in 1849 and established the first major California lodge in 1851. The group attracted entertainment-starved miners, and before long, northern California had chapters all over the place and became the national hub of ECV activity. ECV members—men only, of course—referred to themselves as “Clampers” for short, and met regularly in a Hall of Comparative Ovations, often the back room of a saloon. Their uniforms were typically red shirts, black hats, and “badges” cut out of tin cans. They put new members, or “Poor Blind Candidates,” through a relatively benign blindfolded hazing ritual, at the end of which each initiate was dubbed Chairman of the Most Important Committee. Each member eventually held a unique and equally silly title that served only to mock the strict hierarchy of other fraternal organizations. Clamp On, Clamp Off Apart from drinking and wearing goofy outfits, what did ECV members actually do? For one thing, they spent a good deal of time playing practical jokes on each other and on the general public. They also fabricated their own history, including a story of the group's creation in 4004 B.C. (the date from which their official calendar is reckoned). But E Clampus Vitus was also genuinely charitable. Clampers went out of their way to take care of each other in times of crisis. And death rates among miners being quite high, group members regularly raised money to help widows and orphans, usually making their contributions anonymously. As the gold disappeared from the California hills after a few decades, so did the miners. By the early 20th century, E Clampus Vitus was essentially extinct. However, in 1931, a group of historians from San Francisco decided to bring the organization back to life. Today, the society has more than 40 active chapters, mostly in California. E Clampus Vitus is known for researching sites of historical interest (though perhaps not of interest to mainstream historians) and erecting plaques to mark them. From what I can tell, the rituals have been toned down quite a bit since the society's heyday, but the sense of camaraderie and silliness is still going strong. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/E-Campus.a60cd72ab8d6.mp3"
	},
	{
		"title": "Radio Call Letters",
		"text": "I've never entirely understood radio. As in: why do so many people have a radio on so much of the time? That's a habit I never got into, and the whole concept of radio as an always-on background noise strikes me as odd, if not downright annoying. I love listening to music, but I prefer to pick my own tunes and play them when I'm able to pay attention to them. Besides, if I'm looking for audio, the Internet offers me a much wider range of choices than terrestrial or satellite radio stations do. As a result, I couldn't tell you the first thing about my local radio stations: their frequencies, call letters, or what sorts of programming they offer. When I was growing up in western Pennsylvania, however, I had a somewhat greater awareness of radio stations—particularly during the winter months, when we'd listen eagerly on snowy mornings to find out if school had been cancelled that day. The station we usually listened to was KDKA, which happened to be both the first commercial radio station in the country and a notable exception to the rule that all radio stations in the eastern U.S. had call letters that started with W. I always had the vague idea that these two facts had something to do with each other, but as a habitual non-radio listener, I never thought that much about it. It turns out that not-thinking-that-much-about-it was a prominent theme in the history of radio call letters. Who's Calling? Around the turn of the 20th century, radio was brand new and was originally used as a wireless telegraph, with messages transmitted in Morse code. To shorten the number of dots and dashes needed to identify each party, operators of radio stations on both ships and land adopted the practice already common in telegraphy to begin messages with short (one- to three-letter) identifiers—call letters (or call signs). Without a central authority to hand out call letters, users chose their own, and frequently chose ones already in use. By 1906, an international convention established that every station should have a unique, three-letter call sign, but left vague the matter of how that uniqueness was to be ensured. To help eliminate the confusion, the Bureau of Navigation, part of the U.S. Department of Commerce, began assigning three-letter call signs to American ships in early 1912, using the K prefix for ships on the Atlantic and Gulf coasts and W for ships on the Pacific coast and the Great Lakes; the reasons for choosing K and W, if any, are unknown. Shortly thereafter, at the London International Radiotelegraphic Convention, ranges of letters were assigned to each of the participating nations; in addition to W and most of the K range, the U.S. got the N prefix (to be used only by the navy). On May 9, 1913, the U.S. Department of Commerce issued a 4-page document titled Radio Call Letters, which laid out the official policy in some detail. A couple of paragraphs bear particular mention: 3\\\\. (b) The combinations KDA to KZZ, with a few exceptions, are reserved for ship and coast stations on the Atlantic coast and Gulf of Mexico. 3\\\\. (c) The combinations beginning with W…are reserved, with a few exceptions, for ship and coast stations on the Pacific coast and the Great Lakes. There you have it, clear as day: like the ships off the Atlantic coast, the land-based stations in the east were to have K designations, while stations in the west, like ships off the Pacific coast, were to have W designations. For entirely unknown reasons, though, these labels got swapped before they were implemented. Later that year, stations in the west began getting K call letters, while stations in the east got W call letters. A 1914 booklet of regulations titled Radio Stations of the United States codified the K-in-the-west, W-in-the-east practice, which was followed strictly thereafter, except when it wasn't. From June 1920 until April 1921, the Bureau of Navigation decided, once again for unknown reasons, to use K call letters for almost all new licensees, both marine and land-based. It so happened that during this period, just one commercial radio station—the first, in Pittsburgh, Pennsylvania—applied for a license. They were therefore given the designation KDKA, which happened to be next on the list (and, coincidentally, between the call letters for two ships, which used KDJZ and KDKB). KDKA began broadcasting in November, 1920. By the time the next commercial station was licensed, the official written policy was once again being followed, but KDKA was not required to change its call letters. Where the West Begins Astute readers may notice that Pittsburgh is not particularly close to the east coast. Closer than to the west coast, certainly, but the vague designations of “east” and “west” were soon to be put to the test. Exactly where should the Bureau of Navigation draw the line? For several years the boundary was a line running down the western borders of North Dakota, South Dakota, Nebraska, Kansas, Oklahoma, and Texas. In January 1923, the Bureau of Navigation moved the dividing line to the Mississippi River, quite a bit to the east. Once again, stations in that zone that had already received what would now be considered an incorrect designation were not required to change. Apart from KDKA and stations assigned before the boundary shift of 1923, though, there are a number of other exceptions to the rule. Some exceptions were made by special request, some due to a station's relocation, and some apparently by mistake. But all call letters, anomalous or not, were permitted to stick indefinitely, except in certain cases of ownership change. In the late 19th century and the first decade and a half or so of the 20th, call signs for both ships and land-based stations had only three letters. But as the number of ships and stations increased, the pool of available combinations began to run out. Adding a fourth letter was the obvious solution, though if a ship sank or was otherwise put out of commission, its call sign was sometimes “recycled” by a land-based station. By 1930, only four-letter call signs were available. Meanwhile, authority to assign call letters moved in 1927 from the Bureau of Navigation to the newly formed Federal Radio Commission, which was replaced by the Federal Communications Commission (FCC) in 1934. Show and Tell When TV stations started appearing, incidentally, they adopted the same scheme: with a few odd exceptions, K- stations to the west of the Mississippi River and W-stations to the east. Since radio stations' owners often owned TV stations as well, they generally used the same call letters for both media, typically with a “-TV” suffix for the TV station's call letters, as in KQED-TV. While I lack an awareness of local radio stations and their call letters due to insufficient exposure, I lack an awareness of local TV stations and their call letters due to TiVo. Not only do I no longer have any idea what TV station (or even network) I'm watching, I have only the vaguest idea of the days or times my favorite shows are actually on, because as far as I'm concerned, they're on whenever I want them to be. Expressions like “stay tuned” or “don't touch that dial” seem quaintly anachronistic, as does the whole notion of network loyalty. My loyalty, such as it is, goes to particular shows or personalities, and that appears to be a common trend. So whatever value call letters continue to have, it isn't in building brands. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/28/Call_Letters.96b3749e37b8.mp3"
	},
	{
		"title": "Llívia",
		"text": "As an American, I've always felt a bit embarrassed at my limited grasp of foreign languages. I have friends in Europe who speak four or five languages fairly fluently, and they rightly boggle when they hear that most Americans are monolingual, but for complicated historical, cultural, and political reasons, that's just the way things turned out. I took French classes in high school, studied linguistics as a grad student, and picked up a handful of phrases in half a dozen other languages here and there, all of which probably makes me slightly less clueless as a tourist than many of my compatriots. I usually know at least enough to recognize which language I'm listening to. Several years ago while driving through Europe, we stopped at a gas station in Austria near the Italian border, and when we asked for directions to a certain castle, the clerk's response included French, German, and Italian words in the same sentence. I got the general drift of what he was saying, but I marveled at how intertwingled the languages had become in this border region. All sorts of interesting things happen around international borders, especially when those borders are not clearly defined. I recently bought a new world atlas, and while looking at France and Spain, I saw something I'd never noticed before: a tiny region in southern France surrounded by what appeared to be an international border, but without any label whatsoever to tell me what it was. Andorra, a small country that straddles the border between France and Spain, is nearby, but this little blip was farther east in the Pyrénées and clearly something different. The light bulb went on shortly thereafter when I was reviewing my list of suggested topics readers had sent in: someone wanted to see an article about a curious place called Llívia. That was the blip! Due to a series of weird historical, geographical, and linguistic flukes, an entire Spanish town ended up completely within the borders of France. But that's just the beginning of the story. All Around Town Officially, Llívia is considered a Spanish enclave within France. It's a small town of about 5 square miles (13 sq km), situated less than a mile (about 1km) from the Spanish border and connected to the rest of Spain by a single, small road. The town's official Web site lists its current population as 903, though other estimates put the number at over 1200. Whatever Llívia's population may be, it's historically important that it be considered a town rather than a village. Llívia was a strategically important area as far back as the time of the Roman empire, and was considered the capital of the region known as Cerdanya, which includes portions of modern-day France and Spain. But it wasn't until 1528 that Roman Emperor Charles V (known in Spain as Carlos I) formally designated Llívia a town—apparently more for reasons of history than of population. This decision was to prove momentous a little more than a century later, when France and Spain signed the Treaty of the Pyrénées and thus settled the dispute over the border between the two countries that had been the cause of decades of war. According to the terms of the treaty, the border was to run primarily along the main crest of the Pyrénées, and all villages north of that line were to become part of France. Spain insisted that, according to the letter of the law, Llívia must be excluded from French rule because it was not a village but a town—and that's why Spain continued to control a parcel of land entirely inside France. Llivid About That Border In 1868, the border between the two countries was finally surveyed and delimited explicitly with a series of bordermarkers, numbering in the hundreds, including 45 just for Llívia. Most of these markers are simple chunks of stone, numbered consecutively and marked with “LL” on the Llívian side and initials representing the nearest French village on the French side; a few markers were made by carving numbers and letters into existing rocks. Locating and photographing these markers with the aid of maps and GPS receivers has become a common tourist pastime. Despite the seemingly conclusive nature of the bordermarkers, and despite the fact that Llívia is just a stone's throw from the Spanish border, the two countries have tangled over the details of the border numerous times, with little pieces of land going back and forth according to the terms of the most recent lawsuit. One conflict involved the short road connecting Llívia to the rest of Spain: it was supposed to be neutral, but a certain French road crossed it. Each country felt its citizens should have right of way at the intersection, and ignored the other's stop signs. Eventually an overpass had to be built, at Spain's expense, to make the issue moot. At another, smaller intersection, a similar conflict was resolved by constructing a roundabout. Que Parla el Català? Good information about Llívia in English is hard to come by, though you can find some coverage on the Web in French and even Dutch. When I visited Llívia's official Web site, though, I assumed it would be in Spanish. The text had a familiar look to it, but some of the words appeared to be Spanish while others appeared to be French. It took me a while to figure out that I was actually looking at neither Spanish nor French, but rather Catalan, one of the three official languages of the region of Spain known as Catalonia. Catalonia, which also encompasses Barcelona, is one of Spain's 17 autonomous communities, with its own government and police force and considerable latitude to function, in many respects, independently of the nation as a whole. Thus, culturally speaking, Llívia is more of a Catalonian enclave than a Spanish enclave. Modern Llívia is scenic and quaint, known regionally for its annual music festival in August and a museum that contains Europe's oldest pharmacy. You can stay in a three-star hotel and, during the colder months, enjoy good skiing nearby. If you happen to be passing through the Pyrénées, be sure not to miss it. (Helpful hint: going north, take the first right at Andorra and follow the signs…assuming you can figure out what language they're in.) —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/27/Llivia.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/Llivia.f26484ba902b.mp3"
	},
	{
		"title": "Emperor Norton",
		"text": "When someone refers to my hometown as “San Fran,” I really bristle. People who live in other parts of the world may think “San Francisco” has too many syllables, but locals don't ever call it “San Fran.” Ever. And only in an effort to be intentionally gauche or ironic would a resident call it “Frisco.” That's just wrong, and it immediately identifies anyone who says it as clueless. This judgment goes way, way back. A century and a half ago, by the emperor's decree, calling the city “Frisco” was a high misdemeanor punishable by a $25 fine. Today's interesting “thing” is ostensibly a person, though in fact it's more of a concept: the notion that someone could declare himself to be an emperor, and—without any force or intimidation—actually get an entire city to go along with the fantasy, at least superficially, for more than 20 years. I am speaking of one of San Francisco's most colorful historical figures: Joshua A. Norton, a.k.a. His Imperial Majesty Norton I, Emperor of the United States and Protector of Mexico. The New Emperor's Clothes Joshua Norton was born in England in the early 1800s—sources vary as to the exact year of his birth, but it was somewhere between 1811 and 1819. From 1820 to 1849, he lived with his parents in South Africa. He then moved to the United States, taking up residence in San Francisco. Norton had come to the U.S. with a small fortune, and for several years, he was a successful businessman. Then a major investment turned out poorly, and Norton went bankrupt in 1858. He left the city, but returned the following year—wearing an army uniform with gold-plated epaulets and a funny hat. He presented a piece of paper to the editor of a local newspaper declaring himself to be “Norton I, Emperor of the United States.” The editor found Norton's claim to be so amusing and bold that he printed the declaration on the front page of the paper as though it were genuine. And, surprisingly enough, the general public's reaction was apparently “Cool. We have our own emperor.” Norton began striding regally around San Francisco in his uniform as if he really were the nation's supreme ruler, and the city's residents indulged him. From all accounts, Norton, whatever his eccentricities or mental deficiencies, was a kind, affable, and benevolent man who was much loved by almost everyone he encountered. Whether or not he truly believed he had any power or right to rule, the people of San Francisco treated him with great deference and respect. He spent his days patrolling the streets, inspecting sidewalks and cable cars, supervising street repairs, and praising citizens for any good deed he observed. He especially liked to monitor “his” police force to make sure they were serving the city's needs properly. Norton was given free meals at restaurants, and in fact, restaurants that served him liked to put up brass plaques bragging that they were an official supplier of the emperor—it was good for business. Theaters reserved prime seats for Norton and his two dogs at every opening, and he was invited to lead parades and participate in various civil ceremonies. A local printer even provided Norton with his very own imperial currency, which merchants accepted as cash. (These notes are worth thousands today at auction.) On one occasion, a police officer who didn't appreciate Norton's status arrested him and attempted to send him to a mental institution. The public outcry was immense. The police chief released Norton with a formal apology, and thereafter, all police officers saluted the emperor when they passed him on the street. Laying Down the Law Emperor Norton is perhaps best known for his frequent and audacious decrees, which the local newspapers always printed with great relish. (And when there wasn't an actual decree, sometimes the newspapers made them up.) An 1860 decree dissolved the United States of America; a few months later, another decree prohibited Congress from meeting in Washington, D.C. In 1869, Norton issued a decree abolishing both the Democratic and Republican parties. Of course, no one ever took these decrees seriously, but this apparently didn't diminish Norton's belief in his authority. Some of the decrees, though, were strictly local—and showed an uncanny degree of foresight. In 1872, Norton decreed that a suspension bridge should be built between Oakland and San Francisco by way of Goat Island (now called Yerba Buena Island). Later that year, another decree demanded that a survey be undertaken to determine whether a bridge or tunnel was the best way to connect San Francisco and Oakland—and the members of the city's Board of Supervisors were to be arrested for having ignored his earlier decrees. (They weren't.) But a bridge very much like the one Norton had described was built eventually; the San Francisco–Oakland Bay Bridge opened in 1936. And in 1972, almost exactly 100 years after Norton's decree, so did a tunnel—it's used by BART, the Bay Area Rapid Transit system. Norton's reign as emperor lasted for 21 years. He died in 1880 of an apparent stroke while walking down the street. Although Norton died penniless, the city gave him a regal burial, and about 30,000 people turned out to watch his funeral procession. In the years since, some people have argued that Norton really was the emperor, inasmuch as the public (at least in San Francisco) acknowledged that title. And there's something to be said for that line of thought; after all, the only reason any government is legal or valid is ultimately the general assent of those governed. The United States of America, after all, declared itself into existence once; why shouldn't an individual do the same? I, Joe I Norton did not have a successor, but there's no reason someone else couldn't step into the role, even now. Knowing what I do about the follies and failings of San Francisco's current city government, it seems clear to me that the city—if not the entire country—should once again bring in an emperor to enforce order, fairness, decorum, and maybe a bit of whimsy. Clearly this individual must be someone with intelligence, charm, good humor, and poor fashion sense. As the logical choice, I'd be honored to serve. And so, citizens of San Francisco, the United States, and/or Mexico, should you choose to accept me as your new emperor by public acclaim, I will humbly and faithfully discharge the duties of the office. I promise to come up with great ideas that can't possibly be implemented for a century; to issue impressive-sounding, unreasonable, and unenforceable decrees on a regular basis; to dress in a goofy uniform; and to behave in a generally benevolent and weird manner. In other words…pretty much life as usual. I'll be expecting to receive your tax payments shortly. Oh, and Congress: you're fired. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/27/Norton.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/Norton.343cd4d6dfc6.mp3"
	},
	{
		"title": "Optical Painters’ Aids",
		"text": "Although I like to think of myself as a multitalented “Renaissance man” of sorts, I must admit that when it comes to drawing and painting, I have absolutely no ability. I'm truly pitiful at Pictionary, and I couldn't paint my way out of a paper bag. Or so I've always thought. Based on what I've been reading lately, I could probably produce some fantastic art from the inside of a very large paper bag, as long as it had a pinhole on one side and pretty bright light outside. All I'd have to do is trace the image projected by this primitive camera obscura. According to a controversial theory, this technique—or something very much like it—gave some world-renowned artists a little help as far back as 1420. Then again…maybe not. Getting to the bottom of this puzzle has been the consuming passion of quite a few artists, historians, and optical engineers over the past several years. Without a Trace Tracing over a projected image is a straightforward notion, but if you've ever tried it (as I have) you probably discovered that getting good results is not as easy as it sounds. The easy part is getting the proportions right. But lots of things in any image lack well-defined borders, and trying to make sense of textures and the effects of light and shadow while tracing something is quite a complex undertaking. If, instead of tracing, I were painting, the challenge would become even greater, as I'd have to carefully match gradations in color—and as soon as I applied a dark paint to the light surface, the image in that area would virtually disappear. All that to say: projection or no projection, producing a convincingly realistic drawing or painting takes a lot of skill and practice. So if it turned out that one of the great masters from centuries ago really did pull this off, I'd be no less impressed by the final product—and more impressed by the artist's cleverness. We know that numerous artists nowadays, and over the past couple of centuries, have employed just such a technique; many of Andy Warhol's best-known pieces, for instance, were done this way. Prior to the invention of photography, though, the only images that could be projected were live representations of the real world. The technology to do this, the camera obscura, has been known for many centuries—possibly since as far back as the fifth century B.C. If a tiny hole is placed in the wall of a very dark room and the light outside is bright enough, an inverted image of the outside scene is projected onto the wall inside. But the image is usually fairly dim and fuzzy. Two important innovations in camera obscura design occurred in the 16th century: the addition of a lens (which made the image sharper) and a mirror (which could direct the image onto a horizontal surface rather than a wall). And there are a few scattered records from the mid-16th century of artists suggesting the use of a camera obscura as a drawing aid, though the earliest confirmed date of anyone actually doing so is 1603. An Obscura Artist It should therefore come as no surprise that an artist might have used such a technique in the 1660s, and that's just what some people have claimed for more than 100 years about Dutch artist Johannes Vermeer (1632–75). These suggestions first surfaced when people began noticing that the proportions in Vermeer's paintings didn't match those of other works from the time, in which the subjects were typically painted at the size the artist perceived them to be. But in Vermeer's works, objects and people closer to the foreground are larger than those in the background—seemingly in just the proportions that they would be in a photograph—or a tracing from a camera obscura image. Several other clues in the geometry and lighting suggested the same thing, but there was no evidence that Vermeer actually had (or even had heard of) a camera obscura. In addition, since the scenes in question were interiors, presumably any image created by a camera obscura would have been incredibly dim. So for many decades the debate continued. Then in 2001, architect Philip Steadman described in his book Vermeer's Mirror detailed research into the geometry of several of Vermeer's paintings—backed up with photos of painstakingly recreated miniatures of the rooms from the paintings. Steadman's studies showed that given the dimensions of the room in each scene (which he carefully calculated) and the viewpoint and size of each painting, all are absolutely consistent with an image of the room being projected onto its back wall with a camera obscura. In other words, given not only the uncanny accuracy of the paintings but also the specifics of their perspective, it's very nearly a mathematical certainty that Vermeer partitioned off a small corner in the back of this room as a camera obscura and painted over the image on a canvas that hung on the wall. (In at least some cases, X-ray evidence shows that although there was no underlying sketch, there was a monochrome image beneath the color paint; this makes sense considering the very dim conditions inside the camera obscura. ) Mirror, Mirror Although it would be an exaggeration to call Steadman's arguments uncontroversial, they're pretty convincing—and, of course, they mainly confirm what a lot of people had suspected all along. But shortly after Vermeer's Mirror was published, another book hit the shelves that made much broader (and more dubious) claims. Painter David Hockney, in his book Secret Knowledge, claims that European artists used optical aids for painting as early as the beginning of the 15th century. But rather than using a camera obscura, Hockney believes these artists used a concave mirror to project an image onto the canvas; no documentary evidence exists simply because they all chose to keep it a carefully guarded trade secret. Among the many artists on Hockney's list are Van Eyck, Caravaggio, and Lotto. Hockney noticed that around the early 1400s, paintings began to show a much more natural representation of light and perspective—that, in some cases, they looked nearly photographic. He was convinced that the level of realism and accuracy they displayed was simply too great to have been done by eye, so he started looking for other explanations. As he went back through history, he noted the use of the camera obscura and other optical aids, and he suspected that the practice may have been much older. He formulated a series of theories about how various works of art over a period of several centuries may have been made by using optics of one kind or another. Experts in the art world are deeply divided over Hockney's claims. Because his theories are so wide-ranging, some of them are bound to be accurate to one extent or another. But many critics believe Hockney has gone too far, and a few have spent considerable effort rebutting his theories. David Stork, a physicist and art historian at Stanford University, has published numerous papers debunking various aspects of Hockney's book. Stork found alternative explanations for many claims of optical aids, pointing out that none of the available evidence requires one to posit the use of optics in the oldest and most controversial works; there are other, simpler explanations. In addition, Stork finds it highly implausible that the artists could have discovered, created, and kept secret such advanced technology for so many years. Having read lengthy articles about this debate until my eyes blurred, I feel I have enough information to reach my own conclusion. And that conclusion is: it doesn't matter. What Hockney, Stork, and I agree on is that even if these legendary masters did use optics, that does not in any way constitute “cheating”; they would simply have been tools of the trade. In the end, I think the years invested in this intellectual exercise might have been more profitably spent painting. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/Optical.c0346b692560.mp3"
	},
	{
		"title": "Tableware Taboos",
		"text": "When I was growing up in a large family, my parents instilled in us certain table etiquette—if not for decorum's sake, then at least to keep complete anarchy from breaking out while we broke bread. Commandments regarding posture (don't slouch), arm position (no elbows on the table), and eating style (chew with your mouth closed) were familiar refrains around the supper table. I am thankful to my parents for these lessons, and I'm sure I will drum them into my children's heads, if I ever happen to have any. But after I left home, I found myself in certain dining situations where I did not know the rules, mostly because our family meals did not involve multi-course menus, where it was important to tell the oyster fork from the fish fork. (It was enough that we were not flinging forks across the table at each other.) In these situations, I could always tell myself that these were outdated conventions, and indeed these kinds of customs have mainly fallen by the wayside in our current low-tech food culture. But I always felt a lack, and a secret wish that I could conduct myself in the very highest echelons of society without embarrassment or awkwardness. Pack The Knife I therefore find it very interesting that Margaret Visser, in her book The Rituals of Dinner, asserts that it is precisely to forestall violence that such rules of etiquette came into being. She argues that “table manners are…a system of taboos designed to ensure that violence remains out of the question,” and that only later did they evolve into the complex, but mostly banal, rituals we know today. One of her primary examples of how the shared table can be a dangerous place, and why table manners are necessary, is the presence of sharp eating utensils at most meals. When everyone at the table is armed with knives, the most common eating implement in the West until recent times, there was always a possibility that mealtime fights would erupt into bloodshed. In fact, a few hundred years ago, it was the custom for each man to bring his own knife to a host's table—the same knife he used for countless other purposes. It may have been in response to the danger these knives posed that the French king banned pointed knives from the table in 1699, replacing them instead with the rounded knives still in common use. Even with such a precaution, it is now still correct etiquette for knives to be placed on the table with the blade facing the plate, and to be replaced in the same position after the meal. And even those of us who do not have a delicate grasp of the nuances of cutlery placement know that it is bad manners to point a knife at someone else or at oneself while sharing a meal. The Knives Are Out In contrast to the knife-centered history of the West, chopsticks have been the preferred eating utensils in Japan and China for thousands of years, possibly influenced by the teachings of Confucius, who believed that “The honorable and upright man…allows no knives on his table.” Knives are a symbol of violence or aggression, and therefore were contrary to Confucius's nonviolent teachings. But even though chopsticks do not have the implied violence of knives, there are still certain taboos about how chopsticks may be used. In Japan there is an aversion to passing food via chopsticks from one person to another while eating together. This action recalls part of the Buddhist funeral ritual, in which family members use chopsticks to pick up bones from the crematory ashes, and pass them from person to person before they are placed in an urn. Also, it is not correct to leave chopsticks sticking upright in a bowl of rice, as this is reminiscent of a tribute to the dead (the deceased's chopsticks stuck in a bowl of uncooked rice on the family altar). I guess I always knew that more was at steak (sorry!) than politeness during our family dinner hour. We were keeping our violent tendencies at bay by keeping our knives to ourselves and resisting the temptation to leap out of our chairs at each other. We were, in fact, learning how to peacefully co-exist in a stressful situation (worrying about getting our fair share)—and were following the original intent of table etiquette, if not all of its arcane proscriptions. —Morgen Jahnke ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/27/flatware.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/Tableware.68f57409be2c.mp3"
	},
	{
		"title": "Passenger Pigeons",
		"text": "I have a confession to make. Even though my wife, Morgen, is an endless fount of interesting topics, when she suggested that I write about passenger pigeons, my first reaction was a yawn. How interesting can pigeons be? There are bazillions of them out there—I practically trip over them walking down the sidewalk every day. “But passenger pigeons are extinct,” she said. So are lots of animals, and that's very sad, but it still doesn't make them particularly interesting to the general public. She kept insisting that no, really, this particular kind of extinct pigeon is truly fascinating, and I kept displaying a complete lack of enthusiasm. Finally, she started reading some facts off a Web page. After the first couple of items, I thought, “Yeah, OK, that's a bit interesting, but if that's all there is to it…” Only it wasn't. She kept reading—and I kept saying “Wow.” Even I had to admit, yes, the story of the passenger pigeon is quite interesting. So by way of penance, allow me to present the poop (as it were) on passenger pigeons. The last passenger pigeon in the world died less than 100 years ago—in 1914, according to most reports. In fact, we know exactly when and where the species went extinct: Tuesday, September 1, 1914, at 1:00 p.m. Eastern time at the Cincinnati Zoo. We even know the last bird's name: Martha. She was 29 years old. It's rather extraordinary that we should have such detailed and precise information about the moment when a species meets its demise—the passenger pigeon is almost certainly unique in that regard. What's even more extraordinary is that just a century or so earlier, passenger pigeons had been more numerous than any other bird in North America—numbering in the billions. Passage and Failure The word “passenger” in the name does not mean the pigeon liked to hitch rides on other animals (nor should the passenger pigeon be confused with the carrier pigeon, an entirely different animal). Rather, the name apparently comes from the French word passage, which means, roughly, “passage” (or “transit” or “crossing”); it referred to the birds' massive and frequent migrations. The adjective form of passage is passager, and this apparently became “passenger” in English via folk etymology. The scientific name is Ectopistes migratorius, which means, more or less, “migrating wanderer.” Passenger pigeons, a relative of the Mourning Dove, were remarkable in several respects. They could fly very fast—upwards of 60 mph (about 100kph)—though they did not use this speed for hunting; they ate mostly nuts, seeds, and berries. They were extremely social animals that liked to live and travel in large groups at all times. A roosting colony could comprise well over 100,000,000 birds and cover more than 800 square miles (2000 sq km) of forest, with as many as 100 nests per tree. When a flock migrated, it moved in an almost solid unit that could stretch for 300 miles (500 km); observers frequently remarked that they darkened the sky for days at a time. Around the beginning of the 16th century, passenger pigeons may have constituted as much as 40% of the bird population of the United States—up to 5 billion individuals—and, according to some estimates, were in fact the most numerous bird on Earth. So Much for Safety in Numbers Because the birds always stayed in large groups, the small animals that were their main predators posed little threat; they could never kill enough of a flock to threaten the group's survival. This behavior, however, became their undoing once the human population began to balloon in North America. As European settlers and their descendants moved across the continent, they cut down many of the trees that had provided food and shelter for the passenger pigeons. This had relatively little effect on the birds' overall population, but it did restrict their habitat. Because birds nesting by the hundreds of thousands or millions in a confined area were such an easy target—and, perhaps, in “retaliation” for destroying crops—farmers and hunters began to trap and kill passenger pigeons in huge numbers, selling them (very cheaply) for meat. By the mid-1800s, the number of passenger pigeons was already dwindling noticeably, but this only increased the rate at which they were destroyed—sometimes as many as tens of thousands per day for months on end. Even though conservationists raised an alarm, very little was done to stop the hunting. Some researchers believe it wouldn't have mattered by that point; since the birds seemed to require very large colonies for successful breeding, their population may already have dipped below a sustainable level before anyone realized there was a problem. In any case, the very rarity of the passenger pigeon by the late 1800s seemed to increase hunters' determination to find just one more. The last known wild passenger pigeons were shot in 1900, but a few may have survived longer. One story I read from the early 1900s was truly chilling: a hunter who'd believed the passenger pigeon was already extinct suddenly spotted one years later. He was excited and nervous, because he realized that this would be the last chance anyone would ever have to kill one. So he took his shot and did it in. Apparently he told the story with a great deal of pride. A few passenger pigeons remained in captivity after that, but all attempts to breed them failed. Martha, who had been named after Martha Washington, was the last living member of her species; her remains were on display at the Smithsonian for many years afterward. Even after Martha died, unconfirmed reports of passenger pigeon sightings appeared occasionally until at least 1930. But now the species is known definitively to be extinct, and North Americans will never again see anything like their great migrations. Had we exterminated, say, all the world's cockroaches instead, I think there would be less to mourn. But that implacable impulse to destroy every last one of some creature is, I'm afraid, still a very troubling part of human nature. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/27/Passenger_Pigeons.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/Pigeons.883ce9815d72.mp3"
	},
	{
		"title": "Leonardo’s Robots",
		"text": "As I have mentioned numerous times, I was obsessed with science and technology as a child. I was especially fond of robots—both real and fictional. The magazines I read showed glossy photos of household robots that could vacuum the carpet and serve drinks; it was clear that human beings would no longer have to do such menial tasks in the future. It was less clear that robots would ever be able to do truly useful tasks like repairing the plumbing or washing the windows, but this was unimportant to me. All I cared about was that robots were cool. If they could move around and impress my friends, that would be good enough. Naturally, I dreamed of someday building my own robot, and even made an abortive attempt to do so when I was about 12. But I was equally happy tinkering with smaller, less-ambitious projects. My bedroom was always full of wires, batteries, motors, solar cells, and electronic doohickeys of all sorts. When I wasn't disassembling a TV or radio, I spent a lot of time (and money) in Radio Shack buying components that I could assemble into some amazing contraption. The only problem (apart from my rather incomplete grasp of electronics) was that I had trouble figuring out exactly what I should make. What task needed to be done that a gadget could perform? I couldn't figure it out. So I was constantly asking my mother, “What can I invent?” She'd invariably say, “If I told you, then I'd be the one inventing it.” That was beside the point, of course—it was really the engineering I was interested in, not the idea-generation itself. Renaissance Robotics A little over 500 years earlier, Leonardo da Vinci was in just the opposite situation: coming up with ideas for inventions left and right, but doing comparatively little in the way of actual experimentation and implementation. Of course, I do not in any way mean to belittle Leonardo's remarkable achievements in so many different fields, but he did have somewhat of a reputation for coming up with half-baked ideas that were never constructed—and in many cases, wouldn't have worked if they had been. His human-powered helicopter design is perhaps the best-known of these wouldn't-it-be-nice “inventions.” On the other hand, Leonardo's sketches did contain a lot of designs that showed uncanny cleverness and sophistication, far ahead of his time. Among these are drawings that experts today believe were designs for robots—which, if true, would make Leonardo the world's first roboticist. The sketches in question were made around 1495, but were unknown until an Italian scholar named Carlo Pedretti found them in the 1950s. Nothing in the several pages of drawings looks like a complete robot; the gears, pulleys, cables, and so on appear to untrained eyes to be random machine components. But Pedretti believed that taken together, they could represent the plan for a mechanical man. Leonardo apparently intended a suit of armor to be used as the robot's body. Several decades after the sketches' discovery, a robotics expert named Mark Rosheim came across Pedretti's description of Leonardo's robot. Rosheim studied the drawings extensively and, using computer simulations, determined exactly how they could have fit together to form a humanoid robot. The digital model of the robot showed that it could sit up, wave its arms, bend its legs, move its head, and open and close its jaw; a mechanical apparatus in the chest controlled arm movements, while an external crank moved the legs. Getting with the Program Leonardo's humanoid robot was clearly based on his long and detailed study of human anatomy—the same research that had led to his famous Vitruvian Man drawing and its accompanying list of proportions in about 1490. But apparently, this was not Leonardo's first foray into the world of robotics. An earlier drawing, from 1478, was thought for years to be the design for a spring-powered cart. But Rosheim's analysis showed that it was much more than that. The mechanism inside could be adjusted (by replacing various cams) to determine the course the cart would travel. In other words, it was, in a manner of speaking, a programmable analog computer—and since it was also mobile, it could be considered a robot. Most experts consider it unlikely that Leonardo ever built the robots shown in the sketches. Rosheim, however, did build a reproduction of the cart, as well as a version of the robot that maintained Leonardo's overall design but substituted a few pieces of modern technology, such as electric motors. Both functioned as Rosheim's computer models had predicted, meaning that Leonardo's designs were right on the money, even if he never did build them. The robot doesn't do anything useful—unless you consider entertaining and impressing your friends useful, which I certainly do. I'm sure Leonardo would have agreed. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/27/Leonardo-Robot3.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/Robots.29e4656cc20c.mp3"
	},
	{
		"title": "The 1715 Spanish Plate Fleet",
		"text": "All American school children know the rhyme, “Columbus sailed the ocean blue in fourteen hundred ninety-two.” They learn, by and by, that Columbus (who was probably not Spanish, even though he sailed under the flag of Spain) was not the first European to land in North America; that he never actually set foot in what is today the United States, that he was severely mistaken about the location of the New World, and that his voyages were largely motivated by greed. None of these facts, however, tends to take the sheen off the popular belief that Columbus discovered America, and that in some way his adventures were altruistic explorations that were really undertaken for the benefit of future generations—namely, us. And when we think of Spain’s role in the development of the western hemisphere, many of us think mainly about the Spanish colonization of Mexico and Central and South America. The view from Spain in the 15th century, and for quite some time thereafter, was very different. Whatever else could be said about America, it was a gold mine—both figuratively and literally. Spain’s plan was to monopolize trade with the New World, making sure its gold, silver, and treasures of other kinds flowed back to Spain. This money financed, among other things, Spain’s efforts to expand its territory within Europe and around the world. So for nearly 200 years, heavily armed convoys of Spanish ships made regular, twice-annual voyages to deliver manufactured goods to the Americas and carry treasure (some of it from commerce, but much of it from taxes) back to Spain. Unsurprisingly, some of these ships never made it home, due to piracy, bad weather, or other misfortunes. But one particular loss is notable for its size, its location, and its historical significance: the ill-fated treasure fleet of 1715. Gold Plated The War of the Spanish Succession had been raging in Europe since 1701, and for two years Spain had to postpone all treasure shipments from the New World for fear they’d be intercepted. This unusual delay meant that there was an extremely large stockpile of treasure waiting for transportation. And Spain needed it urgently: the war had severely depleted the country’s resources—and the nation’s new queen, Isabella Farnese, was also particularly keen on getting some jewels from America that had been promised as part of her dowry. So two fleets were sent to collect the treasure—five ships in one, headed for Veracruz, Mexico, and six in the other, headed for South America. The plan was, as usual, for the fleets to load up at their respective destinations and then rendezvous in Havana (assuming there would be greater safety in numbers). From there, the combined fleet was to set out before hurricane season began in July and sail north with the Gulf Stream along Florida’s east coast until they hit the trade winds that would carry them eastward for the long voyage across the Atlantic. The ships were fully loaded with the immense stockpile of accumulated gold, silver, jewels, and rare Chinese porcelain plates; hence the name “plate fleet.” However, a long series of delays meant that the ships didn’t all reach Havana until late July. They were joined by a 12th ship from France and, under immense pressure to deliver their cargo as quickly as possible, set sail for Spain on July 24, 1715. Just a few days into their journey, the ships encountered a massive hurricane that spread out the fleet and blew them toward shore. According to some reports, the French ship, which had sailed slightly farther to the east, escaped the storm. But in any case, all 11 Spanish ships were caught in the thick of it. Before the hurricane had passed, 10 of the 11 ships had sunk, most of them dashed against the reefs just offshore. The final ship managed to anchor safely, but sank the following day in another storm. At least 700 men (1,000 according to some sources—almost half the total crew) were killed. Lost and Found Treasure Over the next three years, the Spanish government sent numerous salvage vessels to recover what they could of the lost treasure; looters and pirates also flocked to the site. Conveniently, some of the ships had run aground or sunk in water so shallow that part of the hull was still visible above the waterline. Estimates as to what portion of the treasure was recovered range as high as 50%, but that’s likely a very optimistic figure: to this day, five of the ships have never been found, and only a portion of the cargo from those that were found could be recovered. By 1718, Spain gave up on any further salvage attempts, and the exact locations of the ships—which still contained many millions of dollars worth of treasure—were lost. However, for over two centuries, gold coins and other artifacts from the lost ships occasionally washed up along a portion of the Florida shore that came to be known as Treasure Coast, and the lost plate fleet remained part of local lore. In 1928, the wreckage of one of the ships was discovered by a diver just 200 yards (about 180m) offshore. Then, in the 1960s, a contractor named Kip Wagner began to search for the other ships in earnest, and eventually succeeded in rediscovering several of them—and recovering a huge amount of gold and silver. Salvage efforts (under contract with the state of Florida) are ongoing, as is the search for the remaining ships. The treasure of the 1715 plate fleet is even more valuable today than when it was lost. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/27/Spanish_Galleon.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/Plate.e6c6ba24dcb5.mp3"
	},
	{
		"title": "The Autogyro",
		"text": "t sounds like a joke: What do you get if you cross an airplane and a helicopter? But the answer isn’t “aircopter” or “heliplane,” it’s “autogyro”—or, sometimes, “gyroplane.” This peculiar type of aircraft, which was the forerunner of the modern helicopter, was once extremely well known. Although it never caught on as a widespread commercial design, the autogyro is beginning to make a comeback, especially among hobbyists and amateur aviators. An Uplifting Story First, a word or two of aeronautical review. A conventional, fixed-wing airplane gets thrust from propellers or jet engines and lift from the wings, but that lift can only be generated when the wing is moving fast enough (and, of course, in the right direction). When an airplane is moving too slowly for its wings to provide adequate lift to keep it airborne, it is said to stall, which is perfectly fine if you happen to be landing the plane, but not so good otherwise. Helicopters, on the other hand, get both thrust and lift from one or more narrow, propeller-like rotors turned by an engine. Rotor blades are thus essentially moving wings. The speed and direction of the craft’s movement are determined by the angle at which the rotor is positioned; in most helicopter designs, a vertically mounted tail rotor counteracts the main rotor’s rotation and prevents the helicopter’s body from spinning. An autogyro has a rotor much like that of a helicopter, with one crucial difference: it is unpowered. A propeller provides thrust, just as on an airplane, while the lift comes from the spinning blades of the rotor. But wait a minute—didn’t I just say that the rotor is unpowered? That’s where the “auto” part comes in. The rotor must spin to provide lift, but that spin comes from the forward motion of the entire craft. If that sounds confusing, think about maple trees. (Or elm or ash, say.) The seeds are encased in little winglike structures that twirl as they fall to the ground. Those casings are called samaras (though, in the case of maples, some botanists refer to them as schizocarps because they form in pairs that split apart). Because of the samara’s unique shape and balance, the force of the air blowing past it as it falls to the ground causes it to spin; that spinning is known as autorotation. And if you could somehow put a very tiny engine and propeller on a samara to give it some forward momentum, that would generate enough air movement to keep it spinning—and in turn, keep the whole thing aloft. That (on a somewhat larger scale) is how an autogyro works. And because the rotor is not spinning under its own power, there’s no need for a tail rotor. Autogyros tend to look rather goofy: either like airplanes with a giant rotor where wings should be, or like stunted helicopters missing their tails. They can’t fly as fast or as far as fixed-wing airplanes, and they can’t hover or maneuver like helicopters. (Some designs, however, do provide power to the rotor temporarily to facilitate a vertical or near-vertical takeoff and landing.) If those trade-offs sound like the worst of both worlds, though, consider that unlike airplanes, autogyros are virtually stall-proof, no matter how slow they’re going. If the engine gave out, the rotor would keep spinning, and the craft—if controlled carefully by the pilot—could simply float to the ground. All this does not necessarily mean that autogyros are safer than other aircraft; numerous other considerations come into play. But in certain circumstances, with proper design and a well-trained operator, they can sometimes be safer. Air Apparent A Spanish engineer named Juan de la Cierva developed a hinged rotor design in early years of the 20th century that would serve as the basis for all future rotary wing aircraft. Cierva built his first stable autogyro in 1923. After a long series of improvements, he began to license his design to aircraft manufacturers in other countries, including the U.S. Legendary pilot Amelia Earhart was quite fond of autogyros. In 1931, she set a record for highest altitude in an autogyro—18,415 feet (about 5,600 m); later that year, she was also the first person to fly an autogyro from coast to coast in the U.S. Autogyros were used for rooftop-to-rooftop urban mail delivery, and a few autogyros were even put to military use during World War II. But despite these scattered successes, the autogyro concept basically stalled by the mid-1940s, having been supplanted by fixed-wing airplanes for some applications, and helicopters for others. Cierva, ironically, died in 1936 in a plane crash. In recent years, however, small, kit-built aircraft of all kinds have increased in popularity—everything from ultralights to gliders to biplanes to mini-helicopters. And along with this trend has come a renewed interest in autogyros: they’re less complex to build and operate than helicopters, and require a lot less runway space than fixed-wing airplanes. Autogyros are also being used increasingly in law enforcement, nature observation, sightseeing, and other recreational flying. A one-person autogyro will still cost you more than most cars, but at least it’s guaranteed not to stall. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/27/Autogyro.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/Autogyro.bad7ae863f35.mp3"
	},
	{
		"title": "House of the Future",
		"text": "I've always been intrigued by alternative building methods and materials. I know, for example, that domes (of the geodesic or monolithic concrete varieties) are strong, inexpensive, and easily built, and that straw bale houses provide excellent insulation. Were I planning to build my own house, I might consider any of these options, as well as adobe, brick, stone, glass block, and good old-fashioned wood. But when I heard recently that Disneyland had once featured an all-plastic house, I just boggled. It did not amaze me in the slightest that such a structure was possible, but I couldn't get over one huge question: Why? Why in the world would anyone build a house out of such a gauche material? And who would want to live in such a house? The Plastic House When Disneyland opened in Anaheim, California in 1955, one of its most popular themed areas was Tomorrowland, where visitors could get a taste of what life would be like in the near future. At that time, commercial plastics were still new enough, and exotic enough, that they excited the public's imagination—any vision of the future must contain a great deal of these futuristic materials. One of the largest manufacturers of plastic products at that time was Monsanto, a sponsor of numerous Disneyland exhibits. The company was looking for ways to expand its markets, and at the same time gather data on the practicality and desirability of various plastics as construction materials. At Monsanto's behest, the Massachusetts Institute of Technology had spent years designing an entirely plastic house; actual construction began in 1956. When Walt Disney heard about the house, he offered to let Monsanto display it at Disneyland. After the house was finished in 1957, it began attracting crowds at the rate of about 10,000 people per day. The single-level house, whose exterior was fashioned from prefabricated fiberglass modules, looked like a giant white + sign. The center rested on a pedestal, while the four cantilevered wings “floated” above the ground. Each of the wings was a single room (master bedroom, children's bedroom, living room, and dining/family room); the center of the house contained the kitchen and a bathroom. The house's main attraction was that the building itself and virtually everything inside was manmade—the furniture, the upholstery, the carpets, the dishes, and even the clothes in the closets. (The windows were made of glass, and there were of course some metal fixtures.) Monsanto described the house as its prediction of what life would be like in 1987—an impossibly distant 30 years into the future. As such, the house naturally contained such marvels as a “revolutionary” microwave oven (which was functional). It also contained a number of non-functional mockups of devices that would surely be commonplace in 1987, such as an ultrasonic dishwasher, video intercoms, and a large, wall-mounted, flat-screen TV (missed it by that much). Because visitors could walk through the house just as a real family would, it seemed entirely believable—if one example could exist, there was no reason to believe others couldn't be made as well. And apparently, guests frequently claimed that they wanted, and would pay for, such a house. But it was merely a proof of concept; Monsanto had never intended to get into the prefab house business. What's Not to Like? According to the marketing materials Monsanto provided, the appeal of plastic was self-evident: it was durable, long-lasting, easy to clean, waterproof, impervious to rot, and so on. These claims are true enough. But Monsanto also described the house and its fixtures using words like “warmth,” “charm,” and “beauty”—as though they could will those characteristics into existence simply by stating them. Perhaps visitors really did think an all-synthetic living room could be warm and cozy 50 years ago, but I find it quite amusing that a comment like “Hardly a natural material appears in anything like its original state” was considered an enticing selling point. Far from being warm and charming, the pictures I've seen of the house strike me as sterile and soulless. But, well—that's me. By 1967, public expectation about the future had changed significantly. Some elements of the House of the Future had already become commonplace, while others seemed less and less likely. The overall shape of the house, too, had gone out of style and looked increasingly dated. So after showing the house to some 20,000,000 visitors, Disney decided to tear it down. An oft-told story, which may be apocryphal, is that the house was so indestructible that a wrecking ball bounced right off it; it took weeks to dismantle the structure by hand. If nothing else, the House of the Future epitomized the vaporware future of the 1960s—the shiny, labor-free, robot-assisted, flying-car lifestyle that, the media assured, was just around the corner. Ten years. OK, maybe 20 or even 30, but basically imminent—definitely in your lifetime. Modern visions of the future tend to be a lot more conservative, a lot grungier—in other words, a lot more like today, with maybe a bit more gadgetry. And as much as I mourn the loss of that once-imagined future, I fully expect the actual future to be full of lovely natural materials. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/27/disneyland-plastic-house.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/House.9f61f42fbe9e.mp3"
	},
	{
		"title": "The Crypt of Civilization",
		"text": "On July 4, 1976, bicentennial celebrations took place all over the United States. I was nine years old at the time, and along with my five-year-old sister, I went to a very special gathering just a few doors down from our house near Pittsburgh, Pennsylvania. A local funeral parlor, in a highly publicized event, was going to bury a time capsule (instead of a coffin) in a corner of its parking lot. Memorabilia from the community would be kept there until the capsule was unearthed, as I recall, 50 years later. Children were particularly urged to come, in order to sign a replica of the Declaration of Independence that would be included in the capsule. By the time my sister and I had made our way to the front of the crowd, the page was completely full, so someone brought out extra sheets of paper to hold the rest of the signatures. I remember being both excited to have my signature in a time capsule and annoyed that I had to sign a stupid blank piece of paper. The capsule was filled with nitrogen to preserve its contents, buried, and covered with a small monument that included a plaque explaining what was inside and when it was to be opened. On a couple of occasions since then, I've visited that monument, which is now pretty dingy and largely forgotten. And I've thought to myself: Will anyone actually remember to dig this thing up in 2026? The people who buried it will be long gone. And who knows what will have happened to that property by then? If I'm alive and I show up for the disinterment, will I have to bring my own pickaxe? And if someone does remember, will we actually learn anything interesting from those 50-year-old artifacts? Museum for the Future The idea of burying something to be found by future generations goes way, way back. But the modern notion of a time capsule didn't appear until the 20th century. The first serious attempt to preserve a large collection of information and artifacts for the distant future is also, to date, the most elaborate: the Crypt of Civilization, sealed in 1940 at Oglethorpe University in Atlanta, Georgia. The idea for the Crypt came to Oglethorpe University president Thornwell Jacobs in the 1920s, and he solidified it into a plan in 1936. Jacobs realized that the information left to us by ancient civilizations is spotty at best, and he wanted to do a favor for historians and archeologists of the future. So his idea was to collect a vast storehouse of information representing all of human history to that point—including science, technology, entertainment, and every aspect of popular culture—and consolidate it into a multimedia museum, specially preserved for millennia. While Jacobs was supervising the three-year collection process, his project got a lot of publicity, and similar (though smaller-scale) efforts began to spring up elsewhere. The Westinghouse Electric and Manufacturing Company decided to create a torpedo-shaped container of artifacts to be buried during the 1939 World's Fair (and opened 5,000 years later). They called their container a “time capsule,” and that term was soon adopted for nearly all such projects. All except the Crypt, that is—even though it was, in a way, the prototypical time capsule, its scope was so much larger that the word “capsule” wasn't appropriate. Pooling Resources In fact, the Crypt is a room that was once a swimming pool. Located on the lower level of Oglethorpe University's Phoebe Hearst Hall, it is a chamber measuring 20 feet long by 10 feet wide by 10 feet high (6 x 3 x 3 m). Because it was originally a pool, the bottoms and sides of the chamber were already waterproof. It rests on bedrock and has a thick layer of stone above it. In other words, the room will survive nearly any catastrophe outside. It underwent extensive renovations to further reinforce and seal it; and the most delicate items inside are hermetically sealed in specially designed containers. The chamber itself can be entered only through a heavy stainless steel door that was welded shut on May 25, 1940. The Crypt contains many hundreds of items, from the sublime to the mundane. Among the contents are copies of over 800 books of all kinds, stored on both microfilm and metal plates; audio recordings; newsreels; a radio; electric light fixtures; games and toys; a typewriter; plastic samples; and a container of beer—to name just a few. There are microfilm readers and projectors; the archivists also thoughtfully included a wind-powered generator in case electricity is not available when the Crypt is opened. And—my favorite part—the first thing one will see on entering the Crypt is a machine to teach basic English, so that the rest of the materials can be understood even if English is long dead. If you're thinking that sounds like the Crypt was destined to be sealed for a very long time, you're absolutely right. Most time capsules are intended to be opened in 50 or 100 years. The Crypt of Civilization, however, is not “scheduled” to be opened until 8113. This seemingly arbitrary date was 6,177 years from the time the Crypt was designed in 1936—which was, in turn, 6,177 years from the first date for which we have historical records (4241 B.C., when the Egyptian calendar began). Thus, the Crypt should contain a fairly good record of the first half of human history as of the date it's opened. Pass It On Considering how much the world has changed in the last 6,000 years, it would be foolish to assume that Hearst Hall, Oglethorpe University, or even the city of Atlanta will still be around when the Crypt is supposed to be opened. After so many generations, it would be quite surprising if someone actually knew the location and nature of the Crypt when the time came. As it is, the Crypt was all but forgotten just a few decades after it was sealed. In 1970, a student exploring an off-limits area of Hearst Hall with a flashlight came upon the mysterious sealed door. That student, Paul Hudson, later became a history professor and co-founded the International Time Capsule Society (ITCS). The organization's sole purpose is to track all the time capsules buried around the world and pass that information on to future generations, so that each one can be found and opened at the proper time. The ITCS estimates there are about 10,000 time capsules buried worldwide, most of which are “lost”—that is, no one knows the capsules' exact locations. I don't know if the bicentennial capsule with my signature in it is on their list or not; their registry is not available to the general public. This seems a bit odd to me; I'd think that the more widely information about a time capsule were disseminated, the smaller the likelihood that it would be forgotten. What happens, after all, if the ITCS fades away, or if the contact information they've compiled goes out of date (as it inevitably will)? Still, surely any effort to collect and maintain this information is better than nothing. The people who bury a time capsule—since they usually will not be the ones to open it—must rely on the goodwill of future generations to follow their instructions as to when the capsule should be unearthed. There's no authority that can ultimately prevent the people of, say, the year 3936 from opening the Crypt of Civilization if they feel like it—or if the instructions for when it should be opened have been lost. If history has shown us anything, it's that buried treasure (even if the treasure is simply knowledge) has a habit of escaping. ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/Crypt.83a794745a6f.mp3"
	},
	{
		"title": "Leap Seconds",
		"text": "There's no easy way to say this, so I'm just going to put it out there: the Earth rotates at the wrong speed. Or, rather, it usually does. You may think it takes 24 hours to go around once, but sometimes it takes about 2 milliseconds more. To be fair, the planet has been spinning at roughly its “proper” speed since about 1999, but for many years prior to that, it was consistently behind. Scientists believe that in the future, it will revert to its old ways, and probably even get worse. Although 2 milliseconds a day doesn't sound like much, it adds up to about a second every year and a half. Which means that, eventually, the world's most accurate clocks get noticeably out of sync with the observed rotation of the planet. The solution, for several decades, has been to add “leap seconds” as necessary to our official time standards so that they match what the planet is doing—although this procedure has some problems of its own. In a way, this is all a question of how you define words like “second” and “wrong.” When it comes to timekeeping, things are seldom as they appear. Just a Second… For starters, how long is a second? Obviously, it's 1/60 of a minute, which is 1/60 of an hour, which is in turn 1/24 of a day—in other words, a second is 1/86,400 of a day. Or is it? Well, it used to be. One can determine when exactly one day has elapsed by looking at the sky, but this means that all the smaller time segments could be known only after some division; they didn't have any real meaning on their own. And the precise astronomical observations needed to determine just when a day has elapsed were rather inconvenient for most scientists, let alone the rest of us. More importantly, astronomers have known since the late 18th century that the speed of the Earth's rotation is not constant—so calculating seconds, minutes, and hours strictly as fractions of a day means that each of those units could have a slightly different value every day. However, the development of atomic clocks in the 1940s and 1950s changed all that. Atomic clocks work by counting the vibrations of certain atoms, which are invariant, theoretically, forever. So in 1967, the International System of Units (SI) defined the second as 9,192,631,770 vibrations of the Cesium-133 atom. Interestingly, they did not arrive at that figure by counting the number of vibrations in 1/86,400 of a day. Instead, they based it on something called ephemeris time, in which hours, minutes, and seconds are derived not from the rotation of the Earth, but from its revolution around the sun. That speed, too, varies; scientists chose the length of the ephemeris second in 1900 as their arbitrary standard. As later research revealed, the last time a day (by ordinary, solar reckoning) was exactly 86,400 SI seconds long was in 1820. So the length of a second, as measured by the Earth's rotation, suddenly became “wrong” according to the new definition of second. No Time Like the Present We did, however, finally have a nice, consistent standard that was readily measurable on its own terms without astronomical observations. But the Earth apparently didn't get the message that it was supposed to conform to this new standard, and its rotation kept slowing, ever so slightly, with each passing year. In 1972, Coordinated Universal Time (which, for complicated reasons, goes by the initials UTC rather than CUT) was adopted as the new international standard, based on measurements from atomic clocks. (An aside: even atomic clocks don't always agree with each other; the official universal standard is based on the average times from about 250 atomic clocks.) But astronomers still needed a timekeeping system that matched what they observed—irregularities and all. To deal with the mismatch between UTC and astronomical time, the scientists charged with maintaining UTC decided that whenever that difference approached ±0.9 seconds, a “leap second” would be added to or subtracted from UTC as a correction—in other words, an occasional 61- or 59-second minute. Between 1972 and 1998, 22 such seconds were added. But then, for reasons that are not entirely clear, the planet decided to stick to an 86,400-second-a-day rotation for a while, and no leap seconds were needed for more than six years. But historical data shows that the Earth has a habit of changing its rotational speed quite frequently, and the trend over many centuries has clearly been a gradual slowing. So most experts believe that the need for leap seconds will never entirely disappear. Take a Leap On the other hand, quite a few people are fed up with the whole notion of leap seconds for reasons both philosophical and practical. For one thing, a lot of the world's clocks and computer systems were not designed to handle leap seconds elegantly. This is not usually a big deal, but sometimes, the difference of a second means everything—in financial transactions, for example, where the prices of stock, currency, or whatnot can change instantly. More importantly, if the planet's rotation continues to slow at its historical rate, leap seconds will eventually be needed more and more often. In as little as a few years, the increased disparity between UTC and other timekeeping standards could cause serious problems, including potential failure of the GPS system and other navigational tools. And on a much longer time scale—say, 50,000 years—the Earth's rotation could take 86,401 SI seconds each day, meaning we'd need to add a leap second every single day, or else redefine “second” to support the facts. So one proposal currently being considered by the world's standards committees is simply to stick with UTC but abandon the use of leap seconds altogether. That sounds easy enough, but there are some drawbacks. Doing so would make astronomers' work harder and require that they invest a lot of money in upgrading their equipment. As for the rest of us, we'd simply live with the small difference between astronomical time and atomic time until it accumulated to 60 minutes—at which point we would simply add a “leap hour,” just as most of us do once a year at the end of Daylight Saving Time. The first such hour wouldn't happen for more than four centuries, at which point it would be someone else's problem to worry about. Until the world's timekeeping experts get this all sorted out—which may be never—the International Earth Rotation and Reference Systems Service carefully measures the speed of the Earth's rotation, issuing periodic bulletins as to whether we need to add another leap second at the end of the following June or December. If and when the next leap second occurs, you probably won't notice. But many millennia in the future, your descendants may finally get 25-hour days. ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/27/Leap.ab2eca4e5a16.mp3"
	},
	{
		"title": "The Antikythera Mechanism",
		"text": "The ancient Greeks were responsible for such marvels as the catapult and the camera obscura. They invented the astrolabe, a forerunner of the sextant, which aided marine navigation by (among other things) measuring the angle between the horizon and the sun or other celestial bodies. By the end of the first century B.C., they had even invented the odometer, which measured the distance a cart or carriage traveled. So when it comes to engineering, they were no slouches. When it comes to preserving their most advanced inventions for posterity…well, that's another story. At the beginning of the 20th century, historians were shocked to learn that Greek thinkers had built a rather sophisticated analog computer in the neighborhood of 82 B.C. and then, astonishingly, left no record of its existence. Low Gear In 1900, a ship carrying Greek sponge divers was blown off course in a storm. They anchored near the small island of Antikythera, and decided that as long as they were there, they might as well dive and look for sponges. What they found instead was a shipwreck, under about 42 meters (140 feet) of water. Returning later with a navy ship, the divers recovered many artifacts from the sunken vessel, including marble and bronze statues. Archeologists who examined the pieces and other evidence reliably dated the shipwreck at around 65 B.C. (give or take 15 years). But one of the archeologists noticed that a clump of bronze contained what appeared to be gears—an astonishing discovery, since that would make it the world's oldest surviving geared mechanism. Further examination showed that the object was originally a wooden case holding about 32 bronze gears, with several dials on the outside. Over the centuries, the bronze had corroded, the wood had deteriorated, and the whole mass had accumulated heavy calcium deposits. But some inscriptions on bronze plates were still legible, and researchers began the painstaking task of reconstructing what the device must have looked like when it was made. The first thorough description of the device—based solely on visual inspection and measurements—was published in 1959. Later evaluations included crucial additional details from X-ray and gamma-ray analysis, among other techniques. Taking all the available facts into account, the prevailing theory at the moment is that the device was a clockwork-like mechanism designed to display the progress and positions of the sun, moon, and probably all five of the other planets known at the time (Mercury, Venus, Mars, Jupiter, and Saturn) over a period of 19 years. In other words: it's an analog astronomical computer. It had apparently been built several years before the shipwreck—most likely in 82 B.C. It's All About Us That's cool, but it gets even better. At the time the Antikythera mechanism was built, the Greeks still believed the entire universe revolved around the Earth. This caused tremendous problems for predicting the orbits of the planets, which from our perspective do not follow nice elliptical paths. So in order to make this mechanism account for the data, its designer had to invent entirely new arrangements of gears. One of these was the differential (a primitive version of what is found in modern cars)—which, until the discovery of the Antikythera mechanism, was believed to have been invented in the 13th century. As for the overall device, nothing similar is known to have existed until about A.D. 1000. One reason historians find all this so interesting is that previously (in the absence of any reliable evidence to the contrary), the ancient Greeks were believed to have terrific theoretical knowledge when it came to astronomy, physics, and math, but little skill in the way of practical application. Sure, there were occasional remarks about an actual device. Cicero, for example, mentioned (at about the time the Antikythera mechanism was created) a device “recently constructed by our friend Poseidonius, which at each revolution reproduces the same motions of the sun, the moon and the five planets.” But since there was no evidence of these devices, few people took such claims literally. The discovery of the Antikythera mechanism changed all that. We do not know for certain who created the device, nor do we know what its intended use was. It could conceivably have been a navigational aid, though that seems unlikely. It may have been used to create horoscopes, or as a teaching tool. It may even have been an elaborate toy designed for a rich patron. The biggest mystery surrounding the Antikythera Mechanism, though, is why and how all records of this technology disappeared. Surely this could not have been the only such device ever created. If technology this important was in use at the time, it stands to reason that there would have been many other similar devices in existence, and that some of those would have survived to this day. But not only is this the only one, it's a fluke that we even know about this one at all. What other ancient technologies may have existed that we don't know about? The answers are probably lying out there—right where you'd least expect them. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/24/antikythera.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/24/Antikythera.a52f35ac352f.mp3"
	},
	{
		"title": "The Longitude Problem",
		"text": "It's the late 1700s and you're on a ship that's lost in the middle of the ocean—nothing but water from horizon to horizon, day after day. What's your most valuable asset? Yes, of course, water and food, but I mean besides that. Would you believe…a pocket watch? Neither would some of Britain's most eminent scientists at the time, but it was indeed a watch of sorts that held the key to a maritime problem that had frustrated sailors for centuries—sometimes with deadly results—and which many people believed was simply impossible to solve. That problem was how to determine one's longitude on a ship. Turn Left at the Third Wave Nothing could be more important to a captain than knowing the ship's location, but without landmarks, this was an amazingly difficult puzzle a couple of centuries ago. There were compasses, of course, which could tell you which direction you're heading. One could judge latitude with reasonable accuracy by measuring the angle between the sun and the horizon—at least if the sun was out and the ship wasn't rocking too severely. And, by tossing a weighted rope off the ship and counting how many knots passed through one's hands in a given period of time, a rough estimate of speed could be obtained. But it's of limited value to know that you're traveling southeast at 7 knots, 50° north of the equator, if you have no idea whether you're closer to Newfoundland or Ireland. And even with rigorous recordkeeping, excellent charts, and detailed knowledge of ocean currents, the equipment available at that time made it impossible to judge east-west position with anything approaching accuracy; the sun simply can't tell you that, because the planet is rotating. There being no apparent solution to the problem, mariners simply lived with this frustration. But on a foggy day in 1707, four large British warships returning from France misjudged their longitude and ran aground on the Scilly Islands off the southwest tip of England. The ships all sank, and more than 2,000 men died. As a result, in 1714, the British government offered a huge cash prize (£20,000—equivalent to millions of pounds or dollars in today's money) to the first person who could devise a way of accurately measuring longitude at sea. It was the 18th century equivalent of the X Prize, and the nation's brightest and best set to work inventing solutions of all kinds. Ticked Off The key, as everyone realized, was being able to tell what time it is—both at one's current location and at some other point on the planet (say, Greenwich). Because the speed of the planet's rotation is known (about 15° per hour), if you know what time it is at a given longitude, you can take the time at your location, do some simple math, and end up with your position. That sounds straightforward enough, but it meant that you'd have to have with you, on a journey that may last weeks or months, a clock that accurately told you the time back home. The problem was that most clocks were extremely inaccurate—gaining or losing a minute or more each day—and even then, they were based on delicate mechanisms (such as pendulums) that would be thrown completely out of kilter on a rocking ship. A few days out of port, even if you could ascertain the time at your current location accurately (based on the sun's position), your reference clock would be worthless. In the quest to solve the timekeeping problem, the most popular approach, by far, involved star charts. The idea was that the relationship between the moon and various stars was unique for each time of each day, so if you could make careful observations at night and correlate those observations with a set of tables, you could tell with precision what time it is—or was, a few hours ago, when you began making your calculations. Apart from the difficulty of cataloging all that data usefully, though, this approach assumed that the observer would have clear skies and a steady observation point—both difficult to guarantee on the high seas. Time for a Solution Meanwhile, an unknown clock maker named John Harrison was busy on a completely different approach: constructing a clock that was far more accurate than any available at the time and able to maintain that accuracy even after weeks of being tossed around on a ship. In the course of his experiments, Harrison came up with many innovative technologies that have since found their way into not only clocks but a variety of other machines, such as the caged roller bearing and a bimetallic pendulum to compensate for temperature changes. But putting them all together into the perfect clock was a very long process. His first prototype, which he called H1, took five years to build. It was, at the time, possibly the most accurate timekeeping device in existence, but still not good enough to win Harrison the prize. Over the next 20 years or so, Harrison worked on improved designs—H2 and H3—but abandoned each when he realized it would not ultimately work. However, while working on H3, Harrison had asked another watchmaker to build him a pocket watch to his specifications. Although pocket watches were not taken seriously at the time, Harrison's design turned out to be fantastically accurate. This convinced him that his next step, H4, should be based on the design of a pocket watch rather than on a larger clock mechanism. Harrison finally completed H4 in 1759 at age 66. It looked like an oversized pocket watch, with a diameter of 13cm (about 5 inches). Two years later, in 1761, Harrison's son, William, took H4 on its official transatlantic trial. The clock performed flawlessly (and well within the range stipulated for the prize). But the judges on the Board of Longitude—which included Isaac Newton—were convinced that no mechanical device could ever solve the longitude problem. So this success, they concluded, must have been a fluke. They demanded (and got) a second trial, which showed similar accuracy but still didn't convince the Board. Eventually Parliament took up the matter, and agreed to give Harrison and his son half the prize money, with the other half to be delivered if other watchmakers could duplicate his design and produce the same results. Three years later, William, frustrated by the Board's continued heel dragging, appealed to King George III, who tested H4 himself. He found it as accurate as had been claimed and, outraged that the Board had kept Harrison's rightful winnings from him, threatened to appear personally before Parliament if they didn't hand over the rest of the prize money. In 1773, at age 80 and after more than 40 years of work, Harrison finally received both the prize money and the recognition of having solved the longitude problem. He died three years later, on his 83rd birthday. Today, sailors no longer need to carry an oversized pocket watch or check the angle of the sun to determine their position. But even our highest-tech navigation devices, such as GPS receivers, ultimately rely on extraordinarily accurate timekeeping. So Harrison's solution has truly stood the test of time. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/24/watch.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/24/Longitude.c8e0ea03067f.mp3"
	},
	{
		"title": "Clepsydras",
		"text": "If you look up the term water clock in a certain online dictionary (which will remain nameless, though you can find it easily enough), you will find that the definition, in its entirety, is “A clepsydra.” (And you thought lexicographers didn't have a sense of humor.) I'd like to be at least slightly more helpful here by telling you a bit about one of the oldest devices for measuring time. Of course, units of measure like seconds, minutes, and hours are a mere arbitrary fiction. Days, years, seasons, and perhaps months (at least lunar months) correspond to easily observed natural phenomena, but any unit shorter than a day is a pure human invention. Had history unwound differently, a second might be shorter or longer than it is now, or we might have divided the day into, say, 537 bligrots. The specific choices our distant ancestors made are, in the grand scheme of things, not nearly as important as the mere fact that they figured out a way to quantify time, repeatably and fairly accurately. It is incalculably important that we be able to determine such things as how long a lawyer should be allowed to speak, whether the athlete who won the race today went faster than the athlete who won yesterday, or when lunch begins. Fire and Water The earliest clocks, which relied on the sun, proved problematic for a number of reasons—the sun was visible for a different amount of time from one day to the next; timekeeping could not take place indoors, at night, or when it was cloudy; and even with a sundial, it was quite difficult to determine the sun's position accurately. The first attempts to keep time without the sun were water clocks—any of a large number of designs that have in common a dependence on the steady flow of water. The simplest water clock design, known as an outflow water clock, was basically a stone or earthenware container with a small hole in the bottom and graduated markings on the inside. As water dripped out (at a more or less constant rate), the water level dropped, revealing successive hour markings. Inflow designs used two containers: one to dispense the water and another, into which the water dripped, to measure it (additively rather than subtractively). Some sources credit the Chinese for inventing water clocks as early as 3000 B.C. ; others say water clocks appeared much later in China and that it was the Egyptians, around 1500 B.C., who first came up with the idea. In any case, water clock designs certainly developed independently in more than one place. We do know that the Egyptian design had made its way to Greece by 325 B.C., where it was given the name clepsydra, which means “water thief.” Good to the Last Drop Although even primitive clepsydras were sometimes more accurate than watching the sun, they were still notoriously irregular, because the water had the annoying tendency to drip out more slowly as its level sank. To compensate for this, some Egyptian designs tapered the container in toward the bottom. A further refinement added by the Greeks was a float regulator—a valve that let more water into the tank only when it sank below a predetermined level, thus maintaining a constant water pressure and keeping the rate of flow quite regular. (This makes the water clock the forerunner of the water closet, if you think about it.) Later modifications included a second float—this one in the receiving container—which was attached to a pointer; this made reading the time, especially from a distance, much easier. More elaborate still were designs that used floats to strike a bell or make some visual signal at given water levels. But even these designs pale in comparison to a clepsydra built in China by Su Sung in the early 11th century. Su Sung's clock was over 30 feet (9m) high and used a primitive escapement mechanism, a bit like what would later appear in mechanical clocks and watches. But instead of being powered by a spring or weights, it was powered by water. This clock displayed not only the time but the positions of the planets, and included a number of animated figures ringing bells at various times. No matter how many bells and whistles a water clock has, though, you still have a couple of problems. For one thing, the flow of water will never be truly precise over a long period of time. For another, you're fighting evaporation. And the rate at which the clock runs can be influenced by temperature, humidity, barometric pressure, and many other variables. The best water clocks were accurate to within about 15 minutes per day—not too shabby for thousands of years ago, but a bit less than what we need today. Even so, the wonderful thing about a clepsydra is that even a child can make one out of scrap containers found in the recycling bin—it's a refreshingly low-tech solution to one of humanity's oldest problems ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/07/Clepsydras.1dce288e956a.mp3"
	},
	{
		"title": "Safety Coffins",
		"text": "Among the many urban myths circulating on the internet is a document called “Life in the 1500s” that began as an anonymous email message and has since found its way onto countless Web sites that took it as legitimate history. Among other things, this list of alleged facts about Renaissance life purports to give the origins of numerous English expressions, such as “raining cats and dogs,” “chew the fat,” and “dead ringer.” Unfortunately, although there are a few kernels of truth in the message, most of it is completely false. Whether it was an intentional hoax or merely the product of someone with a good imagination and poor research skills, it has misled a lot of people into mistaken etymological beliefs. Take, for example, the claim that in the 1500s, people were often unintentionally buried alive—as evidenced by scratch marks on the insides of coffins that were later exhumed for some reason. On hearing such stories, public fear of being buried alive allegedly resulted in a new method of burial, in which a string was tied to the wrist of the departed and fed through a hole in the coffin all the way to the surface, where it attached to a bell. Were the person to awaken, the slightest arm movement would ring the bell, alerting someone to dig them up. Hence—so the tale goes—the origin of the expressions “saved by the bell” and “dead ringer.” That's a lovely and plausible-sounding story, but it happens to be untrue. The expressions “saved by the bell” and “dead ringer” had entirely different origins (about which more in a moment). And the whole business of coffins being designed with warning bells? That was certainly not part of life in the 1500s. Not at all. Not even close. It didn't happen until the 1800s. The Living Dead Even today, the criteria for determining that someone is dead are not entirely unambiguous. If someone is missing a heart or brain, the diagnosis is relatively straightforward. But there are any number of circumstances under which someone's pulse and breathing may be indiscernible—or even entirely absent—and yet death has not occurred. Even the absence of brain waves is not always an uncontroversial sign of death. A variety of medical conditions, or perhaps even a deep trance, can render someone cold, motionless, and unresponsive for some period of time. Occasionally you may see stories in the news about people who wake up in a body bag, a morgue, or even a funeral parlor, having been incorrectly pronounced dead. It doesn't happen often, but it happens. A few centuries ago, when medical science was much less advanced than it is today, this sort of thing happened considerably more often. History is littered with stories of such occurrences—sometimes with happy endings, but usually not. There have even been cases where coffins were found to have scratch marks inside, and though this is not necessarily proof that the person was buried alive, that surely did happen from time to time, especially considering that in the days before embalming became common, burials tended to happen quite soon after death. During the Victorian age (roughly the second half of the 19th century), there was, for whatever reason, an unusual amount of public anxiety about the possibility of being buried alive—in England, continental Europe, and even the United States. Edgar Allan Poe tapped into (and exacerbated) this anxiety with a few of his short stories: “The Black Cat” in 1843, “The Cask of Amontillado” in 1846, and “The Premature Burial” in 1850. Give Me a Sign Such anxiety is not unique to that time period, but that was when a flurry of inventors set out to solve the problem. Patent records from the period show many designs for so-called safety coffins. Some designs merely contained a signaling apparatus of some kind—and yes, a few of them actually did use a bell with a string fed through a tube into the coffin. Other designs were more elaborate, with motion from the body raising a flag, sending a telegraphic signal, or even shooting off fireworks. There were also some coffins with escape hatches or spring-loaded release mechanisms, though the latter would have been useful only before burial. A few of the later designs included air inlets that would open if, and only if, the alarm was actually triggered. This was—excuse the expression—a fatal flaw. A full coffin holds very little air; without even taking into account the exertion of calling out for help or pushing on the lid, an average (healthy) person would pass out within an hour or two after a coffin was sealed, and expire shortly thereafter. However, that detail was apparently a moot point. Although some of the safety coffins were in fact manufactured and sold, there is no record from that time period of anyone having been buried in one. And thus, there are also no records of one of these inventions actually saving someone's life. But still the meme persists. Even within the last decade, there have been several news stories about high-tech safety coffins offered for sale—some of which even include a bottle of oxygen, just in case. So what about the aforementioned phrases? Well, “saved by the bell” is easy enough: it's a boxing term, first used in the 1930s. It refers to a boxer who gets a (sometimes temporary) break from being pummeled when the bell rings to signal the end of the round. “Dead ringer” is a bit trickier—though a moment's reflection will show that it has nothing to do with being buried alive; it refers to a “double,” someone or something that looks just like someone or something else. The “dead” part gives an expression a sense of exactness or completeness, as in “dead even” or “dead wrong.” As for “ringer,” it's a slang term for a fake or an illicit substitute (as in a sporting competition). My dictionary says this meaning goes back to the 15th century. I've read elsewhere that it derives from “ring the changes,” which originally meant to ring a set of church bells in a variety of different sequences, and later took on a metaphorical meaning of varying the way one performs any action. In any case, it clearly predates the use of safety coffins. As for that story about life in the 1500s…some bad ideas just refuse to die. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/07/coffin.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/07/Safety.f3b2ff524b50.mp3"
	},
	{
		"title": "Mail Recovery Centers",
		"text": "Mail used to be one of my favorite things in the world. I was always excited to see what might be in the mailbox today: a letter from one of my many correspondents, a magazine, a check, photos I'd sent out for processing, a gift from a friend or relative, a catalog full of interesting things, or a package containing one of the interesting things I'd ordered from the catalog. Some days I got nothing, and many days I got only bills or junk mail. But the tiny thrill of finding something interesting in my mailbox was always something to look forward to. Times have changed. Although the U.S. Postal Service is still doing brisk business and is in no imminent danger of disappearing due to lack of interest, my own personal love affair with mail has faded. I still have lots of correspondents, but we communicate electronically. I receive and pay most of my bills online too. Photos, of course, go straight from my camera to a Web site or printer. And the whole notion of “mail order” seems quaintly anachronistic, even though the mail carrier is sometimes the person who delivers the stuff I order online. Yes, I do still subscribe to some paper magazines and get the occasional check or letter in the mail, but for the most part, the spark is gone. Addressing Concerns The other day, though, I was in a library looking at a book from the early 1900s in which there happened to be an extensive discussion of the Dead Letter Office. All at once, childhood memories came racing back: stern warnings from teachers to address mail properly, always include a return address, and, when sending a package, put an extra copy of the address inside. Were we not to do these things, the grown-ups cautioned us, our mail may end up in this mysterious and spooky room where it would, so we were led to believe, be unrecoverable for all eternity. And I remembered fantasizing about visiting that sacred vault, wherever it may be, wondering what incredible treasures I might find among its misaddressed envelopes and parcels. The century-old book provided a rather more prosaic description of how the Dead Letter Office had functioned at that time. And that got me thinking: is there still such a thing today? Where do letters really go when they die? The answer, surprisingly enough, is St. Paul, Minnesota. Or Atlanta. In these two cities, the U.S. Postal Service operates large facilities called Mail Recovery Centers (MRCs), as “dead letter offices” have been known officially since 1992. (Formerly, there was also an MRC here in San Francisco.) The Post Office established the first dead letter office in 1825; from then until 1917, all undeliverable mail was sent to a single, central location in Washington, D.C.. But given the staggering number of such items—now on the order of 80 million per year—it made more sense to decentralize the effort somewhat. Bring Out Your Dead (Letters) Items arrive at the nearest MRC when they can be neither delivered nor returned—meaning both the recipient's address and the sender's address are incorrect, illegible, or missing. There, the pieces follow one of two paths—one for letters, one for parcels. Letters are scanned by machine for currency, checks, or other items of obvious value. If such enclosures are discovered, the envelopes are opened and examined. (Incidentally, Mail Recovery Center clerks are the only people who can legally open someone else's mail—for everyone else, it would be a federal offense.) The Post Office makes an effort to locate either the sender or the recipient, using any clues available in the letter itself; if successful, they return the valuables. The rest of the letters are unceremoniously shredded—love letters, poems, manifestos, everything. Packages are a bit different: every one must be opened and inspected by hand. Again, postal workers look for an enclosed address or some other kind of clue—a name, a phone number, or anything they can use to discover the item's rightful owner. If they do find the owner, which happens about a quarter of the time, they normally forward the item without charge. If not, the contents of the package are stored for at least 90 days, in case someone files a claim. Unclaimed items left longer than that are either given away to charities or sold at auction. At these auctions, which take place in either St. Paul or Atlanta every few weeks, bargain-hunters can bid on large lots of merchandise—the quantity is simply too great to auction each item individually. Income from the auctions pays for just a portion of the MRCs' operating expenses, which are considerable: the facilities employ more than 200 full-time staff people in all. Although a great many of the items that arrive in MRCs are truly dead, the purpose of the facilities is in fact to resurrect as many as possible—they're really undead letter offices. MRC employees have found an astonishing variety of items—not only common items like books and CDs but jewelry, computers, live animals, drugs, guns, human remains, and everything else imaginable. And, from all accounts, they find it quite rewarding to reunite lost belongings with their owners. It sounds like the perfect job for someone who still loves getting surprises in the mail. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/07/envelope.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/07/mail.b2a0e2440b35.mp3"
	},
	{
		"title": "The Voynich Manuscript",
		"text": "Twenty-odd years ago, a friend of mine named Eddie spent about 10 minutes creating a simple substitution cipher, and handed me a little key to memorize—each letter of the alphabet represented by some other letter, number or symbol. I still remember most of that cipher, which we used to pass each other countless notes during boring classes, and if I happened upon one of those notes today, I have no doubt that I could read it easily. We weren’t planning a conspiracy or pondering the mysteries of the universe, we just wanted to be sure that if one of our messages fell into the wrong hands, we wouldn’t get in trouble for making fun of the teacher or admitting we hadn’t done our homework. About four centuries earlier, someone developed a rather more sophisticated code and hand-wrote approximately 240 pages of it using a quill pen on vellum—complete with colorful illustrations of plants, stars, naked women, and other assorted figures. Whatever this book is, it clearly required an extraordinary amount of time, effort, and care. It also, very likely, made its author quite wealthy. And yet, to this day, no one knows for sure who wrote it, what it says, what language it’s in, or whether it really says anything at all. Linguists, historians, and cryptographers have spent many decades poring over it and subjecting it to every conceivable form of analysis, only to reveal that there are more questions than answers. This text, known as the Voynich manuscript, is one of the last great unsolved cryptographic puzzles. Book of Mysteries Wilfrid Voynich, an American antique book dealer, discovered the manuscript in 1912 in the library of a Jesuit college in Frascati, Italy. Believing it to be extremely valuable, he purchased it and brought it back with him to the United States. The text itself is written in a completely unique script, which suggests that it’s a cipher of some kind. The characters, which are presumably letters, do not correspond to any known alphabet. They are separated into groups that appear to be words, but lack any punctuation. The book as a whole is divided into several sections, each with distinctive drawings and other individuating features. A cover letter inserted in the manuscript, written by one of its owners around 1666, claims that Roman Emperor Rudolph II had originally purchased the book for a sum equivalent to tens of thousands of dollars in today’s currency, and that Rudolph believed it to have been written by the 13th century English Franciscan friar Roger Bacon. The letter does not say, however, from whom Rudolph acquired the manuscript. Voynich himself apparently believed Bacon to have been the author, and enlisted the aid of the nation’s top cryptographers to decipher it. Over the next several decades, as one expert after another weighed in on the text, several interesting findings emerged. Bacon’s authorship was disproved fairly decisively, and most estimates put the manuscript’s creation somewhere between the mid-15th century and the mid-16th century. Analysis of the text showed many patterns typical of natural language, though it clearly is not a simple cipher of English, Latin, German, or any other European language. On the other hand, some features of the text, such as the range of word lengths and the frequency with which some words are repeated, seem remarkably unlike any known language. Much Ado about Nothing? Some researchers have suggested that the text is an attempt to transcribe a Chinese dialect. Others say it’s a representation of Hebrew. Still others believe it’s an exquisitely coded message in some Romance language. And then, predictably, there are those who say it’s the language of angels—or maybe aliens. In any case, no credible translation of the text has appeared, despite many attempts. The illustrations in the Voynich manuscript—which, I should add, are mostly rather crude drawings—suggest that it covers such topics as botany, cosmology, and pharmacology. There are some indications that it may be an alchemical or mystical text, too, though this is largely speculative. The biggest question facing researchers is whether the text is about anything at all. The fact that the manuscript has resisted all efforts at decoding has led many people to suspect that it’s not a code at all—it’s simply nonsense, very cleverly disguised as language. In 2003, Gordon Rugg, a professor of Computer Science at Keele University, demonstrated that using a simple device called a Cardan grille, someone could have formed words from a fixed set of prefixes, roots, and suffixes that exhibit language-like patterns similar to those in the Voynich manuscript. In other words, it could have been a hoax—and if so, Rugg thinks the most likely culprit is Edward Kelley, a 16th-century English spiritualist who believed in alchemy and was known to be a forger. Although Rugg’s work is interesting, it’s far from definitive. It proves only that the manuscript could be a hoax—and even if it is, that doesn’t eliminate the possibility that there is actual coded text hidden within it somewhere. And according to some researchers, at least, Rugg’s solution does not account for some of the important features of the text. In any case, if the manuscript is actually gibberish, there would be no way to prove that with complete certainty. Now, I’m not saying the manuscript isn’t a hoax. In fact, I lean toward the opinion that it is. But what troubles me is the lack of clarity about what it was supposed to be a hoax of. Presumably, if someone spent months creating the manuscript with the expectation of selling it for a small fortune, the forger must have had a compelling story to tell the prospective buyer about the document. Was it represented as being a recipe for eternal youth, a treasure map, a message from aliens, or what? No one seems to know for sure, and the answer may never be found. All I can say is that if I saw an old page full of incomprehensible ciphered text and doodles of naked women, I’d immediately assume I was looking at a high school student’s notebook. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/07/Voynich.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/07/Voynich.3696ce89dbe7.mp3"
	},
	{
		"title": "Murano Glass",
		"text": "Several years ago, on our first trip to Europe, Morgen and I tried very hard to visit as many sites as possible on our “must-see” list, which meant very short stops and lots of travel time. Venice was one of those obligatory stops, and we were both very sad to leave after only a few days, during which we had managed to see just a tiny sliver of the city. I was impressed by the canals, the architecture, the churches, the museums, and the omnipresent music (everywhere we turned, some little chamber orchestra was playing Vivaldi)—as well as the friendly and accommodating locals. We had no real plan other than to wander around and see what there was to see—which was a shame, because with a bit more foresight we might have planned a visit to nearby Murano, the suburb responsible for keeping Venice’s finest gift shops stocked. The Spittin' Image Murano is a cluster of five small, closely spaced islands in the Venetian lagoon, less than 2 miles (about 3km) north of the city of Venice. Murano’s islands, like those of Venice, are linked by bridges and separated by canals; in fact, nearly everything about the town seems to be an extension of its much larger neighbor nearby. That in itself makes Murano an interesting and picturesque place, but it’s best known for its legendary glass craftsmen. Glassmaking in Venice dates back to at least the 10th century A.D., and possibly as early as the 5th century. But by the late 1200s, the production of glass objects was the city’s major industry. Not only did Venetians produce lots of glass, they made glass of the very finest quality. And the city’s leaders went to great lengths to protect the profitability of this industry and ensure the city’s dominance in the glass trade. A 1271 law prohibited the importation of foreign glass or the employment of foreign glassworkers. In 1291, yet another law required that all furnaces used for glassmaking be moved out of Venice proper and onto the islands of Murano. The usual reason given for this move was to minimize the danger of fire, as the city’s buildings were mostly wood. But a more likely explanation was a desire to keep the city’s glass craftsmen sequestered in a single, more easily monitored location where trade secrets could be prevented from finding their way into the wrong hands. This theory is borne out by the 1295 edict that Venetian glassmakers may not leave the city; those who attempted to leave were threatened with grievous bodily harm. On the other hand, people who worked in the glass trade were at least rewarded handsomely for their efforts. The Venetian government accorded the artisans special social and legal privileges that gave them status rivaling that of the moneyed aristocracy. This carrot-and-stick motivation worked, and glassmakers passed on their secrets to their offspring for generation after generation—giving Venice a near-monopoly in quality glass products throughout Europe that lasted for centuries. Murano glassmakers traditionally created pieces that were primarily functional rather than decorative—but with such skill and artistry that the distinction often blurred. Though they were best known for their blown glass work, they also had special expertise in making mirrors and developed a number of innovative techniques, particularly involving colored glass. Refilling the Glass By the 17th century, though, Murano began to lose its mojo. A combination of political changes in Venice and technological advances elsewhere resulted in greater competitive pressure, and the Murano glass trade waned, nearly to the point of extinction. In the mid-1800s, Murano glassmaking underwent a renaissance—thanks in large part to the efforts of Antonio Salviati, a businessman who specialized in selling the glass tiles used to refurbish Venice’s many mosaics. This trend was later boosted by the tourist industry, which has kept Murano’s glassmakers busy ever since. Today, Murano glassmakers produce stunningly elaborate art pieces that sell for outrageous sums, as well as smaller decorative articles, including jewelry. But although these are the flashiest products, Murano factories also turn out mirrors, lenses, glassware, and other conventional glass items. In a town legendary for its artwork, Murano glass is the clear leader. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/07/murano_glass_vase.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/07/Murano.9b1c9e16a517.mp3"
	},
	{
		"title": "Weather Station Kurt",
		"text": "My “geek” gene has manifested itself in many different ways over the years—I've gone through phases of obsessions with gadgets of many kinds. My latest interest is cooking gadgets, but before that it was computers; before that, synthesizers; and still earlier, photographic equipment—going all the way back to Erector Sets. And somewhere along the way, in my early teens or so, I had a brief flirtation with meteorological equipment. I received a home weather station kit as a gift one year and set about building my own barometer, sling hygrometer, anemometer, and weather vane. The latter two devices, once assembled, had to be mounted on the roof and wired up to an indoor readout to display wind speed and direction, but for some reason that never happened. Since those were also the geekiest of the gadgets, my inability to use them quickly shut down my interest in the whole subject. The equipment I'd built lay unused in a closet for years before I finally threw it out. Around that same time (this would have been the early 1980s), a similar collection of equipment was found in a secluded location on the east coast of Canada. It, too, had been abandoned for years. But in this case, it had been built and installed secretly by the German military nearly 40 years earlier as part of an elaborate remote weather-forecasting system in the North Atlantic. Winds of War During World War II, German submarines, known as U-boats, kept very busy blowing up allied ships in the Atlantic—particularly those bound for Europe with supplies from North America. The U-boats' operations had to be planned carefully and were in part dependent on weather conditions. In order to get the best data about weather systems approaching from the west, the Nazis devised an elaborate network of 21 automated weather stations that were to be installed in secret locations all across the North Atlantic, from Norway to Greenland to Canada. The stations, designed by Siemens (a German company that still makes electronics and appliances), collected readings of temperature, humidity, barometric pressure, wind direction, and wind velocity. They translated this data into Morse code and broadcast it, every few hours or so, via shortwave. The stations were powered by large banks of batteries that were expected to last about three months. Bearing in mind that this was long before the advent of digital computers, I can't help but be impressed at the clever engineering that went into these stations, their purpose notwithstanding. Two of the stations were destined for Canada. One of these was station WFL-26, code-named “Kurt.” On October 22, 1943, U-537 arrived in Martin Bay, Labrador. Its crew waited for fog to set in, and then surfaced and quickly ferried 10 large canisters full of parts to shore. On a hill about 300 meters inland, they set up the equipment, which had been labeled as property of the nonexistent “Canadian Weather Service.” They even left empty American cigarette packages lying around to further divert suspicion. Less than 24 hours later, after confirming that the station was broadcasting correctly, the U-boat snuck away. (The sub carrying the second weather station to Labrador the following year was sunk before it reached its destination.) Unreliable Predictions Soon after U-537 departed, however, something went wrong with Kurt. According to some reports, the station went mysteriously silent after a few days, or perhaps as long as two weeks. Other reports say the station continued to broadcast, but that its transmissions were jammed. Intriguingly, the Americans and Canadians apparently never picked up any of the signals, so the culprit may actually have been a German jamming station. In any case, the Germans got little if any useful data from the station, and having been known to very few people in the first place, it was soon forgotten. In 1980, a retired engineer from Siemens named Franz Selinger was working on a history of the German weather service. He knew of the existence of the automated weather stations, but could not determine where Kurt had been installed or what had become of it. After extensive research, he determined that it must have been set up in Labrador, so he contacted the Canadian authorities for assistance. In 1981, Selinger, with the help of the Canadian Coast Guard, located the remains of the weather station. Although some of the equipment had disappeared, the parts remaining had clearly belonged to Kurt. The station's career had been brief, but it succeeded in staying a secret for almost four decades. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/07/Weather_Station_Kurt.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/07/Kurt.82e3c168fb02.mp3"
	},
	{
		"title": "The Oak Island Mystery",
		"text": "Canada's maritime provinces may not be the first place you think of when you hear the words “buried treasure,” but for over 200 years, treasure hunters have had their eyes on tiny Oak Island in Mahone Bay, Nova Scotia. Over the years, millions of dollars have been spent—and at least six lives lost—in repeated attempts to excavate one of the world's most infamous alleged treasure sites. What could be worth so much effort? Possibly an enormous cache of gold and silver, ancient manuscripts, or…nothing at all. Can You Dig It? The story begins in 1795, when a boy was wandering around on the island and found a curious depression in the ground. Right above this depression was an old tackle block hanging from the limb of a large oak tree, as though someone had used it to lower something heavy into a hole. Having heard stories about pirates frequenting the area in centuries past, the boy immediately suspected buried treasure. He returned the following day with two friends and began digging. A few feet down, the boys found a layer of flagstones; 10 feet below that was a wooden platform. Both of these markers strongly suggested the hole was man-made. They kept going, but by the time they reached 30 feet, they realized there was no end in sight and called it quits. Several years later, having secured some financing and additional help, they returned, this time digging to more than 90 feet—hitting several additional wooden platforms on the way down. At 90 feet they found a stone inscribed with strange symbols they could not decipher. (Later, some would claim that the symbols were a cipher for “Forty feet below two million pounds are buried,” but that stone was soon, conveniently, lost.) Just below that was a layer of mud. Probing down into the mud with a crowbar, they hit another solid surface—perhaps another wooden platform, or perhaps a treasure vault. But when they returned the next day, the shaft had filled with 60 feet of water, which foiled all attempts at bailing. Shortly thereafter, they tried to dig a parallel shaft, thinking they'd get below the treasure and tunnel in horizontally—but this second shaft filled with water as well. The first crew of treasure hunters abandoned their dig. In 1849, a second group attempted an excavation. Then another, and another, and another. Each time, treasure hunters made some intriguing discovery, but each time, their attempts to go deeper were frustrated—by flooding, cave-ins, accidental deaths, and other misfortunes. On several occasions, workers attempted to drill into the earth beneath the water that filled the pit, and the drills brought up some interesting fragments—a piece of gold chain here, some wood there…and a small scrap of parchment that had one or two letters written on it. The evidence suggested that below more layers of earth and wood was an empty space—a vault containing chests, perhaps with gold coins inside. But these were just educated guesses, because no one could actually get down to them. Some attempts to widen or deepen the hole—or to get at the treasure indirectly through other holes—caused whatever the drill bits had hit to sink even farther down. The diggers eventually realized that the flooding was due to two or more horizontal tunnels that ran to the shore, and had seemingly been dug as booby traps. Unfortunately, repeated attempts to block those tunnels also failed. By the early 20th century, so many large holes had been created that the original location of the so-called money pit was no longer certain. Excavations using modern equipment in the 1930s enlarged the main hole greatly, but still nothing of value was found. In the decades since, various groups have made additional attempts to unearth the treasure, digging ever larger and deeper holes, but always coming up empty. And now a new series of complications has arisen: legal disputes about the ownership of the land, and the rights to any treasure that may be buried there, have hindered large-scale recovery attempts. To this day, no one knows for certain what—if anything—is buried under Oak Island. At least, if they do, they're not saying…or digging. Getting to the Bottom of It Over the centuries, dozens of theories have been advanced as to what the Oak Island treasure really is. One popular theory holds that it's Captain Kidd's fortune—or that of some other pirate. Another says it's the lost treasure of the Knights Templar. Some say (based apparently on that one tiny piece of parchment) that it's Shakespeare's original manuscripts. Others say it must be the Holy Grail. Although proponents of each of these theories make persuasive arguments as to why they must be correct, a recurring theme is that any treasure hidden so carefully and protected so elaborately as to defy two centuries' worth of determined treasure hunters must be unfathomably important. Except that it apparently wasn't important enough for whoever hid it to come back for it—or pass on information of its whereabouts to anyone else. And that assumes there's something hidden there in the first place. There might not be. There is some evidence to suggest that the original “pit,” as well as the tunnels that fed water into it, were actually natural formations, and that the wooden “platforms” found at various points were nothing more than dead trees that had fallen into a hole once upon a time. What of the tackle block? And the gold chain? And the parchment? And the stone with the mysterious message? Well, all these artifacts have disappeared, and even if someone produced them, it would be impossible to prove they came from the pit. They could have been planted; they could also have been imagined. At no point in the last 200 years was work on the site controlled or documented carefully as an archeological dig would have been. All we truly have are the reports of people who wanted desperately to believe they were about to find a fabulous treasure. Perhaps some day, when the legal disputes have been settled and the best technology has been brought to bear on the problem, the Oak Island Mystery will be resolved once and for all. Whoever discovers the definitive answer—even if that answer is that the whole thing was an elaborate 18th-century hoax—will have the real treasure: a very rare bit of knowledge. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/07/Oak_Island.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/07/Oak_Island.ec25c3138c9f.mp3"
	},
	{
		"title": "St. Patrick",
		"text": "Many years ago, I read the following provocative statement in a trivia book: “St. Patrick was neither Irish nor Catholic.” Although, as in most trivia books, these claims came with no historical references to back them up, they sounded plausible. I had no particular reason not to believe the book, and I tucked these tidbits away in my brain's “interesting facts to investigate one of these days” file. I've been digging into that file a lot lately, and this seemed to be an appropriate time to get to the bottom of who St. Patrick really was—and which of the numerous and contradictory stories about him have some basis in truth. Not being Catholic myself, I never learned even the very basic facts (or legends) about most of the saints—information that, I recognize, is common knowledge to a large segment of the population. On St. Patrick's Day, all I ever managed to deduce was that we were all wearing green because that had something to do with Ireland; any information about the historical St. Patrick was not part of my secular experience of the holiday. I didn't even know that he was supposed to have expelled all the snakes from Ireland—after all, I'd never seen a snake on a St. Patrick's Day card. As I read up on St. Patrick, Guinness in hand, I discovered that one of the most interesting things about this man is how little one can know for certain. The Mists of History Confusion starts at the very beginning: Patrick's birth. We can say with confidence only that he was born in the late 4th century or early 5th century; most accounts put the date between A.D. 385 and 389, though some say it was much later. At any rate, it wasn't even “Patrick” who was born then. His given name at birth was—according to some sources, at least—Maewyn Succat, and he apparently took on the name Patrick as an adult, when he began his work for the Church. As for Patrick's place of birth, again, this is a matter of some disagreement. In one of his writings, Patrick referred to his birthplace as “Bannavem of Taburnia,” but no one knows for certain exactly where this village may have been. Sites in Scotland, Wales, England, and even the north coast of France have been advanced as possible matches. Patrick's parents were likely Christians of some variety, though apparently not terribly devout, and Patrick may have considered himself a pagan as a child. We do know that when Patrick was a teenager, he was captured by pagan raiders and taken to Ireland, where he was sold as a slave to a Druid chieftain. During his captivity, his Christian faith apparently blossomed. He remained a slave until roughly age 22, when he somehow managed to escape and return to Britain. Patrick began studying for the priesthood, and in either 432 or 462, after he was ordained, he returned to Ireland—this time as a missionary. He was not, as is often assumed, the first Christian missionary to Ireland, but he was among the first—perhaps the third. It was during this time that the most colorful of Patrick's exploits allegedly occurred. The best-known of these, of course, was that Patrick, by the force of his prayers, banished all the snakes from the island. Ireland likely never had any snakes in the first place; the story may have evolved from a symbolic association of snakes or serpents with non-Christian religious beliefs. In any event, there is no evidence whatsoever that this actually happened, nor does the Catholic church claim that it did. Green Without Envy Legend also has it that Patrick taught the Irish pagans about the concept of the Trinity using a shamrock as a visual aid. This story is almost certainly apocryphal, meaning the whole association of the shamrock with St. Patrick's Day is based on a mistake. But in fact, it gets worse: because the shamrock is green and was traditionally worn as a symbol of St. Patrick, the color green itself eventually took on the same meaning. As it turns out, though, the color blue was originally assigned to St. Patrick, and for centuries, Irish superstition held that wearing green was unlucky. Patrick is, however, credited with inventing the Celtic cross; he felt that by superimposing the pagan symbol of the sun on a cross, he could make it more appealing to the Irish people he was trying to convert. So what about that claim that St. Patrick was not Catholic? Well, the Catholic church clearly believes he was, but some Protestant commentators claim he was not. Among the reasons for these claims are statements from Patrick's writings that indicate he practiced, and preached, a fairly simple version of Christianity in Ireland—seemingly not a fully Romanized version. There is also some doubt about his parents' status in the Church, and a suggestion that only centuries after his death did Rome decide to absorb his story into official Church history. On the other hand, there is substantial evidence that Patrick was indeed ordained as a priest in the Roman church before beginning his missionary work. But the bottom line is that reliable written records from that period are few and far between. The true nature of St. Patrick's religious convictions, like so much else about his life, will probably never be known with complete certainty. Even the date of Patrick's death is in doubt. It has been reported variously as occurring in the years 462, 491, 492, or 493. However, tradition has it that in whichever of these years Patrick died, it was on March 17—which is why the Feast of St. Patrick, or St. Patrick's Day, is celebrated then. On this day, as I don my green—or blue—shirt, I will think fondly about the patron saint of Ireland, who was not Irish, who may or may not have been Catholic, and who was almost definitely, at some point during the indeterminate years of his life, named Patrick. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/07/St.Patrick-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/07/Patrick.5cca76e36dd3.mp3"
	},
	{
		"title": "Petra",
		"text": "Like every other fan of action movies, I went to see Indiana Jones and the Last Crusade when it came out in 1989. I enjoyed the film as an entertaining adventure, notwithstanding the silly premise and the wildly improbable plot. As the story neared its climax, our heroes arrived at the Canyon of the Crescent Moon, where, according to their research, they believed they'd find the temple in which the Holy Grail had been kept hidden all these centuries. And as they rode on horseback through a narrow gorge into this supposedly secret site and the canyon walls opened to reveal the reddish facade of a huge temple carved into a cliff face, my reaction was a bit different from that of most of the other theatergoers. I was thinking: “Hey, my grandparents visited there! I remember seeing the slides when I was a kid.” And I was right: that scene had been shot on location in Petra, Jordan—one of many famous sites my grandparents had visited and photographed on their travels in the Middle East. Hard Living The name Petra, from the Greek word for “rock,” aptly describes this long-deserted city that is best known for its numerous buildings and tombs carved directly into sandstone cliffs—many with elaborate facades that would have been challenging to create even for free-standing structures. Everything about Petra seems improbable, from its location to its architecture to the fact that it was mostly forgotten for hundreds of years. Nothing but the outside of that one building is really the way the movie depicts it, but Petra contains enough mysteries and surprises that you could almost believe any fanciful tale about the city. The desert canyon now known as Petra was first settled in roughly the sixth century B.C. by a formerly nomadic group of Arabian people called the Nabataeans. The Nabataeans had begun carving buildings and tombs into the stone by at least the third century B.C. ; they also developed a sophisticated aqueduct system to supply plentiful fresh water to the city from springs several miles away. Because of the city's strategic location at the intersection of two major international trade routes, it soon became a center of commerce. Trade in spices, incense, perfumes, textiles, and other products made Petra a large and wealthy community; residents numbered an estimated 20,000 around the beginning of the first millennium A.D. The city was annexed by Rome in A.D. 106\\\\. The Romans maintained the city as a commercial center for more than two centuries; they also exerted a great deal of influence on its culture and, of course, its architecture. Some of the most impressive ruins visible today are from the Roman era, including an amphitheater. Splitting the Rock A tremendous earthquake rocked the area in A.D. 363, destroying about half the city. By that time, Constantinople had become the new Roman capital. Because of Petra's decreasing importance as a trade center, the city had neither the impetus nor the resources to rebuild, and soon lost most of its population. Little is known about what went on in Petra from around the early seventh century A.D. until the 19th century; it appears to have been inhabited—at least sporadically—but clearly not a town of any interest beyond its immediate environs. In 1812, a Swiss explorer named Johann Ludwig Burckhardt “rediscovered” Petra—which is to say, he was the first European to come upon the site, and was therefore largely responsible for getting it on maps made by western cartographers. Today, Petra is a hot spot for archeologists—if Indiana Jones were a real person, he'd probably be digging there. Only about five percent of the city has been excavated so far, but fascinating new discoveries are being unearthed on an almost daily basis. In the process, engineers are even planning to restore a portion of the city's waterworks. The Jordanian government, meanwhile, is simultaneously eager to promote tourism and anxious about the wear it inevitably causes to the ancient structures. Discovering Petra's remaining secrets without destroying it is the researchers' holy grail. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/Petra-120.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/07/Petra.8fab397c6e2f.mp3"
	},
	{
		"title": "Alcatraz",
		"text": "San Francisco is one of the most beautiful cities in the country, with more famous landmarks, scenic vistas, and other tourist attractions than you can shake a stick at. But like most San Franciscans I know, the only times I ever seem to experience any of these things for myself are when friends or family visit from out of town. That's when we ride the cable cars, visit Fisherman's Wharf, go see the Golden Gate Bridge, eat in Chinatown, check out the museums, and so on. And when we do, we think, “Wow, this is cool. What a great city we live in! We should do this more often.” And inevitably we don't…until the next visitor shows up. One sight we rarely get excited about, though, is the one visitors invariably want to see: Alcatraz, the little island out in San Francisco Bay that was once a federal penitentiary. Because we've been there so many times, the novelty wore off long ago. The first time I went there many years ago, I didn't understand what the big deal was until I heard people talking about a movie called Escape from Alcatraz. It did seem interesting to visit the place where a movie had been set, even though I hadn't seen the movie at that time. Once there, the tour guides regaled us with stories about notorious criminals who had served time at Alcatraz—again, I hadn't heard of these people, but I took the guides' word that they were infamous and that therefore it must be a great privilege to stand in their former cells. And frankly, it's a good thing I did have those stories to help spark my interest, because when you get right down to it, Alcatraz is a thoroughly unpleasant place: cold, windy, dilapidated, and depressing. No wonder it loses its tourist appeal after a while. Of course, this unpleasantness was not lost on the officials who decided to designate the island a prison in 1934. That, along with the site's isolated, escape-resistant location made it the ideal home for some of the nation's most dangerous and recalcitrant offenders until 1963. As the old saying goes, “familiarity breeds contempt.” And yet, I realize that there must be plenty of people in the rest of the world who still haven't seen the movies, heard the stories, and endured one too many visits to the island nicknamed “The Rock,” and that such people might still find Alcatraz a bit more interesting than I do. Rather than rehashing the entire history of Alcatraz, about which you can read any number of perfectly good accounts, I thought I'd share just a few of the most interesting things I've learned about Alcatraz. * The Name: The name Alcatraz is a shortened, anglicized form of the Spanish word for “pelicans.” A Spanish explorer named the island “Isla de los Alcatraces” (Island of the Pelicans) in 1775. * The Fort: The military began building a large fort on Alcatraz in 1853 to help defend the San Francisco Bay against invaders who might be attracted by the recently discovered gold deposits nearby. It went into operation in 1859. Less than two years later, the U.S. Civil War broke out, and Alcatraz was considered an important Union defense post against the Confederate army. Although a military base remained in use on the island until 1933, Alcatraz was never actually attacked. (For much of that time, the island served as a military prison more than as a defensive outpost.) The year after the military left, the Bureau of Prisons began using the island as a maximum-security prison. One of its first inmates was Al Capone. * The Birdman: Another legendary prisoner, Robert Stroud, was known as the Birdman of Alcatraz. Stroud had studied canaries while incarcerated at Leavenworth before being transferred to Alcatraz—and had even published a book on canary physiology and disease. But during his 17 years at Alcatraz, he was never permitted to study birds—making the nickname a misnomer. Nor was Stroud ever permitted to see the 1963 film Birdman of Alcatraz, for which actor Burt Lancaster won an Oscar. * The Escapes: Several prisoners did escape from Alcatraz—sort of. Two who made it off the island were later recaptured, and five others are unaccounted for. Because the waters of the San Francisco Bay are so cold and the currents so strong near the island, most people assume these prisoners drowned. However, the swim can be done successfully. In fact, hundreds of people do it every year as part of the annual Escape from Alcatraz Triathlon. Most of these participants, however, are wearing wetsuits! * The Indian Occupation: During the years between the prison's closure in 1963 and the island's reopening as a national park in 1972, Alcatraz was not entirely uninhabited. For 19 months from 1969 to 1971, up to 100 Native American protesters occupied the island in an attempt to force the government to declare it Indian property. They planned to establish a university, cultural center, and museum on the island. Although the occupation did not achieve those results, it did have the effect of raising public awareness and prompting the government to give greater recognition and autonomy to Native American tribes. The sight of a deteriorating former prison facility in the Bay contrasts sharply with the nearby Golden Gate Bridge and scenic Angel Island, not to mention San Francisco's famous skyline. Alcatraz is famous mainly for being famous, its harsh, decaying outline now perceived as beautiful by residents of the city where people once complained about having their Bay views marred by a prison. And that, I think, is the very most interesting thing about Alcatraz—its mysterious transformation from a place of pain to a place of pride. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/Alcatraz-120.JPEG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Alcatraz.b37a5ad31ba3.mp3"
	},
	{
		"title": "The Stone Balls of Costa Rica",
		"text": "When I was last in Costa Rica a couple of years ago, I was on the lookout, as usual, for interesting things. And I found plenty of them: sloths, leaf cutter ants, poison dart frogs, volcanoes, and so on. I was not, however, on the lookout for lawn ornaments, under the assumption that decorative stone sculptures were not particularly interesting. I should have known better than to make such an assumption—after all, I saw “Amélie,” which cast an entirely new light on garden gnomes. Shortly before the end of my trip, a fellow tourist asked me if I knew about the stone balls. “What stone balls?” I asked. “There are these mysterious ancient balls,” he said, “that are so perfectly round, they could not have been carved by hand. Nobody knows where they came from or how they were made, but they're scattered all over the country, and people like to find them and use them as lawn ornaments.” Sure enough, as we drove along, I spotted stone balls in a few yards, but I didn't have a chance to photograph one. It seemed strange to me that artifacts with such obvious archeological significance would end up as the Costa Rican equivalent of plastic pink flamingos. Rolling With the Bunches The first discovery of the unusual stone balls was made around 1940. The United Fruit Company was preparing large tracts of land in the Diquis Delta on the southern Pacific coast to be used for banana plantations. In the process of clearing the land, they unearthed several dozen balls, ranging in size from a few centimeters to over two meters in diameter. Subsequent archeological research identified and catalogued hundreds of the balls, some of which appeared in other parts of the country. As news of the find began to spread, the balls were rounded up (sorry) by collectors and treasure hunters; today, only six are known to remain in their original positions. No one knows exactly how old the balls are, because Costa Rica had no recorded history before 1502, when Columbus arrived there on his fourth transatlantic voyage. Archeologists have made educated guesses by dating pottery and other artifacts found near the balls or buried at a similar depth. Assuming the balls were made at about the same time as the surrounding objects, they could have been carved anywhere between A.D. 200 and 1500, with most estimates in the range of A.D. 800 to 1200. So they're old, but not that old—unlike, say, the pyramids or Stonehenge. Most of the balls are made of a hard, volcanic stone called granodiorite, though a few are composed of coquina, a type of limestone. The quarry from which the granodiorite came is located in the Talamanca mountain range, about 50 miles (80km) from the area where the balls were located. This discovery of course led to speculation as to how such massive stones could have been moved such a long distance without modern transportation. I see no mystery here; spherical objects have been known to roll rather readily, especially downhill; presumably they were carved before being moved. There are, however, two very interesting questions about the balls: How were they made, and why? Round, Round, Get Around There's nothing particularly tricky about carving stone; many ancient cultures all over the world made complex statues. But according to some accounts, these spheres are so perfectly round that not even modern equipment could have produced something with such precise tolerances. This seems to imply either a lost technology, or—as some have predictably conjectured—help from aliens. These claims of perfection have some problems, however. For one thing, few of the balls have actually been measured with any precision, and in some cases, measurements that appeared to be mysteriously perfect were made on only a portion of a partially buried ball. For another thing, many of the balls have been subjected to centuries of wear and erosion from sunlight, wind, and rain, so no meaningful statements can be made about how round they might once have been. And even the best specimens have (and probably always had) rough surfaces, making truly precise measurement a lost cause. That said, it is certainly true that at least some of the balls, having been preserved nicely over the years by layers of soil, are surprisingly round. This fact, interesting though it may be, does not require a belief in extraterrestrials. Geologists have noted that when granodiorite is heated and then quickly cooled, a thin layer of stone comes off in flakes. It's simple enough to pile some hot coals under a rock and then splash some cold water on it. If this procedure is performed repeatedly and with care, a fair approximation of a sphere can result. The stones could then have been chiseled or ground to a more perfect ball shape using simple guides fashioned from wood or even rope. It would have been difficult and tedious, for sure, and would have required a fair amount of mathematical sophistication on the part of the carvers. Thus the precision is interesting—perhaps even astonishing—but not unbelievable. My, What Big…Ornaments You Have The only real mystery, then—and it's a doozy—is why so many of these extraordinary sculptures were created. Dozens of reasons have been advanced, but in the absence of written records, there's no way to say for sure. One popular theory is that they were used as markers of some sort—as signposts, celestial references, or indicators of property lines. Unfortunately, if this was indeed the case, we'll never know, since nearly all the stones have been moved from their original positions. Some people believe the stones functioned as antennae in an ancient power grid, or that they were part of a receiver for alien communications. Or they may have had ceremonial significance in religious rituals. My favorite theory, however, is the one that says they were created as status symbols. In other words, they were in fact designed to be the lawn ornaments they now are. Besides the fact that most of the spheres have lost any positional meaning they may once have had, many have been damaged by agricultural machinery, worn away by the elements, or even destroyed by people who believed a popular myth that gold was hidden inside them. So they are, in a sense, yet another addition to Costa Rica's endangered species list. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/07/stone-balls.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Balls.5ec61b8028.mp3"
	},
	{
		"title": "Cueva de las Manos",
		"text": "Graffiti spray-painted on the side of a building is an annoying act of vandalism. Graffiti spray-painted on a natural stone formation is an appalling desecration of nature. Graffiti spray-painted on a natural stone formation and allowed to age for thousands of years is a priceless work of art. Go figure. Patagonia being a rather large area, I was unable to visit all the spots that interested me. One that, unfortunately, I didn't have time for was La Cueva de las Manos, or “the cave of hands,” in south-central Patagonia. A UNESCO World Heritage site, it's one of the world's oldest outdoor art museums; its most striking characteristic is hundreds of stenciled paintings of human hands. And the paintings were made using a primitive but highly effective form of spray paint. Handing It to Them Like so many things in Patagonia, the name “Cueva” is a bit of a misnomer; the so-called cave is more of a shallow indentation in a cliff face with overhanging rock. At first glance, the walls appear to be covered with hand prints. On closer inspection, it's clear that the hand shapes themselves were not painted or imprinted on the walls; instead, you see empty spots in the shape of hands with halos of paint around them. The borders are too diffuse to have been painted with brushes; it looks like someone pressed a hand on the wall and then spray-painted around it to form the image—a process known as negative stenciling. And in fact, this is exactly what happened. The artists apparently blew liquid pigments through small tubes—perhaps the hollow bones of birds—to create the images. Because most of us consider spray-painting a relatively recent invention, these paintings give the impression of being modern art; the impression is heightened by the deep, vibrant colors. In fact, the oldest of these paintings dates from at least 7,300 B.C., and perhaps earlier. The earliest contributors to the cave were known as Toldense; millennia later, Tehuelche artists were still adding new figures—the most recent paintings were made around 1,000 B.C. Hands are not the only subject, by the way—also pictured are human figures and local animals such as guanacos (relatives of the llama) and rheas (flightless birds that look like miniature ostriches). The paints, of which there are many distinct colors, were made from a variety of substances, including the Calafate berry and mineral pigments. A layer of sealant made from guanaco fat and urine helped to protect the paintings from the elements for all these years. The Right Way to Paint A frequently mentioned statistic is that only 31 of the more than 800 hand prints are of a right hand—as though this should be a surprise. Assuming most of the artists were right-handed (which is statistically likely), it's only logical that they'd use their dominant hand to direct the pigment while using the non-dominant hand as the stencil. No mystery there. It does suggest, though, that most of the artists painted their own hands, as opposed to someone else's. A more interesting question is the same one asked about nearly every ancient artifact: Why? Why did the ancient residents of this part of Patagonia spray-paint images of their hands all over the side of a cave wall? Archeologists have speculated, as they usually do, that the paintings were religious symbols or perhaps were made as part of an adolescent rite of passage. The latter explanation carries the disturbing implication that parents required their teenage kids to spray-paint personal tags on walls in public places. I favor the more mundane notion that everyone just thought the images looked cool. There is also, of course, the whole question of how the artists got the paint off their hands—if in fact they did. Perhaps the point was to paint the hands, and the images on the wall were nothing more than a nifty side effect. There's just no telling with kids. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/CuevaManos-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Cueva.45838fadbbec.mp3"
	},
	{
		"title": "Extinction of the Yámana",
		"text": "Months before I left for my visit to Patagonia, “learn some Spanish” was high on my to do list. Even though I knew I'd be with English-speaking guides much of the time, I figured I should at least know some basics beyond “please,” “thank-you,” and “where are the restrooms?” I had tapes, dictionaries, and phrase books, but what with one thing and another I never had time to learn much. What little Spanish I did know was the variety spoken here in California, which is similar to Mexican Spanish and, it turns out, very different from Argentinean Spanish. For example, in Argentina, speakers replace the “y” sound in words containing “y” or “ll” with a “sh” or “zh” sound, depending on the context. When we tried to order a hamburger without onions (“sin cebolla” in Mexican Spanish) we got puzzled looks, followed by, “You mean, ‘sin cebozha'?” Oh. Yeah. But that difference tripped us up every time. And when our guide in Ushuaia talked at length about a race of native people he pronounced “Shamana,” it took me a long time to figure out that he was referring to the Yámana I'd read about. Beginning at the End The story begins some 10,000 years ago—give or take a couple of thousand years. According to the Museo Mundo Yámana in Ushuaia, Argentina, Tierra del Fuego was the last place on Earth to which humans migrated, and also the farthest point geographically to which human civilization had spread from its origin. The museum thus depicts these first human residents of the area as being the hardiest of explorers. The people called themselves Yámana, which simply means “human beings.” They lived in what to all accounts was a stable and efficient society for thousands of years. The Yámana were a semi-nomadic people. They lived primarily in small family groups and relocated as necessary to avoid endangering the populations of seals, mussels, and other marine life that made up the bulk of their diet. The European explorers who first made contact with the Yámana in the early 17th century were appalled that they wore no clothes, especially considering the cold and rainy climate. In lieu of clothing, the Yámana kept their skin covered with a layer of grease to help retain heat and repel moisture; they also kept fires burning near them at all times—even in their canoes. It was these constant fires that earned the area its name Tierra del Fuego, “Land of Fire.” The Scourge of Civilization In 1830, the British ship H.M.S. Beagle (under the command of Captain Robert FitzRoy) took four Yámana captive and returned them to England. One of the captives soon died of smallpox; the rest learned English and “civilized” behavior—including, naturally, the practice of Christianity. When the Beagle sailed to Tierra del Fuego again three years later—this time with Charles Darwin on board—the three surviving Yámana were returned to their home, where they soon reverted to living as they had before. One of these, whom the English had dubbed “Jemmy Button,” was implicated decades later in leading a massacre of European missionaries. But still the missionaries and other settlers came, and still they persisted in their attempts to bring civilization to the Yámana, to whom they gave the name Yaghan (or Yagan). In the 1880s, the Yámana population was estimated at 1,000, but within three decades, fewer than 100 remained. Most of the Yámana were wiped out by diseases, such as measles and tuberculosis, carried by the Europeans. The settlers, meanwhile, over-hunted the animals the Yámana depended on for food, and tried to encourage adoption of an agricultural society instead. This change in diet, however, apparently increased the natives' susceptibility to disease, as did the missionaries' insistence that the Yámana live in mission communities. Through a combination of arrogance, carelessness, and bad luck, the missionaries managed to kill off the very people they were trying to save. Many sources refer to the Yámana as an extinct race—and this is almost, but not quite, correct. The last pure Yámana man died in 1977, and the last woman who lived according to the traditional Yámana culture died in 1982. As far as I know, there are still two Yámana women living in Puerto Williams, Chile—the last remaining native speakers of the language and the only people left on the planet with pure Yámana DNA. Their children are of mixed race and grew up speaking Spanish, so when these women die, the Yámana will officially be extinct. It makes me terribly sad to think of an entire race dying out in my lifetime, especially due to such an unfortunate cause. The irony that this group of people had survived millennia of adventure and hardship on their way to the end of the world makes the story all the more heartbreaking. They leave behind a 30,000-word dictionary, a museum full of artifacts and photographs, and, I hope, an important lesson. ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Yamana.b49d0883c80c.mp3"
	},
	{
		"title": "Legends of Tierra del Fuego",
		"text": "As an American, I’ve always been accustomed to very clearly defined state, national, and continental boundaries. The border between Canada and the U.S., for example, may be an arbitrary line of latitude, but we all know exactly where it is—what’s in, and what’s out. We know exactly where North America stops and Central America starts; we also know when we’ve reached the easternmost or westernmost edge of the continent because we run into an ocean. Sure, there’s the odd island off the coast here or there, but conceptually, these cause no problems for my notion of what a continent is. The map of South America, though, has always offended my sense of geographical tidiness. At the southern end of the continent, the land sort of swoops out to the east—but wait, that last big chunk is actually an island. Is that part of the continent? And what about the bazillions of smaller islands littering the coastline to the south and west? If I’m on one of those islands, am I on the continent or not? The geological answer is yes—I’m on the same continental plate. The political answer is also yes—any given spot of any given island is uncontroversially under the control of either Chile or Argentina. But to the average person on the street (or boat, as the case may be), these boundaries are neither visible nor intuitive. Today, we can get the answers to such questions from highly accurate maps. Hundreds of years ago, though, the answers were far less obvious. Speculation about continental boundaries led to some fanciful maps, tall tales, and grand adventures. What Goes Around I was standing in a museum in a town on Tierra del Fuego—a name given to the entire archipelago of little islands at the tip of South America as well as to its largest island, which is known more properly as Isla Grande de Tierra del Fuego. On the wall was a map from the 16th century showing the landmass we know today as South America extending all the way south to connect with a vast southern continent much larger than Antarctica. In other words: an unbroken stretch of land all the way from pole to pole. This hypothetical continent, which also encompassed Australia, had a detailed imaginary coastline that was represented as being accurate, even though no cartographer had come anywhere near it. Europeans at the time referred to this continent as Terra Incognita (the Unknown Land)—or Terra Australis (the Southern Land). In the 4th century B.C., Aristotle had advanced the idea that a great southern continent must exist, because without it the world would be top-heavy. This view was later expanded on and popularized by Greek geographer Ptolemy in the 2nd century A.D. But as of the early 16th century, no European had actually seen this land. In 1520, Ferdinand Magellan became the first European explorer to discover a sea route from the Atlantic ocean to the waters west of South America, to which he gave the unfortunate name “Pacific ocean.” But as he was passing through what came to be called the Strait of Magellan, with South America clearly on his right, Magellan could also see land to his left. When he realized the channel went all the way through, he drew what was for him the logical conclusion: that land he’d seen to the south must be the tip of the great southern continent. He gave it the name Tierra del Fuego (“land of fire”) upon seeing the smoke rising from numerous fires built by the land’s inhabitants. This name, of course, suited the continent’s popular image as a mysterious and forbidding place. And Magellan’s discovery—apparently the first proof of the existence of Terra Australis—required only minor modifications to the maps of the time. Down and Out It was not until 1578 that Francis Drake, in an attempt to circumnavigate the globe, discovered the truth about Tierra del Fuego. Drake sailed through the Strait of Magellan, but his ship was blown south by a storm; he soon found himself rounding the tip of a large island chain. Now there was another way to get between the oceans—the Drake Passage. Although Drake did not sail all the way to Antarctica, he again drew the logical conclusion that it must be down there somewhere—as in fact, by chance, it was. Shortly thereafter, in 1616, Cape Horn—at the tip of Horn Island—was identified as the southernmost point of land that could be construed as part of South America. In the 18th century, captain James Cook discovered the location of Australia—and that it, too, was not the imagined southern continent, its new name notwithstanding. Only in the early 19th century did explorers first set foot on Antarctica and begin to correct the old maps once and for all. All of the foregoing is, I’m sure, familiar to anyone who (unlike me) actually paid attention in history and geography classes. But it was a revelation to me, looking at an old map in a museum, that assumptions about the nature of the world—unsubstantiated though they were—could have led to such startling errors, such blatant (if well-meaning) fabrications, and so many years during which myths were misrepresented as fact. True or not, deeply ingrained beliefs die hard. If you never thought you could learn anything from history, keep this little lesson in mind as you read today’s news. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/Tierra_del_Fuego.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Tierra.7cb8375d2c21.mp3"
	},
	{
		"title": "Saint Bernards",
		"text": "In October 2004, I read an article with some shocking and disheartening news: the Swiss monks responsible for breeding St. Bernards since at least the 17th century were getting out of the dog business. The last 18 dogs living in the alpine hospice where the breed originated were up for sale. At that time, I didn't know anything about St. Bernards except that they were known as rescue dogs and usually pictured wearing a little barrel or cask on their collars. It had not occurred to me that there was some particular base from which their rescue operations had traditionally begun, or an actual Saint Bernard after whom the dogs had been named. But as I read about the imminent end of the monks' caretaking operations, I began wondering about the real story behind these dogs. Did they ever really perform rescues? How did the monks figure in? And what was the deal with those little casks? Glass of brandy in hand, I began my research. Anyone for a Walk? The story begins in the year 962, when Bernard of Menthon founded a monastery and hospice in the Swiss alps. To the north is the Swiss canton of Valais; to the south, the Valle d'Aosta in Italy. It was not for seclusion that Bernard chose this particular spot, at a snowy pass some 8,000 feet (2500m) high. The pass was often used by pilgrims making their way from France into Italy to visit Rome, and was known as a treacherous and forbidding spot. Bernard's idea was that the hospice could provide shelter for the pilgrims and aid to those who became lost or injured on their journey. By the time Bernard was canonized in 1681, the hospice he had founded centuries earlier had begun keeping dogs, which the monks found helpful in carrying out their rescue missions. Over many years, the monks bred a type of dog ideally suited to both the weather and rescue work—a huge, energetic, friendly, and faultlessly loyal breed related to the mastiff, with thick fur and keen senses of smell and hearing. And from the early 1700s, when the oldest surviving records were made, until the late 20th century, the dogs assisted in rescuing about 2,500 people. The dogs were first referred to informally as “St. Bernards” in 1833, and the name became official in 1880. Dog Days In the 1950s, however, helicopters appeared on the scene, and technology began increasingly to fill the dogs' role. The last time a dog helped with a rescue was around 1975. In the years since then, the monks—who now number only four or five—have continued to raise the dogs. But St. Bernards are costly to feed and require a great deal of time to care for; the monks felt that since the dogs were no longer assisting them, their limited time and money would be better spent serving human beings. And so, in late 2004, the dogs were put up for sale. Although from the monks' perspective this was a reasonable and utilitarian decision, it prompted a tremendous public outcry. Those most vocally opposed to the change included local merchants, dependent as they are on the business of thousands of tourists who come to the area each summer only to see the famous dogs. In less than two months, the matter was resolved. A couple of Swiss philanthropists donated the equivalent of over US$4 million to buy the dogs, who will continue to spend their winters in a kennel in the nearby city of Martigny but will return to the hospice each summer. A museum honoring the dogs will also be built in Martigny and is scheduled to open in the spring of 2006. As for the barrel on the collar, it first appeared in a painting by artist Edwin Landseer called “Alpine Mastiffs Reanimating a Distressed Traveler” in 1820; Landseer was only 17 at the time. The cask was thought to contain brandy and quickly caught on in the public imagination, though the monks and their dogs never actually used such a thing. (Alcohol, after all, could hasten dehydration—not a good treatment for a snowbound traveler.) Nowadays, that little barrel could prove more useful as a carrying case for a GPS receiver and a cell phone, giving the next generation of St. Bernards updated rescue capabilities more suitable to the modern age. And, if the helicopter is on its way anyhow, maybe a wee nip of brandy wouldn't be so bad after all. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/Saint-Bernard-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Bernards.ff1e4a57fc93.mp3"
	},
	{
		"title": "The Legend of Deolinda Correa",
		"text": "Tour guides, docents, and professional speakers of all sorts love to ask their audiences questions to which the answers are obvious. They do this in order to “encourage participation,” but I always find these exchanges patronizing. “Who can tell me the title of the seminar you’re currently attending? That’s right! Communicating Clearly. Now if we’re not communicating clearly, how are we communicating? Anyone? Yes! Unclearly!” Ugh. So I don’t like to encourage this sort of behavior. If you have facts to relate to someone, then relate the facts. If you can’t ask genuinely useful questions, find some other way of involving your audience. So there we were in a van with seven other tourists, a driver, and a chipper guide who was eager to practice both her English and her professional guide skills. We were a captive audience in the only vehicle for many miles on one of the narrow highways that stretch across Patagonia. It was going to be a long ride, and we did pay a lot of money to be there, so we tried to make the best of it. “Who can tell me what meteorological feature this part of Patagonia is best known for?” she asked. Silence. We all knew. She knew we knew. No one wanted to play. I sighed and decided to throw out the obvious answer just to take the pressure off my fellow tourists, and make the guide feel better about her job. “Wind,” I said. The guide smiled condescendingly with the look that means, in any language or culture, “Not the answer I was looking for.” Dang it. “Well,” she said, trying to reassure me that I hadn’t said something completely boneheaded, “it is indeed very windy here.” And she went on to talk about how many windmills were being installed, what a large portion of the nation’s electrical needs they hoped wind would provide in a few years, and so on. But this was all a diversion. She was looking for a particular answer to her question, and after asking a second time with no response, she filled it in for us. “It’s incredibly dry here.” Well, yes, of course—we knew that. We were confused because it was too obvious. Our guide went on to tell us how very few centimeters of rain the Chubut province received each year, how only the hardiest plants and animals could survive, how heavy pollution in other parts of the world was leading to dramatic climate changes here, and so on. This was all interesting in a vague, academic sense, but not what I really cared to listen to at that time. As I would later discover, however, stories involving thirst figure prominently in this arid region’s popular mythology. Shrines of the Times As we drove all over Chubut province—and again in each of the regions we visited—we repeatedly passed small roadside shrines, often in the remotest and unlikeliest locations. We always zipped by too quickly for me to get a good look or take a picture, but something told me there must be a story behind them. Finally someone asked what they were. Our guide said, with a mildly embarrassed tone, “Those are shrines or monuments to Deolinda Correa.” The story she then related is one she clearly did not believe in herself, but equally clearly, a great many other Argentineans did. As legend has it, in the 1830s, María Antonia Deolinda Correa lived in Argentina’s San Juan province—an area at the foot of the Andes well north of Patagonia. Her husband, Bustos, was taken by force and drafted into the private army of Juan Facundo Quiroga, a regional gaucho warlord. Deolinda was so distraught that she set out on foot, with her newborn son in her arms, to follow her husband. After days of walking through the desert without food or water, she finally collapsed and died. Days later, passing mule drivers found her body; amazingly, her infant son was still alive and nursing at her breast. The men buried her, and having found the name Correa on a pendant she was wearing, labeled her tomb “Difunta Correa,” difunta being a word that literally means “defunct” but is more commonly used to mean “dead.” Birth of a Saint Years later, as her story spread, the locals began to think of her as a saint who had given her life for her child. And so, in this predominantly Catholic nation, people in need began to pray to her. When one man’s prayers were miraculously answered, he built a small chapel to honor Deolinda. Shortly thereafter, someone brought an offering of water to this chapel, symbolizing the divine relief from thirst. Soon, small roadside shrines began to appear all over the country, some of them littered with hundreds of bottles of water brought either in supplication or in thanks. Deolinda Correa has become the unofficial regional patron saint of travelers, farmers, and all those whose lives or livelihoods depend on a precarious supply of water. The monument built on the site where Deolinda is said to have died is now a large sanctuary—a hilltop where 17 chapels, and numerous smaller shrines, pay her honor. Over half a million pilgrims visit this site in the small town of Vallecito each year. Deolinda was never canonized by the Catholic church, which regards the entire tale as nothing more than a superstition. There is little evidence of Deolinda’s existence and even less of the supposed miracle. The legend also does not say what happened to Deolinda’s son. But none of this weakens the beliefs of thousands of people who claim that Difunta Correa’s intervention resulted in miraculously answered prayers. Travelers do not often cross the deserts and plains of Argentina on foot these days. But I can easily imagine a parched and weary soul, stranded far from food and water, who stumbles upon a shrine to Deolinda Correa and drinks from a water bottle left as an offering. Whether or not this ever happens, I like to think that in death—or even as the figment of someone’s imagination—Difunta Correa now has the power to save countless thirsty travelers. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/Deolinda-Correa-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Deolinda.3bc73099fefd.mp3"
	},
	{
		"title": "Introduction to Patagonia",
		"text": "On December 25, 2004, my wife, Morgen, turned 30. She had decided many months earlier that she wanted to celebrate this milestone by taking a grand trip that would be, in a sense, a sort of pilgrimage. No one has to twist my arm to talk me into going on vacation, especially if it’s to some exotic, faraway place. But I told Morgen that the decision where to go should be hers alone: my only input in the process would be smiling and nodding. “You tell me where you want to go,” I said, “and I’ll be there.” For a while she was thinking seriously about going to Spain and doing the pilgrimage to Santiago de Compostela. Then she started talking about Rome. After that, it was Australia, and for many weeks I thought she was leaning strongly in that direction. Then one day last summer she announced that she’d reached a final, irrevocable decision. “Where are we going?” I asked. She replied, matter-of-factly, “Patagonia.” I smiled and nodded and said, “Great!” And then I thought for a moment and added, “Where’s Patagonia?” Since then, virtually every time I’ve told friends or family about our two-week trip, they’ve had the same reaction. “Patagonia? Oh yeah, the clothing brand. You mean it’s an actual place too? Where is it?” Had I myself not been entirely ignorant about Patagonia just a few months ago, I would be incredulous that such a huge place—and one so full of stories—could be unknown to so many otherwise intelligent, educated North Americans and Europeans. Patagonia is in fact chock-full of interesting things—people, animals, plants, customs, natural wonders, and amazing stories—and now that I’ve had a small taste of it in person, I’m going to do my part to share that information with the rest of the world. Each of the articles on Interesting Thing of the Day this week, and again during a second week next month, will have something to do with Patagonia. Accordingly, I thought we should begin with a little primer on Patagonia: its whereabouts, its history, and most importantly, some of its best-known legends. We’ll revisit some of these items, and many others, in more detail as the series progresses. Where Patagonia Is Patagonia is the southernmost portion of South America. Its exact northern boundary is somewhat vague, but it begins somewhere in the vicinity of 40° south latitude, or roughly where the Rio Colorado cuts diagonally across the continent. Patagonia extends all the way to the tip of the continent—encompassing, by most accounts, Tierra del Fuego and the many smaller islands up to and including Cape Horn. The western quarter or so of Patagonia is in Chile; the rest, to the east of the Andes mountains, is in Argentina. Patagonia is an immense region; its area of about 400,000 square miles (1,000,000 sq. km) makes it well over twice the size of California. And trying to describe Patagonia is very much like trying to describe California—do you want to hear about the deserts, the mountains, the valleys, or the coast? The cities or the rural areas? The wildlife or the politics? With so much to describe, generalizations become difficult. One thing you can say with certainty, though, is that Patagonia is sparsely populated—it has a total of roughly 1.5 million inhabitants (compared to California’s 34 million), of which the vast majority live in large towns. Depending on whose estimates you believe, sheep outnumber humans by at least 5 to 1, and perhaps as many as 20 to 1. And one of those sheep contributed the wool for that Patagonia-brand sweater you have in your closet. The name “Patagonia” was once thought to have been derived from a Spanish expression for “big feet”—a supposed reference to the proportions of the area’s original inhabitants, described by early European explorers as “giants.” But the generally accepted etymology is that the word Patagonia actually comes from Patagon, the name of a giant in a Spanish novel called Primaleon—apparently a favorite of Ferdinand Magellan’s. The Stuff of Legend Magellan, of course, lent his name to the strait that separates mainland South America from Tierra del Fuego; he discovered the long-sought passage between the Atlantic Ocean and the Pacific in 1520. Even three centuries later, though, when Charles Darwin set out on H.M.S. Beagle (under command of Captain FitzRoy), Europeans knew very little of Patagonia or its inhabitants; it was more of an inconvenient obstacle to sea travel than a place one might actually want to visit. The exotic descriptions Darwin brought back—especially his confirmation that the inhabitants were savage giants—reinforced in the minds of many Europeans the notion of Patagonia as being a desolate and forbidding place, far from (and perhaps unworthy of) civilization. Partly because of its remoteness, Patagonia attracted its fair share of outlaws. Following a major heist in the U.S., Butch Cassidy and the Sundance Kid hid out in Patagonia for several years in the early 1900s. Pirates, too, found the busy shipping channels near Patagonia a lucrative source of business. As recently as the 1970s, English-speaking people in the northern hemisphere knew little of Patagonia. British author Bruce Chatwin almost single-handedly brought Patagonia into the popular consciousness with his best-selling 1977 book In Patagonia, a travelogue of sorts that is part autobiography, part fiction. Two years later his friend, travel writer Paul Theroux, wrote The Old Patagonian Express, detailing his attempt to travel by train from Boston all the way to the heart of Patagonia. These two books have inspired generations of travelers to discover Patagonia for themselves. Far and Away Today, Patagonia is a favorite destination for ecotourists and adventure travelers. Some go to see the vast expanses of steppes—desert-like plains that are constantly buffeted by strong winds and support only the hardiest plant, animal, and human life. Some are interested in the impressive glaciers descending from the Andes, or in the millions of nesting penguins along the coast. Still others are interested in the cultural anomalies, such as the Welsh colony of Gaiman, where you can always get a proper tea. And many tourists stop briefly in Patagonia on their way to Antarctica—a mere 600 miles (1,000km) or so south across the Drake Passage. But one of the biggest reasons to go to Patagonia, even for residents of northern Argentina, is its sheer remoteness: it is one of the last places on Earth that can still be called “one of the last places on Earth.” ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/Patagonia.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Introduction.b889293e0ec9.mp3"
	},
	{
		"title": "The Battle of Dunkirk",
		"text": "Stories of war—whether modern or historical—are not usually of much interest to me. I don’t like to dwell on tragedy, and war is always tragic, for every side, regardless of the motivations or outcome. Occasionally, however, in the midst of tragedy is a story of hope that is worth retelling. Today’s interesting thing is an inspiring and unique episode from history that is well known in Britain and France, but seldom heard in North America. It’s called the Battle of Dunkirk. The year was 1940, and World War II was raging. Hitler’s army had overtaken Belgium and advanced into France. Britain sent over 300,000 troops to assist the French army, but in spite of those sizable numbers, the German force was winning, due to their superior armaments, training, and organization. By late May, German troops had the bulk of the allied forces surrounded, trapped in the northernmost corner of France across the English Channel from Dover. To the east was occupied Belgium; to the south and west, the advancing German army; to the north, the sea. Operation Dynamo Britain had already suffered severe casualties in France, and they knew this battle could not be won. Retreat was the only option, but all escape routes had been blocked. Vice Admiral Bertram Ramsay, headquartered in the reinforced tunnels beneath Dover Castle, was put in charge of evacuating the troops. The rescue plan was code-named Operation Dynamo. Unfortunately, there were several major problems. Time was quickly running out for the cornered British troops. Ramsay believed he had a week at most to rescue the soldiers, who were packed onto the beaches and being shelled mercilessly. An exodus by sea was the only possibility, but German planes had sunk so many ships in Dunkirk harbor that it was nearly impossible to navigate, and U-boats posed a constant threat. Farther to the west, where the beaches were, the water was so shallow that British destroyers and transport ships could not get any closer than about a mile (1.6km). As if that weren’t enough, Britain had far too few vessels available to transport the hundreds of thousands of soldiers trapped on the beach, even under the best conditions. Ramsay was deliberate and methodical in his preparations. He arranged transportation, food, and medical care for the troops that would soon be arriving in Dover. He sought out every available ship, and established a complex and efficient communications network. Logistics in place, Operation Dynamo was put into motion on May 26. But after the first day, the outlook was grim. Fewer than 8,000 troops had been rescued, and the most optimistic estimate was that a total of 45,000 might escape before Germany overtook the beaches—at the rate the operation was progressing, it would take 40 days to rescue all the remaining troops. Ramsay faced the possibility that the core of the British army would be decimated. At that time, conventional wisdom held that Britain would inevitably be invaded as soon as France fell, and with so much of its army gone, Britain’s defenses would be in ruins. The Bathtub Navy Saves the Day In desperation, Ramsay put out a public call for help: everyone with a boat—any kind of boat—was asked to help rescue the troops. The response was instantaneous and overwhelming. A makeshift flotilla of 850 “Little Ships”—yachts, lifeboats, fishing boats, and anything else that could float rushed to the scene. Most of the boats were manned by British sailors, but in many cases the civilian owners themselves risked gunfire and mines to make the 22-mile (35km) crossing. When possible, the small craft were used just to ferry troops to the larger vessels offshore, but thousands of troops used them for transport all the way back to England. By the morning of May 29, officials estimated that 2,000 troops per hour were being evacuated. Nine days after Operation Dynamo began, a total of 338,226 people—including about 95,000 French troops—had been rescued. Churchill called it a “miracle of deliverance,” and the “Dunkirk spirit” quickly became the stuff of legend. In retrospect, the eventual allied victory might well have been thwarted had Britain lost hundreds of thousands of troops at Dunkirk. Nevertheless, the massive rescue could hardly be considered a victory. There was more to the story than the heartwarming tale of heroism. The Other Side of the Story For one thing, the escape was not as clean as the media made it sound. While swarms of small boats were shuttling soldiers off the beach, more than four hundred Luftwaffe fighters attacked, dropping bombs and inflicting heavy casualties. Soldiers returning to England described the beaches as littered with dead bodies. In all, tens of thousands of people lost their lives at Dunkirk. In addition, the highly publicized rescue obscured the fact that thousands of British troops were still trapped elsewhere in France. Two weeks later, the British ship Lancastria was returning from a rescue mission when it was sunk off the coast of Brittany. Half of the 6,000 passengers lost their lives, but nothing was mentioned in the press about the incident for weeks, lest it dampen the spirits that had been uplifted by the Dunkirk miracle. Meanwhile, France felt deeply betrayed. The British troops had ostensibly come to their rescue, but then fled the German army. Without any hope left from across the Channel, France surrendered to Hitler within three weeks. Notwithstanding the many French soldiers rescued at Dunkirk, many in France resented what they regarded as British cowardice. It wasn’t until 1944 that Britain redeemed itself, when British and American forces collaborated in the D-Day operation, leading to France’s liberation. Dunkirk Redux In June of 2000, on the sixtieth anniversary of the Battle of Dunkirk, Britain commemorated the event with a massive celebration. A large number of small boats reenacted the Channel crossing to Dunkirk. Although there weren’t nearly as many boats as there had been in 1940, some of the original craft had been restored specifically so that they could make the journey again. While British television crews lined the Dunkirk shore to relay the landings to exuberant crowds back home, the French media—as might be expected—gave little coverage to the event. About 800 British and French veterans who had been rescued at Dunkirk attended a massive parade past the town hall. Prince Charles gave a speech at the Dunkirk Memorial in both English and French, praising the courage of all those who had helped in the miraculous rescue. The remaining members of the Dunkirk veterans' associations—many in their 80s and 90s—chose that occasion to officially disband their organizations. Politics and media spin aside, the story of the Battle of Dunkirk inspires me for one simple reason: it shows ordinary people lifting the veil of war—the impersonal propaganda of numbers—and seeing each other as human beings. Fisherman didn’t row across the English channel to transport “troops”; they risked their lives to rescue people with names and faces. That the public could, however briefly, set aside their habit of detached reliance on the machinery of government and take personal responsibility for other lives—especially in a time of war—is to me an immensely hopeful sign. It’s a step toward understanding that the soldiers wearing different uniforms are human beings too. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/Dunkirk-soldiers-120.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Dunkirk.3448f772ff9e.mp3"
	},
	{
		"title": "Palacio Barolo",
		"text": "At the end of 2004, Morgen and I left San Francisco for a two-week vacation in Argentina. Our final destination was Patagonia, but we were to spend several days each at the beginning and end of our trip in Buenos Aires. When we got to the San Francisco airport, we discovered that the first leg of our flight, to Dallas, had been delayed—meaning we would miss our connecting flight to Buenos Aires. The ticket agent worked valiantly to find us an alternative route, but for a long time had no success. Then she started laughing. She said the computer had suggested the following itinerary: San Francisco to Los Angeles; Los Angeles to Santiago, Chile; Santiago to Paris, France; and Paris to Buenos Aires. We had to admit, that was funny—we probably could have driven from Santiago to Buenos Aires in less time than a flight by way of Paris. Fortunately, another, less circuitous option turned up. But perhaps we should not have been surprised; Argentineans sometimes think of themselves as living in a European satellite nation of sorts, and Buenos Aires does resemble Paris in many respects. Rise and Shine European influences are especially evident in the architecture. Take, for example, the Palacio Barolo (or Barolo Palace). This 22-story office building may not strike modern visitors as the most flamboyant structure in the city, but in its time, it was—excuse the expression—one hell of a monument. Italian architect Mario Palanti was educated in Milan and moved to Buenos Aires in 1909. He belonged to a fraternal order called La Fede Santa (the sacred faith), as had poet Dante Alighieri, according to legend, centuries earlier. In any case, this brotherhood certainly reveres Dante, and Palanti conceived of a grand building that would embody in great detail Dante's epic poem The Divine Comedy. Luis Barolo, an Italian-born businessman who had made his fortune in textiles, agreed to bankroll the project—and in so doing lent it his name. When the building opened in 1923, it was the tallest building in the city; it held this title until 1935, when the Edificio Kavanaugh was constructed. Palacio Barolo was the first major building in Argentina—and one of the first in the world—to have been made entirely from reinforced concrete. The building's ornate styling set it dramatically apart from the more austere architecture that was common at the time, and it even featured a domed lighthouse at the very top with a rotating beacon. Stairway (and Elevators) to Heaven Although the average pedestrian may have seen nothing more than a strikingly styled skyscraper, those who looked more carefully could see innumerable references to The Divine Comedy. For example: * The building's height of 100 meters represents the 100 cantos of the poem. * From bottom to top, the building has three distinct sections, corresponding to the three books of the poem. The ground floor represents Inferno, or hell; the next 14 floors are Purgatorio, or purgatory; and the uppermost floors are Paradiso, paradise or heaven. * Above the ground floor entranceway are nine vaults, corresponding to the nine infernal hierarchies. * Each floor has either 11 or 22 offices, just as most of the poem's cantos have 11 or 22 stanzas. And the list goes on. It is also said that in early June at 7:45 p.m. or thereabouts, the Southern Cross constellation aligns exactly with the axis of the building—though this may be a coincidence. I even read a report that Dante's ashes were at one time intended to have been relocated to the Palacio Barolo, though that never in fact happened. Across the Rio de la Plata in Montevideo, Uruguay, Palanti built Palacio Salvo, which is very similar in design to the Palacio Barolo but slightly larger—and intended for residential, rather than commercial, use. Like Palacio Barolo, it features a lighthouse at the top; the two lights may even have been visible to each other on a clear night in the 1920s. Today, both buildings have been eclipsed by much larger and flashier structures, but they continue to lend their respective towns a taste of other worlds—in this life or the next. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/Barolo-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Barolo.c966e2616015.mp3"
	},
	{
		"title": "The Thinker",
		"text": "There’s no getting around it: in junior high and high school, I was a nerd. I actually wore pocket protectors. I had my digital watch synchronized to the second with the school’s clocks. I excelled at academics (especially science and math), I dreaded phys ed, and I didn’t understand sports. I was in the band, but never got elected to the student council. The few friends I had were also nerds, and we had no idea why being smart didn’t make us more popular. One of the nerdy activities many of us overachievers participated in was Academic Games, in which students from various schools competed in tournaments of math, language, and social studies games. The best players on the best teams got to attend the national finals. The one year I went to the nationals, my team and I failed to distinguish ourselves, but we did leave with lovely T-shirts bearing the program’s logo: a picture of Rodin’s sculpture The Thinker. That was my favorite shirt for years, and once when I wore it to an amusement park, I had a caricature made of my head on The Thinker’s body. So I like to think that Rodin and I go way back. No Laughing Matter On a visit to the Orsay museum in Paris several years ago, I saw a casting of Rodin’s monumental work, the Gates of Hell. This enormous bronze sculpture features hundreds of three-dimensional figures arranged on and around two doors. According to the placard nearby, the Gates of Hell was inspired by Inferno, the first book in Italian poet Dante Alighieri’s epic trilogy The Divine Comedy. So, of course, all these folks are depicted in a variety of anguished poses. And there at the top, in miniature, is The Thinker, looking down at the spectacle below. The first time I saw this sculpture, I thought, “Oh, that’s what The Thinker is thinking about,” which seemed like a fascinating revelation. However, that first impression was largely inaccurate. There’s much more to The Thinker than meets the eye. In 1880, the French government commissioned 40-year-old sculptor Auguste Rodin to create a grand entrance for the planned Museum of Decorative Arts. Rodin was quite fond of Dante’s poetry, and decided almost immediately that the entrance to the museum should depict characters from the Inferno. The specifics, however, took a long time to evolve. After a couple of years and hundreds of sketches, Rodin had created models of many characters that would later appear in the finished piece—including The Thinker. At that time, Rodin intended the figure to represent Dante himself, pondering the poem that had been brought to life before him; accordingly, Rodin referred to the figure as The Poet and began to call the entire sculpture the Gates of Hell. Thinking On His Own Over time, however, the individual figures took on lives of their own, as more and more of those smaller studies became independent works. Rodin’s vision for the overall piece began to stray ever further from the poem, and his plan for the final set of characters changed constantly. When he realized that The Poet would become a large, stand-alone piece outside the context of the Gates of Hell, he renamed it The Thinker. Meanwhile, though the museum for which the Gates of Hell was to have been the entrance never got built, Rodin continued working on his sculpture off and on until his death in 1917. The Gates of Hell, which Rodin never considered finished, was not cast in his lifetime. There are now a total of 25 castings of The Thinker in its largest size (and many, many smaller ones)—not to mention the various posthumous castings of the Gates of Hell. Because Rodin created the plaster molds, all can be considered equally “authentic” and “original.” But one of the 10 castings of The Thinker made during Rodin’s lifetime sits atop his tomb in Meudon, a Paris suburb. What is The Thinker really thinking about? Perhaps he’s pondering his creator’s eternal reward. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/Thinker-120.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Thinker.a65ac5e4a466.mp3"
	},
	{
		"title": "The Tunnels of Moose Jaw",
		"text": "The first couple of times I visited Saskatchewan, where my wife’s family lives, it was winter. Temperatures hovered around –40°, making holiday shopping along the streets of downtown Saskatoon a challenge. Even bundled to the gills, we could barely stand to be outside for more than a few minutes. Morgen assured me that during the summer (or “mosquito season,” as it is affectionately known), the prairies of southern Saskatchewan took on an entirely different look and were quite hospitable to humans. But I was thinking, this is why they invented malls. Malls are good. Let’s go to the mall! We went to the mall. Moosey in the Sky with Diamonds I like to kid my wife about Saskatchewan: the monotonous flatness of the landscape, the dearth of trees, the nasty winter weather, the fact that the province’s slogan, “Land of Living Skies,” suggests there’s not much interesting about the land itself. Morgen, in turn, can kid me about western Pennsylvania (where I grew up), which has its own peculiarities. But even though Pennsylvania has no shortage of oddly named towns, Saskatchewan’s legendary town of Moose Jaw takes the cake. Although everyone in Canada has heard of Moose Jaw, it’s known more for its silly name than for any other characteristic. Which is a shame, because if you dig a little bit, you can find all sorts of interesting things in Moose Jaw. Moose Jaw, located just west of the provincial capital of Regina in south-central Saskatchewan, most likely got its name from a Cree word meaning “warm breezes” via folk etymology—though there are several other theories too, including one that the river running through town was thought to be shaped like a moose’s jawbone. Warm breezes or not, Moose Jaw (like the rest of Saskatchewan) gets plenty cold in the winter. In the early 1900s, when the town was beginning to undergo significant growth, most of the larger buildings were heated by steam, with coal-powered boilers located in the basements. The engineers who kept the heating equipment running didn’t like having to go upstairs and outside in the cold repeatedly to move from building to building, so they arranged for the creation of a series of tunnels linking the basements to provide easier access. Over a number of years, the tunnels expanded and interconnected, becoming a large network. Down and Out in Moose Jaw Not long after the tunnels were built, a wave of Chinese immigrants arrived in Moose Jaw. Anti-Chinese sentiment at the time made it difficult for these immigrants to live and work in public view, yet business owners valued them as a source of cheap labor. So the tunnels were expanded and used as both living quarters and workplaces. Conditions were harsh in the tunnels and pay was poor, but the workers stayed because their options for earning money in the outside world were limited. During Prohibition (1917–1924 in Saskatchewan and 1920–1933 in the U.S. ), Moose Jaw became a hub for liquor distribution both domestically and across the border. Along with speakeasies, gambling and prostitution became big businesses in the town. The tunnels provided a conveniently obscure place for all these activities. According to several reports—though no conclusive evidence exists—Al Capone himself called Moose Jaw home for a short while, overseeing a profitable bootlegging operation in person. Because of the town’s connection to organized crime in the U.S.—and its physical link to Chicago via the Canadian Pacific Railway’s Soo Line, used heavily for transporting illicit alcohol—Moose Jaw became known as “Little Chicago.” Over time, most of the tunnels fell into disuse; many were filled in or blocked off as new buildings were constructed. But a portion of the tunnel network that remains has been developed into an elaborate, theatrical tourist attraction. Guests can take either or both of two tours featuring both live actors and animatronic figures. One tour highlights the tunnels' use by Chinese immigrants; the other tour focuses on the organized-crime angle. The tours attract more than 100,000 visitors per year—about three times the town’s population. The tunnels are now a source of civic pride, though they may never match the incredible drawing power of the town’s unusual name. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/Tunnels-of-Moose-Jaw.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Tunnels.51006329b87e.mp3"
	},
	{
		"title": "Origin of the Trophy Cup",
		"text": "Having written several articles based on the theme “Throwing Down the Goblet,” I found myself wondering about trophies. Lots of major sporting competitions award the winning team a trophy in the shape of a cup (or, if you prefer, a bowl, chalice, or goblet)—the Stanley Cup, the America's Cup, the World Cup, and so on. Trophy cups are also found quite often in collegiate sports, and Harry Potter fans will of course remember the House Cup as the highly coveted award for the house that has accumulated the most points during a given term. Often, though not always, tradition dictates that a single trophy cup be passed from one winning team to the next. In individual competitions, by contrast, trophy cups are much less common; designs are based more often on a human (or angelic) figure of some kind. The Salad Fork of Victory When you're rooting for your team to win, say, the World Cup, it's probably not especially important to you what the actual token of victory is shaped like. The important thing, most competitors and fans would agree, is simply to win—and to have some commemorative token. A cube or sphere or an inscribed toaster oven could just as easily serve this purpose, though without a doubt, larger, more elaborate, and costlier trophies give the winner something further to brag about. All I wanted to know was, why a cup? How did a cup, of all things, come to symbolize competitive victory? The answer has been surprisingly difficult to track down; in fact, after several hours of research I can only advance a couple of plausible theories. For many centuries, a “trophy” was simply something of one's enemy—a piece of armor, perhaps, or occasionally a body part—that was displayed after a battle as a tangible proof of triumph. This may, of course, have been a cup on occasion, but I have not been able to find any examples of cups designed for the sole purpose of serving as trophies (in particular, for sporting events) until the mid-18th century. This means the inspiration for such a design must have appeared earlier than that. For Methodists Who Love to Win One explanation traces the origin of the trophy cup to the “loving cup” designed by theologian John Wesley (1703–1781). Wesley founded the Methodist church, and part of the church's early rituals included “love feasts”—community gatherings that included a simple meal of bread and water. Although superficially similar to Holy Communion, love feasts were simpler and were conducted by laypeople rather than clergy. Wesley's loving cup was given two handles so that the water could be passed easily from person to person. The handles and the tradition of passing the cup fit with the trophy cup, although I have not been able to find any explicit evidence that a trophy designer used the loving cup as inspiration. An alternative theory is advanced by Ian Pickford (of Antiques Roadshow fame). According to Pickford, the modern trophy cup was based on the two-handled “ox-eye” college cup design from the 17th century. Far be it from me to gainsay an antiques expert, but I was not able to corroborate this claim—and even if true, it begs the question of where that design came from or how it came to have its current meaning. If any trophy historians out there would like to chime in with evidence supporting either explanation (or a different one), I'd be all too happy to set the record straight. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/trophy.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Trophy.45c725162776.mp3"
	},
	{
		"title": "The Invention of the Wheel",
		"text": "On occasion, you may have heard it said of some wonderful gadget, “This is the greatest invention since sliced bread!” Such a comment is intended to be both a compliment and a reference to how revolutionary and world-changing the invention is. It's worth bearing in mind, though, that while people have been slicing bread for eons, pre-sliced, packaged bread has only been available since 1928, when Otto Frederick Rohwedder introduced the world's first mechanical bread slicer in Battle Creek, Michigan. I don't know what revolutionary invention the bread-slicer was compared to when it first appeared, but sooner or later, it all goes back to the wheel. Nobody seems to be able to come up with an older, or more important, invention than that. Giving It a Spin Before I began my curatorial duties here at Interesting Thing of the Day, I had never really wondered when the wheel was invented, much less why it was invented. That's obvious, isn't it? Everyone knows the wheel was invented to enable people to move stuff around more easily—a revolutionary alternative (so to speak) to carrying, pushing, or dragging heavy objects. Surprisingly enough, some historians and archeologists aren't so sure about that. There is in fact a fairly good case for the hypothesis that the wheel was invented to facilitate pottery making. The wheel was almost certainly invented in Mesopotamia—present-day Iraq. Estimates on when this may have occurred range from 5500 to 3000 B.C., with most guesses closer to a 4000 B.C. date. The oldest artifacts with drawings that depict wheeled carts date from about 3000 B.C., though for all anyone knows, the wheel was in use for centuries before these drawings were made. But there is also evidence from the very same period of time that wheels were used for pottery. Drinking and Driving It was around 3000 B.C. that the first goblets appeared. Clay goblets are normally made by throwing them on a wheel in two parts—first the bowl, then the stem (including the foot). This makes for a far more smooth and regular shape than could be achieved by manual coiling, and since the oldest surviving goblets bear the telltale signs of wheel manufacture, it is plausible that wheels were used for pottery before they were used for transportation. For that matter, it's conceivable—though admittedly a wild and improbable speculation—that the wheel was invented for the express purpose of making goblets. Be that as it may, it is virtually certain that historically, the preferred way to make goblets was to throw them. If the wheel was indeed invented for the convenience of potters, the question then becomes how it came to be used for transportation; clearly, whichever use appeared first, the other quickly followed. To be honest—putting myself as best I can into the sandals of someone living many thousands of years ago in Mesopotamia—I probably never would have thought to turn a pottery wheel on its edge and put it under a box (or vice-versa). But then, I've always had a knack for overlooking the obvious. This story also has an interesting postscript. Some sources claim that prior to the invention of the pottery wheel, most pottery was primarily made by women, whereas afterward, it became a man's job. Thus we can see that the stereotypical male trait of liking gadgets goes way back. I can just picture those prehistoric dudes standing around bragging about their new wheels and saying, “This is the greatest invention since fire!” ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/Wheel.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Wheel.7a3b6ebdb43c.mp3"
	},
	{
		"title": "Hymir’s Cauldron",
		"text": "Thor’s goblet-throwing prize You’d be surprised how few literary examples of goblet-throwing there are. I mean, sure, this sort of thing shows up every now and then in your basic fantasy novel, but history isn’t exactly littered with the shards of goblets broken dramatically at the climax of some great epic tale. Except for one, of course: the Hymiskviða (The Lay of Hymir), a poem that tells the story of Thor’s heroic acquisition of Hymir’s Cauldron. This is the sort of story you read to your kids at bedtime—if you happen to live in Iceland in the year 1300 or thereabouts. For those not familiar with the story, here is an extremely abbreviated and very slightly accurate retelling. Give Me a Cauldron Large Enough, and a Place to Stand… The gods of Asgard were looking for an eternal source of mead, and they demanded that Ægir, god of the sea, provide it for them. Ægir, unhappy with the tone of their request, said he’d only do it if the gods could supply him with a cauldron large enough, such enormous vessels being rather scarce. Tyr, the god of war and justice, knew just where to obtain such an item: his father, the giant Hymir, had one that was “a league deep” (that would be about three and a half miles—certainly large enough to keep the gods drunk for a few millennia). But Tyr knew his father wouldn’t acquiesce easily, so he enlisted the aid of Thor, the god of thunder, to trick Hymir into parting with the giant cauldron. Thor and Tyr went together to visit the bellicose Hymir. After braving their way through a variety of adventures, including a fishing trip during which Thor managed to catch two whales, Hymir still was not warming to his guests. He taunted Thor by saying, “Sure, you may be able to row a boat well, but if you’re really strong you should be able to prove it by breaking this glass goblet.” Thor threw the goblet against a stone pillar, but the goblet remained intact while the pillar shattered. Hymir’s wife whispered a word of advice to Thor: “Try again; this time, throw it at Hymir’s head, which is much harder than any goblet.” Thor did as he was told, and the goblet broke. Hymir was upset that his goblet was broken, but nevertheless conceded that Thor had outwitted him, and offered him the great cauldron as his reward—provided, naturally, that he could carry it. Although Tyr couldn’t budge the cauldron, Thor handily carried it away. But the two gods had not gotten far when they turned to see Hymir following them with a band of his multi-headed henchmen; apparently he’d had second thoughts about letting go of his prized possession after all. Thor set down the cauldron, dispatched the pursuers with his trusty hammer, and then resumed the journey home. All’s Well that Ends with Infinite Quantities of Mead The gods were greatly impressed when Thor and Tyr returned with Hymir’s cauldron. Even Ægir changed his tune and began cheerfully brewing up mead to last Asgard through the winter. The mead flowed freely, the gods were happy, and they all lived happily ever after, except for those who didn’t. (We are not told how Hymir and his wife got along after that “hard-headed” remark cost him his cauldron, but one imagines the incident led to marital discord, if not worse. Such matters are, of course, of a more delicate nature than is generally addressed in Norse mythology.) ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/cauldron-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Hymir.825b569c3cb7.mp3"
	},
	{
		"title": "Folk Etymology",
		"text": "I need to say a few words about woodchucks. (First let me pause while you say the rhyme to yourself. Go on, you know you want to. Get it out of your system. Good.) I never understood what the word “chuck” was supposed to mean in the rhyme. Chuck isn’t often used as a verb; when it is, its most common meaning is “to throw” (as in, “Chuck that AOL CD in the trash”). This is naturally not the type of thing we expect a woodchuck to be capable of (as indicated by the counterfactual nature of the question in the rhyme). So the real question is why anyone would have given this animal such a nonsensical name in the first place. (As an aside, woodchuck isn’t the only nonsensical name this animal has. It’s also called a groundhog. Oddly enough, “groundhog” is a fairly literal translation of the Dutch word aardvark, even though aardvarks don’t look anything like hogs. Woodchucks (Marmota monax) are rodents, or more precisely marmots, and are not even distantly related to either aardvarks or hogs. The most salient similarity among the three species is a propensity for burrowing. ) Gimme a W The name woodchuck is derived from a word in one of the Algonquian languages spoken by Native Americans—either the Cree word otchek or the related Ojibwa word otchig. The English-speaking settlers in North America found these words hard to pronounce, so they substituted syllables that sounded more familiar and yet approximated the original sound; hence “woodchuck.” The process of consciously or unconsciously changing the shape of a word to reflect the existing morphemes (minimal units of meaning) in a language is known as folk etymology. This process frequently occurs when one language “borrows” a word from another and the speakers of the borrowing language mishear, or misunderstand the origin of, the original word. English has many examples of folk etymology. Cockroach comes from the Spanish word cucaracha. As with woodchuck, the Spanish word was transformed into English by substituting similar-sounding morphemes: cock (as in rooster) and roach (which at that time was simply the name of a type of fish). There wasn’t anything about a cockroach that suggested “rooster” or “fish,” of course; it’s simply a matter of the sounds fitting. The same thing happened with the word polecat (from French poule chat, a cat that feeds on poultry) and ten-gallon hat (from Spanish galón, a braid). English speakers also mistook a napron for an apron, and even an ewt for a newt. Begging to Differ Closely related to folk etymology (or even, according to some people, a subset of the phenomenon) is a process called back-formation. Back-formation occurs when speakers remove a portion of a word, incorrectly assuming it’s a suffix, to form a new word. For example, the word pea was pease in Middle English, but that sounded like a plural, so the “s” sound at the end was dropped to make a false singular. Similarly, the word emote is mistakenly assumed to be the root of emotion, which is logical enough since\n-tion is a common suffix in English. But in this case, the word dropped whole from French (émotion) into English, so that derivation is erroneous. Other words in English that have been mistakenly created by back-formation include liaise, enthuse, laze, and evanesce. Some back-formed words, however, after enough time in circulation, become generally accepted: donate, sculpt, and even beg (from beggar) fall into this category. A postscript about the woodchuck: The Algonquian words from which “woodchuck” was derived actually refer to the fisher (or wejack), a carnivorous mammal (Martes pennanti) that bears only a superficial resemblance to the woodchuck. So woodchuck turns out to be not only folk etymology, but a misnomer at that. ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Etymology.2b544e245b95.mp3"
	},
	{
		"title": "Halcyon Days. Why tranquility is for the birds",
		"text": "In the western world, December is a month of holidays—Christmas, of course; Boxing Day (except, strangely, in the United States); winter solstice; New Year’s Eve. But it’s especially the month for multi-day holidays. Hanukkah, which usually falls in December, is celebrated for eight days, Kwanzaa lasts for seven days from December 26 through January 1, and the “twelve days of Christmas,” contrary to popular belief, begin on Christmas Day and run through January 5, the day before Epiphany. As a result—notwithstanding all the touchy-feely greeting cards and made-for-TV movies—the waning days of the year are, for most of us, not a time of joyous and peaceful celebration but rather a protracted period of frenzied shopping, chaotic preparations, and harried travel. We long for January so we can finally get some rest. Peace on Earth (or Sea) In the midst of all this commotion, there’s yet another multi-day observance that often falls through the cracks: halcyon days, which begin a week before the winter solstice and end a week after. Halcyon days are not a holiday as such, but more of a mythological tradition. According to legend, this two-week period is associated with unusually calm seas; hence the common meanings of halcyon as “quiet” or “peaceful,” and by extension, “prosperous.” I could not imagine any two weeks of the year less suited to such a description, but the term has been around longer than most of our December holidays. Greek mythology recounts the story of the goddess Alcyone (or Halcyone), daughter of Aeolus, god of the winds. Alcyone married a mortal king named Ceyx, who drowned at sea in a storm. Such was Alcyone’s love for her husband that she threw herself into the ocean after him. Seeing this, the gods transformed Alcyone and Ceyx into birds. Thereafter, Aeolus kept the winds calm on the sea for a week before and a week after the solstice, enabling the birds to build nests on the water and lay their eggs there. The Kingfisher Days The Greek words from which the name halcyon is apparently derived mean, roughly, “sea” and “conceive.” Over the centuries, the term came to refer both to the kingfisher (an actual bird) and to the mythical bird that nested on the sea and mysteriously calmed the winds around the time of the winter solstice. The latter usage extended the story of Alcyone to account for the calm seas considered common in late December, but also eventually gave rise to a belief among ancient sailors that storms could not occur at sea during the halcyon days. Unlike the mythical halcyon, kingfishers (of which there are several distinct species) dig holes to nest in, though the holes are sometimes found on riverbanks and in other spots close to the water. But breeding never takes place in the winter. Nowadays, when we use the expression “halcyon days,” it’s almost always a way of saying “the good old days” or “when life was easy” or “back during the dot-com boom.” More often than not, the expression refers sentimentally to a bygone time that we remember as being much more tranquil and prosperous than it really was, so the mythological origin of the term is rather apt. I’ve never heard anyone speak of looking forward to halcyon days, nor have I ever received a “Happy Halcyon Days” card on December 14. But a few weeks from now when you’re putting away decorations, repairing broken toys, and looking at unpleasant credit card bills, you can look back at these two frenzied weeks of late December and reminisce, “Those were the halcyon days.” ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/Halcyon-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Halcyon.b710e24b294b.mp3"
	},
	{
		"title": "The Wieliczka Salt Mine",
		"text": "Shortly after our article about Salzbergwerk Berchtesgaden was published, I received an email from a reader who wanted to know if I’d heard of an even more interesting salt mine in Poland called Wieliczka. Although I always enjoy receiving suggestions for new topics, I wondered, briefly, just how many salt mines I could reasonably feature on Interesting Thing of the Day in a single week. But after researching Wieliczka a bit, I discovered the answer: at least two. This was simply way too impressive to pass up. Worth Its Salt Located about 10 miles (14km) from Kraków, Wieliczka has been in continuous operation since at least the 13th century, with its first known historical mention dating back to 1044. Over so many centuries, a truly staggering quantity of salt has been removed from this underground mine, with plenty more still left in the deposit. The mine currently occupies nine levels, with a maximum depth of over 1,000 feet (about 325m) and over 180 miles (about 300km) of passages. But instead of simply abandoning all the vast empty spaces formerly filled with salt, miners over the centuries have transformed them into magnificent, ornate chambers—which together form a massive complex that has been likened to an underground city. Wieliczka’s amazing transformation began in 1689. Because it was so inconvenient and time-consuming for the miners to get to and from their place of work, the mine arranged for Catholic services to be held daily inside the mine. In an effort to make the bare chambers feel more church-like, the miners began to carve statues out of rock salt. This led to murals, bas-relief carvings, and other decorative work, until eventually entire chapels were created—with floor tiles, ceilings, walls, altars, and even chandeliers carved entirely from pure salt. The chapels were soon joined by dining rooms, ballrooms, and thousands of other rooms—complementing underground lakes and other natural formations. Pouring Salt in the Wound Wieliczka attracted a certain number of tourists even in its earliest days. As the grandeur and scale of its carved rooms and artwork increased, it became a favorite destination for the rich and famous, a trend that has continued to this day. However, many people visit the mine not merely to look, but for health reasons. An underground health clinic, which has operated off and on since the early 1800s, provides treatment for people with respiratory ailments, allergies, and skin diseases; at one time, soaking in the mine’s brine pools was also considered therapeutic for a wide variety of other ailments. In 1978, the mine was among the first sites added to UNESCO’s World List of Cultural and Natural Heritage. Wieliczka is now one of Poland’s top tourist attractions, with nearly a million visitors per year. Besides touring the mine’s most popular chambers (including a museum, gift shops, a restaurant, and a post office), visitors attend concerts, sporting events, church services, and even weddings inside the Wieliczka mine. But all this attention has also led to considerable damage. Moisture from ventilation systems, visitors' breath, and natural sources has dissolved some of the salt artwork; recent improvements in dehumidification have greatly slowed the decay. However, there is apparently no stopping tourists from licking the walls (a temptation that, I must point out, would never occur to me)—and salt is fragile enough that the mere contact of hands and feet will cause it to erode much more quickly than stone. On the other hand, given the number of paying visitors each year, I imagine that tourism has become considerably more profitable for the mine than the salt itself—reason for a degree of tolerance, even if the mine does occasionally take a licking. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/Wieliczka-saltmine.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Wieliczka.bacdf776c77f.mp3"
	},
	{
		"title": "The Yo-Yo",
		"text": "A recent meeting of our Dreams Group was held at the home of my friend Heather. I was perusing her bookshelves, as is my custom, and a thick volume called Panati’s Extraordinary Origins of Everyday Things caught my eye. I always enjoy learning where things and their names came from, and I thought the book might also provide some useful fodder for Interesting Thing of the Day. Heather graciously agreed to loan me the book. I have a fair number of reference books myself, not to mention several good libraries at my disposal. But more often than not, I end up doing the bulk of my research online, because it’s so much quicker to search the Web than it is to thumb through books. Still—and I’m speaking here as someone who writes for both print media and the Web—I’m strongly biased to trust printed books more than Web pages, because in general, books have much more rigorous editorial standards. A novel, of course, will not be held to the same standard as a textbook or a dictionary, but still, one assumes that a competent editor will at least spot-check facts and verify that the author can produce primary sources to back up any claims, should a question arise. With this implicit confidence, I began flipping through the book and soon encountered an entry for “Yo-Yo.” Excellent. Panati says that the yo-yo originated around 1000 B.C. in China; that it spread from China to Europe where it went by such names as “quiz” (in England) and “bandalore” (in France); that in the 16th century a yo-yo-like weapon was used in the Philippines; and that it was this weapon that American entrepreneur Donald Duncan adapted to create the toy we all know and love. All that sounded pretty interesting, but I wanted a bit more detail, so I turned as usual to the Web. There I found, as I might have expected, a great many histories of the yo-yo, half of which were clearly copied from each other. The other half differed in a great many details—not only with each other, but with Panati. Naturally, this being the Web, citations of primary sources were nearly nonexistent, and I was not feeling disposed to spend days of anthropological research sorting out who was more likely to have been telling the truth. But from what I’ve been able to piece together, I’m sorry to say that of all the sources I consulted, I now have the least confidence in Panati’s book. Thus I would like to assert right here, boldly and confidently, that I am not at all sure where the yo-yo originally came from. You can quote me on that. Tracing the Yo-Yo’s Ups and Downs I was able to glean some useful facts, though they become murkier with age. So let’s start with the present and work backward. For starters, this being the week for serendipitous discoveries, November 2004 marks the 75th anniversary of the Duncan yo-yo. (Happy birthday!) The humble yo-yo is sold in a bewildering array of shapes, sizes, and designs—some of which include high-tech mechanisms ranging from ball bearings that reduce friction on the axle to a centrifugal clutch that enables the yo-yo to “sleep” (spin in place at the end of its string) and then snap back up just before it runs out of energy. The famous Duncan brand is now owned by the Flambeau Products Corporation, which bought the rights to the name from Duncan’s bankrupt company in 1968. But plenty of other manufacturers also make toys called yo-yos; in the United States, Duncan had lost the right to use the word as a trademark in 1965. (And in fact the legal battle over that issue contributed to the demise of the company. ) Duncan had gone into production in 1930 after buying out Pedro Flores, an immigrant from the Philippines who brought the design (and the name) with him to the United States. From 1928–1930, Flores had successfully created a yo-yo fad, partly by organizing contests where yo-yo enthusiasts could show off their skill. The yo-yos Flores made had the string looped around the axle rather than tied to it, enabling the toy to “sleep” (and thus, by extension, making a wide variety of tricks possible). Toys similar in design to the yo-yo, but called by other names, were known in the United States at least as far back as the 1860s, and they were popular in England and France as long ago as the 1780s. Although their popularity waxed and waned, they never truly achieved fad status until Flores began mass-producing them in the U.S. Before the 18th century, though, accounts differ wildly. Clearly something resembling the yo-yo was in use in the Philippines centuries before Flores brought it to America, but whether it was a toy, a weapon, or both is unclear. Some say that the “weapon” theory was based on the fact that some hunters tied vines to a rock before throwing them at their prey in order to facilitate retrieval; I find this connection rather implausible. A Greek painting made around 500 B.C. depicts a boy holding something that looks very much like a yo-yo, and spindle-like artifacts that match this description have been found that date from around the same time. However, no one can say with complete certainty how or why the proto-yo was used in ancient Greece. Similarly, toys matching the general description of the yo-yo did exist around 1000 B.C. in China, though details of their use are even harder to come by. And I have seen no convincing account of if, or how, the yo-yo traveled from China to Greece or to the Philippines; it is entirely possible that the design evolved independently in several different parts of the world. And the very least plausible claim I’ve encountered—in several places—is that the yo-yo is the second-oldest toy in the world (the doll being the first). What about marbles? Or the top? Panati (to the extent I’m still willing to trust him) claims that both date back to about 3000 B.C. Even if he were off by a couple of millennia, either of these could still be an earlier toy than the yo-yo. Just Say Yo Perhaps, I thought, the etymology of the word “yo-yo” would reveal something about the toy’s origin. Merriam-Webster’s Collegiate Dictionary states that it “probably” derives from the Ilocano word yóyo, while allowing that cognate words appear in other Philippine languages. Almost every other source I consulted (including Panati’s Extraordinary Origins of Everyday Things) said that “yo-yo” was a Tagalog word, supposedly meaning “come-come” or “return.” Knowing that the word originated in the Philippines, Tagalog is a reasonable guess, since it’s the nation’s official language—but there are hundreds of others, including Ilocano, and I was not able to corroborate the claim of a Tagalog origin. One Tagalog-English dictionary I checked said that yoyo is slang for “wristwatch” or “timepiece”; another helpfully translated it as “toy.” While I have no doubt that Pedro Flores grew up calling the toy a “yo-yo,” I don’t know what his native language was. In addition, it’s possible that the term was a regional or slang expression that simply didn’t make it into the dictionary. So there you have it: a laundry list of everything I don’t know about the yo-yo. In fact there’s one more little thing I don’t know—how to do any tricks. Sure, I had yo-yos as a kid—including the kind that light up—and sure, I read the instruction booklets and tried to learn the moves. But I could never quite get the, uh, hang of it. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/yoyo-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Yo-Yo.d52d8f3fe308.mp3"
	},
	{
		"title": "The Trapeze",
		"text": "The world’s first trapeze performance took place in Paris on November 12, 1859. On that date at the Cirque Napoleon, Jules Léotard amazed the audience by swinging through the air on his new invention. The trapeze has been a staple of circus performances ever since. Circus Circuit I’ve never been much for conventional circuses—maybe clown humor is too sophisticated for me, or maybe I sense that those trained animals could be doing something more natural than balancing on giant balls or jumping through hoops. But I’ve never failed to be impressed by Cirque du Soleil, whose shows are mainly about highlighting human strength, skill, and artistic ability—along with wonderful music and costumes. The first time I saw their show “Mystère” in Las Vegas, I thought it was the most amazing performance I’d ever witnessed. When they added a second permanent show, “O,” just a few doors down the Strip, I started wondering how many Cirque du Soleil shows one city could possibly support before reaching the saturation point. Now I know the answer: at least five (but the city keeps growing, so you never know). But I digress. One of the attractions that keeps people going to the circus—and enables Cirque du Soleil to expand its empire endlessly—is a deceptively simple apparatus known as the trapeze: a horizontal bar hanging from a pair of ropes or cables. Before Jules Léotard came up with this idea, circus performers sometimes walked tightropes and swung from fixed bars. Merely becoming a human pendulum, of course, is not the interesting part—it’s doing things like jumping from one swinging bar to another in midair, with maybe a couple of somersaults in between. The whole notion of jumping, falling, or flying freely through the air high above the ground is what terrifies and delights audiences. The Trend Setter That 1859 debut trapeze performance, on a rig with three trapezes, lasted 12 minutes and featured the first midair trapeze somersault. Léotard, whose father, Jean, was a gymnastics instructor, invented not only the trapeze apparatus and technique, but also the garment typically worn while performing on it: the eponymous leotard. Although it is sensible enough not to wear loose or restrictive clothing while performing acrobatics high above the ground, Léotard was apparently just as interested in showing off his muscular physique. Léotard himself called the garment a maillot, the word that would later come to mean “swimsuit” in French. In retrospect, this was an apt term: although there was no safety net during the performance, Léotard had developed his act while practicing on trapezes suspended over a swimming pool. Léotard was the inspiration for the song “The Flying Trapeze,” written by George Leybourne in 1868. Although I’ve seen at least half a dozen different versions of the lyrics, the chorus goes approximately like this: He’d fly through the air with the greatest of ease, That daring young man on the flying trapeze. His movements were graceful, all girls he could please And my love he purloined away. I do not know if Léotard, in his skin-tight costume, did in fact purloin anyone’s love away, but if so, the romance was brief. Two years after the song was written, in 1870, Léotard died while visiting Spain—not from trapeze-related injuries, but apparently from smallpox. The year of Léotard’s birth is a matter of some dispute (I’ve seen claims ranging from 1838 to 1842), but in any case he was around 30 when he died. Had he lived another year, he would have seen the first safety nets installed under trapeze rigs, which emboldened future performers to attempt flashier and riskier moves. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/06/Jules_Lotard-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/06/Trapeze.f379adc86037.mp3"
	},
	{
		"title": "Charlie and His Orchestra",
		"text": "My son, Ben, plays trombone in his school’s jazz band. I think this is very cool—and in fact I’m a bit jealous, because I never got to be in jazz band when I was his age. As a trumpeter, I just wasn’t good enough. Later I switched to baritone horn and got a bit better as a musician, but the baritone wasn’t one of the instruments needed in the jazz band. Although it would be a stretch to refer to the music my junior-high jazz band played as true jazz, I certainly found it more interesting and more moving than the stuff the concert band played. And in some sense, that’s the point of jazz: to inspire a visceral reaction, an unfiltered, direct emotion. Never was this more true than during the early days of the 20th century, when jazz was young, new, and shockingly unconventional. This American invention was outrageously popular not just in the United States, but also in other parts of the world—including places where English was not the primary language. In the 1930s and 1940s, German residents were just as enamored of jazz as everyone else, but Nazi leaders saw it as much more than mere entertainment: they saw it as a threat. For one thing, the Nazis felt that jazz lyrics encouraged a level of sexual permissiveness that was at odds with the standards they set. But more deeply, jazz represented the enemy—both literally, in the sense of its being American, and figuratively in the sense that its African roots made it racially degenerate, an offense to Aryan purity. To enjoy jazz music was to thumb your nose at the Nazi cause. There were also those who claimed that American Jews were behind the whole jazz movement, and the Nazi anti-Semitic rage only added to their distrust of jazz. It Don’t Mean a Thing if You Ain’t Got that Swing So Hitler’s government tried repeatedly and in various ways (though with mixed success) to outlaw jazz. Playing, listening to, or owning recordings of jazz music was made illegal—and that included listening to jazz from abroad on a shortwave radio. The very worst form of jazz, from the Nazi perspective, was swing, which was especially popular among young people. As shown in the 1993 film Swing Kids, German youth frequently used swing music and dancing as their outlet for rebellion—in this case, rebellion against the Nazi values in general and the Hitler Youth in particular. Many of the young people who were caught at covert swing parties were sent to concentration camps. But, of course, every attempt to wipe out swing just galvanized its fans further. The surest way to make something desirable, after all, is to forbid it. This much of the story is relatively well known. But there was another side to the swing phenomenon in Nazi Germany. Just as the government was doing its best to stamp out swing domestically, it was secretly using its very own swing band to spread propaganda abroad. Josef Goebbels, Hitler’s propaganda minister, was already in charge of radio broadcasts to the U.S. and Britain intended to demoralize and confuse the public, if not actually arouse pro-Nazi sympathy. Hitler suggested that these broadcasts should include music, just as comparable anti-Nazi broadcasts by the allies did. So Goebbels took it upon himself to assemble a group of talented swing musicians who could discreetly put Hitler’s message to toe-tapping music. The group was headlined by singer Karl Schwedler, who anglicized his name to “Charlie.” Along with an array of instrumentalists, including conductor Lutz Templin, he began recording in 1940, and shortly thereafter the group became known as “Charlie and His Orchestra.” Close Enough for Jazz The group’s primary M.O. was to take well-known American swing tunes and alter the lyrics—often after the first verse so that listeners didn’t catch on to the deception immediately. These alterations, which ranged from subtle to blatant, included criticisms of American and British leaders, anti-Semitic messages, and other dispiriting comments. Schwedler’s English was excellent, and since the Nazis were careful to conceal the source of the broadcasts, their hope was that American and British listeners would enjoy the music, start singing along, and with any luck actually believe some of what they were singing. But of course, while making the music freely available overseas, the Nazis did their best to keep it from the German public. Despite the pro-Nazi lyrics, the government could not be seen promoting a form of music it had gone out of its way to repudiate. So although all swing music was forbidden to Germans, the music of Charlie and His Orchestra was the most forbidden, with extremely severe penalties for those caught listening. Naturally, this increased the band’s popularity within Germany. It’s OK, I’m With the Band The band members themselves, curiously enough, were not particularly sympathetic to the Nazi cause. Schwedler may have been in it for the money, and some of the band members, who spoke little English, would later say they did not even realize what the lyrics said. But playing in the band paid well and exempted the members from military service. More importantly, it may have saved the lives of some members. Drummer Fritz Brocksieper, for example, had a Jewish grandmother, and so would have been considered Jewish according to Nazi reckoning. Also curious is the fact that the group developed a significant following among Americans who were exposed to their music. This either says a lot for their music or very little for their lyrics—but in any case, the propaganda was clearly ineffective. The individual members of Charlie and His Orchestra went on to successful careers in music after the war, their unique songs all but forgotten once the authentic originals were again in free circulation. All in all, not a bad gig for a bunch of musicians who found themselves on the wrong side of a war. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/05/Trombone.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/05/Charlie.3422c5d5eac1.mp3"
	},
	{
		"title": "Foucault’s Pendulum",
		"text": "Science museums are among my favorite places to visit. In probably a dozen or so museums in several different countries I’ve seen an exhibit called “Foucault’s Pendulum,” in which a heavy weight, suspended from the ceiling by a wire, very slowly changes direction over the course of a day, knocking over a small peg every hour or so or tracing patterns in sand. I was vaguely aware that this was supposed to have something to do with the rotation of the planet, but I never really understood what that was. And to be perfectly honest, I always thought that watching a pendulum swing for an hour so was about as exciting as watching wheat grow. Then, in the early 1990s, I read Umberto Eco’s novel Foucault’s Pendulum. The novel has little to do with the pendulum as such, but some of the characters muse over its philosophical implications, and the climax of the story takes place at the site where the original pendulum is now hanging—the Conservatoire des Arts et Métiers (Conservatory of Arts and Trades) in Paris. Eco’s story piqued my interest, and while vacationing in Paris I decided to visit the Conservatoire and look a little more deeply into the science and history of the real Foucault’s Pendulum. Getting Into the Swing Jean Bernard Léon Foucault was born in Paris in 1819. He had planned to study medicine, but eventually realized he was too squeamish to deal with blood, so he turned his attention to less organic branches of science. In the mid-19th century—and for that matter, for most of history up until fairly recently—scientists did not confine themselves to a single, narrow specialty. Foucault was no exception in this regard; although he spent most of his career studying optics and astronomy, he was also responsible for major discoveries in chemistry, electricity, and magnetism. But the invention for which Foucault is best known is his pendulum. In 1848, Foucault noticed something extremely surprising about a swinging pendulum. Even if you turn the point from which it is swinging, the pendulum continues to swing in the same direction. You can try this experiment yourself with a yo-yo (or, say, a computer mouse—as long as it’s not wireless). Tie the string or cable around a finger, hold your finger out at arm’s length pointing at some handy spot in the room, and set the weight swinging in a straight line. Now take a step or two in an arc so that your finger points at something else, and notice that the weight’s swing hasn’t changed direction, even though the point from which it was suspended has turned. Foucault thought this curious behavior of pendulums—their refusal to be bothered by the position of their point of suspension—might be used to make a stunning visual proof of Earth’s rotation. The Pendulum and the Planet By Foucault’s time, the rotation of the Earth was no longer in dispute, but there was still no direct way to demonstrate or measure it. Foucault reasoned that if he hung a pendulum from a fixed point and the direction of the pendulum’s swing appeared to change, that could only be because the Earth itself was moving underneath the pendulum. Over the course of a 24-hour day, if his theory was correct, a pendulum should trace out a complete circle—at least, it would if it were located at the north or south pole; at the latitude of Paris the offset would amount to a circle every 32 hours or so. (At the equator, incidentally, this experiment would not work at all. ) There was a complication, though. Because of the effects of air resistance, gravity, and friction, a swinging pendulum will eventually come to a stop, and in order to demonstrate the rotation of the Earth, it needed to swing for a significant period of time—at least an hour or two. To increase the inertia of a pendulum, and therefore the amount of time it will swing without stopping, you can increase either the length of the wire, the mass of the ball at the end, or both. So Foucault hung an 11-lb. (5kg) ball at the end of a 6-foot (2m) wire in his basement, and sure enough, before it stopped swinging the angle had rotated slightly clockwise. Foucault then repeated the experiment with a much longer, 36-foot (11m) wire in the Paris Observatory, and the effect was again just as he had predicted. In 1851, he constructed an even grander, 220-foot (67m) pendulum in the Panthéon in Paris, and held the first public demonstrations, promising the crowds they would “see the Earth go round.” Sure enough, the giant pendulum made a slow but predictable clockwise motion. Later, Foucault tried the same test with a spinning (rather than swinging) weight. It worked, and this led to his invention of the gyroscope. Fixed Points and Local Motion There is, however, even more to Foucault’s pendulum than the brilliant proof of the Earth’s rotation. The experiment works because the pendulum is hanging from a fixed point. Or is it? If you think about it, the building from which the pendulum is suspended is moving along with the Earth, which is in turn rotating around the Sun. The Sun, too, along with the rest of the solar system, rotates around the center of the galaxy, and so on. So it’s really not correct to think of the bracket on the ceiling as being a fixed point. And yet, curiously, it’s not just movement of the attachment point that the pendulum ignores—it ignores the movement of the planet and even the galaxy. The swing of the pendulum remains aligned with, apparently, the universe itself—or, to make it more comprehensible, think of it as being aligned with some very distant star. So the pendulum acts as if it’s hanging from some absolutely fixed location deep in the center of the universe. Whether this is simply an illusion or a deeply meaningful metaphysical discovery is still a matter of some debate among the few scientists and philosophers who worry about that sort of thing. The pendulum Foucault originally used in 1851 at the Panthéon was moved in 1855 to the Conservatoire des Arts et Métiers in Paris. The Conservatoire includes a public museum, part of which is housed in a building that was once a church. The pendulum hangs from the ceiling of the choir, and is the museum’s star attraction. For several years during the 1990s when the museum was undergoing renovations, the pendulum was temporarily exhibited at its original home in the Panthéon, but was returned before the museum reopened in 2000. In order to show the movement of a pendulum over longer periods of time than inertia will provide—and to satisfy museum-going crowds—most modern exhibits of Foucault’s Pendulum, including the one in the Conservatoire, use an electromagnet under the floor or platform beneath the pendulum to give it a tiny extra boost as it swings past. When I first heard about the magnets, it sounded like cheating to me—the image I had in mind was of moving magnets that influenced the direction of the swing. But in fact the magnets are circular and simply pull the pendulum very slightly toward its vertical center just as it approaches the middle of each swing, so the direction of the swing is unaffected. That in itself, I think, is a very clever piece of engineering. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/05/Foucault_Pendule.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/05/Foucault.af70926cb458.mp3"
	},
	{
		"title": "The Great Clock of Westminster",
		"text": "And now for something slightly different. Last year on my first-ever visit to London, I took in many of the standard tourist attractions—dutifully snapping photos, reading the histories in the guide books, and so on. But I quickly realized that there was a disconnection between the kinds of things I find interesting and the kinds of things most tourists find interesting. Take Big Ben, for example. You can’t go to London without seeing (and hearing) Big Ben. It’s just one of those things. (And it’s a rather prominent feature of the skyline, too, so it would be difficult to avoid seeing even if you wanted to.) So we saw Big Ben. But other than having heard about it in children’s songs and stories since I was young, I couldn’t figure out what I was supposed to be so excited about. I’ve seen clocks. I’ve heard bells. Here’s one that’s larger than average. So? It was not until well after I returned that I discovered a whole list of facts about Big Ben I hadn’t previously known. Although individually these facts are not extraordinarily impressive, I think that collectively they are rather interesting. If my British readers, for whom all of this is probably old news, will forgive me, I’d like to present a sampling of interesting things about the world’s most famous clock tower. * The part and the whole: For starters, contrary to common usage, Big Ben is actually the nickname of a single bell—not the clock itself, the tower in which it is installed, or the building of which the tower is a part. The building is the Palace of Westminster, commonly known as the Houses of Parliament. The clock tower of the Palace of Westminster (a catchy name if I ever heard one) houses the clock—officially known as the Great Clock of Westminster. It has four faces, one very large bell, and four smaller bells. The largest bell, which chimes on the hour—and which, by the way, is not visible from the outside of the tower—is the Great Bell of Westminster, or Big Ben for short. It was cast in 1856 and is one of Britain’s largest bells, at 9 feet (3m) in diameter. * For whom the bell is named: According to most accounts, Big Ben was named after Sir Benjamin Hall, Commissioner of Works at the time of the bell’s construction. Sir Benjamin was a large man, and so the nickname seemed appropriate given the size of the bell. However, others say the clock was named after champion boxer Benjamin Caunt. In either case, it was a man named Benjamin who had the nickname “Big Ben” first. * Cracks and replacements: The original specification for the clock had called for a bell weighing 14 tons. The foundry, however, made a much larger, 16-ton bell—which cracked during testing. So a different foundry was selected, and the original bell melted down as raw material for a second bell, which weighed 13.8 tons. This bell was thoroughly tested before being installed in the clock tower. After just one month in operation, though, the new bell also cracked—though not as severely as the first. The crack was filled, a lighter clapper installed, and the entire bell rotated so that the clapper struck an undamaged portion of the bell. This arrangement has survived ever since, but the crack affected the character of the bell’s tone as well as the pitch, which was originally an E. * The Liberty Bell connection: Whitechapel Foundry, where the (second and final) bell was cast, had also cast the Liberty Bell—which cracked on its first public ringing—almost exactly a century earlier, in 1752. By yet another coincidence, the Great Clock of Westminster famously broke down in 1976, the U.S. bicentennial year, requiring major reconstruction. * Accuracy: The Great Clock of Westminster is one of the largest mechanical clocks in the world—and, to this day, one of the most accurate. Its original specification stipulated that the first ring of the clock each hour should be within one second of the correct time. The leading clock designers of the day considered that an unreachable goal, because the hands and other exposed parts were subject to the action of wind, moisture, temperature changes, birds, and other variables that could easily throw off its accuracy by more than a second. However, after winning a design competition, Edmund Beckett Denison was hired to design the clock, which did in fact obtain the specified accuracy. When minor adjustments need to be made to regulate the clock’s speed, pennies are placed on the clock’s pendulum to alter its weight slightly. Those who investigate the history of the clock’s design and operation will find many other fascinating facts, including any number of controversies and scandals that emerged during the years of its construction…and the presence of a prison cell in the clock tower, intended to hold Ministers of Parliament who have breached parliamentary privilege (though it has not been used for this purpose in over a century). All that to say, Big Ben is very much more than an oversized clock bell, but its most interesting features, like the bell itself, are nearly always hidden from public view. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/05/Big-Ben-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/05/Westminster.c3d5493d1c46.mp3"
	},
	{
		"title": "Demosthenes’ Stones",
		"text": "It's a good thing I had never heard of Demosthenes when I was a child. I would have gotten in trouble. My mom would have said, “Don't talk with your mouth full.” And I would have replied, “Don't you want me to be a famous orator like Demosthenes? I'm training!” And then I would have been sent to my room without any more of whatever my mouth was full of. Kids, this is why grownups are always saying things like, “You're too young to understand. Just take my word for it.” It's for your own good. And if you get in trouble for talking with your mouth full, don't say I didn't warn you. Repeat After Me Even as an adult, I get in trouble over Demosthenes. A while back, Morgen and I were watching “My Fair Lady” on TV. For those unfamiliar with the story, a linguistics professor in London named Henry Higgins makes a wager with a friend that he can rid a working-class girl, Eliza Doolittle, of her Cockney accent and teach her to speak like a proper lady. In one of his many drills, he insists that Eliza fill her mouth with marbles and then read a series of phrases. So of course I said, “Oh, just like Demosthenes.” Morgen gave me one of her patented looks that means “How do you expect me to know these obscure facts if I don't read about them on Interesting Thing of the Day?” I was tempted to respond with a look that meant “Oh come on, everybody knows about Demosthenes,” but I opted instead for the path of marital concord. After all, one shouldn't look a gift topic in the mouth. Appropriately enough, Demosthenes had a name that, for many English-speaking people, is a tongue twister. I have always pronounced it “di MAHS thə neez,” which is what my trusty dictionary says. However, no less an authority than Demosthenes Spiropoulos, proprietor of the Web site WorldOfDemosthenes.com, says: “The name is pronounced: Dee-moss-sta-kness.” So take your pick; I suppose it depends on how authentically Greek you want to sound (which, in my case, is not at all). Speaker System The story is this. Demosthenes lived in Athens from 384 B.C. to 322 B.C. As a young man, he suffered from a speech impediment—which may have been a stutter, an inability to pronounce the “r” sound, or both. He designed a series of exercises for himself to improve his speech. According to legend, he practiced speaking with stones in his mouth, which forced him to work very hard to get the sounds out. When his diction became clearer, he got rid of the stones and found he was able to enunciate much more effectively than before. He also practiced reciting speeches while running and speaking over the roar of ocean waves to improve his projection. These strategies must have worked, because Demosthenes achieved fame as the greatest orator in ancient Greece. He is best known for his passionate speeches urging the Greek citizens to defend themselves against invading Macedonian king Philip II. Naturally this story is repeated often with a moral of “work hard, be persistent, and you will succeed.” Alas for Demosthenes, historical acclaim is all he got for his efforts. His speeches, though popular and well-received, did not prevent Greece's conquest by Macedonia. Shortly thereafter, Demosthenes was falsely accused of taking a bribe and sent to prison. He escaped, but remained in exile until Alexander the Great died. Demosthenes then returned to Athens and once more tried to lead a popular uprising. He failed again, but not without attracting the attention of the authorities. When he learned that he faced imminent capture and possibly death, he committed suicide by taking poison he had long kept hidden in a pen. Tragic though his end was, the story of Demosthenes' dramatic forensic achievements continues to inspire speakers to this day. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/05/Demosthenes-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/05/Demosthenes.25ca76f030de.mp3"
	},
	{
		"title": "The Globe Theatre",
		"text": "In my senior year of high school, all the students in my English class were required to write two term papers. But two of us were granted a special exception. The teacher gave my friend Nick and me the option of handing in alternative projects in lieu of the second paper. In my case, I had written a funny yet tragic account of an unhappy relationship—I use the term loosely—that I had experienced the previous summer. I was writing it just for fun, but my teacher found out about it and said I could type it up and turn it in as my second essay. I did—and got an A, too. Nick was the only student in class who was not required to type his term papers. As long as I'd known him—since kindergarten—he had said he wanted to be an architect. And he had developed an architect's handwriting: every letter perfectly formed. The teacher's offer to Nick was that he could build a scale model of the Globe Theatre out of Popsicle sticks instead of handing in a second paper. He declined, and I always thought that was a pity. We had learned about Shakespeare's famous London venue in class, and I would have loved to see what it looked like. Besides, I couldn't imagine that writing a term paper would have been more fun—but maybe that was just me. I was thinking about this last year when I visited London for the first time. I had heard that the Globe Theatre, destroyed centuries ago, had recently been rebuilt, and I was eager to see it. I didn't particularly care if I saw a play there; I just wanted to go inside and look around. When we got to the Globe, on the afternoon of our last day in London, they had just admitted the last tour group of the day; the only way left to see it that day was to buy tickets for a play. The box office informed us that the show was almost sold out. There were two options: we could buy either fabulously expensive tickets for seats behind a pole that would obscure our view, or cheap tickets for standing room. We debated which option we'd dislike the least, but by the time we had made up our minds two minutes later, all the remaining tickets for the day were gone. So all I got to see of the Globe Theatre was the outside, the gift shop, and the ticket office, none of which was especially impressive. (Note to self: plan ahead next time. ) I take some consolation in the fact that this combination of comedy and tragedy would probably have delighted William Shakespeare, or whomever it was that wrote the works attributed to him. Building and Rebuilding The original Globe Theatre was built in 1599 on the south bank of the Thames in London's Southwark district. The 1599 Globe was not an entirely new building, however. Shakespeare's troupe had been performing in another theater across the river (called simply The Theatre), but because of the high cost of leasing the land on which The Theatre was located, it was dismantled; the pieces were moved across the river and reassembled, then dubbed The Globe Theatre. Not only was the Globe the primary venue for many of Shakespeare's plays, he specifically wrote many of them for that theater. The original Globe burned to the ground in 1613, after a cannon went off during a production of Henry VIII and a spark ignited the thatched roof. The Globe was rebuilt within a year, however, and continued to operate until 1642, when it was closed (along with the rest of London's theaters) by the Puritans who found it morally objectionable. In 1644, 28 years after Shakespeare's death, the Globe was demolished. Only a few rough sketches of the Globe survived over the centuries, but based on archeological evidence, texts, and other sources, it has been possible to make some fairly reliable educated guesses about the details of its construction. The original Globe apparently had 20 sides, making it appear almost circular. The central part of the theater was open to the sky; seating was provided in a three-story, covered gallery around the outside. But many theatergoers stood in the central court in front of the stage to watch performances. The audience was expected to interact with the actors in Shakespeare's time, though in many cases they simply wandered in and out, eating, drinking, and talking with the play going on in the background. Return of the Globe In 1996, after almost three decades of planning, a new replica of the Globe—built by hand using authentic materials and construction techniques—reopened in London not far from the site of the original. The designers' goal was to make the new Globe as similar as possible to the first one, making concessions only as necessary to comply with fire regulations. The replica of the Globe Theatre in London is just one of many around the world, but it is undoubtedly the most historically accurate. As in the early 1600s, actors perform without amplification, spotlights, backdrops, or other scenery, and with only a minimum of props. The new Globe represents not just the reconstruction of a historically significant piece of architecture, but a way to relive the entire experience of live drama in the 1600s. All the world may be a stage, but if you want to see Shakespeare as the author intended, this particular stage is the best. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/05/theatre.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/05/Globe.1279e95f761d.mp3"
	},
	{
		"title": "Bahasa Indonesia",
		"text": "During college I spent a summer in Indonesia, and naturally I picked up a bit of the language. When I say “the language,” I’m referring to Indonesian or, as it is known in Indonesian, Bahasa Indonesia (“language of Indonesia”). This statement is not as obvious as it may sound; Indonesia is home to hundreds of languages, and of these, Indonesian is not spoken as a first language by the majority of the population. But it is the lingua franca, so it’s useful for citizens and travelers alike. I found Indonesian to be very straightforward and easy to learn, free of most of the irregularities and annoyances of the Romance languages. What I understood at the time was that Indonesian is, for the most part, the same language as Malay (Bahasa Melayu), the national language of neighboring Malaysia. I assumed that there were some differences, but that the main one was simply the name. I had no idea at that time of how either version of the language came into existence. It turns out that there’s a bit of a modern myth about the language’s origin—but the truth is even more interesting. Artificial Intelligence Several months ago while doing some research on an unrelated topic, I stumbled upon a Web page claiming that Indonesian was an artificial language. I’d never heard that before and it piqued my interest, so I searched further. A few minutes of Googling turned up quotes such as the following (identities omitted to protect the guilty): Bahasa Indonesia is an artificial language made official in 1928. By artificial I mean it was designed by academics rather than evolving naturally as most common languages have. …Indonesian [is] a very simple Malay-based artificial language, designed by academics, and was the official language for a multiethnic country of over 230 million inhabitants. …Indonesian is a constructed language made by a Dutch missionary in the 1920s on the basis of synthesizing some local languages. …[Indonesian] was devised by a Dutch linguist, based on various Malayan and Indonesian varieties…in the 1920s. The language in Malaysia, Bahasa Malay, is a constructed language, and was designed to be easy to learn, as the various people in Malaysia and Indonesia who were told to form rather large nations after WWII needed a common language. …every language is artificial—it just depends how many people create it. Bahasa Indonesia is also invented but by a group. Bahasa Indonesia is essentially a constructed language designed to fool foreigners into thinking Indonesia is a monoculture. …the other major semi-artificial language of recent times, Bahasa Indonesia, the national language of Indonesia, is a syncretic amalgamation of existing Malay dialects that were still in current use. Even though it is basically the Malay language, [Indonesian] has in common with Esperanto…the fact of having underwent [sic] a kind of planned restructuration to simplify grammar and reduce exceptions. With all that evidence, I was very nearly convinced—though I wasn’t entirely certain what I was convinced of. This string of claims sounded a bit like the telephone game, where a message changes just a bit with each retelling. Then a little voice in the back of my head whispered, “Primary sources, Grasshopper.” Every fact on the Web appears to be equally authoritative, but just because somebody says something with conviction doesn’t mean it’s true. So I went to an actual library (two of them, in fact) and looked at ancient documents known as “books”—some more than fifty years old—to see if I could get to the bottom of this story. After all, if a Dutch linguist (or missionary) did in fact invent the language, I should be able to find that person’s name. And if a committee of academics invented it, I should be able to find some record of that momentous project. Let me cut to the chase: as with all myths, this one has a kernel of truth to it. But the claim that Indonesian is an “artificial” or “constructed” language is simply untrue. This Land Is Your Land, This Land Is Island Indonesia is an archipelago consisting of over 18,000 islands, of which about a third are inhabited. That these islands—and their greatly varying cultures and languages—should be considered a single nation is a relatively recent (and, ethnographically speaking, artificial) notion. Nevertheless, for centuries, traders sailing from one island to another have needed to communicate with each other. Malay was the local language of Malacca, a port town near the southern tip of the Malaysian peninsula. According to legend, local fisherman in Malacca developed Malay as a synthesis of several nearby languages in the late 16th century. However, written records of Malay date back as far as the 7th century, so it is more likely that the fisherman simply integrated new words into the language. (Such borrowing happens in virtually all languages, and the newly incorporated words are known as “loan words.”) In any event, Malacca was a hot spot for traders, and by the time the Dutch colonized Indonesia (then known as the Dutch East Indies) in the 17th century, Malay had already come into widespread use as the regional trade language. During their more than three centuries of occupation, the Dutch, unsurprisingly, attempted to enforce the use of their own language for trade. In the process, Malay—as spoken in Dutch territory—picked up a number of Dutch loan words, while the Malaysian speakers of Malay developed a somewhat different vocabulary. Meanwhile, due to the influence of Islam, which had been introduced in Indonesia as far back as the 13th century, Malay also picked up a number of Arabic loan words. Because parts of Indonesia were Hindu, Sanskrit also gave numerous words to Indonesian—including “bahasa” (“language”). And since Portugal traded in Indonesia and for many years controlled East Timor, many Portuguese words also found their way into the language. In short: without question, the Indonesian variety of Malay did indeed borrow heavily from numerous other languages, but this was a natural linguistic evolution. However, there’s still more to the story. The Language of Change By the 1920s, public sentiment in Indonesia was turning strongly toward gaining independence from the Netherlands. In October 1928, the Sumpah Pemuda (Pledge of the Youth) proclaimed that in Indonesia, Malay was to be called “Bahasa Indonesia” and considered the national language. However, there being no nation as yet, this was more of a rallying cry than anything else. In 1945, Indonesia declared its independence from the Netherlands and stated in its constitution that Bahasa Indonesia was its official language—though it took four years of fighting before the Dutch acknowledged Indonesia’s right to self-rule. So depending on how you look at it, Indonesian became the official language in 1928, 1945, or 1949—though at that time, only a tiny percentage of the nation’s population spoke Indonesian as a first language. Following independence, the people of Indonesia rapidly abandoned Dutch (to the extent that they had grudgingly adopted it) and began to embrace their new official tongue. It is now the first language of as many as 30 million people, and a second language for more than 140 million. Although these numbers are still small given Indonesia’s total population of more than 230 million, they represent astonishingly rapid growth for the language. In 1972, the governments of Indonesia and Malaysia collaborated on a project to reform and simplify spelling for both versions of the language; this consisted largely of eliminating Dutch spellings in favor of more phonetic Malaysian spellings. Malay and Indonesian have about an 80% overlap in vocabulary and are mutually intelligible; the variations in vocabulary, pronunciation, and usage have been compared to the difference between American English and British English. Where Indonesian retains many Dutch loan words, Malay typically replaces these with words based on English. I like Indonesian a great deal; it has such an elegant structure that it’s tempting to believe it could only have been made artificially. But in fact it’s as natural as the next language, notwithstanding its exceptional capacity for absorbing foreign vocabulary—and contributing to linguistic mythology. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/05/Bahasa-Indonesia.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/05/Bahasa.b404b9c8e670.mp3"
	},
	{
		"title": "The Equation of Time",
		"text": "When someone asks me how I’m doing, I habitually answer, “Fine,” because that’s what social convention dictates—whether or not I really am fine. Most people probably don’t want to hear the detailed truth, and would be sorry they asked if I told them. Similarly, when people ask what I do for a living, more often than not they’re looking for a quick and easy way to categorize me, rather than a litany of the sundry and somewhat unconventional means by which I earn a living. So I tend to oblige with a short answer that requires no further discussion. One day, however, I was at a party, and being in an uncharacteristically charitable mood, I decided to tell people what my occupation really is. One guy I spoke to—let’s call him “Bob” (for that is his name)—seemed particularly intrigued by the notion of Interesting Thing of the Day. He scribbled down the URL and promised me he’d send me some suggestions for topics to write about. A few days later, Bob sent me a link to a news article that led off with the following tantalizing claim: “Now we may know why the South lost the Civil War: Confederate time was about a half-hour slower than Yankee time.” I had heard of famous historical blunders based on confusion over differing calendars, but not over differing clocks. How cool. Time Is On Our Side The article never delivered on the teaser, though. It did discuss the fact that the North and the South used different methods of reckoning time, and it went on to speculate that those differences might shed light on the final moments of a Confederate submarine that disappeared shortly after sinking a Union ship. The time differences had nothing to do with the outcome of the war, but the reason for the differences was quite interesting indeed. The South based their timekeeping on apparent solar time, in which noon is the moment the sun reaches its highest point. This is a sensible enough approach, but it has two problems. First, because of the angle at which the Earth is tilted and the elliptical shape of its orbit around the sun, the interval between noons on two successive days is not identical throughout the year. Although one day may be only a few seconds shorter or longer than the next, the cumulative effect of those extra seconds can mean a difference of nearly 16 minutes over several months. Second, the sun arrives at its apex at a different time depending on one’s longitude, so “noon” on the east coast will be earlier than “noon” on the west side of the state—thus making synchronization tricky. Just an Average Day The problem of irregular day lengths is addressed by the use of mean solar time, in which all days are exactly 24 hours long (based on the average noon-to-noon interval)—at the cost of being somewhat out of sync with the sundial. The North, in addition to following mean solar time, used Washington, D.C. as the reference point for noon. These two facts combined to make Union time about 26 minutes ahead of Confederate time. It was not until 1883 that standard time zones were first adopted (thus eliminating the problem of local variations in mean solar time); they became law in the U.S. in 1918. As for the equation of time, here it is: EqT = apparent solar time – mean solar time. This equation (or a table derived from it) is what you need to use if you have a sundial in your garden, since it will almost always be out of sync with your clocks. If you plot this equation on a graph, it makes a pair of broad curves over the course of a year. On the other hand, if you were to plot the position of the sun in the sky (from a fixed point on Earth) at the same time every day for a year, it would make an asymmetrical figure 8, a shape known as the analemma—the Latin word for sundial. ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/05/Equation.af2ff8cd84ca.mp3"
	},
	{
		"title": "Decimal Time",
		"text": "As an American, I have always been a bit ambivalent when it comes to units of measurement. I learned units like inches, pints, and pounds first, but all through elementary and secondary school, the metric system (or S.I., Système International) was taught, along with dire warnings that we’d better get used to the new measurements because the U.S. was going to be giving up Imperial units Real Soon Now. That would have been fine with me, because I’m fluent in meters, liters, and grams too, and they all make more sense to me than their Imperial counterparts. (Temperature, strangely, is the exception: I can’t seem to switch my brain out of Fahrenheit.) The entire world—excluding us wacky Americans—has come to the sane conclusion that units of measurement based on outdated and arbitrary standards should be abandoned, and that everything should be based on easy-to-calculate units of ten. Everything, that is, except time, the measurement of which requires dealing in inconvenient quantities such as 60, 12, 7, 365, 31, 30, 28, and every so often, 29 and 366. Why shouldn’t time be measured in units of 10, 100, and 1000? Seconds, hours, weeks, and months, after all, are simply arbitrary divisions of days, seasons, and years. Why not divide them up in a decimal-friendly way? And why not choose a system that is inherently immune from stupid computer glitches on the one hand, and free from religious biases on the other? It turns out that there have been numerous proposals to do exactly that. Days (and Years) of Our Lives Let’s back up a bit and consider a few basics. Everyone agrees that time measurements should be based on regular, observable phenomena such as the dependable fact that the sun rises and sets every day, and that the Earth’s position relative to the sun follows predictable, year-long cycles. One could argue that the notion of a “day” having a fixed duration is a bit of a fiction, since the hours of sunlight vary according to season and latitude, but I think most people are content taking an average (i.e., a mean solar day) as the rule. And of course there’s the whole leap year problem, but that need not hold up an entire timekeeping revolution. Though the idea of a “day” and “year” are with us to stay, however, all the other units—seconds, minutes, hours, weeks, and months (and even seasons, depending on where you live)—are arbitrary divisions that are ripe for revision. The first serious attempt to slice up the clock and calendar decimally happened in France as a consequence of the French Revolution. The new government instituted a republican calendar that consisted of 12 months of 30 days each, months bearing names suggestive of the season in which they fell (but only, of course, in France). An extra five days of festivities were added at the end of each year (not part of any month) to make the solar cycle work out. Each month consisted of three “dekades,” or 10-day weeks. New clocks had to be designed and built, too. A day now had 10 hours; hours had 100 minutes, and minutes had 100 seconds. Because the months were not that much different from existing months (breaking the strict unit-of-10 rule), they were relatively easy to get used to. But having a “minute” that was almost a minute and a half long, and an “hour” that lasted almost two and a half hours, was too much. The republican government fought a losing battle to institute the new timekeeping system from 1793 until 1805, when it was finally abandoned. Over the years, numerous other proposals have been advanced for dividing time into units of 10, with the common thread being that there’s always a basic unit of time (whether or not it’s called an “hour”) that lasts 1/10 of a day. To deal with the problem of that being a rather unwieldy period of time, smaller units have been proposed, such as the “centiday” or “decihour,” which would be 1/100 of a day, or about 14 minutes according to current measures. Multiples of 2 and 4 centidays are close enough to current half-hours and hours to give a reasonable means of making mental conversions. Beat It One exception to the “centiday” solution is Internet Time, a standard promoted by Swiss watchmaker Swatch. In Swatch’s system, the day is divided evenly into 1000 units called “.beats”; each .beat lasts 1 minute, 26.4 seconds. Internet Time is designed to be universal, rather than local—so if you say an event is going to occur at @435 .beats (which is how Internet Time is notated), that represents a fixed time that works anywhere in the world. Beat 0 is defined as midnight in Biel, Switzerland, where the Swatch headquarters is located. The downside to the lack of time zones, of course, is that Internet Time has no consistent relationship to the cycle of the sun; you simply have to memorize what .beat range constitutes periods such as “morning,” “afternoon,” and “evening” in your local area—and then recalculate if you travel. This illustrates another problem with any decimalized time system: where and when do you start counting from? By international agreement, all time zones around the world are calculated based on Greenwich Mean Time, that is, the time on an arbitrary line of longitude running through Greenwich, England, that we’ve designated the Prime Meridian. But just as Internet Time measures from a different starting point, any decimal time measurement will have to declare some location as the “starting point,” and either calculate local time zones accordingly or bypass the whole notion of local time as Swatch did and let everyone fend for themselves. Remembering Z Day In decimal time schemes that also deal with weeks, months, and years, there’s an even trickier problem. What should count as day 0? In other words, let’s say decimal dates were represented as YYYY-MM-DD, with more Y’s added as needed. Which date is 0000-01-01? Some would say, sync it up with the Gregorian calendar—but that perpetuates its Christian bias. Others say, pick a date, any date (such as midnight on January 1, 2000 or July 13, 1903) and just deal with it; presumably, events that occurred before that date would have to be represented with a negative number. The notion of decimal time appeals to my sense of logic—though it would appeal more if a year were, say, 100 or 500 or 1000 days long. That would make the math work out much more conveniently. (Some proposals, by the way, try to divide the year up into 100 “days” of about 88 standard hours each, which is better for calculations but considerably worse for human beings.) But if meters and liters are a tough sell in the U.S., metric time is going to be tougher still. Maybe in a century or two…hmmm, century. I guess we use a kind of metric time after all. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/05/decimal-clock.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/05/Decimal.fa42d3f51062.mp3"
	},
	{
		"title": "Body-Based Units of Measurement",
		"text": "Like most guys, I love tools, especially if they’re expensive and so specialized I’ll only use them on rare occasions. Bonus points if they require electricity. My wife, knowing this about me, bought me a groovy little ultrasonic digital laser-guided measuring device as a gift. It even came with a holster. Now I can measure the size of any room (even its area and volume, if I need to) in just seconds. Morgen’s explanation for why she chose this gift was that she was tired of having to hold one end of a tape measure while I dragged the other end across the room. But I think it may have been that she thought I looked extremely goofy using my standard device for making linear measurements: my forearm. Is That a Ruler in Your Pocket? At some point years ago, I picked up the seemingly useless piece of information that an ancient unit of measurement called the cubit was the distance from the elbow to the tip of the middle finger. For an average adult male (at least, average as of a couple of millennia ago), a cubit works out to about 18 inches (45.7cm). Cubits were a standard unit of length in Sumeria, Egypt, and other parts of the Middle East long before anyone dreamed of an arbitrary, decimal-based measuring system. Cubits were most often used in the context of building; if you have an English Bible published before the mid-20th century, it probably lists the measurements of Noah’s ark (among other things) in cubits. Not long after learning this tidbit, I began discovering how useful such a built-in measuring device could be. I don’t always carry a tape measure with me, but I frequently need to estimate whether, for example, a piece of furniture will fit in a certain room. Knowing the approximate length of my arm is surprisingly handy, because it’s extremely easy to use for rough measurements. Hand, Hand, Fingers, Thumb The cubit was just one of numerous units of measurement based on the typical size of body parts. Here are a few more: * foot: It probably goes without saying that the unit foot was based on the length of a man’s foot. * span: Stretch out your hand so that the tip of your thumb is as far away as possible from the tip of your pinky. That distance is called a “span,” which for most people is almost exactly half a cubit. * handbreadth: The width of your four fingers where they meet the palm—usually about 4 inches—is a handbreadth or sometimes just a “hand.” The height of horses is usually expressed in hands. * digit: The width of a finger, which tends to be about 2cm (about 13/16 of an inch). * thumb: The width of a thumb, which was later used as the basis for the inch. * fathom: If you stretch out your arms to either side of your body as far as they’ll go, the distance between the tips of your middle fingers will be very close to your height, or about six feet—your own feet, that is—a length also known as a fathom. * handful: Although we normally use the word handful in the informal sense of “just a little bit,” your hand can serve as a fairly repeatable measure of volume for dry goods such as grains, beans, and seeds. The reason units of measurement like these fell out of favor is that they vary from one person to the next, so if you need accuracy or repeatability, they’re not the best choice. (It turns out, for example, that my personal “cubit” is 18.375 inches (46.67cm). I always was an overachiever.) But for quick-and-dirty estimates when you don’t have a standard measuring device handy, they can’t be beat. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/05/measurring-tape-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/05/Measurement.df990bebbd29.mp3"
	},
	{
		"title": "Herrenchiemsee Castle",
		"text": "King Ludwig II of Bavaria is one of the most colorful characters in German history. Widely regarded as insane, he was certainly a troubled individual and not well suited to the demands of a monarch's life. Although as a ruler he was neither effective nor well-liked, he is remembered fondly today primarily because of his contributions to the future economy of Germany: his castles, which attract huge numbers of tourists each year. Of the three castles Ludwig had built, Neuschwanstein was the most famous, with its fairy-tale pseudo-medieval design. But even more ambitious was Herrenchiemsee Castle. Sup-Versailles It At the foot of the Bavarian Alps lies the Chiemsee, a large lake with a number of islands. To reach the largest island, Herreninsel, you take a ferry from the shore. Hidden from view by trees until you reach the island is what appears to be an exact replica of Versailles. And in fact, that was just what Ludwig was after. He didn't like the thought of being outdone, and fancied himself as one of the great kings of Europe. So he studied Versailles carefully in order to make his version as close as possible to the original. Herrenchiemsee lacks the two side wings of Versailles, has a somewhat different interior layout, and is located in a much more secluded setting. But the overall design of the architecture—and even the choice of artwork, fabrics, and décor inside—reflects the sensibilities of French royalty. It is not always apparent from photographs, but Herrenchiemsee was the largest and most lavish castle Ludwig had built. Construction began in 1878, financed by the king's personal fortune. Like Neuschwanstein, this castle was never completed. Its structure was built in just a few years, but only a fraction of the interior rooms were ever finished. Visitors are uniformly impressed by the ornateness of the furnishings and attention to detail—gold and marble are everywhere you look. Unless, that is, you look very closely. A great many surfaces that appear to be marble are merely painted, and much of the gold is nothing more than a thin leaf over wood. Ludwig was not known for economy, and it is thought that the faux finishes were more a reflection of the design aesthetic of the time, just as wood-veneer plastic was considered very modern a couple of decades ago. Leave Me Alone, I'm Eating Ludwig was notoriously shy and reclusive. When possible, he avoided interacting with members of his own government, and though he was an avid fan of music and theater, he always demanded private performances. Such was Ludwig's passion for privacy that he not only dined alone, but wanted to avoid even seeing kitchen staff before and after meals. (In all likelihood the staff didn't want to see him either: he reportedly had terrible table manners.) This led to the most talked-about room at Herrenchiemsee: the dining room. Ludwig had an elaborate mechanism designed to lower the dining room table through the floor to the kitchen below so that it could be set and raised into the dining room without any need for the king to encounter human beings. One of the king's other castles, Linderhof, has a similar arrangement, though at Herrenchiemsee the kitchen is open to tours so you can see the mechanism beneath the table. According to our tour guide, Herrenchiemsee included one more bathroom than Versailles (for a grand total of one). And it is quite an extraordinary bathroom. The circular tub, if you can call it that, is the size of a small pool. Ludwig was known to be an excellent swimmer, but also, in his later years, quite rotund. So the tub (or pool) may have been designed more for the king's bathing comfort than for exercise. Herrenchiemsee shares another historical trait with Neuschwanstein: despite the huge sums of money spent on it and the years it remained under construction, Ludwig never got to enjoy it. He stayed there for a total of just 16 days in 1885. Shortly thereafter, construction was stopped due to a lack of funds. With three major castles simultaneously under construction and no sense of fiscal responsibility, Ludwig had exhausted his considerable resources and gone deeply into debt. The Decline and Fall of Ludwig II Even though the castles were not funded with state money, Ludwig's cabinet was deeply concerned about his expensive obsession. They were concerned for other reasons too. He rarely communicated with his staff or attended to matters of state; he had frequent affairs with young army officers; he appeared to suffer from hallucinations and delusions. But more important than all these issues was the rumor that Ludwig was planning to replace his entire cabinet. In order to remain in power, the cabinet members hatched a secret plan to remove Ludwig from power. They had a detailed report of Ludwig's troubling behavior compiled and signed by a psychiatrist named Dr. Berhardt von Gudden, even though the doctor had never even met Ludwig at the time. According to Bavarian law, the king could be removed from power only if shown to be incapable of performing his duties, and this report served that purpose. In June of 1886, Ludwig was deposed and arrested. Just one day later, while still under custody at Berg Castle, Ludwig went for a walk on the castle grounds, escorted by Dr. Gudden. When the two did not return after several hours, a search began, and the bodies of both men were soon found floating in a nearby lake. Official reports called Ludwig's death a suicide; Gudden, whose forehead was badly injured, was assumed to have been killed by the king before he drowned himself. However, there is considerable evidence to suggest that both men were murdered by the conspirators who removed the king from power—to be sure he never regained it. Yet another theory suggests Ludwig may have killed Gudden and then died while trying to escape by swimming across the lake. Ludwig's death, like his life, will always be a mystery. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/05/Herrenchiemsee-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/05/Herrenchiemsee.4dc99c0da57.mp3"
	},
	{
		"title": "Neuschwanstein Castle",
		"text": "Before visiting Germany a few years ago, I didn’t know very much about German history or culture, and didn’t really care to. I had always had a warm place in my heart for France, and felt my Gallic tastes were fundamentally at odds with what little I had grasped of life in Germany. As I saw things, the French language was smoother and more mellifluous than German; the French favored wine (as I do) where Germans were more fond of beer; the French countryside was organic and endearingly unkempt while rural Germany was spotless and well-manicured, and so on. In other words, Germany was undoubtedly nice enough, but just not my style. My wife, however, has more overt German roots (even her name, Morgen, is spelled like the German word for morning). She had spent some time in Germany while in high school, spoke German well, and had the same sort of idealized fondness for Germany that I had for France. So in the interest of fostering marital harmony, we humored each other on our first trip to Europe together. She agreed to spend some time in Provence, and I agreed to spend some time in Bavaria. Needless to say, this was not a hardship for either of us. We ate and drank well in both countries and collected plenty of interesting stories. Where Fairy Tales Come From A recurring theme in the sights we saw in Germany—and believe me, I mean this in the best and most complimentary way—was wackiness. I’m not just talking about lederhosen and sauerkraut either, though it has always puzzled me how such things came to exist. A particular slice of German history we became well acquainted with was the rule of Ludwig II, king of Bavaria from 1864 until his death in 1886. While the many stories about Ludwig are strange and colorful (and some are featured as Interesting Things of Other Days) his most famous follies are the castles he built—especially his grandest and best-known castle, Neuschwanstein. Neuschwanstein is a beautiful castle set in one of the most scenic locations on Earth. If it looks a bit familiar, that may be because Walt Disney used it as inspiration for Cinderella’s Castle at the Disney theme parks. It really does evoke images of fairy tales, in more ways than one. But the story of its origin is one of tragedy, despair, and outright weirdness. Swan Song To understand the story, you’ll need to know a bit about Ludwig. As a child, he loved swans. This is not surprising, considering the castle he lived in was called Hohenschwangau (or “high region of the swan”) and contained artwork depicting the story of Lohengrin, a medieval knight of the Holy Grail who rescues a princess with the aid of a swan. Ludwig liked to feed swans and draw pictures of them, and when at age thirteen he heard of Richard Wagner’s opera “Lohengrin,” he was very excited. He memorized the entire libretto, and this led him to an interest in Wagner’s other music and writings. Within a few years, this interest turned into an obsession. In 1863, Ludwig got a copy of Wagner’s “The Ring Cycle.” In the preface, Wagner talks about “the miserable state of the German theater,” and that “a German Prince would need to be found to provide the required funds” to produce the opera. Ludwig took this as his personal mission. The very next year, at age eighteen, Ludwig became king when his father died. His first official duty was to send for Wagner and have him brought to Munich. Wagner, who at that time was in his fifties, was a gifted musician but not, apparently, a very nice guy. History records Wagner as arrogant and self-centered, prone to excess, indiscretion, and intolerance. It so happened that at the very time Ludwig summoned him to Munich, Wagner was trying to evade his creditors and was very much in need of a patron. So Ludwig and Wagner struck up an almost symbiotic relationship. Ludwig funded Wagner’s work and put him up in a handsome villa, and Wagner played the part of mentor and idol. Not long thereafter, though, amid reports of yet another affair and worries that Wagner might be exerting too much influence over the young king, he was forced to leave Bavaria and move to Switzerland. Although Ludwig was upset, he continued to support Wagner, and the two kept up a steady correspondence. Meanwhile, Ludwig was not having a very good time as king. He lost an important war against Prussia, was forced to submit his army to Austrian control, and then ended an unhappy engagement. Depressed and bitter, he withdrew from the public eye as much as possible and consoled himself by planning the construction of several great castles. In 1869, work began on his most ambitious castle, Neuschwanstein (which means “new swan stone”). Reinventing the Castle Ludwig had always wanted a medieval castle, so he had Neuschwanstein built in what you might call a neo-Romanesque style. That is to say, it was made to look a lot older than it really was, and unlike authentic medieval castles, it had such luxuries as forced-air heating and indoor plumbing. But the most distinctive feature of the castle was that it was designed to be a stage for Wagner’s operas, both literally and figuratively. Some rooms were designed explicitly as places where an opera might be performed, but in every room and corridor of the castle the architecture and artwork reflected the German mythology that formed the basis of Wagner’s operas. All but a very few of Wagner’s operas are depicted in one way or another in the castle. One of the most unusual rooms—if you can call it that—is called the Grotto. It’s actually an incredibly convincing artificial cave, complete with stalactites and a waterfall. The Grotto was intended to represent a cave from Wagner’s opera “Tannhäuser.” Around the time construction began, estimates were that Ludwig would be able to move into the castle within about three years. But the work proceeded at a painfully slow pace and more than a decade later, the castle was still not complete. In 1883 Wagner died, causing Ludwig tremendous grief. So the composer never actually set foot inside the castle that had been built in his honor. A year later, Ludwig decided to move in, even though the structure was still unfinished and the throne room was not yet ready to hold a throne. But the king resided there for a grand total of only eleven nights. After Ludwig died under suspicious circumstances in 1886 at the age of 41, construction on Neuschwanstein continued for another eight years. When the builders finally stopped, only a third of the rooms had been finished and decorated. Without Ludwig, Wagner may never have achieved the successes he did, and without Wagner, Neuschwanstein would never have been built. But there is much more to the story of the life and death of King Ludwig II than Neuschwanstein. The “swan king,” as he is sometimes called, built other equally interesting castles and led a fascinating, if deeply troubled life. His story, like his castles, reminds me that there’s more to Bavaria than meets the eye. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/05/castle.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/05/Neuschwanstein.c918ebd14678.mp3"
	},
	{
		"title": "The Story of Phineas Gage",
		"text": "In September, 1848, the Rutland & Burlington Railroad was expanding its line across Vermont. In order to keep the tracks as straight as possible, construction workers first had to remove a great deal of stone. The foreman of one group of men undertaking this difficult task was Phineas P. Gage. Twenty-five-year-old Gage was intelligent, kind, and well-liked. He was also quite athletic and agile, and impressed his employers as being exceptionally efficient at his work. Gage was an expert at removing rock using explosives. The procedure was to drill into the rock, fill the hole halfway with explosive powder, insert a fuse, and then cover the powder with sand. The layer of sand was necessary to direct the force of the blast into the rock, rather than out the top of the hole, and the sand had to be packed down by pounding it with a specially designed iron tamping rod. Gage had a custom-made rod that weighed 13 pounds (5.9kg) and measured 3 1/2 feet (1.1m) long, with a diameter of 1 1/4 inches (3.2cm) at the bottom, tapering to a dull point at the top. Sticks and Stones May Break My Bones At 4:30 p.m. on September 13, Gage was preparing a charge, and apparently failed to notice that it had not yet been cushioned with sand before he began tamping it. When the iron rod scraped against the rock, it created a spark that ignited the powder. The resulting explosion propelled the rod out of the hole, through Gage’s left cheek, and out the top of his skull. The rod landed nearly 100 feet (25m) away. Remarkably, despite the two new and rather large holes in his head and the significant bleeding that resulted, Gage did not even lose consciousness. He remained upright and lucid as his coworkers loaded him onto an ox cart and took him to the nearby town of Cavendish. A half hour later he was sitting on the hotel porch, chatting with the owner while waiting for the arrival of Dr. John Harlow, the local physician. Dr. Harlow treated Gage’s injury as best he could, piecing the remaining portions of the skull back together and cleaning and dressing the wound. Over the coming weeks Gage developed a series of infections but fought them successfully under Harlow’s care. Other than the loss of sight in his left eye, Gage was declared to have made a full recovery in just a couple of months. Suddenly, I’m Not Half the Man I Used to Be An experience like this is bound to make anyone a bit grumpy, but even as he healed physically, Gage underwent a profound change in personality. Although he never lost his language ability, memories, or motor skills, his temperament was completely different. He became profane, impatient, rude, obstinate, and unable to carry out any of the endless plans he made. His friends said that “Gage was no longer Gage”; it was as though all of his ethical filters had been turned off. Because he was such unpleasant company, he had difficulty keeping jobs, and at one point put himself on display at Barnum’s Museum in New York City. Several years later, having made his way to California after an extended stay in Chile, Gage began having epileptic seizures. These continued for several months until he suffered a series of major convulsions that led to his death on May 21, 1860—nearly twelve years after his accident. Gage was buried without an autopsy, but seven years later his body was exhumed. The skull (along with the tamping iron, which had been buried with him) were sent to Dr. Harlow, who examined them and then donated them to the Warren Medical Museum of the Harvard Medical School. Later they were transferred to Harvard’s Countway Library of Medicine. Brains and Personality I first heard the story of Phineas Gage in a graduate course in cognitive science; anyone who studies the brain is bound to run across the story in textbook after textbook. Although no one can say with complete certainty exactly what parts of Gage’s brain were damaged, it seems the injury amounted to a very crude frontal lobotomy. This case became famous as the first hard evidence that aspects of one’s personality (and, by implication, behavior) were localized in portions of the frontal lobe. Neurologist Antonio Damasio has spent years studying brain injuries similar to Gage’s. His research has led him to believe that emotion figures crucially into rational thought and decision-making. If the portion of the brain that processes emotion is damaged, it becomes difficult or impossible to make good decisions. The sad tale of Phineas Gage has produced valuable insights for the field of neuroscience, not to mention a lesson we can all heed: stay far away from explosives! ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/04/Phineas_Gage_Death_Mask.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/04/Phineas.6a714a40b59b.mp3"
	},
	{
		"title": "The Conservatoire des Arts et Métiers",
		"text": "A trip to Europe without visiting museums would be like a trip to Fiji without visiting a beach. It just seems wrong to ignore such an embarrassment of riches. So when I was in England and France last year, I dutifully walked through museum after museum, taking in art of every kind, and along with it the history and culture of many different lands and peoples. But I soon noticed a strange phenomenon. Every time I think about going to a museum, it seems like a fascinating and engaging way to spend an afternoon, but once I get there, I almost always find myself getting very, very sleepy by the time I get to the second or third gallery. My state of alertness at museums doesn’t have any apparent correlation to the amount of sleep or coffee I’ve had recently; I think it’s some strange psychological reaction to environment. After a while, all those little plaques seem to say the same thing: “This is an object created by a person in the past.” I want to be enthusiastic…I try to be enthusiastic…but usually I’m no match for the long halls of display cases. There is an exception to this rule, though: science museums. I love inventions and gadgets, learning about how things work and how people went about solving very difficult problems. I can stay awake in a good science museum indefinitely. So while in Paris, I made a point of visiting the holy grail of invention lovers: the Conservatoire des Arts et Métiers—the conservatory of arts and trades. Part of this centuries-old institution is a museum that’s open to the public, and it contains a fascinating variety of objects and exhibits including the original Foucault’s Pendulum. Progress’s Pilgrims The Conservatoire is off the beaten path; most English guidebooks don’t even mention it. It does, however, attract a certain number of pilgrims who were fascinated by Umberto Eco’s novel Foucault’s Pendulum, part of which takes place there. The museum underwent a massive renovation after the book was written, so it’s no longer possible to retrace the steps of the characters. But one hall in particular still looks familiar: a large room that was once the sanctuary of an abbey. The Pendulum still hangs from the apex of the nave, and nearby stand old cars, airplanes, and a model of the Statue of Liberty. In the novel, a secret passage under the floor of the nave connects with the Paris sewers. That isn’t the case in reality, but truth is perhaps more interesting than fiction. There is something under the floor of the nave, a curious part of the building’s long and strange history. The foundation for the abbey church of Saint-Martin-des-Champs (St. Martin of the Fields) was laid around 1059, about the time of the Norman conquest. The church was dedicated in 1067. In 1079 Philippe I gave control of the church to Hugues, abbey of Cluny, who then transformed it into a priory—its first prior a man named Ourson. Over the next seven centuries, numerous additions and renovations were undertaken; the current nave dates from the 13th century. All the while, though, the building remained a monastic home for the monks of Cluny. Revolutionary Changes All that changed in the French Revolution. A great many of the monks fought zealously on the losing side and were beheaded for their troubles. In 1794, abbot Henri Gregoire submitted a proposal to the National Convention: “There will be formed in Paris, under the name Conservatoire des Arts et Métiers, […], a depository for machines, models, tools, drawings, descriptions and books in all the areas of the arts and trades.” The now-deserted priory of Saint-Martin-des-Champs was designated as the home for this new collection, which began to form almost immediately. The Conservatoire officially opened in 1802. In addition to collecting inventions the way a library collects books, the Conservatoire became a respected educational institution, holding classes and seminars in a wide variety of industrial trades. The museum closed for a much-needed renovation in 1993, and as part of the process, archeological excavations were undertaken beneath the floor of the nave. For the entire history of the church, there had been rumors that the site on which it stood was once a Merovingian funerary basilica, but this had never been proven. What archeologists discovered was a large necropolis dating from the 6th or 7th century but apparently rebuilt during the Carolingian era (8th and 9th centuries). Inside were about 100 plaster coffins, some of which had been reused for new occupants as late as the middle ages. The rumors were indeed true. Everything Old is New Again When the museum reopened a few years later, it was as shiny and up-to-date as any modern science museum—or at least, any modern science museum housed in an 800-year-old building. Almost every museum has many more articles in its collection than can be displayed at any one time, but the Musée des Arts et Métiers decided that their thousands of additional articles should be made available to scholars even when they’re not on exhibit. So they opened a satellite facility in the nearby town of Saint-Denis, where qualified researchers can go—by appointment only—to examine the rest of the museum’s collection. I’ve been to the Conservatoire on two different occasions—in 2000 and in 2003. As a science museum—even with most of the explanatory text only in French—I found it a sheer delight. The former abbey is only a portion of the museum, and the museum is only a portion of the Conservatoire. But all the history of the building and the institution seems to be concentrated in the large nave with its bones beneath and gadgets above. The odd juxtaposition of centuries of monastic simplicity with centuries of technological progress tickles me in a way I can’t easily describe. Perhaps the Pendulum says it best: as a scientific wonder that’s also meditatively simple, it symbolically bridges the illusory divide between technology and spirituality. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/04/museum.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/04/Conservatoire.aba208f869c8.mp3"
	},
	{
		"title": "The Church of the Flying Spaghetti Monster",
		"text": "Faith with a side of Parmesan I admit that I’m rather obtuse when it comes to religion. I do know enough to recognize that meatballs, pirates, and midgets probably aren’t the cornerstones of a thriving religion, yet these three items are vital to The Church of the Flying Spaghetti Monster. Participation in this church would involve worshipping an extraordinary being who reveals himself in the form of tangled noodles and russet-colored meatballs. You might think I am making this up. You’ll have to read on to find out. Every Action Has a Reaction At the heart of the ages-old struggle between science and religion is the theory of evolution, a concept that many devout religious worshippers don’t want to accept and that hard-core scientists fervently stand by. Ever since the Scopes Trial in 1925, school officials, teachers, parents, and students have been fighting over whether and how to teach evolution in public schools. This argument came to a head in 2005 when the Kansas State Board of Education decided to require the teaching of Intelligent Design (ID) alongside evolution in science classrooms. The basis of ID is the proposition that features found in nature did not appear as a result of random processes such as natural selection, but instead were brought about by an intelligent agent—although this agent is not specifically named. ID advocates state that it is a scientific theory that can hold its own next to the theory of evolution. Needless to say, the idea of Intelligent Design, as well as the decision by the Kansas State Board of Education, drew serious criticism from the scientific community. It also caught the attention of Bobby Henderson, a physics graduate who thought ID had it all wrong. In 2005, Henderson published an open letter to the Kansas State Board of Education on his Web site. In this letter he stated that belief in Intelligent Design can take many forms. But the version to be taught in Kansas omitted an important scientific viewpoint, namely, the idea that the world was created by the Flying Spaghetti Monster (or more commonly, the FSM). He requested that the Board consider teaching this theory alongside ID and evolution, and threatened legal action if they refused. The letter included an artistic rendition of the FSM creating the mountains, trees, and a “midgit” [sic] with His powerful Noodly Appendage. Evidence for the Existence of Him In his letter to the Board of Education, Henderson gave points of evidence that he believed imply the existence of the FSM. Even though no one was around to witness His creation of the universe, there was plenty of literature to implicate the FSM in the universe’s formation and this lack of observable evidence was enough to create a large following. The letter goes on to explain that “He built the world to make us think the earth is older than it really is.” The FSM does this, Henderson explained, by altering scientific data collected by researchers who seek to find the true age of the earth, because “the Flying Spaghetti Monster is there changing the results with His Noodly Appendage.” Furthermore, as pirates appear to be a crucial part of the FSM religion (more about this in a moment), the decrease in their numbers over the past 200 years can be used to explain the increase in global warming and natural disasters on Earth. The dwindling number of pirates is inversely proportional to the increase in average temperature, nicely displayed in the letter by a scientific-looking graph. With such substantial evidence, it’s hard to argue against the existence of Him. Pasta + Rastafarian = Pastafarian Anyone who decides this evidence is enough to become a follower will find many attractive features of the religion. First, followers call themselves Pastafarians, a very invigorating term guaranteed to bring about images of cuisine. There is even a Guide to Pastafarianism, easily located on the FSM Web site, which explains that every Friday is considered a religious holiday! Second, as mentioned earlier, pirates are considered “absolute divine beings.” What does this mean for Pastafarians? The right to wear full pirate regalia, of course! The guide even says that shouting “Yar” and wearing the religious head dress every day is totally acceptable and expected. And finally, following the simple rules of Pastafarianism can grant a ticket to heaven where “beer volcanoes as far as the eye can see” and “a stripper factory” await. But don’t take my word for it; you can read the entire guide on the FSM Web site and decide whether a conversion to Pastafarianism is right for you. All Kidding Aside If it hasn’t been clear up to this point, the Church of the Flying Spaghetti Monster is entirely a spoof on real religion and religious followers; Henderson was clearly taking advantage of the lack of methodological evidence supporting Intelligent Design in an attempt to expose its fallacies as a scientific theory. However, Henderson did receive real responses from Kansas State Board of Education members, including two who planned to vote against the teaching of Intelligent Design in Kansas classrooms. In late 2005, the Board voted 6 to 4 in favor of redefining science so that the search for scientific explanations was no longer limited to natural explanations, and this was viewed as a victory for Intelligent Design proponents. However, in August 2006, pro-evolution candidates took control of the board and emphasize their plan to continue to educate the public about the issue of evolution. As for Bobby Henderson, he has written a book titled The Gospel of the Flying Spaghetti Monster. He still runs the FSM Web site, where he posts the email he receives from various supporters and protestors as well as news updates and holiday greetings. Evolution itself is still a touchy subject with respect to public schools. The National Center for Science Education (NCSE), a proponent of teaching evolution in schools, reports that Ohio’s Governor Taft plans to appoint four new members to the state Board of Education before he leaves, and these individuals will be supporters of the theory of evolution. And you might remember the 2004 fight in Dover, Pennsylvania, where it was decided the ninth-grade biology students must be read a statement mentioning Intelligent Design. Later, a federal judge decided that this decision was in violation of the Constitution, but board members who supported the statement had already been voted out. This fight between evolution and creationism even reaches beyond the borders of the United States. The United Kingdom is even taking a stand on the separation of science and speculation, as the government plans to inform schools that they cannot use teaching materials that promote creationism in the classroom. However, it is hard to believe that the fight between evolution and public schools will quietly fade anytime soon. Henderson capitalized on an issue that is becoming paramount not only to our schools, but also to our society. More and more science finds itself under religious fire. But religion is extremely important to many individuals as it gives them a sense of meaning, while science is an essential component of the push to understand the world around us. In a perfect world, science and religion would find a common ground so that people wouldn’t feel disengaged from one side or the other. Perhaps Henderson’s underlying message is that by keeping religion and science separate, we protect both realms from each other and then absurd constructions like the Flying Spaghetti Monster aren’t necessary. But Henderson’s message may be much simpler: pirates are always cool. Yar! ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/04/Flying_Spaghetti_Monster.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/04/Spaghetti.a192ea1d67f6.mp3"
	},
	{
		"title": "Churchill, Manitoba",
		"text": "When I was in college, I went hiking with a group of friends in Riding Mountain National Park, located in southwestern Manitoba. We decided to hike quite a distance into the park before making camp for the night. Having had some camping experience, I looked forward to the adventure, but for one fact: the certain presence of black bears. Compared to grizzly bears, black bears can be relatively harmless, and I had seen them from a distance many times, most often scouring the garbage dump near our family cabin in northern Saskatchewan. But I had never gone this far from civilization, into the bears' territory, surrounded by the wilderness. We took the necessary precautions, making plenty of noise as we hiked into the park, and making sure that our food was carefully put away after our evening meal. That night we had no problems, and it seemed like we were in the clear. As we hiked back out of the park, some members of our group with more backcountry experience went farther ahead on the trail. Suddenly they returned with stunned looks on their faces. They had seen a bear cross the trail in front of them, much too close for comfort. The rest of us were relieved that we hadn’t come face to face with a bear, but there was a certain excitement to the rest of our hike, knowing we had come so close to doing so. The only other national park in Manitoba, Wapusk National Park, is also home to bears; in this case, polar bears. Not far from the town of Churchill, visitors to Wapusk (Cree for “White Bear”) can have their own near-bear experience, while safely out of reach of these mighty predators. Good Fur Business The area around Churchill is the ancestral home of the Chipewyan and Cree peoples who lived and hunted there before the first European explorers arrived in the 1600s. Located near the mouth of the Churchill River where it meets Hudson Bay, the town of Churchill began as a trading post for the Hudson’s Bay Company, and was named for one of its governors, John Churchill, the first Duke of Marlborough and an ancestor of Winston Churchill. Churchill was well-situated to become a hub for the fur trade, with its access to Hudson Bay and the Arctic Ocean on the one hand, and the availability of trading partners among the native population. Also unique to the location is that it sits at an ecotone, or the meeting of two different ecoregions. To the north is the tundra landscape of the Arctic, and to the south, the boreal forests, which extend down into the southern part of the province. Bay City Rulers In 1741, the Hudson’s Bay Company replaced its initial log fort with one built of stone, the Prince of Wales Fort, in recognition of the growing hostility between the French and English. This fort was overtaken by a French force in 1782 and burned to the ground. Soon after, a new fort was built farther upriver. As the fur trade eventually declined in the area, a new means of trade was envisioned by backers of a rail line to be built from Winnipeg in the south, up to Churchill in the north. This railroad would enable grain and other agricultural products to be transported from the southern prairies to the port at Churchill, in reality the closest seaport in the region. The Hudson Bay Railway was completed in 1930, and stretched for 1180 miles (1900 kilometers) from south to north. To this day, the railroad remains the only overland way to reach Churchill; there are no roads to the town, although an airport now exists to bring visitors to the area by air. Days of Tundra Although the fur trade initially drew the Europeans to Churchill, the town of almost 1000 residents now relies on its local wildlife for another kind of economic activity: ecotourism. Churchill calls itself the Polar Bear Capital of the World, and with good reason. Every October and November, large numbers of polar bears gather near the town, waiting for the ice to form on Hudson Bay, which will allow them to reach their primary source of food: seals. Many tourists come yearly to see the polar bears in their natural habitat, and during the “Bear Season” months, the town is bustling with activity. Polar bear viewing has become so popular that potential visitors must often book their trips a year ahead of time. Travelers to Churchill may arrive by air, but many make the journey by rail, which takes almost two days from Winnipeg. While in Churchill, visitors have many choices for lodging, meals, and tour operators, but one of the best known is the Tundra Buggy Adventure. This company takes its guests into Wapusk National Park to view the polar bears in Tundra Buggies, enormous vehicles heated by propane and equipped with washroom facilities and an outdoor viewing deck. For those who want an immersion experience, the company also maintains the Tundra Buggy Lodge, a mobile hotel that is set up each year near the polar bear groupings. Guests are housed in sleeper cars, and can spend the night out on the tundra, ready to see the bears in action the next morning. The Northern Sights Polar bears are not the only wildlife worth watching in Churchill. During the summer months, Churchill is an excellent location for watching migrating Beluga whales, and bird enthusiasts come in the spring and summer to view the local species on display. Also on display, weather permitting, are the spectacular northern lights of the Aurora Borealis. While it can be scary to encounter large predators, such as black bears and polar bears in their natural habitat, under the right circumstances, such as those present in Churchill, visitors can have this exhilarating experience and live to tell the tale. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/04/Polar_Bears.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/04/Churchill.18cd26537b70.mp3"
	},
	{
		"title": "The Swedish Ship Götheborg",
		"text": "Not long ago I had the chance to view an exhibit of artifacts raised from the wreck of the Titanic. These artifacts included personal possessions of the passengers, such as glasses, hats and jewelry, as well as glassware and plates from the ship’s stores. To give context to these items, the exhibit’s creators had reproduced different parts of the ship, including the Dining Room and the Grand Staircase. The centerpiece of the exhibit was a colossal piece of the ship’s hull, weighing 30,000 pounds, and taking up the majority of the large room that housed it. Although it seemed enormous, diagrams indicating its position on the intact ship showed the piece to be just one tiny part of the whole. Reflecting on this incredible artifact, I felt awe at the ingenuity and workmanship of Titanic’s builders, but also sadness for the fate of its passengers and for the destruction of the once-mighty ship. It was a great opportunity to be immersed in history, to see first-hand an approximation of history’s details. In a similar vein, a project underway in Sweden to bring history into the modern world also involves a ship that sank—the East Indiaman Götheborg. That Sinking Feeling In 1731 the Swedish East India Company was founded to pursue trade in southeast Asia, exchanging Swedish timber, tar, iron, and copper for silver, tea, porcelain, and silk. Over the course of its 82-year history, it launched 38 ships on 132 expeditions. One of those ships was the Götheborg. The Götheborg had made three voyages to China when it made its final approach to its home port, Göteborg, on September 12, 1745. After 30 months at sea and within sight of its ultimate destination, for reasons still unknown, the Götheborg ran aground and began to sink. Luckily, the entire crew was rescued by the numerous bystanders who had gathered to watch the ship’s entry into port. However, the ship’s precious cargo—estimated to be worth as much as the national budget—was lost, and the ship sank to the ocean floor. Shaping the Timbers The Götheborg was largely forgotten until 1984, when divers began reexamining the wreck and found remnants of the ship under layers of clay. Their discoveries kindled public interest in the ship, and inspired a plan to build a replica ship that would once again sail to China. In 1993, a new organization called the Swedish East India Company was formed to make this plan a reality. Construction on the ship began in 1995, when the keel was laid, and continued through the ship’s first sea trial in May 2005. Throughout the process, great care was taken to emulate the shipbuilding techniques that formed the first Götheborg, with a few key exceptions. While the exterior of the ship was built using the classic 18th-century materials of oak, pine, spruce, and elm, the interior of the ship is much more 21st century. Due to modern regulations requiring the inclusion of a propulsion system, the new Götheborg had to be fitted with two engines and two main generators plus an emergency generator, although its default power source is the wind. In addition, the ship has been equipped with five watertight steel bulkheads to comply with international seaworthiness standards. Slow Boat to China On October 2, 2005, the Swedish Ship Götheborg (as it is officially called) set sail from Sweden, headed toward Shanghai, China by way of Spain, Brazil, South Africa, Australia, and Indonesia. The ship reached Shanghai on August 29, 2006, for a two-month stay before returning to Sweden. Like my visit to the Titanic exhibit, the Götheborg project has given many people a chance to see history first-hand, and to experience what life was like so long ago. But more than that, it has combined the strength of tradition with the innovation of the present—a rare and valuable thing to behold. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/04/Gtheborg-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/04/Swedish.e1736d46b52.mp3"
	},
	{
		"title": "Plate Clouds",
		"text": "A couple of summers ago, I was driving from San Francisco to Los Angeles along California’s Interstate 5. I’d left the Bay Area mid-morning, and after five and a half hours of driving on the long, straight highway through the great central valley, I was approaching the modest range of mountains that separates that valley from southern California. I was happy to be within an hour’s drive of my destination so early in the afternoon, and had already started to plan the hours of evening I had gained by leaving early and not stopping to eat. It wasn’t going to go the way I was planning, though. I got stopped by a cloud. Within an hour’s drive of the mountains, I started noticing that something was—well, it looked like something was balanced on top of the nearest mountain. As I got closer it started becoming obvious that a giant spacecraft was poised over the mountain, maybe even tethered to it like an airship to a mooring post. It was colored as you’d expect a cloud formation to be, but had sharp, clean edges, and a precise layered structure. More ominously, I could see that as time passed, and my view of the mountain stayed more or less the same, the nearby clouds were moving but the “thing” wasn’t. They Want You to Think It’s a Cloud Of course, I always knew it was a cloud, of some kind. But the closer I got to it, the harder it became to accept that it was a natural phenomenon. It was elegant, delicate. There was an architecture to it. And it wasn’t moving. Because of this I was compelled to buy a disposable camera and wait at the little “last chance” gas station at the foot of the mountain until sunset rolled around and started throwing wild colors of light onto the…the… “They’re called ‘plate clouds,'” said a waitress who stepped out of the diner to smoke. She’d seen it once before, in the same spot, about the same shape, “but not as big a deal as this time.” She didn’t know how they were formed, or why they stayed frozen like that for so long, making the illusion of solidity so eerily real. Giant Lentils in the Sky Lenticularis (from the same root word that gives us “lentil”), or “lenticular clouds,” are a cloud species occasionally found over mountain peaks, or on the leeward side of a mountain. As wind forces air up one side of a mountain, the air cools, and the moisture within that air condenses into visible drops. As soon as the air begins to descend down the other side of the mountain the moisture in the air warms, and is no longer visible. What appears to be a stationary cloud is actually the condensation point of a constantly moving stream of air, and the layers within the apparent cloud represent “waves” within the stream. It doesn’t happen all the time, or even often. It happens, for example, when the upper air is stable, meaning lenticular clouds are a good indication that it’s not about to rain. But the event can grow. Altocumulus lenticularis (the formation that I saw), an already unusual occurrence, can grow into the legitimately rare Stratocumulus lenticularis, whose elements are larger yet, and must either be so spectacular as to stop hearts within a hundred-mile radius, or actually be so large that they cover the sky and thus go unnoticed. Other rare cousins in the sky lentil family are those lenticular clouds that form absent any orographic features (mountains). Large bodies of ice surrounded by warmer ground can cause the same mysterious, unmoving “stack of pancakes” formations, though they will not have the intriguing concave underside, caused by the updraft from the mountain, that made mine so artificial-looking. Lenticularis is also the species of cloud known for “irisation,” an effect of iridescence at the sharp edges of the “plates.” I don’t recall having noticed this quality in the formation I saw. Of course, I might just be inadvertently continuing the grand cover-up, by describing these as meteorological events with plausible causes. Maybe they really are alien spacecraft. Either way, I’m keeping a camera in my car from now on. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/04/plate-clouds.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/04/Plate.c4221bcd05b.mp3"
	},
	{
		"title": "Mouth Music",
		"text": "When I was young, my Dad had a record featuring songs and comedy sketches by the comedian Peter Sellers (formerly of “The Goon Show”). I loved to listen to it so much that even today, I can recite nearly the entire album from memory. One sketch in particular sprung to mind when I sat down to write this article. Sellers plays a German folk music aficionado, who is rather stiffly introducing his field recordings. “Ziss recordink is of Scottish mouth music.” He pauses. “Played on ze mouth.” Actually, what followed wasn't mouth music at all, but a drunk Scotsman singing on a street before getting run over by a bus, but it was the first time I had ever heard the term. I didn't hear real mouth music—or puirt-a-beul in Gaelic—until many years later. Isn't That Just Singing? Surely music “played on the mouth” is just what most people refer to as singing? Well, yes and no. Genuine puirt-a-beul (pronounced porsht-ah-buhl) has a number of distinctive features which mark it out from standard singing. Mouth music is a primarily rhythmic form of song, where the words are chosen for their rhythmic qualities and the patterns of sound they make. Consequently most of the lyrics are more or less nonsense, but sometimes they take the form of puns or tongue twisters. Some songs contain syllables called “vocables,” which are chosen to sound like a particular instrument, or as a kind of sound effect to fit in with the meaning of the song. One of the reasons that I love mouth music is that it is a truly representative form of folk song; even the poorest of people can afford to use their own voices, so the songs record the everyday lives of ordinary people. The music itself is really striking to listen to, with a driving, toe-tapping rhythm. Expert mouth music singers will tell you that the hardest thing to learn is when to breathe, because the rhythm can't be broken. Listening to Talitha MacKenzie singing “Sheatadh Cailleach” on the album “Sòlas,” and reading along with the Gaelic lyrics, I always marvel at how she can possibly fit all of the words in, such is the speed and complexity of the song. Dances Without Instruments Mouth music served three distinct functions, the first of which was to provide music for dancing. The majority of people would have been unable to afford musical instruments, but there was also a ban on the pipes after the 1745 Jacobite uprising, which ended in the notoriously bloody battle at Culloden, and victory for the English king, George II. Anything associated with the Highland clans or Gaelic tradition was ruthlessly suppressed, but by using their own voices, the people could still enjoy dances and traditional tunes, while leaving no incriminating evidence. The words are chosen to represent the dance steps of traditional dances, and the rhythm is so strongly ingrained in the structure of the words that it can be used to accompany dancing even if it is spoken rather than sung. This type is thought to be the most technically difficult form of mouth music to sing because of the fast tempo and complex rhythms. Singing While You Work The second function of mouth music was to alleviate the tedium of manual work. These songs—known as “waulking songs” or orain luaidh—were sung as tweed cloth was “fulled” or “waulked.” When tweed is newly woven, it is rather loose and not at all wind-proof. Since Harris tweed is supposed to be able to stop a Highland gale, the cloth needs to be worked to plump up the fibres and shrink the weave. Traditionally this was done by soaking the cloth in stale urine, and then sitting around a table, pushing, pulling and pounding the cloth around (always passing it clockwise), until the fibres shrank. The whole process could take hours, and as you might imagine was a tiring, boring and—above all—smelly process, and singing while you worked helped to pass the time. The waulking songs usually took the form of “call and response,” with one person singing the verses, while everyone joined in on the choruses. In Scotland, waulking was done exclusively by women, so the songs tend to be light-hearted, teasing each other about their sweethearts, and including a fair measure of ribald gossip. In Nova Scotia, Canada, waulking was done by men and women together. I've never heard any Nova Scotian waulking songs, but I'd be fascinated to know whether the tone of the songs was changed for mixed company. Many countries have similar forms of work songs, like sailors' sea shanties, or West African work music. In fact, waulking songs have a very similar feel to traditional West African music and an odd affinity with them, which probably accounts for the popularity of bands like Mouth Music and Afro Celt Sound System, who blend the two styles. Remembering Tunes Finally, mouth music was used to help musicians to remember and pass on traditional tunes, or to practice the music when they did not have an instrument available. Most traditional musicians would not have read music, so they would learn songs by playing with others, and by singing the tunes. A further style of mouth music (more often employed in Ireland) going by the charming name of “diddlage,” uses vocables sounding like the fiddle to represent the tunes. For many fiddlers, the sounds of the mouth music are inseparable from the tune actually played on the fiddle. There is even a form of mouth music—called canntaireachd or cauntering—in which the singer imitates the sound of the bagpipes to learn the tunes. Given the limited volume of the human voice, this can be a much more pleasant way to hear the bagpipes than the real thing! Again, these traditions are not restricted to the Celtic people; in India, players of the tabla (a small, expressive drum) learn and pass on tabla rhythms via a spoken notation called bol, in which onomatopoeic words stand for particular strokes. Take Your Music with You One of the most striking things about mouth music, when you come to look into it in detail, is the way that it reveals the migration, inter-mingling, and social history of people over time. Many people of Celtic origin in Scotland, Ireland, and Brittany, France already shared a similar tradition of music. In the 17th century, French peasants (including those from Brittany) were “cleared” from their land by rich landowners, and had to emigrate to Eastern Canada. Around a century later, Scottish highlanders were also involved in clearances, and many also ended up in Canada, in the region now called Nova Scotia. The French settlers (Acadians) got moved from place to place by political problems, and settled successively in Cape Breton, the Appalachian mountains, and eventually Louisiana, where they became known as Cajun. So there is a local version of mouth music found in Nova Scotia, and a rich gumbo of vocal tradition in Cajun Louisiana, where French and Celtic mouth music met the traditions of African and Caribbean slaves. So, no—it isn't just singing. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/04/singer.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/04/Mouth.7f9e10e28869.mp3"
	},
	{
		"title": "Non-Human Farmers",
		"text": "On a recent trip to the Galapagos Islands, I was astonished when our guide showed us how damselfish (family Pomacentridae) farm algae on their own. It was also amazing to see how aggressively protective they were of their farms. To demonstrate, our guide took a sea urchin and dropped it into the damselfish’s algae farm, and within seconds the damselfish pushed the sea urchin out of the farm. Some damselfish farm algae on coral heads and nip the coral to create cuts that encourage the algae to grow. Apparently, they are known even to attack human beings that swim near their farms. Fortunately, they are very small fish with small teeth, so death by damselfish is unlikely! The damselfish inspired me to learn about other animals that farm their own food. It turns out that besides humans, four kinds of animal are known to farm fungi (fungiculture)—leaf cutter ants, termites, ambrosia beetles, and marsh snails. We humans capitalized on the invention of agriculture to place ourselves on the path to achieve a dominating position in our ecosystem. It is our gregarious nature, societal structure, communication skills, and a measure of engineering skills that were key. Let’s examine how non-human farmers stack up in these areas. Society & Organization All three of the insect farmers have very well organized societal structures that in all likelihood developed before they learned fungiculture. They have built complex societal structures with task specialization that would put a Henry Ford or a Frederick Taylor to shame. This has also allowed these insects to sustain very large populations—colonies of leaf cutter ants (previously discussed on Interesting Thing of the Day) are known to have tens of millions of ants. Leaf cutter ants belong to a group of ants called “attines”—the genus Atta. Attines are notorious for their ability to deforest vast tracts of land in a matter of days. All the ants in the leaf cutter ant community are specialists—the queens that are the breeders and also start the farming area called nests, ants that specialize in cutting the leaves from the trees, ants that specialize in reducing the leaves to a mulch, and ants that specialize in harvesting the fungi. There are also garbage worker ants that help manage the waste in garbage chambers that are kept isolated from the nest. Since there is a risk of contamination if these garbage worker ants mingle with the rest of the ants, these garbage workers cannot leave the garbage chambers. Scientists have observed that if these garbage worker ants go to the main part of the nest, they are forced to return to the garbage chambers or even killed by the other worker ants. There are 210 species within 12 genera of attines that are farmers. Ants have developed at least 553 strains of farmable fungi belonging to seven different genera. Ambrosia beetles (order Coleptera) are a type of bark beetle. In the ambrosia beetle community, the females create farming areas inside the trees called galleries where they lay the eggs; the males do the rest of the work. The beetles cultivate a fungus called “ambrosia” that serves as food for both the adults and newly hatched larvae. The fungi cultivated by the ambrosia beetles are not pathogens, but the tunneling itself can kill trees. The fungi carried by other closely related bark beetles, however, can be deadly to plants all by itself. About 3,400 species of farming beetle are known. About 330 species of termites farm fungi. Fungus-cultivating termites are found in tropical Africa and Asia. Termite colonies consist mainly of worker types, which work to feed the other colony members. There are also soldier types to fight predators and the queen, which reproduces. Similar to ambrosia beetles, they are monoculturists, as they farm only one type of fungus—which in the case of termites is Termitomyces (Termite Fungus). It was only recently that marsh snails (Littoraria irrorata) were added to the list of animal farmers; they are also the first in the marine world known to be fungiculturists. Marsh snails live in salt marshes and their main food is a fungus that grows on cordgrass leaves. Similar to the damselfish, they cut the cordgrass leaves to create wounds, and lay their excrement into the wounds. The excrement contains the fungal spores (like seeds) and also the nutrients for the fungus to flourish in. Although in snail colonies as many as 1,000 snails per square meter can be found, snails are non-social. Therefore, complex societal structures are not a requirement for farming. Engineering & Communication Skills The insect farmers use specialized chemicals called pheromones to communicate amongst themselves; this communication is essential to forming complex societal structures. Leaf cutters build nests as large as football fields. Termites build mounds that are true engineering marvels—some of them can be as high as 9 feet (3m) above ground. Scientists have documented the sophisticated methods termites use to regulate the environment inside these mounds. What is amazing is that the mound has an elaborate ventilation system that enables the internal area to have carbon dioxide and humidity levels that exceed that of the outside air. This ventilation system also helps maintain the temperature at an optimal level to allow the fungus to flourish. Ambrosia beetles bore tunnels deep into tree branches. As they bore, they push out the dust into small protrusions. The tunnels typically number in the hundreds and form large networks known as galleries. The insect farmers also use a variety of techniques to weed out unwanted fungus from their farms. Interestingly, the leaf cutters use antibiotic-secreting bacteria of the group actinomycetes to weed out other unwanted fungus growing in the garden. What is amazing is that we derive many of our own antibiotics, such as streptomycin and tetramycin, from actinomycetes. The parallels with human farmers do not end with agriculture. There are species of ants that herd aphids in much the same way humans herd cattle and live on the sugary excretions of the aphids. Why do they farm? Why these animals farm is a highly debated topic in the scientific community. In my opinion, these are likely to be highly evolved symbiotic relationships. Symbiosis—two or more organisms living together such that both are more successful within the partnership than they would have been if they were living on their own—originated as a survival method 400 million years ago in the form of lichens. Interestingly, one of the components of the symbiosis we know as lichens is a fungus and the other is algae. I would hypothesize that scientists may one day discover that some other species also practice fungiculture. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/04/fish-damselfish-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/04/Farmers.1c1bba08803c.mp3"
	},
	{
		"title": "Burghausen",
		"text": "On a visit to the Louvre a few years ago, I was astounded by the amount of stuff there was to see—everything from da Vinci to Dührer to ancient Egyptian papyri. The collection is simply huge—the museum displays around 29,000 works of art in its endless halls. If you were able to stand in front of every object in the museum for only twenty seconds it would still take a full week, day and night. Not surprisingly, the “container” for all this stuff—the former Louvre palace—is gigantic as well. From its origin as a fortress during the reign of Philippe Auguste in 1190, to its present state today, successive governments and royal regimes have modified and beautified and expanded it along the length of the Seine into what it is now: a very large frame for the Mona Lisa. After walking what seemed like miles past more Madonnas and children than I ever hoped to see, I had to keep reminding myself that there is a castle in Europe that is longer than the Louvre. Many years ago, when I was sixteen, I visited this castle while I was at a summer language camp in Bavaria. On one of our field trips, we went to Burghausen castle, 68 miles (110km) east of Munich, and 31 miles (50km) north of Salzburg. At the time, being a naive North American kid, castles and centuries-old European culture were still a novelty, and Burghausen made a huge impression on me. Heavy rain could not dampen my delight in visiting this imposing fortress, even though for my European friends it was just another castle. I was particularly wowed by its history, its size, and by the fact that Napoleon had once stayed there. The Long and the Short Burghausen may not have the high profile of other Bavarian castles (Neuschwanstein springs to mind), but it does have a long and complex history. Built on a ridge overlooking the Salzach river, the area was once the site of a Celtic settlement (around 100 B.C. ), and then was occupied by the Romans before becoming a power centre for various Bavarian aristocratic dynasties. The longest-lived of these dynasties, the Dukes of the Wittelsbach family, ruled Bavaria from A.D. 1180 until 1918. During their reign, the castle was built up in stages (as was the Louvre), beginning in 1255 and continuing until around 1480–1490. In its finished state, the castle had six linked courtyards, and ran for over a kilometer along the ridge, making it the longest castle in Europe. In more recent history, Napoleon made use of Burghausen’s strategic position on the banks of the Salzach during his campaign against the Austro-Hungarian Empire. From April 28 to May 2, 1809, the one-time Emperor of France quartered his 100,000 troops and their horses in the area while a pontoon bridge was built to replace the one destroyed by the Austrian troops across the river. Despite the inconvenience of having tens of thousands of soldiers hanging around the town, this visit put Burghausen on the map for a time, and its local newspaper proudly declared: “We are the center of Europe: Napoleon stayed inside our walls.” Modern Burghausen Besides its fascinating history, Burghausen is a wonderful place to visit for its modern incarnation as well. The Altstadt (“old town”) at the base of the fortress is extremely charming, filled with colorful row houses along the river, and narrow pedestrian-only streets replete with cozy shops. I found it fascinating that I could to travel to another country by simply crossing a bridge from the town center over the Salzach river into Austria. It was a much shorter walk than a stroll through even one of the galleries of the Louvre. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/Burghausen-120.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/Burghausen.99b9a64a3622.mp3"
	},
	{
		"title": "The S Curve",
		"text": "Guest Article by Rajagopal Sukumar The S Curve While the saying “success begets success” has almost become a cliché, there is no dearth of stories covering inexplicable failures of extremely successful people and corporations. Reading some of these stories and the books on this topic led me to the question: What if there is something fundamental that we are missing about success that leads to all these spectacular failures? S Curve My research brought me to the fascinating concept of the S Curve. Apparently, when you plot expertise with respect to time, it traces an S-shaped curve. As depicted in the accompanying diagram, when we begin learning a skill, we are a bit slow initially at the tail of the S curve. As time progresses, learning proceeds at a dramatically increased speed, helping us to climb the steep slope of the S curve very quickly. At the top of the slope, we are deemed experts in that particular skill. From then on, even if we put a lot of effort into improving ourselves in that area, the resultant learning will not be proportional. The top end of the S curve is also called the slope of diminishing returns. At the top of the S curve, many people succumb to the effects of hubris, which gives them a false sense of security because the world believes and acknowledges that they are the experts in that field. Unfortunately, the world keeps moving and some other new skill becomes important, which renders this expert obsolete. Success May Breed Failure John R. O’Neil has written an extremely interesting book titled Paradox of Success. In this book, O’Neil analyzes many high-profile failures and in the process explains how the S curve closely fits the pattern of learning and how success causes people to fail because some strengths have become so accentuated to now be the cause of their failure. Is there a way out? What do we do after we reach the peak of the S curve? One answer is that we can start a new S curve. By analogy, consider mountain climbing, which is sort of similar to learning new skills. Initially, we start at the bottom with a clear estimate and a timeline to climb the mountain. As we come to grips with the terrain of the mountain, we are able to climb more efficiently and reach the summit. Having reached the summit, we cannot stay there for long, depending on the altitude. For instance, if we were climbing Mt. Everest, we could be there at the peak only for a few minutes due to atmospheric conditions and human limitations. Descent becomes important pretty soon. But if we are keen mountaineers, we set our sights on the next mountain to climb. In a similar way, when we reach the top of the S curve of a particular skill, we should start the S curve of the next important skill. Ultimately, our skill set should look like a mountain range with a lot of mountains (or a lot of S curves) in it representing various skills that we have learned. Many of us trace multiple S curves in our lives as we learn new skills, but mostly these are incremental or evolutionary transitions. It is harder to make major or revolutionary transitions—ones that involve us moving from one career to a completely different one—say, a teacher becoming a politician. Master of the S Curve To take the idea of making revolutionary transitions to its extreme, I wanted to see if there is anyone out there we could call the Master of the S Curve—someone I define as having had at least three revolutionary S curves in his or her life. I set the threshold at three, because a lot of people have two S curves—for instance, many politicians come from other walks of life, and many sportspersons become commentators or coaches. Therefore, a lot of them automatically have two S curves. Using a quick and dirty research approach, I looked at individuals both contemporary and historical, including TIME magazine’s 100 greatest people list and other Greatest-People-of-All-Time lists. I was looking for people who reached a high degree of success in one field, transitioned into an unrelated field, achieved success in that field, and so on—3 or more times. Since I felt that innately multi-faceted geniuses such as Leonardo da Vinci excelled in many fields at the same time, I excluded them. Of course, I also did not include people who did not become famous because it is hard to know about them. Believe it or not, I could shortlist only two people: Albert Schweitzer (musician/theologian, doctor, humanitarian/social reformer) and Benjamin Franklin (printer/publisher, inventor, statesman/politician). Many scientists have shown that when you expect something to turn out a certain way, it almost always does—a self-fulfilling prophecy. As a note of caution, while we should be aware of the S Curve and how it affects us, we should not automatically assume and expect that the S Curve will play out no matter what we do. If we do that, we will take away the power of human endeavor. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/12/01/chart-120.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/01/Curve.eff77852cdf1.mp3"
	},
	{
		"title": "Benedictine Oblates",
		"text": "Guest Article by Sheri Hostetler Thanks to Kathleen Norris, being a Benedictine oblate is almost hip these days. Norris is the author of the critically received books Dakota: A Spiritual Geography and The Cloister Walk. Both tell the story of a literary New Yorker who moved to the Great Plains and found a spiritual life at—of all places—a Benedictine monastery. More than any other person since Thomas Merton, Norris has helped rekindle interest in monastic spirituality among the “thinking crowd.” While I’d like to think that I became a Benedictine oblate before reading Norris (somehow I think it is morally superior to choose a path before it becomes popular), the truth is that her ruminations on the relevancy of Benedictine spirituality for contemporary life were formative in my own choice. I became an oblate of a small Benedictine community in Oakland, California, in 1999. The Life of a Saint So what is a Benedictine oblate? “Benedictine” does not, in this case, refer to the liqueur of the same name (although that liqueur is made by Benedictine monks in France). Rather, Benedictine means an association with the monastic order based on the teachings of St. Benedict, himself worthy of a separate column on this Web site. St. Benedict was born in 480 A.D., 70 years after the fall of Rome. He came from an educated, wealthy family but eventually left that life behind to pursue the spiritual life. Over time, his reputation as a holy man spread, disciples flocked to him, and he eventually established 12 small monasteries. All monastic communities require some kind of “rule of life” that orders their common spiritual life together. In Benedict’s time, there were several monastic rules in circulation. The most popular one seems to have been a document called The Rule of the Master. Benedict drew from this rule, but with significant changes—mainly in spirit and tone. The Rule of the Master saw monastic communities as a group of individuals gathering around the feet of a sage (usually the abbot), to whom was given enormous power. Benedict, instead, emphasized the relationship of the monks to each other. He saw the monastery as a community of love and the abbot’s main job as tending to the well-being of this community. In addition, The Rule of the Master was harsh and unrelenting in its demands on the monks. Benedict’s rule was known for its moderation, its humanity. Benedictines R Us Benedict’s rule ended up having an enormous influence on Western civilization. At the time of Benedict’s death, his rule was one among many. However, within a century or two, the Rule of St. Benedict had become the norm for Western monasticism. And monasticism had, by this time, become the norm for what was left of Western civilization. Monasteries were, by the sixth century, the one vital institution left in the societal breakdown precipitated by the fall of Rome and the waves of “barbarian” invasions. Benedictine monasteries accumulated illuminated manuscripts and works of art, kept the light of learning and scholarship alive, and generally provided order and stability in a chaotic world. As the Benedictine scholar Esther de Waal writes, “To sketch the history of the Benedictines in the Middle Ages would be not only to write a history of the church, it would be to write a history of medieval society as well.” (From Seeking God: The Way of St. Benedict, pg. 21\\\\. ) Although not as numerous as in their heyday, there are still today hundreds (if not thousands—I couldn’t find an exact number) of Benedictine monasteries around the world. What’s most interesting to me about contemporary Benedictine life, however, is the number of lay men and women who have found spiritual sustenance in the Benedictine rule and in the spirituality it expresses. The test of its popularity? Go to Amazon.com and type in “Benedictine spirituality.” You’ll get more than a dozen titles, most published quite recently (oddly enough, none of Norris’s books is included in that list). Becoming an Oblate Which brings me to the second word in the phrase “Benedictine oblate.” In the most general sense, an oblate is someone who makes an act of oblation. (That explains everything, right?) An oblation literally means “an offering.” So an oblate is someone who makes an offering of themselves—that is, someone who dedicates themselves to a spiritual life. More specifically, oblates are lay people who take an abbreviated form of monastic vows (called “promises”) and become associate members of a particular monastic community. The promises are considered to be for life and are not tied to that particular monastic community—so if you move, you are still an oblate, even if you have no regular contact with the monastic community in which you made your promises. No getting out of them that easily! Oblate promises differ from community to community, but most of them (and this was certainly true of my own) will be based on the three vows taken by all Benedictine monks: * Obedience. While obedience for monks certainly includes the idea of following the will of an abbot or one’s monastic community, it also means more generally attuning one’s spiritual ear to the voice of God in all people and situations and responding to that call. (In fact, the word obedience comes from the Latin root oboedire, which shares its roots with audire, to hear. ) * Stability. Stability refers to physical stability, meaning that a monk commits to life in a particular community and to not leaving when the going gets tough. However, for the oblate, stability is interpreted more generally as not only keeping one’s commitments in life but also committing to the deeper stability of one’s inner being, to a calmness and peace of mind. * Conversatio Morum (or, in English, roughly “ongoing conversion”). Finally, the truly fun and scary promise of conversatio morum simply means that one (whether monk or oblate) commits to always being a pilgrim, to remaining ever open to change and transformation. In addition to the above three ideas, oblate promises would also tend to include some language that says the oblate will follow the Rule of St. Benedict insofar as one’s station in life allows. Now, I confess that to simply sit down and read the Rule of St. Benedict leaves me a little cold. As with the Bible, I need modern scholars to help interpret the relevancy of this book for my life. Thankfully, there are many such books available. My favorite authors are the already-named Norris and de Waal, and also Joan Chittister, a Benedictine nun and rabble-rouser. I’d recommend any of their books on the subject. An Ancient Rule for Postmodern People One of the things I appreciate most about Benedictine spirituality is its emphasis on moderation and balance. Nothing is to be taken to the extreme. For instance, it recognizes the need both for community and for solitude. As a person brought up in a relentlessly community-minded Anabaptist tradition, I have found this an important balance. I love my community; I also need holy solitude on a regular basis. And while Benedictine life is centered around prayer, it’s understood that this must be balanced by work (with a historic emphasis on manual work) and scholarship. Although this insight may seem rather self-evident, I have found it quite helpful in practice. When I feel out of balance, I ask myself, “What do you need, Soul? Do you need to go out in the garden and pull weeds; do you need to read a challenging book; or do you need to sit down and meditate?” The question is always helpful, and usually yields the answer I need. It’s fascinating to me that contemporary men and women have a common bond with those first small monastic communities founded 1,500 years ago. Our lives couldn’t be more different, and yet both I (a married, Mennonite woman) and a celibate, Catholic monk of A.D. 600 have found a foundation for a vital spiritual life in the writings of St. Benedict. In a time when new spiritual fads abound, I find this kind of continuity and stability comforting…and possibly even hip. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/monk.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/01/Benedictine.e0eb2b0f0c8c.mp3"
	},
	{
		"title": "Athabasca Sand Dunes",
		"text": "Picture of a part of the world covered with enormous sand dunes. You may be thinking of a desert in Africa, Asia, or the southwestern United States. But there’s another place, above the 49th parallel, where you can find such sand dunes—Saskatchewan, Canada. Many of my compatriots from other parts of Canada love to make fun of how topographically dull Saskatchewan is; they say it’s an endless expanse of flatness, with no trees or hills. But this western Canadian province is full of surprises. Although the southern half of the province—where you’ll find major cities such as Regina and Saskatoon—is mostly prairie grasslands, the northern half is a wild expanse of rivers, lakes, and coniferous forests. It even has a salt lake with a mineral density greater than that of the Dead Sea, Lake Manitou (Cree for “Lake of Good Spirit”). And furthermore, Cypress Hills, in the southeastern corner of the province, is the highest point in Canada between Labrador and the Rockies. Besides, you can’t claim that a piece of land twice the size of Italy and almost as big as Texas could have so little range (pardon the pun). Is my defensiveness showing? And did I mention the glorious sunsets? The sand dunes I mentioned earlier are associated with a body of water—Lake Athabasca, the province’s largest lake. Located in the far northwest of Saskatchewan, almost at the border with the Northwest Territories, Lake Athabasca is accessible only by floatplane, there being no roads that go that far north. On the south side of the lake, there is a natural geological formation that is unique and surprising to find at this northern latitude—the Athabasca Sand Dunes. In places 30 meters (98 feet) high, and stretching 100 km (62 miles) along the shore of Lake Athabasca, the Athabasca Sand Dunes are the world’s largest area of active sand dunes north of 58 degrees latitude. Don’t Desert Me Although we often associate sand dunes with deserts, in the case of the Athabasca Sand Dunes, this doesn’t hold true. For one thing, deserts are identified by their lack of water, and not only do these dunes border 7,850 square kilometers (3,030 square miles) of water, they also contain significant patches of water in places, percolating up from the shallow water table below. Another feature of deserts—limited plant and animal life—does not hold true for these sand dunes either. In fact, of the 300 plant species that grow in the dunes, there are 10 species that are endemic (found nowhere else in the world), and another 42 species that are considered rare in the province. Not that the dunes are entirely welcoming to the local flora. Because the dunes are active, shifted by wind and eroded by water, they are constantly on the move. Visitors to the region tell of seeing entire stands of skeletal trees emerging from the sand—once above ground and flourishing, these trees were slowly buried by the shifting sand, and now are revealed by further dune movements. Icing on the Lake So, if these sand dunes are not a desert ecosystem, created by extreme drought and aridity, how were they formed? The short answer is: the glaciers did it. The sand dunes are the product of the Athabasca sandstone formation, originally a delta in a freshwater lake created out of materials eroded from ancient mountain ranges by glaciers and rivers one billion years ago. These materials were eventually compressed into sandstone, and later still, eroded by wind, water, and glaciers to create the sand dunes that exist today. Of course, I find the native Dene legend about the dunes' creation more interesting—that a giant man speared a giant beaver, which thrashed and ground the earth with its tail, making soil into sand. Sand by Me Although I’ve never been to the Athabasca Sand Dunes, I do hope to see them one day. Until I do, it makes me happy just to know that they are there, a concrete affront to all those who say that Saskatchewan is nothing more than a boring strip of land between the Alberta and Manitoba borders. And did I mention the sunsets? ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/dunes-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/12/01/Athabasca.529985f7a252.mp3"
	},
	{
		"title": "Cochineal",
		"text": "When I was a kid, there was a time when artificial red food dyes came under intense scrutiny because of their purported health risks. In 1976, the U.S. Food and Drug Administration banned the dye FD&C Red #2 because scientific studies showed it had carcinogenic effects on female rats. In response to the public concern about red food coloring, food manufacturers discontinued some of their red products, even if they didn’t contain Red #2. I remember this clearly because it meant that certain types of candy (such as M&Ms) no longer included red-colored pieces, and that I avoided any red candies I came across. More recently, another type of red food dye, FD&C #40, has been linked to increased hyperactivity in children, although it remains on the list of FDA-approved color additives. Because of the controversy surrounding these artificial dyes, some food manufacturers have turned to another source of red coloring. Known as cochineal, or in some forms, carmine, this dye, produced from a type of insect native to South America and Mexico called the cochineal, has a history that goes back hundreds of years. A Prickly Subject The cochineal insect’s entire life cycle takes place on the pads of certain species of prickly pear cacti. Although sometimes mistakenly referred to as a beetle, it is in fact a scale insect, a type of bug that is usually quite small and that lives by attaching itself to a host plant and drawing sustenance from it. Like other scale insects, the cochineal produces a protective covering for itself, which appears as a white fluffy material on the pads of the cactus. The females are larger than the males, and live longer than the one week that is typical for males. Cochineal insects produce a chemical called carminic acid, which helps them repel predators, and is the source of the dark purple color used to make cochineal dye. The traditional method of obtaining the dye is to remove the insects from the cactus pads by hand, and then to dry them in the sun before crushing them into a powder. It’s estimated that it takes about 70,000 cochineal insects to produce one pound (about 500 grams) of the cochineal powder. Carmine is a further refinement of the cochineal dye, obtained through a process of boiling the powder with certain other chemical compounds. The Cochineal Craze The production of cochineal was well established in Mexico when the Spanish first arrived there in the 16th century. Impressed with the vividness of the dye, they soon began exporting cochineal to Spain and the rest of Europe in vast quantities. Cochineal became a prized commodity on the Continent (Spain refused to trade it with the English), and it created huge profits for Spain. For this reason, the cultivation of cochineal was aggressively restricted to Spanish-controlled Mexico, although this changed when a French naturalist managed to smuggle cochineal-infested cactus pads to Haiti in 1777. From there, cochineal production eventually expanded to South America, India, Portugal, and the Canary Islands, where it became particularly successful. The long-time demand for cochineal started to ebb in the late 1800s as new synthetic dyes were developed, and soon it was no longer economically viable to continue its production. Seeing Red Now, however, cochineal has emerged as a non-toxic alternative to the artificial dyes that supplanted it in the 1800s, and it is again cultivated in the Canary Islands, Peru, and Mexico. Not limited to food, cochineal and carmine are used to give alcoholic beverages, cosmetics, shampoo, and pharmaceuticals a bright red color, and are now regularly added to such food items as meat, poultry, jam, cheese, pastries, yogurt, and fruit juices. Until recently, manufacturers in the U.S. were not required to list cochineal and carmine as specific ingredients in their products, but in response to public protest, the FDA began to look into the issue in January 2006. Certain groups of people, among them vegans, those who observe kosher or halal dietary restrictions, and people who have found they are allergic to cochineal, argue that they should be warned about food items containing crushed insects. I agree with them; although I have no concrete objection to consuming insect carcasses with my daily yogurt, I would appreciate having full knowledge about what I’m eating all the same. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/cochineal-insects-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/Cochineal.f2088cf3add9.mp3"
	},
	{
		"title": "The PB&J Campaign",
		"text": "When I was younger and didn’t have a lot of money to spend on lunches outside the office, I often brought a bag lunch to work which usually (although not always) featured a peanut butter sandwich. My coworkers teased me about this habit, chalking it up to frugal necessity, but it really was a matter of preference. I really liked, maybe even loved, peanut butter sandwiches, and as a vegetarian at the time, it was also an easy way to get some protein into my diet. According to a new online initiative called the PB&J Campaign (referring to peanut butter and jelly, for those uninitiated into this North American tradition), it turns out I was not only saving money and my health, but the environment as well. Through their Web site at www.pbjcampaign.org, the organizers behind the campaign lay out the facts about how incorporating this humble treat into your lunch plans can be a simple way to help the planet. Butter Me Up The PB&J Campaign gives four main reasons why choosing a peanut-butter-and-jelly sandwich over other types of lunch food can have a positive impact on the environment. These reasons are all based on how much of the earth’s resources are needed to produce a meal that contains no animal protein, such as a PB&J sandwich, versus a meal that contains animal protein, such as meat, eggs, or cheese. By chowing down on a PB&J more often, an individual can make a difference in four areas, according to the campaign: global warming, water conservation, land conservation, and animal welfare. Because of the greater resources needed to raise livestock, the group argues that by eating a PB&J sandwich rather than a hamburger for lunch, a diner could save almost 3.5 pounds (1.6kg) of carbon dioxide emissions, and about 280 gallons of water. That meatless lunch could also preserve 12 to 50 square feet (about 4 to 15 square meters) of land from deforestation or other harmful practices. Lastly, a meal without animal protein would definitely have an effect on the animals concerned; the group estimates that eating 16 PB&J sandwiches is equal to saving the life of a chicken. Hard Nut to Crack Whatever your beliefs are about eating meat, I think this campaign is a simple and positive way to make a difference on environmental issues. I am no longer a vegetarian, but I can see the value of giving greater thought to the resources involved in putting food on my plate. Practical suggestions like the PB&J Campaign make it easier for those of us concerned about the environment to integrate enviro-friendly changes into our lives. I also like the fact that instead of being told what not to do, this group is advocating something we should do. All that being said, I worry that this effort, and others like it, may be too simplistic, and may only make me feel better about things I’m already doing (although unfortunately I’ve had to give up peanut butter because it no longer agrees with me). In addition, this is not a one-size-fits-all campaign; those with peanut allergies or sensitivities, or even those concerned about the fat or sugar content of a PB&J, cannot jump on the bandwagon. And this campaign disregards the preferences of those of us who do not like jelly with our peanut butter, but would rather have a PB&H (honey) or PB&B (banana), or other less-mainstream combinations. Sticking To It I’m playing devil’s advocate of course, because the PB&J Campaign itself addresses many of these potential pitfalls on its Web site. They even provide alternatives to PB&J, like black bean chili, vegetarian burritos, and falafel. It’s clear that the call to greater PB&J consumption is not meant to be taken literally, but rather as a means to a worthwhile end. However, I do think touting this mostly unsung culinary creation is a great strategy; there is something very familiar, at least to North Americans, and therefore iconic about the melding of bread, peanut butter, and gelatinized fruit. Now if only I can find some information about how eating chocolate croissants for breakfast every morning can stop global warming, I’d be very happy indeed. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/PBJ.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/PBJ.885aaf796c10.mp3"
	},
	{
		"title": "Coffee Decaffeination Processes",
		"text": "Every day it seems medical researchers come out with a new study about coffee, how it is extremely unhealthy for you and/or full of amazing benefits. The focus of most of these studies is more particularly about the effects of caffeine on human health, caffeine being coffee’s most potent element. As caffeine is a stimulant, it can produce both positive and negative effects. It can wake you up in the morning, but it can also lead to sleeplessness, a racing heartbeat, and anxiety. It is therefore no surprise that many people have decided to cut caffeine out of their diets. What I sometimes find surprising is how many people still opt to drink coffee, just without the caffeine. I have grown to like the taste of coffee, but to me the main purpose of drinking it is to get an extra jolt of energy. I’ll admit to a certain prejudice against decaf, perhaps prompted by bad experiences in the past with weak and tasteless brews. It is true that the actual process of removing caffeine from coffee can degrade the taste beyond repair, however, new methods of decaffeination have been developed to help the coffee retain more of its flavor in the process. In addition, a new strain of coffee beans with a naturally low level of caffeine has recently been discovered. This may all spell good news for those who still crave coffee without its kick. Buzz Kill Early decaffeination attempts involved soaking the green beans in water and then using various solvents to separate out the caffeine in the resulting water solution. The beans were then re-introduced to the caffeine-free solution in order to absorb some of the flavor they had lost. Solvents used included benzene, chloroform, and trichloroethylene, all of which were later found to have toxic effects. In the 1970s, dichloromethane came into use to replace the earlier solvents before it too was deemed possibly carcinogenic. In response to these concerns about solvents, some coffee companies began to run the water solution through charcoal filters as a means of removing the caffeine. The so-called Swiss Water Process, developed in Switzerland in the 1930s, goes one step further. After a batch of coffee beans has been steeped in hot water, that water is filtered (the resulting solution is referred to as “flavor-charged”), and then is used to soak the next batch of beans to be processed. In this way, the beans lose caffeine as they soak, but lose less of their flavor. Yet another method that aims to safely remove caffeine from coffee beans involves a fascinating chemical process. The solvent used in this method is neither water nor one of the earlier toxic solvents. Instead, caffeine in the coffee beans is dissolved by means of carbon dioxide. In order to accomplish this, the carbon dioxide must become a supercritical fluid, created when it is compressed and heated to the point that it has the same density in liquid and gaseous forms. As this supercritical CO2 is passed through the beans, it can penetrate them because of its gaseous properties, and yet is able to dissolve the caffeine they contain because of its liquid properties. Hold the Caffeine All these decaffeination methods are useful in extracting the caffeine from beans that already contain it, but how much more efficient would it be if the beans themselves contained less caffeine in their natural state? In 2004, Brazilian scientists identified three coffee plants from Ethiopia that contain almost no caffeine; these plants seemingly lack an enzyme necessary to caffeine production. If these plants can be crossed with commercial strains of coffee plants, we may one day see more coffee on the market that is naturally low in caffeine. With these advances, and the current methods of decaffeination, decaf junkies are sure to be able to get their fix of coffee that not only tastes great, but won’t keep them up half the night. As for me, I do want to stay up half the night, so I’ll stick to my full-strength brew. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/coffee_beans-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/Decaf.11dd322d2191.mp3"
	},
	{
		"title": "The Influence of Color on Taste Perception",
		"text": "It’s not a secret that the way food looks has an effect on our willingness to eat it. That’s why top chefs spend so much time perfecting the presentation of their plates, and food companies spend so much money on marketing and packaging. Of course, taste is the most important sense when it comes to enjoying food, but just how important is sight? Try this thought experiment: a bowl of yellow-colored gelatin is placed before you. How would you expect it to taste, sweet or sour? It could be that you think it will taste sour, because of your prior experience with other yellow foods that are sour, such as lemons and grapefruits. Or you could think it will taste sweet, based on your memory of other sweet foods that are yellow (like bananas or pineapple). Food producers rely on these kinds of taste associations to help sell their products, and can change their customers' perception of how products will taste by manipulating their coloring. They go to great lengths to find the perfect mouth-watering hue for their goods because they know when it comes to taste, as some studies have shown, color really does matter. Blue Steak and Green Fries In his book Fast Food Nation, journalist Eric Schlosser mentions a study conducted in the 1970s that found the color of food had a great effect on people’s appetites. Test subjects were placed in a room with special colored lighting installed, and then given a plate of steak and French fries to eat. In that setting, the food appeared to be a normal color, but when it was revealed that the steak was blue-colored and the fries were green, some participants became ill. This reaction can be attributed to our instinctual aversion to certain colors of food, blue and purple chief among them. Since these colors don’t occur very often in natural foods, and in fact are sometimes associated with spoiled, moldy food, we have an expectation that foods of this color won’t taste very good or will be bad for us (although there are exceptions of course). On the opposite end of the spectrum, certain colors enhance our enjoyment of food because we have linked the taste of a food with a color, even if it differs from that food’s natural color. A prime example of this is butter, which in its original state can be nearly white, but for commercial purposes is dyed yellow (often using annatto dye) because it is seen as more appealing. Color can even fool our taste buds into perceiving taste differences where none exist. This point was illustrated by a recent study that appeared in the March 2007 issue of the Journal of Consumer Research, “Taste Perception: More than Meets the Tongue.” By changing both the sweetness and the color of orange juice in various increments, researchers found that test subjects ascribed a greater difference in taste between juices of different colors than they did between juices with unequal levels of sweetness. Seeing Green, Tasting Red While food companies know that consumers can be influenced by the intentional use of dyes to make food more appetizing, there have also been some attempts by these companies to go the opposite route: creating products in strange colors. Perhaps the most high-profile example of this in recent years was the EZ Squirt ketchup line from Heinz that included ketchups in green, purple, pink, orange, teal, and finally blue. Heinz saw this as a way to get kids excited about their ketchup, and for a few years it seemed to work, although they are no longer producing the crazy-colored ketchup. Another, not-so-successful, example of this type of marketing ploy was the introduction of Crystal Pepsi in 1992. This colorless, caffeine-free cola’s failure to become popular was most commonly attributed to the disconnection between the color and the taste. It was hard for consumers to imagine a cola being clear, and some claimed it tasted like lemon-lime soda, even though those flavors were not in the beverage (another example of associations affecting taste). I remember trying both products when they came out and getting a kick out of the sensation of expecting one type of taste and getting another. Rationally I knew that the green ketchup tasted just like regular ketchup, but my brain had a hard time processing that; the green ketchup just tasted different. I eventually tired of making that cognitive leap every time I ate macaroni and cheese, and returned to the formulation that seemed more natural. Even knowing that the bright red color I’d come to associate with ketchup was also a fabrication, my taste buds wouldn’t have it any other way. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/dinner-plate-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/Taste.75a4bd1e3d36.mp3"
	},
	{
		"title": "Entomophagy",
		"text": "Having lived the majority of my life in the northern latitudes, I have rarely had to deal with the everyday aspects of life in a tropical climate. Despite this fact, on those occasions when I have visited countries to the south, I have been able to endure the usual tropical conditions, chiefly high heat and humidity, without too much difficulty. However, there is one aspect of tropical life I find particularly hard to handle: coming face to face with insects of gigantic proportions. While there are insects I find annoying in my part of the world (such as mosquitoes and ants), their relatively small size makes them seem less threatening than their tropical cousins. I realize that many people are used to seeing such creatures every day and and therefore don’t find them unnerving. However, this knowledge didn’t help me much when I was Indonesia, and we found two enormous water bugs hiding out in the mosquito netting above our bed. After some comically desperate maneuvers, we finally succeeded in banishing the bugs from the room. Perhaps if we had known that water bugs make a tasty condiment (ground up with chilies to make a spicy Thai paste), we might have welcomed them instead. A Plate of Locusts Although in Western cultures there is a general aversion to being around insects, let alone eating them, in many parts of the world (and also increasingly in the West) the insect kingdom is seen as an important and coveted source of food. The practice of eating bugs as food is known as entomophagy, and has been part of the human experience throughout history. There is evidence that ancient cultures in Mexico, Spain, China, and what is now the United States included insects in their diets. The biblical book of Leviticus mentions locusts, bald locusts, beetles, and grasshoppers as acceptable food for the Israelites, and in the book of Matthew, John the Baptist is said to have subsisted on locusts and wild honey. The ancient Romans also reputedly practiced entomophagy, consuming locusts, cicadas, and stag beetle larvae at their lavish feasts. Today, insect-eating is popular in parts of Africa, Australia, Central and South America, and Asia, including Thailand, Indonesia, China, and Japan. In some places, such as among the Aborigines in Australia, insects are part of the traditional diet, being a readily available source of protein. In other places, insects are considered delicacies, and are prepared in numerous ways meant to tempt the palate—including roasting, frying, and grilling. In Colombia, for example, Hormigas culonas, or fried giant ants, are a regional specialty. Hachi-no-ko, or boiled wasp larvae, can be found in some restaurants in Japan, along with fried cicadas (Semi), rice-field grasshoppers (Inago), and silk moth pupae (Sangi). (Lots of insects are made into candy and snacks, too; see 32 Edible Insect Foods You Can Buy Online at SenseList for examples of such products. ) How to Eat Fried Crickets Despite Western societal taboos against human consumption of insects, a growing number of enthusiasts believe there are economic, environmental, and health benefits to the practice of entomophagy. They argue that it is cheaper, and more efficient, to raise insects as a protein source than it is to rely on other animal products, and that it is less damaging to the environment. In addition, they claim that insects provide more nutritive value, while being lower in fat than other types of protein. These benefits make entomophagy seem like the answer to some pressing problems, but there are a few barriers to it becoming more socially acceptable. Besides the obvious reluctance to eat creatures that many people find repulsive, there is debate about what effect the large-scale practice of entomophagy might have on the environment, with some voicing concern that certain species could be eradicated entirely. Also, some people have adverse reactions to eating insects, whether from allergies or pesticide contamination, making it necessary to educate the public about these dangers. Despite these issues, as a former vegetarian I understand and applaud people’s efforts to eat lower on the food chain, for both health and environmental reasons. However, I don’t think I’d ever be able to switch to a bug-eating lifestyle, no matter how tasty or nutritious they might be. I’ll leave that to those with more adventurous palates and stronger stomachs. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/grasshopper-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/Entomophagy.120e1987dc9e.mp3"
	},
	{
		"title": "Fernet-Branca",
		"text": "While some companies are moving toward greater transparency regarding the ingredients of their products (to allay fears about trans fats, for instance), in some cases the secret of a product’s makeup is not only closely guarded, but promoted as a key part of its allure. Mysteries can be a great advertising gimmick. The proprietors of Antoine’s restaurant in New Orleans were clearly operating from this idea when they created their famous recipe for Oysters Rockefeller; although it has been widely speculated upon, this recipe has remained a secret since it was first developed in 1899. Having sampled Oysters Rockefeller at Antoine’s, I would say that I greatly enjoyed their taste, but I got more enjoyment out of trying to guess the elements of the recipe. This same type of marketing is at work in the promotion of Dr Pepper soda. The only information given by the manufacturer is that it contains 23 flavors; it’s up to customers to draw their own conclusions about what those flavors are. Ditto for Coca Cola’s secret recipe and the “11 herbs and spices” in Kentucky Fried Chicken. In a similar vein, the makers of one of Italy’s best-known liqueurs, Fernet-Branca, prefer to keep the composition of their product top secret, but rumors about what it may contain are certainly tantalizing. Saffron So Good Fernet-Branca is a type of bitters, a spirit made from different herbs, plants, and roots that supposedly aids digestion and stimulates the appetite. Other types of bitters include Campari, Angostura bitters, and orange bitters. While the complete list of 40 herbs and spices that go into Fernet-Branca has never been made public, some of its ingredients are common knowledge, and include myrrh, chamomile, cardamom, aloe, and saffron, as well as its base component of grape alcohol. Saffron in particular seems to be an important ingredient; this rare spice, harvested from the saffron crocus flower, is the world’s most expensive spice by weight. According to an article about Fernet-Branca that appeared in a San Francisco newspaper, the company that produces Fernet-Branca, Fratelli Branca, is the largest consumer of saffron in the world, claiming 75 percent of worldwide output. As far as the other ingredients are concerned, there is wide speculation about what these may be. A few of the rumored mystery elements include: rhubarb, cinchona bark from South America (known for its anti-malarial properties), gentian root (a powerful medicinal herb), wormwood (once used in absinthe), bay leaves, sage, peppermint oil, and the ginger-like spices galanga and zedoary. Medicinal Compound With all these medicinal ingredients, it is not surprising that Fernet-Branca was first developed as a health elixir. The creator of the formula, Bernardino Branca, was a self-taught apothecary in Milan, who first offered Fernet-Branca to the public in 1845. Marketing his product as a tonic to cure many kinds of illness, Branca even persuaded the director of a local hospital of its curative benefits. Even today, Fernet-Branca is known for its ability to calm upset stomachs and soothe hangover misery. If other accounts are to be believed, it can also cure cholera and ease menstrual cramp pain. The health-enhancing nature of this spirit proved handy during Prohibition in the United States. Since it was considered a medicinal product, pharmacies could import and sell Fernet-Branca without interference from the government. Where Everybody Knows Its Name Although Fernet-Branca is made by an Italian company, Italy is not the largest consumer of this liqueur. In fact, there are two other places in the world known for their prodigious consumption of the bitter quaff. These two places are San Francisco, California, and the country of Argentina. San Francisco is the biggest consumer of Fernet-Branca in the United States, and has the highest per capita consumption of it in the world. Its popularity in the city may be partially attributed to San Francisco’s large Italian-American community, centered around the commercial district of North Beach. Whatever the reason, San Franciscans drink Fernet-Branca in large quantities, usually followed by a chaser of ginger ale. Argentina also has a large Italian population and a similar thirst for Fernet-Branca. There is even a popular song that celebrates the joys of “Fernet Con Coca,” or Fernet mixed with cola, the usual way it is prepared in Argentina. A Matter of Taste Being a long-time resident of San Francisco, and feeling ashamed that I had never enjoyed this quintessential San Francisco experience, I tried my first shot of Fernet-Branca not too long ago. Unsure of what to expect, and slightly put off by the strong pine scent I registered, I closed my eyes and gulped it down. The intense menthol-like sensation caused me to cough, and I didn’t enjoy the bitter aftertaste the drink created, but soon after finishing it, I began to feel a bit better. I can’t say whether or not I gained any health benefits from drinking the Fernet-Branca, but the next time I experience an upset stomach I will have to try another shot of it, for purely medicinal purposes of course. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/Fernet-Branca-120.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/Fernet.3af72b06fe26.mp3"
	},
	{
		"title": "Anopsology",
		"text": "I’ve always liked the expression “all things in moderation.” I’m not sure it represents some sort of universal law, but it seems to be a reasonable attitude with which to approach most situations in life. It suits my personality, too, because I like novelty and variety while I resist both excesses and prohibitions. When it comes to food, this sort of mindset means I wouldn’t categorically say no to any class of food—vegetables, meat, dairy, alcohol, junk food, and genetically modified organisms are all valid options. However, I try to be aware of the nutritional properties and likely health implications of what I eat, and to make food choices deliberately. So I’ll eat that occasional crème brûlée without guilt, but I’ll probably also back off on sugars and carbs the next day. The problem is, I can’t always figure out whose opinions about nutrition and health I should believe. Among the many paths to optimal health I’ve heard are these: avoid all carbohydrates and eat mostly protein; eat only plant products; eat only fruits; eat just one particular fruit; take vitamins; stay away from vitamins. I’ve heard that eggs are bad for your health; I’ve heard that they’re great for your health. Ditto for coffee and wine. I’ve heard that foods like honey and tea will help you live to be 100 and that they’ll lead to an early grave. Many of these contradictory claims were made by trained health professionals with years of experience, and have a stack of studies and anecdotal reports supporting them. For this reason, I take any proclamation about a particular diet’s virtues with a large pinch of kosher salt. I say all this by way of qualifying today’s topic: anopsology. Also known as instinctive eating, instincto, or anosology, it’s the practice of eating only raw foods—and specifically, those raw foods that humans would have eaten before the development of agriculture or fire. So fresh fruits, vegetables, seeds, nuts, honey, and even raw meats are in; dairy, grains, and all processed foods are out. By “processed,” I mean “altered in any way.” In other words, you can’t grind, press, or squeeze your foods. Nor can you season them. In fact, a central tenet of anopsology is that foods should never be combined in any way in the same bite. And, worst of all, you must never apply heat to foods in any fashion. Basic Instinct My first reaction upon hearing about anopsology was that it’s highly kooky. After reading more about it and considering it in greater detail…OK, I still actually think it’s highly kooky. But there’s also more to it than meets the eye. The rationale behind the notion of eating raw, unprocessed foods is not without some merit, and while I wouldn’t choose that path for myself, it does provide, shall we say, food for thought. Anopsology was the brainchild of Guy-Claude Burger, a Swiss cellist and physicist born in 1934. Burger was diagnosed with cancer, and decided to treat himself by eating only raw foods. The cancer went away, so Burger concluded the raw foods had cured him. He went on to study, write about, and promote the virtues of raw foods. Although Burger was not trained as a physician or nutritionist, he developed an extensive theory to explain how and why anopsology works. The gist of the theory is that humans evolved over millions of years eating only raw foods (as would have been necessary before the advent of agriculture and the use of fire for cooking); therefore, the human body must be genetically adapted to function best when only raw foods are consumed. Further, the theory goes, humans can instinctively tell (by smell and taste) which foods are good for them. After consuming a certain quantity of any “original” (or raw and unaltered) food, its taste will change to become less appealing; this is the body’s signal that you’ve had enough and it’s time to stop eating that food. By mixing, cooking, seasoning, or processing foods, you mask these taste changes, so the only way to guarantee that you can detect and respond properly to the changes in taste is to eat foods completely separately from each other. By eating raw foods in this manner, proponents say, one can cure or prevent a long list of diseases (everything from athlete’s foot to cancer) and ensure a long and healthy life. Anecdotal stories of miraculous cures abound. Unfortunately, very little medical research exists to support or refute these claims. Meanwhile, according to another set of anecdotal stories, some people who have religiously followed a raw-food diet for decades have still somehow gotten sick and died. A Raw Deal That’s just the beginning of the criticism of anopsology. Some observers point out that instinctos (as they call themselves) typically eat a lot of foods that didn’t exist in the pre-fire, pre-agriculture world—hybrids and selectively cultivated plants that have only been available relatively recently. They also, curiously, avoid foods such as rhubarb and kidney beans, which are toxic until cooked. Furthermore, contrary to anopsologists' claims, some foods are demonstrably easier for the body to digest when cooked. Then there’s that whole notion that humans haven’t evolved appreciably since cooking was invented—at least 10,000 years ago, and more likely 40,000 years ago. That strikes me as unlikely, but even if it’s true, it’s a stretch to assume that before that time, humans were perfectly adapted to eat any, all, and only raw foods. In addition, it’s ridiculous to assume that no one ever ground, squeezed, or combined foods before the discovery of fire. Even if there is a process by which raw foods change in taste to signal us that we’ve had enough, evidence is scant that our ancient ancestors relied on it. And if smell and taste are truly such outstanding indicators of what’s good for us, then I think it’s odd to say that mechanism couldn’t apply to, say, baked goods—to assume that because the ingredients have been processed, they must be fooling our senses. Interestingly, vegans have been among the most vocal critics of anopsology, saying that it goes too far by permitting meat. Some vegans, on the other hand, say it’s also too limiting in not allowing all plant products. And then there are the fruitarians, who advocate eating only raw fruit (including seeds and nuts); according to them, anopsology and veganism are too broad. Meanwhile, Burger was sentenced to a 15-year prison term for pedophilia in 2001 (and not for the first time, either). Of course, this fact has no bearing on anopsology as such, but it obviously casts a generally dim light on his thought processes. Personally, I find the arguments in favor of anopsology unconvincing. Although I can see the appeal in wanting to eat those foods for which the body is best adapted, it seems unlikely that we’ll ever determine conclusively what those are, or that they’re the same for all people for all time. Unless or until such proof is forthcoming. I’ll carry on eating my balanced diet of raw and processed foods. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/vegetables-2-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/Anopsology.52b4bbc6305e.mp3"
	},
	{
		"title": "Beurre Salé. The savory treat from Brittany",
		"text": "For those of us paying close attention to what we eat these days, there are always food items whose absence we mourn more than others, and we may even question why these items are restricted. What could be more wholesome than butter, made fresh from healthy milk, and with all those happy images on the carton? And as Mark Kurlansky detailed in his book Salt: A World History, salt has played an important role in human society and is even necessary (in a certain amount) to the healthy functioning of our bodies. But, as we know, butter and salt are very high on the current list of dietary no-no’s, and with good reason. Just because we crave something doesn’t mean it’s healthy to have it in copious quantities. However, having switched to olive oil for most of my cooking and having made attempts to reduce my salt intake, I still love (and will indulge in) buttery, salted things from time to time. Knowing all this, I was still inspired and haunted by an image I saw recently on a food blog of the tastiest combination of this “evil” duo: creamy butter laced and studded with large crystals of salt. This tempting concoction is beurre salé (literally, “salted butter”), a regional specialty from the Brittany region of France. Worth Its Salt So what makes this salted butter different from the kind you can buy at the local supermarket? For one thing, it’s made with Brittany sea salt, some of the finest produced anywhere. Brittany is located in the northwest corner of France (south of Normandy) and its lengthy ocean coastline is a perfect place for cultivating salt. Its most famous type of salt, fleur de sel , comes from the town of Guérande (which was historically part of Brittany, but is now part of the Pays de Loire region), and is world-renowned for its texture and flavor. Having such ready access to salt, Breton cuisine developed to take advantage of this situation. Whereas in most other regions of France there are dozens, if not hundreds, of types of cheese specific to that region, there is not even a word for cheese in the Breton language. There are a few cheeses to be found in the region, but less-processed dairy products (butter and cream) are much more prevalent in the Breton cuisine. The reason is that before the advent of refrigeration, making milk into cheese was more effective against spoilage than making butter—that is, unless you had plenty of salt. Sel Preservation Salt has historically been used as a preservative; that is a large part of why it has been so coveted throughout human history. In the case of butter, this was especially so, since butter has a tendency to quickly go rancid when it is exposed to air. Refrigeration has taken care of this problem for modern butter-eaters (and the invention of a water-sealed butter dish helped too), but it was a serious problem for our ancestors. According to Margaret Visser’s book Much Depends on Dinner, butter that has been oxidized (exposed to the air) can cause “diarrhoea, poor growth, loss of hair, skin lesions, anorexia, emaciation and intestinal haemorrhages.” Mixing butter with salt, or storing it in brine, was a way to prevent butter from going rancid, and was commonly done before the days of refrigeration. Indeed, a record from A.D. 1305 noted that one pound of salt was added to every ten pounds of butter or cheese. To remove some of the salt, people had to rinse the butter by kneading water into it, and then squeezing it out again along with some of the salt. Butter Batters No longer a necessity, beurre salé is today a gourmet treat; it is used in many traditional Breton dishes, and is coveted for its delicious effect on everything from fine chocolates to buttery cakes. It may seem counterintuitive, but salt can be as important as sugar in many dessert recipes, and lends an interesting counterpoint to the sweetness. Traditional Breton desserts made using beurre salé include: gâteaux Breton, a type of poundcake made with flour, butter, sugar, and eggs; palets Bretons, small buttery cakes; and caramel au beurre salé, which can refer to individual candies (salted caramels) or the process of caramelizing sugar and salted butter while baking a dessert, such as Kouign Amann. Amann is the Breton word for butter, and this cake is made with plenty of it, along with yeast, sugar, flour, and water. Personally, I can’t wait to try all of these delicacies, despite my commitment to healthier living. For though butter and salt may play havoc with my cardiac capabilities, together they seem capable of melting anyone’s heart. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/butter-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/Beurre.9b641a42081c.mp3"
	},
	{
		"title": "DNA Fingerprinting",
		"text": "Guest Article by Rajagopal Sukumar From high-profile trials to popular TV shows, numerous events have imprinted on our collective psyche the fact that DNA evidence can be used to solve crimes. But the technique has extensive uses that go far beyond forensic science. You may even owe tonight’s dinner, in part, to DNA fingerprinting. My curiosity about this subject was piqued when I came across a recent newspaper report that talked about how DNA fingerprinting is being used in India to identify different varieties of basmati rice. The report mentioned a hotel that buys around 200 tons of basmati rice per year. The hotel’s chefs found it difficult to cook the rice properly because each type of basmati rice has different soaking times and cooking properties. A visual inspection is of limited use because all the varieties look nearly the same. They decided to solve this problem by working with the rice’s producer to certify each bag of rice using DNA fingerprinting; the chefs then use the information to help them determine the proper cooking parameters. How Does It Work? DNA sequences are extremely long, and comparing an entire DNA sequence with another would be hard to do. Fortunately, though, about 99% of human DNA is identical from one person to the next. The 1% that’s different includes several frequently repeating sequences; the number of repeating sequences in any given position on a chromosome is different for each person. Therefore, in DNA fingerprinting, fragments of DNA are extracted and a collection is created that is unique for each person. There are several techniques for doing so; they differ mainly in how the fragments are extracted and how they are converted into a form that can be analyzed for identification. While human DNA fingerprinting has numerous uses in law and forensics—from verifying paternity to identifying murder suspects—this technique also applies to other organisms. Plants, animals, and even bacteria have unique DNA fingerprints. An increasing range of applications makes use of this fact. For example: * Fighting Disease: The big problem in treating bacterial infections using antibiotics is the fact that, over time, bacteria become resistant to the antibiotics, thereby making the treatment ineffective. DNA fingerprinting is being used to identify antibiotic-resistant strains. This helps doctors to select an antibiotic other than the one to which the bacteria are resistant, or consider a different type of treatment altogether. The Centers for Disease Control (CDC) has been using DNA fingerprinting successfully for controlling the spread of tuberculosis (caused by Mycobacterium tuberculosis) for the past few years. * Fighting Foodborne Illnesses: E. coli is a type of bacteria that lives in the intestines of humans and animals and is generally harmless. However, there are a few strains of E. coli that are quite dangerous—such as O157:H7 (sometimes found as a contaminant in beef), which produces a powerful toxin and can cause severe illness. By using DNA fingerprinting, this harmful strain can be identified easily if it’s present in food. After a major outbreak of this E. coli strain in 1993, the CDC created PulseNet, a national network of laboratories that performs DNA fingerprinting on food-borne bacteria. PulseNet has been instrumental in stopping outbreaks by quickly identifying the strain in contaminated food after comparing it against known patterns. * Fighting Fraud: How do you know that the contents of the bottle of wine or the bottle of medicine you are about to consume is authentic? Wine producers are using DNA fingerprinting to ensure that the correct grapes have gone into the making of the wine, thereby guaranteeing its authenticity. Pharmaceutical manufacturers are working on using DNA fingerprinting for labeling medicines so that counterfeits can be detected more readily. Experts now think that DNA fingerprinting, when combined with rapid detection methods, can give rise to better authentication tools than the ones in use today. * Genography: Not to be confused with geography, genography (or genetic anthropology) studies the migration patterns of humans over long periods of time. The National Geographic Society has embarked on an ambitious 5-year project that will use DNA fingerprinting to map the journey of human beings since prehistoric times as they migrated to various parts of the globe. They are relying on the fact that some parts of the DNA, called “genetic markers,” are passed down generation to generation without modification. Using these markers, the project attempts to trace the movement of humans over the ages and the path of human evolution from their prehistoric roots in Africa. As the field of genetic engineering increases in popularity, the range of applications for DNA fingerprinting is likely to widen. Just as with conventional fingerprinting, there is always some margin of error, and ethical questions abound, particularly when humans are involved. But the evidence so far suggests that the potential benefits far outweigh the risks, and the future of DNA fingerprinting looks bright. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/Fingerprint.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/DNA.532950e0e19c.mp3"
	},
	{
		"title": "Saffron",
		"text": "As I’ve mentioned a few times, I’m a bit of a French food snob. Before Morgen and I went to France the first time, we did our homework—reading up on lots of French dishes, particularly regional specialties. The list of things we had to try included authentic bouillabaisse, an elaborate fish stew seasoned with saffron. Unfortunately, what constitutes “authentic” is a matter of strenuous debate among French chefs; there are many, many different recipes. But since the dish was invented in Marseille, a large Mediterranean port city, we decided we’d define “authentic” as “whatever they served us in Marseille.” Based on what I’d read, I didn’t have much interest in Marseille apart from its food, and our schedule was tight. Our itinerary called for us to take an overnight train there from Paris and then pick up a rental car so that we could tool around Provence for a while. We’d have, at most, a few hours in the city, during which time we had just one task to accomplish. Our plan was to get in, get some bouillabaisse, and get out. After we got our car, we drove to the old part of the city where we’d heard we could find some great restaurants. Since it was still before lunchtime and they weren’t open yet, we walked around for about an hour, studying menus and building up an appetite. In the end, we couldn’t figure out which restaurant was the most authentic-looking, so we picked one at random. The waitress offered us menus, but we didn’t need them—we were on a mission. We dutifully ordered bouillabaisse for two, which turned out to be about five times as much as we could eat. But it was unbelievably good—a truly profound experience that made our visit to the city more than worthwhile. Ever since then, the smell of saffron has taken me back to that restaurant in Marseille. Flower, Sugar, and Spice Besides bouillabaisse, some of the other dishes famously flavored with saffron include paella (from Spain) and risotto alla milanese (from Italy). I’ve even had saffron-flavored ice cream at an Indian ice cream shop here in San Francisco. (No kidding.) It was delicious. Saffron is obscenely expensive, but unlike many expensive foods, it has a unique and wondrous flavor that makes it worth every penny. The expense is a result of the manual labor required to harvest and prepare it. Saffron comes from the saffron crocus, Crocus sativus. Each purple flower has three threadlike orangish-red stigmas, which form part of the plant’s reproductive apparatus. When these are removed by hand and then dried, they become saffron. The stigmas are very, very small, and it takes several hundred to make up a gram of saffron. Depending on their size, it can take as many as 200,000 flowers to make a pound of saffron. Only about 30 tons are produced per year worldwide. Saffron’s distinctive color has led to its use as a dye; Buddhist monks traditionally wear saffron-colored robes. (It’s also very effective at imparting a yellow or orange color to foods.) Interestingly, though, the chemical compounds that provide the color are not the same ones that provide the aroma and flavor. Saffron has numerous medicinal properties; it’s particularly known as a natural antidepressant. It reportedly has antispasmodic properties, functions as a digestive aid, and reduces intestinal gas—among many other attributes. It can be dangerous if ingested in large quantities, but fortunately, few people can afford to buy enough saffron to make them sick. Gold Spice Saffron currently costs about two-thirds as much as gold by weight. That makes saffron the most expensive food product in the world, gram for gram—more expensive than truffles or caviar. And even though you can buy dishes that include flakes of gold leaf, the overall price of the food will still be less than a comparable mass of saffron. OK, I’m sure someone could find some really cheap saffron or outrageously rare caviar and disprove this claim; there are also a few insanely expensive old bottles of wine out there that can cost US$1,000 per swallow. But let’s just say it’s the most expensive food product I’ll ever have in my kitchen. Fortunately, a little bit goes a long way. A gram of saffron, which you can buy in a little bottle for less than $10, will amount to about a teaspoonful when crumbled—enough to flavor a very large batch of bouillabaisse. The aroma will also permeate your entire house and linger for some time; assuming you like the aroma, that gives it some bonus value as an air freshener. All in all, it’s money well spent for the spice that’s as good as gold. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/Saffron-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/Saffron.54294947038d.mp3"
	},
	{
		"title": "Water Freezing and Boiling Myths",
		"text": "One of my favorite classes in high school was Chemistry. I remember on one occasion, our teacher gave us all a very strange and difficult assignment. It was a list of “real-world” questions to which chemistry could presumably provide the answers, and we were given several days to figure them out, with complete freedom to consult libraries or any other available sources to get the information. One of these questions had to do with the freezing point of water. I no longer remember the exact wording, but the gist of it was that if you had two wooden buckets of a given size, one containing hot water and the other containing cold water (with precise temperatures specified in each case), and if you exposed said buckets to an air temperature of such-and-such, which one would freeze first? The obvious answer, of course, would have been the one with colder water, which led us to believe that this must be the wrong answer. However, it was not sufficient to provide the correct response; we had to justify the answer based on our knowledge of chemistry. Well, despite a great deal of research—and bear in mind, this was back when research meant looking at books rather than searching the Web—I came up empty-handed. I left that one blank, and I even missed class on the day the assignment was discussed, so I never found out the solution to this mystery. Years later, I was to discover that there are a number of urban myths about the boiling point and freezing point of water, with “hot water freezes faster” being just one of them. I scoured a bunch of Web sites, and came up with contradictory information. But this is not, after all, rocket science—there’s no reason I should have to live with uncertainty about something so easily demonstrated. So I decided to conduct my own experiments and find out for myself. Although I didn’t have a wooden bucket handy, I did have a freezer, a stove, some water, and a digital thermometer. I’ll tell you the results of my experiments in just a moment. But first, here are some of the interesting claims about water I found. * Hot water freezes faster than cold water. Most experts say that, all things being equal, cold water freezes faster. However, things are not always equal. A curious phenomenon known as the Mpemba effect can, under some very specific (and poorly understood) circumstances, result in hot water freezing faster than cold water. One of the several possible explanations for this effect involves evaporation: if you start with extremely hot water, a good bit of it will evaporate (and a smaller quantity of water will freeze faster than a larger quantity). And so, according to chemists, this one is not a myth, and this is presumably what my high school chemistry assignment was getting at. * Previously boiled water freezes faster than regular water. Notwithstanding the previous explanation, water at room temperature that was once boiled, according to some experts, should freeze faster because the dissolved oxygen has been removed. * Previously boiled water boils faster than regular water. Likewise, previously boiled water at room temperature should boil faster than water that has never been boiled, for the same reason it freezes faster (less dissolved oxygen). * Cold water boils faster than hot water. If hot water freezes faster, maybe cold water boils faster! Again, this defies common sense—and again, say scientists, it’s simply wrong. Hot water from the tap should in fact boil much faster than cold water. However, using hot water for boiling does not actually save any energy. You may use less gas (or electricity) on the stovetop, but your water heater will have used the same amount of energy to heat the water in the first place. (If you use solar energy to heat your water, of course, that’s a different story.) Some water heaters may introduce additional sediment into the water, giving you another reason to consider starting with cold—at least, if time is not of the essence. * Adding salt to water raises its boiling point. Chemically speaking, this is a verifiable fact. Salt does raise water’s boiling point (and lower its freezing point—which is why home ice cream makers use rock salt). But the real question is whether this makes it take longer to get to the boiling point (and, for that matter, how far above 212°F/100°C it will get). Despite what you read in cookbooks, scientists claim that the amount of salt you’d typically add to a pot of boiling water is too small to make any meaningful difference in the boiling time or boiling point. So, given what I knew should happen, here’s what actually occurred in my experiments. Freezing Water: I started with three identical glass containers, each holding 100ml (about 3.5 fl. oz.) of filtered water: one at room temperature (72°F/22°C), one at the same temperature as my hot water tap (115°F/46°C), and one boiling (212°F/100°C). I put all these into my freezer, which has an air temperature of 0°F (–18°C). Since I knew that the water would not turn from liquid to ice all at once, my arbitrary standard for frozenness was the time at which a wooden chopstick dropped into the center of the container would no longer touch the bottom. I checked each of the containers every 5 minutes. The results? The room-temperature water froze in 50 minutes. The hot water froze in 80 minutes. And the boiling water froze in 95 minutes. My verdict: no contest—not even remotely close. Given the conditions in my freezer and the water I used, I could not reproduce the Mpemba effect. I also tried a container of previously boiled water, now at room temperature. It froze in 60 minutes—more time (not less) than the unboiled water had taken, but not by much. Boiling Water (Hot vs. Cold): I put a liter (about 34 fl. oz.) of water at room temperature in a pan at room temperature and set it on a high flame. It boiled in 6 minutes. I then cooled the pan back to room temperature and put in a liter of hot (115°F/46°C) tap water. With the flame unchanged, the hot water boiled in 4 minutes, 30 seconds. My verdict: hot water does boil significantly faster, just as you’d expect. Boiling Previously Boiled Water: I put a liter of water that had previously been boiled, now cooled to room temperature, into a pan at room temperature. With the flame unchanged from the last experiment, this water boiled in 6 minutes, 11 seconds. My verdict: essentially the same as water that hadn’t been boiled. Boiling Water (with salt): I added a generous 2 tablespoons of table salt—much more than most people would ever use for boiling pasta or vegetables—to a mere 1 liter of water. It boiled in 6 minutes, 33 seconds (versus 6 minutes for unsalted, room-temperature water) and reached a temperature, according to my thermometer, of 216°F (102°C). So clearly the salt had an effect, but not much of one—and this was with an uncommonly high concentration. My verdict: Add salt to water if you want to season it, but don’t expect it to make any significant change in the water’s boiling time or temperature. Now, I freely admit that my kitchen is no laboratory, and that any number of variables could have influenced the outcome. My measurements may have been imprecise. My freezer may have had uneven zones of warmer or colder air. My glassware may have been contaminated. And so on. But whatever may occur under ideal conditions in a laboratory, when it comes to freezing or boiling water in an ordinary kitchen, common sense prevails. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/boiling-water.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/Water.655e00c3c9a5.mp3"
	},
	{
		"title": "Castor Oil",
		"text": "I have never had the pleasure (or displeasure) of ingesting castor oil. As a kid, though, I remember watching reruns of The Little Rascals, in which castor oil was used from time to time, and I have a vague recollection that my grandmother may have had an old bottle sitting around somewhere. Whenever I heard castor oil mentioned, comedically or otherwise, it seemed to have a threat attached to it: “If you’re not good, I’ll give you a spoonful of castor oil.” Oddly enough, this threat even seemed to be present when a child was apparently sick: “If you don’t get better, we’re going to have to give you some castor oil.” In other words, this stuff was seemingly so awful it could scare you into recovery, though I never quite grasped why that was. Presumably it tasted bad, but then, so did cough syrup. How terrible could a spoonful of anything be? And apart from tasting bad, what exactly was castor oil supposed to do? In-N-Out The short answer is that castor oil is a strong laxative—and presumably, cleansing the bowels in such a forceful manner could serve either a beneficial or a punitive purpose. But then, if it’s a laxative you’re after, there are less obnoxious potions, such as prune juice or even oatmeal. The taste itself, apparently, was supposed to build character. Castor oil is also known to induce vomiting—again, occasionally a medically useful thing, though more often, a symptom one would wish to be cured of. It turns out that there’s much more to castor oil—both good and bad—than Grandma ever suspected. Castor oil comes from the seed of a plant called Ricinus communis, which grows in most parts of the world. The seeds are commonly known as “castor beans” because they look like beans, though the name Ricinus is Latin for a type of tick, which the seed also resembles. To obtain castor oil, one simply removes the hulls of the seeds and cold-presses them. The oil is extremely versatile. Castor oil is used in the production of plastics, soaps, textiles, paints, cosmetics, inks and dyes, adhesives, lubricants, polishes, and numerous other products. It’s also sometimes used to induce labor in pregnant women, though from what I’ve read, its effectiveness in such cases is somewhat in doubt. Only a tiny percentage of the oil is sold for medicinal use—and only a tiny percentage of that is ever actually used as a purgative or emetic. Although it’s very effective at causing the digestive system to discharge its contents (from whichever end), its unpleasant taste has made its use quite rare these days. Weapon of Mass Doo-Doo Mussolini famously used castor oil as a weapon of sorts against political dissidents in Italy in the 1920s. Fascist operatives would capture their opponents and force-feed them a large quantity of castor oil. This produced severe diarrhea—in some cases, severe enough to cause death. (When the explicit goal was to murder someone rather than scare them, a little gasoline was mixed into the castor oil for good measure. ) But the humble castor plant can in fact do much worse. The residue left over after pressing castor seeds contains about 5% ricin, an astonishingly toxic poison. How toxic? Well, I’ve read that it’s twice as poisonous as cobra venom, 6,000 times as poisonous as cyanide, and 12,000 times as poisonous as rattlesnake venom. A dose as small as the weight of a single grain of salt can be lethal to an adult human. And it’s even more deadly when inhaled than when ingested. In other words, it’s really not something you want to mess with, especially since there’s no antidote. Ricin has been used in the production of chemical weapons, and although it’s not as toxic as some such agents, it’s extremely hard to control, as the plants can grow nearly anywhere and extraction of the poison is relatively simple. (For that matter, simply consuming a few of the raw seeds can kill you. ) All this, of course, leads one to wonder whether there might not potentially be tiny amounts of ricin in castor oil. I’ve read conflicting statements—some sources say no, pure castor oil contains no ricin at all; others say it contains some, but it’s such a miniscule amount that it wouldn’t hurt anyone. For some reason, I don’t find that terribly comforting. All in all, it’s a good argument to stick with that high-fiber diet, and if I really need an awful-tasting laxative, I’ll spike my prune juice with vodka. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/castor-oil.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/Castor.8b53f74627f0.mp3"
	},
	{
		"title": "The Bavarian Purity Law",
		"text": "When guests come to our home, we offer them something to drink. We typically have a rather wide range of beverages available—water, milk, coffee, tea, fruit juices, soft drinks, wine, spirits, and perhaps even some Tang—in other words, something for pretty much everyone. I used to tell people, “Whatever you might want to drink, we probably have it,” but this invariably resulted in requests for either beer, which we seldom have in the house, or decaffeinated coffee, which we never, ever have. (We do have to maintain some standards, after all.) It’s not that we have anything against beer, it’s just that we habitually think of it as the type of thing one enjoys in a restaurant or pub rather than at home. I do, however, believe that if you’re going to drink beer, it ought to be a good beer, one made with some care and exhibiting a bit of character. Insipid, generic beers that are consumed by the six-pack with no more thought than cola are not, in my humble opinion, worth drinking. Several years ago, Morgen and I visited Germany—more specifically, the region in southeastern Germany known as Bavaria. Although Germany ranks third in per-capita beer consumption (after the Czech Republic and Ireland), it is clearly a place where people take their beer very seriously. Bavaria, in particular, is home to the oldest (non-religious) legal standard of food production still in force: The legendary Bavarian Purity Law of 1516, known in German as the Reinheitsgebot. The Duke of Beers The short version of this law, which was enacted on April 23, 1516 by Bavarian Duke Wilhelm IV (a.k.a. William IV), is that beer may contain only three ingredients: barley, hops, and water. Ostensibly, this makes the law one of the oldest “consumer protection” regulations, instilling confidence in purchasers that the beer they get will contain no questionable grains or additives. (Among the additives the law sought to ban were some commonly used herbs that had hallucinogenic effects.) But in fact, the bit about beer ingredients was simply one sentence in a much longer ordinance that primarily specified beer pricing regulations. The intention of the law was not only to ensure the quality of the beer and control pricing, but also to guarantee that more valuable grains such as wheat and rye, which were needed for bread and often in short supply, were not used for beermaking. This was not actually the first law of its kind, either—similar ordinances date back as far as 1165—but it was the first to apply to all of Bavaria, and the oldest such regulation still in force today. Astute observers will note that yeast is not among the three ingredients listed—and without yeast, beer could not ferment. In the 16th century, the existence of microorganisms was still unknown, and beer was sometimes made simply by allowing the ingredients to sit out until some airborne yeast found its way into the vat and fermentation began on its own. Other times, sediment from an earlier batch was used as a starter—but this was not thought of as a separate “ingredient.” The Yeast You Can Do During the 20th century, the Reinheitsgebot underwent some significant changes. For one thing, yeast was officially added to the list of allowable ingredients. For another, a distinction was made between beers brewed with “top-fermenting” yeasts and those brewed with “bottom-fermenting” yeasts. For bottom-fermenting beers, only malted (that is, sprouted) barley is permitted; for top-fermenting beers, any malted grain (such as wheat) can be used, as can sugar. There are also a number of exceptions and variations in the law that can be applied under certain circumstances. In some cases you can manufacture a “special” beer that colors outside the lines slightly as long as you clearly identify it as such, and of course you can put anything you want in your beer as long as you don’t actually call it “beer.” Critics have pointed out that one can follow the Bavarian Purity Law and still produce very bad beer (for example, using poor-quality ingredients or sloppy technique)—and that, conversely, many excellent beers (including some well-known Irish and Belgian varieties) do not and could not conform to this law. (European Union rules, by the way, now stipulate that the Reinheitsgebot can only apply to beers brewed inside Germany, not to imports.) So in a way, what the regulations enforce is “purity” in the sense of values traditional to the region, rather than the absence of contaminants or a guarantee of quality. German beers that conform to the Bavarian Purity Law get to advertise this fact on their labels, and it’s popularly believed to have a great deal of marketing appeal. So much so, in fact, that the principles have been adopted by beermakers in many other countries as well, right down to local microbreweries in the U.S. and Canada. I must admit that, despite having my own high standards for beer, at this point I think the Bavarian Purity Law is anachronistic and more than a bit gimmicky. Or at least, I did until I discovered that Anheuser-Busch is now selling a beer with caffeine, guarana, and ginseng (not to mention fruit flavors). That is a prime example of a beverage that, whatever its merits may be (and I can barely imagine), should not be permitted to call itself beer. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/beer.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/Purity.38f1fa64eebb.mp3"
	},
	{
		"title": "The Toast",
		"text": "At weddings and banquets, at celebrations of birthdays, anniversaries, and holidays, and on other special occasions both large and small, toasts are as normal a part of a meal as eating with utensils. This is undoubtedly more true in some areas and among some demographic groups than others, but I generally think no more of this strange habit than of the equally strange compulsion most of seem to have to say “Bless you!” after someone sneezes. I was even, for a while, a member of an organization called Toastmasters—whose name derives from the association of the word “toast” with speechmaking—even though our meetings never actually included toasts (not to mention toast). I think most of us over a certain age have absorbed the ritual at some point in our lives, even though it’s not something generally taught at home or at school. It typically begins with someone making a declaration—often in honor of a person or achievement, but sometimes an all-purpose utterance that basically means “let us now celebrate nothing in particular together.” So it could be “Here’s to Mr. Smith, the finest leader this institution has ever known,” or “Best wishes on your new life together,” or simply “Cheers!” During this speech, participants are expected to hold in front of them a glass containing some beverage, often alcoholic. At the conclusion of the statement, the speaker raises his or her glass as a signal that everyone else should do the same. (In a frequently occurring variant, the participants clink their glasses together; social custom usually dictates in such cases that unless the group is quite large or spread out inconveniently, each person should endeavor to touch his glass to every other person’s glass—a sometimes rather tedious affair.) And then, finally, everyone drinks. This process may repeat an indefinite number of times. Participating in a toast usually implies both agreement with whatever the speaker said and solidarity with the other people in the group. These are the basic facts we all know, but why do we perform this odd ritual? What’s the significance of the clinking glasses? And why do we call it a toast? It all has to do with poison. Stop By for a Drink and We’ll Talk About It Let’s go back a few millennia to ancient Greece, where one of the preferred means of disposing of an unwanted political rival (or spouse) was to invite the person to share a nice meal with you and slip a little something into the wine. This happened a surprising number of times before people started to catch on and realize that they might want to think twice before imbibing. And yet, it would have been incredibly impolite not to drink what you were served. The solution to this problem was for the host to take the first drink after the wine was poured from a single bottle or decanter; if he didn’t keel over forthwith, the guests could be assured the wine was safe for them to drink too—and they ceremonially tossed back a preliminary sip from their own glasses. This, then, is the beginning of the notion of “drinking to one’s health.” Now jump ahead several centuries and across the water to Rome, where much the same customs (namely, poisoning and goodwill drinks by the host) were in force. It was a peculiar Roman practice to put a piece of burnt toast in a wine glass. The usual reasons given are almost certainly incorrect—this was done neither to add flavor to the wine nor to provide a “treat” at the bottom of the glass; if someone wanted wine-soaked bread, a quick dip would be more than adequate. Rather, it was a way to remove undesirable flavors from the wine. In particular, the burnt crust reduced the wine’s acidity, making it more drinkable—especially if it happened to be a cheaper variety in the first place. If that sounds rather strange, bear in mind that the water filter in your kitchen most likely contains activated charcoal, a special, oxygenated form of carbon that has a tremendous ability to absorb unpleasant odors and flavors—not to mention certain toxic substances. Burning toast carbonizes its surface, making it a very crude, primitive approximation of a modern chemical filter. Although a burnt toast crust is not activated charcoal and does not have anywhere near its absorptive capacity, you will get at least a bit of the same effect. You can’t count on toast to protect you from hemlock or whatever other poisons your enemies may have put into your wine, but it is at least remotely plausible that at some point in history, a particularly inept poisoner was foiled by a piece of toast. Just saying. Let’s Hear It for Metonymy In any case, the toast-in-the-wine habit persisted for quite a long time, and even made its way to England. By the 16th century or so, the English word “toast” had been extended to refer to the wine glass containing toast—a phenomenon linguists call metonymy, in which one word is substituted for another with which it is associated. (The canonical example of metonymy is an expression like “The White House said such-and-such.” The building itself, of course, is not doing the speaking, but rather someone associated with that building.) So when someone said, “Let’s drink a toast,” the more precise meaning was, “Let’s drink wine from a glass that may happen to contain toast.” Later, the term was stretched even further to refer to the act of drinking itself, and then further still to refer to the entire ritual and even to a person being honored by the ritual. At this point, since the actual toast was irrelevant (and often, in fact, absent), one could perhaps make the case that the use of “toast” in its more tangential senses is in fact a case of metalepsis, which is similar to metonymy except that the association between the word and the concept is more remote. As for the clinking of the glasses…there are several theories. One theory is that the “spirits” in alcoholic beverages were at one time considered actual malicious entities, but ones that could be frightened away with a bit of noise. Another theory, which I like better, goes back to the poison problem. Some people claim that at a certain point in history (exactly when or where is unclear), guests would actually pour some of their wine into the host’s glass before drinking—just to make completely sure the wine was safe. After all, I suppose the glass itself could have contained poison. If someone wanted to make a gesture of confidence in the host without all that messy wine-pouring, so the theory goes, a symbolic touching of the glasses would do the trick. This makes more sense to me because it ties the clinking of the glasses in with the communal nature of the toast. But I have been unable to locate any definitive account of the custom’s history. Today, all the historical (and pseudo-historical) associations of this ritual have been lost, and yet we continue to go through the motions of what appears to be a sort of secular communion. Not that there’s anything wrong with that. In fact, I think we could do with a few more customs that bring us together in spontaneous acts of community. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/30/glass-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/30/Toast.23796824e84e.mp3"
	},
	{
		"title": "Kefir",
		"text": "I have a sort of love/hate relationship with bacteria, as I think many of us do. Over the years, I’ve experienced the usual number of infections from “bad” bacteria, grateful each time for modern antibiotics. On the other hand, I can barely imagine a diet without cheese, wine, soy sauce, sourdough bread, and many other fermented foods that are among my favorite things in life—and without “friendly” bacteria, this whole range of foods could not exist. More to the point, without our intestines being populated with bazillions of beneficial bacteria, we’d be unable to digest any food. So on the whole, I’d have to say I’m quite fond of the little critters. My food choices are influenced much more by taste than by nutrition. I do recognize that fermented foods, as a class, are not always the healthiest—but in my experience, the foods touted as “healthy” often seem to have the least appealing flavors and textures. While I’m willing to make some compromises in the name of nutrition, I have my limits. On the other hand, on those rare occasions when taste and healthiness intersect, I couldn’t be happier. Such is the case with kefir, a fermented milk beverage that has been in existence for centuries but has only recently begun to attract a popular following here in North America. Going With the Grain Kefir bears more than a passing resemblance to yogurt (or, at least, yogurt-based drinks): it’s much thicker than milk, has a tangy flavor, and is formed by the action of live cultures. But the differences are significant—starting with the microorganisms themselves. Kefir production begins with something known as kefir grains, though “grain” is an odd choice of word to describe this substance that is white, rubbery, and roughly cauliflower-like in appearance. The grain is formed from a conglomeration of over 30 kinds of bacteria and yeast, along with a structure of proteins, fats, and sugars that the organisms create to live in. This may sound yucky, but it’s actually rather fantastic: this mega-colony has emergent properties that make it act as though it were a single entity. It grows (when immersed in solutions containing sugars or starches) and repairs itself when damaged. Even more interesting, the various types of bacteria are able to defend the entire colony against foreign pathogens in a way that any single strain could not. Producing drinkable kefir from kefir grains couldn’t be easier: put some grains in a glass container of milk at room temperature and wait 24 hours or so. During this time, the liquid thickens due to the bacterial action. When it has reached the desired consistency, strain out the grains (which, in the process, will have grown a little bit), and pop them into another container of milk for tomorrow’s batch. Repeat indefinitely—as long as kefir grains have a relatively consistent supply of food, they can live, theoretically, forever. When a clump of grains grows too large, you can pull off a piece and eat it or share it with a friend who needs a kefir starter. According to an old ethic of kefir making, the grains must never be sold, but may be freely given away to anyone who wants them. As a result, there are several Web sites where you can search for one of the thousands of people all over the world who are willing to mail you, for the cost of postage alone, enough kefir grain to start your own production. Ancient Cultures This drink originated in the Caucasus Mountains eons ago, most likely as a method of preserving milk for long periods of time without refrigeration. According to legend, the first kefir grains were gifts from the Prophet Mohammed; where he may have obtained them is anyone’s guess. In any case, the grains were passed on for many generations within a rather small community but always kept diligently from outsiders. As the story goes, in the early 1900s, a Russian woman named Irina Sakharova managed (after many misadventures) to persuade a Caucasian prince to part with some kefir grains, which she then took to Moscow. Before long, the drink became a staple in the Russian diet, and by now it has spread all over the world. To what does this strange concoction owe its success? Well, first things first: it tastes good. That’s a matter of opinion, of course, but if you like the taste of yogurt or buttermilk, you’ll probably like kefir too. (And if not, you can certainly flavor it with honey, fruit, chocolate syrup, or whatever else strikes your fancy.) Unlike yogurt drinks, though, kefir is very slightly carbonated and very slightly alcoholic. These properties are barely noticeable—like the tiny bite apple cider gets when it’s sat in your refrigerator just a couple of days too long—but they undoubtedly contributed somewhat to kefir’s popularity. The biggest advantage of kefir over milk or yogurt is in its nutritional properties. The bacteria in kefir are usually referred to as probiotic, or life-supporting. In one sense, this refers to the mutually supportive relationship the various bacteria have with each other. In another sense, it refers to the fact that the bacteria support human life by aiding digestion once they arrive in the intestines. (Kefir also, by the way, produces a mild laxative effect.) According to some reports, the friendly yeasts in kefir can even wipe out pathogenic yeasts that may be found in the body. Kefir is rich in protein, vitamins, and minerals (particularly calcium). And like yogurt, it has very little lactose, making it safe for lactose-intolerant people. Goat Milk? Most experts claim that the best kefir is made from raw goat’s milk, but cow’s milk also works, even if it has been pasteurized. If fact, people have made kefir from soy milk, coconut milk, and even fruit juices. But kefir grains differ in the combinations and proportions of bacteria and yeasts they contain, so not every grain is compatible with every food. Kefir is sold commercially under such brands as Lifeway and Helios; my local Whole Foods Market, for example, carries both brands. Many who produce their own kefir at home regard these mass-produced varieties as grossly inferior to “real” kefir. One often-heard complaint is that some commercial suppliers, in the name of consistency, use a laboratory-engineered starter powder rather than the authentic kefir grains from the original lineage. Not being a microbiologist, I can’t say precisely what differences such starters might make in the final product—for all I know, store-bought kefir may be chemically and biologically identical to the stuff you can create at home. And at least one major brand, Helios, claims to use actual kefir grains. Be that as it may, since kefir is so easy to make at home, and since the kefir grains can be obtained at virtually no cost, you might want to think twice before buying the bottled product. On the other hand, if the presence of bottled kefir in grocery stores can help to popularize the taste, that can only be a good thing. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/29/Kefir-culture.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/29/Kefir.a32fe8eea1b3.mp3"
	},
	{
		"title": "White Tea",
		"text": "I remember what a revelation it was to discover, many years ago, that green olives and black olives come from the same plant; the difference is that green olives are harvested (and cured) before they ripen, whereas black olives are left on the tree longer. Later, I learned that black pepper comes from the same plant as white pepper; in the latter case, the dark outer hull of the peppercorn is removed. Still later, and even more surprising, was the discovery that black tea, green tea, and even oolong tea (in all their many varieties) come from a single plant, a shrub known as Camellia sinensis. These teas vary not only in color but in chemical composition—everything from the taste to the nutritional properties is extremely different from one type to another. The latest rage in designer tea, white tea, once again comes from the same plant. But it’s still full of surprises. How Dry I Am The differences in teas are not primarily a matter of ripeness, but of oxidation (sometimes known, rather inaccurately in the case of tea, as fermentation). After tea leaves are harvested, they immediately begin to dry, and in the process, chemical changes occur that greatly affect the tea’s flavor. In addition, the longer the leaves are left to dry on their own, the darker they become. The leaves are usually rolled to break them down somewhat and release juices that will contribute to their flavor and facilitate oxidation. At a certain point, the oxidation process is brought to an abrupt halt by heating (or sometimes steaming) the tea leaves. Green tea is dried for only a day or two, while black tea may be left to oxidize for as long as a month. (Oolong is somewhere in between. ) White tea comes from the youngest, tenderest tea leaves, which are often covered in tiny white hairs. In some cases, the leaves are protected from the sun while growing to limit the production of chlorophyll, which makes them lighter in color (though not actually white in most cases—more of a light greenish-gray). Immediately after harvesting, the leaves are dried briefly (without being rolled) and then heated quickly so that they do not oxidize. The result is a tea with a very delicate flavor—none of the “grassiness” sometimes associated with green tea, and none of the tannins associated with black tea. Tea experts say that you should continue handling it carefully even when brewing it—steep white tea in water that’s very hot, but well short of the boiling point. A Cup a Day Keeps the Doctor Away? Green tea is well known for its health benefits. For example, it contains antioxidants that may help to prevent cancer; it may also decrease LDL cholesterol. The nutritive components of green tea that give it these properties are found in greater concentration in white tea. University studies have also shown that white tea extract can kill bacteria, viruses, and fungi in the body (more so than extracts of other teas). White tea with a spoonful of honey must be a sort of super antimicrobial elixir. I’ve read some claims that white tea has more caffeine than green or black tea, but in fact it has much less. Well, sort of. The caffeine is present in the leaf when it is harvested, so a given mass of leaves from a particular plant will have a given mass of caffeine—and that’s true regardless of how long the leaves are permitted to oxidize. So, ignoring differences between plants and plantations (which can be significant), any tea leaf will have as much caffeine as any other. The difference is how much of that caffeine makes its way out of the tea leaf and into your cup. Brewed white tea has much less caffeine per cup than brewed green, oolong, or black tea (with increasing levels in that order)—partly because the leaves are larger, partly because they underwent less mechanical processing, and partly because the water for brewing is cooler. Because white tea is much rarer than other teas (and, especially, because it’s trendier), you’ll pay a premium for it—sometimes several times as much as for a premium green tea. But then, that’s often the way these days: the foods with less processing cost more. But think of it as an investment in your health and your status: your friends will be green with envy. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/29/White-Tea.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/29/White.e9e184dd00dd.mp3"
	},
	{
		"title": "Raku",
		"text": "I understand coffee. I know where it comes from, how it’s processed, how to prepare it in numerous ways, and how much I enjoy drinking it. When it comes to tea, though, I’m out of my element. It’s not that I’m unfamiliar with tea—I’ve got probably a dozen varieties in my kitchen, and I have at least learned how to brew it in a way that wouldn’t cause my British friends to scowl. But beyond the basic concept of using hot water to extract flavor from dried leaves are many subtleties that utterly confound me. On a couple of occasions, for instance, I’ve enjoyed sharing tea with a friend who’s a Buddhist monk. He can discern those infinitesimal hints of flavor and ineffable variations in character that separate one tea from another, in much the same way a wine connoisseur distinguishes a note of vanilla here, a slight whiff of cherry there. Then there’s the tea ritual. For me, tea has always been a mere beverage, but in many parts of the world, tea must be prepared and consumed according to a strict set of protocols and using just the right implements. Perhaps the best known custom is the Japanese tea ceremony, a ritual that in its most elaborate form can last hours. Japanese tea rituals were heavily influenced by Zen, which accounts for the simplicity, deliberateness, and mindfulness that customarily accompany ceremonial tea drinking, making it more of a meditative practice than an act of hydration. Every element of the ceremony, from the cloth used to clean the tea scoop to the ladle used to transfer the water must be made, used, and cared for in just the right way. Bowling for Defects But the most essential element of the ceremony is the tea bowl, or chawan, which takes the place of the cup or mug in western traditions. Mass-produced, factory-made tea bowls are frowned upon. Bowls that are individually made by hand are preferred. What westerners would consider irregularities or defects are highly valued; a perfectly round, smooth bowl would in fact be unsuitable. And among traditional, hand-made tea bowls is a particular style that is specially prized: raku. Raku dates back to the late 16th century, when a potter named Sasaki Chojiro began making special bowls that differed from the colorful, if generic, bowls of Chinese design that were more common at the time. Chojiro was a friend of legendary tea master Sen no Rikyu, who was largely responsible for bringing the sensibilities of Zen and Taoism to the Japanese tea ceremony. Because the bowls had Rikyu’s approval, Chojiro soon developed a strong reputation. After Chojiro’s death in 1592, his son Jokei continued making the bowls in the same way his father had, and in 1598, Japanese ruler Hideyoshi honored them with a new family name: Raku, from a word that can mean “ease” or “enjoyment.” (Raku is a shortened form of Rakuyaki, which in turn came from the term Jurakudai, a type of architectural design common at that time.) Ever since then, Chojiro’s descendants have continued the tradition, which is now being practiced by the 15th generation of the Raku family. You’re Fired Raku bowls are always thrown by hand, never using a wheel. The clay is traditionally covered with a lead-based glaze. The pieces are fired in a relatively low-temperature kiln and removed while still glowing, after which they are cooled rapidly, sometimes by immersion in water. This method of production results in bowls that are lightweight, fairly porous, and much more delicate than other kiln-fired pottery. Each piece is unique and they truly are (to my eye, at least) quite beautiful. Nowadays, the term “raku” is often used to describe any materials created according to the methods of the Raku family. The process usually known as raku among western practitioners would probably be unidentifiable to its originator, relying as it does on both electric and gas kilns and an additional process of smoking the pieces while still hot to impart interesting patterns and textures to the glaze. (And, of course, lead glazes are rather uncommon in the west, owing to concerns about lead poisoning.) But some artists follow a tradition that says a potter must visualize the raku piece completely before creating it, and through strict attention and careful work, create a piece exactly as it appeared in the imagination. When a piece doesn’t match that image, it is destroyed—and the process begun again. For this reason, serious raku potters consider it a most challenging art form. But it’s only appropriate that the making of tea bowls should be every bit the Zen exercise as drinking from them. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/29/tea-bowl.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/29/Raku.1d8ba7bb60c1.mp3"
	},
	{
		"title": "Edible Gold",
		"text": "I like to think of myself as an open-minded person, someone who is tolerant of those with different beliefs, however wacky they may seem to me. Every rule has its exceptions, though. A few years ago while traveling in England, I met a woman who claimed her diet consisted solely of durian, the smelly tropical fruit that looks like a medieval weapon. That was weird, but I was prepared to overlook it; I’ve heard of stranger things. During the course of our discussion about food, however, the woman asked if I’d heard of edible gold. I cheerfully replied that I had, which was true—I’d seen a TV show years earlier about chefs using gold leaf as a decorative but edible garnish on dishes in extremely upscale restaurants. I assumed that’s what she was talking about. But she seemed very surprised that I should know about this, and in a hushed, conspiratorial tone, began excitedly talking about how the ancient Egyptians had discovered that by eating powdered gold, one could become immortal. Very clearly, she believed this too. O…K. Right then and there, all my good intentions of open-mindedness went out the window—that was just way too strange for me to get my brain around. Later, when I consulted Google to see if I could learn any more about this seemingly outrageous claim, I was shocked and dismayed to find there are tens of thousands of Web pages describing, with great seriousness and credulity, a miraculous substance usually referred to as white powder (or powdered) gold. I spent the better part of an afternoon trying to sort out all the bizarre and competing claims about this stuff—a futile exercise that left me scratching my head. While I can’t claim the slightest expertise in this, ahem, esoteric field, I thought I’d make an attempt to distill, in my alchemical way, the essence of some of these claims for your consideration. All That Glitters Let’s begin on some solid footing: culinary gold. If you walk into your nearest gourmet supply store, you can probably find, for about US$20, a box of gold leaf (sheets, flakes, or sprinkles) manufactured expressly to enable you to impress your friends at your next dinner party. These unbelievably thin pieces of nearly pure gold add an impressive touch to chocolates, soups, sushi, and just about anything else you can think of. Because the quantity of gold is so small, the price is not unreasonable; yet these gold highlights make a meal appear to be extravagant and give restaurants an excuse to charge exorbitant prices. And yes: it’s safe to eat (if not particularly flavorful). Metallic gold is biologically inert; that’s why dentists can use it for fillings, caps, and crowns. (Gold salts, on the other hand, such as auric chloride, can have toxic effects over time. ) Some purveyors of herbs and mineral supplements sell a gold colloid: that is, a suspension of extremely tiny particles of metallic gold in water or another liquid—or solid pills made from such a suspension. In a gold colloid, each particle contains (according to one source, at least) a mere nine atoms or so of gold. A daily dose of colloidal gold ranging from a few drops to a few teaspoonfuls is supposedly enough to provide a wide range of health benefits. Here, at least, there is a wee bit of scientific support. A few studies performed at the behest (and expense) of a gold colloid manufacturer found their product to be effective in managing rheumatoid arthritis and also, intriguingly, increasing I.Q. scores in their test subjects. I’d have greater confidence in independent testing, but the claims are at least plausible. Fool’s Gold Our next step is one decidedly outside the realm of scientific certainty. David Hudson, a farmer living in Arizona, was trying to extract gold and silver from the tailings of an abandoned mine in the mid-1970s. In the process, he found a mysterious substance that defied analysis, despite years of experimentation by reputable laboratories, undertaken at great personal expense. Here the details get very fuzzy, but it seems that Hudson eventually concluded the white powder he’d found was gold in a monatomic (or, as he called it, monoatomic) state, in which each atom was physically separate from all others, rather than being joined in molecular groups as is more common. (There are some good reasons to doubt that Hudson’s gold truly was monatomic, but that’s neither here nor there.) He also, somehow, developed a process for creating (or separating) this special form of gold from ordinary metallic gold—though how he managed to figure this out without any scientific training is unclear. In any case, this white powder gold, according to Hudson, has some rather amazing properties: it is allegedly a high-temperature superconductor and, when heated in just the right way, weighs less than nothing—it can levitate. And, of course, it has a long list of incredible health benefits. Hudson received patents in Britain and Australia (though not, interestingly, in the U.S.) for this special form of gold and 10 other elements, which he referred to collectively as Orbitally Rearranged Monoatomic Elements (ORMEs). (I should interject that the awarding of a patent does not mean that a government agency has successfully reproduced the invention in question, or even that they have validated it as being scientifically sound. ) Then Hudson began reading about alchemy, and he became convinced that his white powder gold was the stuff of legend—well, many legends, in fact. He equated it with “manna,” “the philosopher’s stone,” “the food of the gods,” and “the elixir of life,” among other things. Hudson believed he had rediscovered an ancient alchemical formula. He began promoting this belief in New Age and mystical circles, which eagerly latched onto it and have been proclaiming it as truth ever since. And, naturally, numerous companies sell solid or liquid forms of “white powder gold” supposedly created using variants of Hudson’s recipe. Hard to Swallow Needless to say, consumers have to take the composition of this substance on faith. Maybe it really is monatomic gold, maybe not. But if it is, so what? That doesn’t make it magical…and it certainly doesn’t make it the philosopher’s stone. You’d think claims of room-temperature superconductivity could be tested readily enough, and that if true, they would be headline news. You’d think a substance that possesses anti-gravity capabilities would attract some scientific attention. And you’d think that if this substance had any meaningful health benefits—let alone the promise of an indefinite lifespan—researchers would be tripping over themselves trying to demonstrate this in objective studies, the better to sell more of the stuff and benefit all of humanity. Curiously, none of this appears to be the case. Hudson himself, meanwhile, has reportedly halted his research, partly due to heart disease—an ailment apparently beyond the healing capabilities of his magical elixir—and partly due to actions by the U.S. Environmental Protection Agency that he considered harassment. Whatever else can be said about white powder gold, I can testify that it has the magical power to give me a headache—merely by reading about it. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/29/easter_chicken_with_chocolate_egg.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/29/Gold.c2a59c3fe9a9.mp3"
	},
	{
		"title": "Durian",
		"text": "When I was 19, I spent a summer in Indonesia. That was the first time I heard of a very unusual tropical fruit called durian. Prior to that time, my experience with tropical fruits was limited to relatively familiar ones such as pineapple, banana, mango, and papaya. But durian, which is sometimes called “the king of fruits,” was definitely something different. A missionary told me they have a saying about the fruit: “smells like hell, tastes like heaven.” Whatever else could be said about it, it seemed to provoke very strong reactions from people—either they loved it or they hated it. Unfortunately, durian was out of season at the time, and though I heard that durian ice cream was easy to find, I never actually encountered any. A decade and a half later, I was living in Vancouver, British Columbia. On an expedition to my favorite Chinese supermarket, I came across a package of frozen durian and thought this would be the ideal way to try it. But I wanted to save it for a special occasion when I could share it with some friends, and before that occasion arose, I went on vacation. I returned to find that the refrigerator had broken down while I was gone, and the freezer—well, the entire house, actually—had a very strong and very foul odor, which I traced to the once-frozen container of fruit. The package of durian went in the trash and was forgotten. I did once have a piece of durian cake at a local bakery—a thoroughly unpleasant experience, I must say—but other than that, durian remained outside my consciousness. Keep Out of Reach of Children Since then, however, I’ve heard durian mentioned a few times, and in the noble pursuit of interesting things, I felt it was time to revisit durian. I picked up a City CarShare car and headed to Chinatown. I had read that the fruit’s growing season ran from roughly March through May, so I figured I just might get lucky and find some fresh durian in one of the many produce markets there. It took about half a dozen tries, but I did eventually find a market with a large bin of durian. I selected the smallest one—which was still about the size of a small watermelon—and took it to the counter. The cost for a 5-lb. (2kg) durian: a whopping US$20. But no matter: I was on a quest. The fruit was greenish-brown and covered with sharp, hard spikes. It looked very much like a mace, and could no doubt be used as one. The sharp spikes, along with the sharp odor, are no doubt nature’s way of saying “stay away,” but sometimes such warnings must be ignored in the pursuit of culinary adventure. I put the durian—which was sealed securely in a plastic bag—in the car while I did some other shopping. Returning less than an hour later, a strong, pungent odor filled the whole car. I rolled down all the windows and drove around for an hour—the car still smelled. I took the durian home, hermetically sealed it in three layers of plastic bags, and went out again. After another hour I returned, opened the door, and immediately confronted the same strong smell. It’s a vaguely fruity smell, in the way that apples rotting in a manure pile smell vaguely fruity. It’s hard to say quite what it smells like, but it isn’t likely to become an air freshener or cologne scent. And the scent is very tenacious—plastic won’t stop it, it sticks to everything, and it dissipates very, very slowly. The Taste Sensation Well, smell or no smell, I had to find out what fresh durian tasted like. I sliced it open and found several pulpy masses inside, and at the center of each one, a hard pit. I cut a small piece of the edible flesh for myself and one for my wife, who bravely volunteered to assist in the experiment. The smell, of course, was worse on the inside than on the outside, and just as the fruit was about to touch my lips (that is, coming in very close proximity to my nose) I nearly lost the will to eat it. At such close range the smell is very, very off-putting—almost oniony, which is not what you expect from a fruit. We ate. After the first bite, Morgen said, “Wow, that’s so delicious!” And I was thinking: “Wow, that’s slightly more edible than I had imagined.” The texture is very soft and creamy, almost like an avocado, but slightly fibrous. The flavor is rather hard to pin down; Morgen said it reminded her a bit of a piña colada—a sort of mishmash of tropical flavors. But with each successive bite, we both found the experience less and less satisfying. The oniony smell also translated into an acidic, oniony aftertaste. After just a few bites, we agreed that the experiment had been completed, and we hustled the remains of the fruit out of the house. Durian is grown in Southeast Asia and several other tropical regions and exported—either fresh or frozen—anywhere there’s a market for it, which is to say, anywhere there are masochists. I’m sure there must be people who genuinely enjoy the taste, but durian recipes are few and far between. From what I’ve read, it is actually very difficult to find durian at the precise peak of ripeness; supposedly, it’s overripe durian that gives the fruit its bad reputation, and only a trained professional—yes, there really are such people—can pick out a durian you’ll really love. I have yet to meet such a person, so for the time being I’ll continue regarding durian as a very useful tool for ridding yourself of an unwanted roommate or spouse, or perhaps defending your household against vampires or invading armies. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/29/durian.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/29/Durian.46e6a691e465.mp3"
	},
	{
		"title": "Kopi Luwak. The world’s strangest and most expensive coffee",
		"text": "My fondness for good coffee, and the lengths to which I’m willing to go to indulge it, are well known. As someone who loves coffee and craves interesting things, it is only natural that I should be intrigued by stories of a rare, exotic, and obscenely expensive type of coffee bean. Several years ago, I was fortunate enough to sample this coffee, but most of the people I’ve told about the experience—even confirmed coffee snobs—grimace, then raise their eyebrows in that “you’ve got to be kidding me” look. The story you’re about to read is, I assure you, true, though I myself became convinced only after extensive research and personal experience. The Fruits of Labor First, some background. Most coffee beans sold in North America come from plantations in tropical Central or South America. Colombia and Costa Rica, in particular, are well known for their excellent coffees. Coffee grows on plants that are commonly called “trees” (because that’s what they look like), even though they’re really a type of shrub. Coffee trees produce a sweet fruit known as a “cherry,” so called because of its red color when it ripens. Inside each cherry are two seeds, which are the coffee beans, encased in a thin covering called parchment. Cherries are usually picked by hand, then processed by machine to extract the beans from the fruit and remove their mucilaginous coating. The beans are rinsed and dried, then fed into another machine to remove the parchment. After sorting the raw (or “green”) beans into different grades (and, sometimes, blending different types of beans together), they are roasted to varying degrees of darkness and then packaged for shipment. The final step in preparing the beans before brewing is to grind them to your desired level of coarseness. All in all, preparing coffee beans is quite a labor-intensive process. It is only natural, I suppose, that someone might try to find a simpler method to get the desired end result—a way to get the coffee beans without all that tedious harvesting and processing. It was presumably this line of reasoning that led to the invention, or discovery, or whatever you might call it, of Kopi Luwak. Has Beans On a handful of Indonesian islands lives a small catlike animal called the palm civet (Paradoxurus hermaphroditus, if you care), also known as a “musang” or “toddy cat”—or, in Indonesian, a “luak.” The palm civet is not a marsupial, though nearly every Web site about Kopi Luwak describes it as such—caveat lector. It’s a nocturnal mammal that spends its life in the trees and eats a balanced diet of insects, rodents, and fruit. One fruit it’s especially fond of is the coffee cherry, and it’s very picky about which cherries it eats, too—only perfectly ripe ones will suffice. The palm civet’s digestive system processes the skin, pulp, and mucilage of the coffee cherries quite nicely, but can’t break down the seeds. So they appear—sometimes in rather large quantities—in the animal’s droppings. Other than being slightly fermented, the seeds are intact, and enterprising locals, eager to bypass several of the most onerous tasks of bean preparation, collect these specially processed beans and sell them to coffee distributors. The beans are washed, dried, and roasted just like other beans, but because of their relative rarity and unique processing, are sold at a premium to distributors who ship them to Japan and the United States. Paradoxically, the savings in human labor provided by the paradoxurus is reflected inversely in the price. Black Gold Just how much of a premium will you pay? Well, in 1999 I paid about US$100 for a half pound (about 225g), though I’ve heard of prices much higher and much lower. But on average, Kopi Luwak runs about ten times the cost of Illy, the famous Italian gourmet coffee, and about 50 times the cost of Folger’s. If you’re lucky enough to find a local coffee shop that sells it by the cup, though, you might pay a mere $5, which is about the cost of a Starbucks specialty coffee. But what you really want to know, I expect, is how it tastes. Describing the flavor of a fine coffee is a bit like describing the flavor of wine—it’s more of an art than a science, and no two people will agree on exactly the same terminology. I’ve seen Kopi Luwak described as “nutty,” “spicy,” “chocolaty,” and “gamey,” for example, but I don’t know that I’d use any of those terms myself. It tasted very, very good—let’s start there. In addition to the sort of rich aroma I’d expect from any good coffee, it had a complex intensity of flavor that I have not tasted elsewhere. Unlike the taste of, say, a chicory-laced café au lait or a mocha, the “extra” flavor did not give me the impression of an additive, but rather of intrinsic depth. In other words, it tasted more thoroughly coffeelike than ordinary coffee, if you can imagine that. I don’t think it would be unfair to say that my first cup of Kopi Luwak was the best cup of coffee I had ever tasted. Was it ten times better than Illy—enough to justify its cost? Certainly not; it was better, but not that much better. On the other hand, it was well worth the money just to have the experience, and indeed it would have been worth the money even if the taste had been unpleasant. The novelty of the experience was worth every drop (or, as some purveyors of Kopi Luwak would say, dropping). The Bottom Line The name “Kopi Luwak” simply means “luak coffee,” though as you can imagine, it also goes by a number of more colorful names. In some cases, the unique processing method is used as a marketing gimmick; in other cases, it’s the punch line of “what-has-our-culture-come-to-now” editorials. To be sure, it is slightly unsettling to imagine being the person to have originated this idea, or worse—the first person to try it. But the end result (sorry) makes it all seem worthwhile. Nevertheless, it is hard not to have some lingering doubts about the authenticity of the coffee. My research has satisfied me that Kopi Luwak is in fact a legitimate product, produced and collected in the manner described. But the beans don’t look or smell significantly different from other coffee beans (at least, not to my untrained senses). How am I to know that the company that sold me the coffee didn’t substitute a cheaper brand? And how are they to know that their supplier, and every link in the supply chain before that, was delivering the genuine article? Quality control and certification of production is, as you might guess, a bit problematic. When all is said and done, it’s a matter of faith. I would like to believe that the sheer weirdness of the product makes it more likely than not that what I got was what I thought I was getting. And if not, well, it was still a damn fine cup of coffee. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/29/palm-civet-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/29/Kopi.8ea6ca2c9f7b.mp3"
	},
	{
		"title": "Bubble Tea",
		"text": "One of the great things about spending time in another country is learning about new and unique foods. When I was living in Vancouver, Canada a few years ago, I became acquainted with bubble tea, an odd beverage that was rapidly becoming the rage across town. This strange concoction originated in Taiwan in the early 1980s, and in the last few years, it has spread all over Canada, into the United States and England, and across many other parts of the world. Popping Some Bubbles The term “bubble tea” is at best an unfortunate translation and at worst a euphemism. Alternative names, such as “pearl tea” or “tapioca drink,” are slightly more descriptive. Basically, bubble tea is a sweetened beverage made with water, natural flavors, (usually) a dairy component, and…tapioca balls. These “bubbles” or “pearls” are dark brown, about one centimeter in diameter, slippery on the outside and very chewy on the inside. The bubbles by themselves have very little flavor; their main purpose is to provide texture. Because they’re so large, you need a special, oversized straw to drink bubble tea with. Or should I say eat? Consuming bubble tea is a matter of both drinking and chewing, and after finishing a glass you feel quite full. In other words, it’s not so much an accompaniment to a snack as an entire snack and beverage all in one. Bubble tea comes in many flavors, with some of the more popular being almond, mango, chocolate, and my personal favorite, taro. You can also find red bean, coconut, lavender, and a number of tropical fruit flavors. Paradoxically, every outlet where I’ve seen bubble tea sold also offers it without the pearls—in some cases, you get them only by special request. That seems to me to be missing the point—but then, bubble tea is, for many, an acquired taste. Some people just can’t get past the idea of drinking squishy tapioca balls. Personally, I loved bubble tea the first time I tried it, but opinions vary widely. I surveyed three of my close friends, who by sheer coincidence were all blond Canadian women. After trying bubble tea for the first time, 33% of my sample group said they enjoyed it and would drink it again. The other 67% said it was the most disgusting thing they had ever put in their mouths. Whatever other nuances could be read into that statement, my general impression was that they were not favorably disposed toward bubble tea. (One of these friends later said she had tried it again and thought it wasn’t so bad.) There’s no accounting for taste. Pearls of Wisdom If you want to make your own bubble tea, the most difficult part is locating the ingredients. First and foremost, you’ll need the tapioca pearls. You can sometimes find these in Chinese markets, sold dry in plastic bags rather like pasta. There are also, naturally, a number of online sources. Most pearls are dark brown, though I have seen them in various colors. To prepare them, you boil them in a generous amount of water for about a half hour, then turn off the heat and let them sit for another half hour. Rinse them, and they’re ready to go—or refrigerate them for later. The tea itself is normally made by mixing a flavored powder with water and adding sweetened condensed milk (or, sometimes, nondairy creamer and a sugar syrup). Add ice and shake, pour the mixture into a glass with a generous portion of tapioca pearls at the bottom, and drink. There are numerous variations on this basic recipe, however. I’ve seen hot bubble tea, fruit juices with pearls, and even frozen bubble smoothies. In fact, just about any sort of beverage you can think of can be made into bubble tea. Strangely enough, actual tea is used only rarely as the base. For that matter, the so-called tapioca pearls are—if you want to be really nitpicky—not actually tapioca. They do have much the same consistency as tapioca, but the starch they’re made from comes from a type of sweet potato. Bubble tea is not going to replace cola as the standard fast-food drink anytime soon. But every time I turn around I find another local shop that sells it, and the North American public is slowly but surely warming to the idea. Once you overcome the initial weirdness, it’s quite tasty. If your idea of a strong drink is a single-malt Scotch or a dark lager, try the drink that really has balls: bubble tea. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/29/bubble-tea-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/29/Bubble.65cb63794b21.mp3"
	},
	{
		"title": "Oysters Rockefeller",
		"text": "I studied philosophy in college, but as much as I enjoyed it, I had to choose a different profession. If I hadn’t, I risked a fate that seems to befall most philosophers sooner or later: having one’s name turned into an adjective. Think about it: Platonic, Socratic, Aristotelian, Augustinian, Cartesian…I’ve even heard Husserlian and Wittgensteinian. Of course, it’s not just philosophers who suffer this fate. So do psychiatrists (Freudian), novelists (Orwellian), filmmakers (Kubrickian), physicians (Hippocratic), and explorers (Columbian). With all due respect to those who will no doubt wish for a concise way of referring to my system of thought or writing style, I would be very unhappy to think of anything or anyone being referred to as “Kissellian.” I’m not sure why, but the whole notion of adjectivizing names has always bothered me (whereas verbing nouns does not). If my name is to be immortalized, I would prefer that it be kept intact, preferably in close proximity to the name of a food. Peaches Melba…Crêpes Suzette…how about Cherries Kissell? Instead of Quiche Lorraine, try Shrimp Kissell. You can even wash it down with a Joe Kissell on the rocks. (See my forthcoming book The Joe of Cooking for recipes…) The Color of Money Of course, the ultimate tribute food is Oysters Rockefeller. This dish was invented in 1899 by Jules Alciatore, son of Antoine Alciatore, the eponymous founder of Antoine’s in New Orleans. The dish consists of oysters that have been topped with a purée of mixed greens and then baked. The dish was deemed so rich that it could only take the name of the richest family in the country at that time, the Rockefellers. (It is no coincidence, I’m sure, that the color approximates that of U.S. currency.) The recipe has been kept a closely guarded secret at Antoine’s for over 100 years, though there have been countless imitations. I tried Oysters Rockefeller at Antoine’s and it was good, but in my opinion it didn’t live up to its hype. On the other hand, if it had been called “Baked Oysters with Greens” I wouldn’t have given it a second glance on the menu. It was the legendary name that made it sound especially appealing. Well, that, and the mystery of what the dish actually contains. While Antoine’s has never revealed their original recipe, they have stated categorically that the one ingredient it doesn’t include is spinach. This is significant, because it looks like it contains spinach, and the majority of imitators use spinach in their recipes. But as with Colonel Sanders’s recipe for Kentucky Fried Chicken, it doesn’t matter what the specific details are or whether the recipe is better than all the rest, it only matters that it can claim to be original and unique. The game of trying to guess how Antoine’s Oysters Rockefeller is made has driven many thousands of customers to the restaurant over the past century. Everybody Loves a Mystery The shrewdness of this marketing ploy cannot be overstated. Antoine’s has benefited enormously from the great mystery surrounding their recipe. Quite a few journalists have tried unsuccessfully to bribe ex-employees for information. One author claims to have smuggled a sample to a lab for analysis. Even if it turned out that the ingredients were corn flakes and food coloring, the simple fact that they are a mystery has contributed to Antoine’s status as one of the most respected and popular restaurants in the city. There’s just nothing like free publicity. What various researchers have been able to piece together from a variety of sources is that there are probably 18 ingredients in Oysters Rockefeller, among which are watercress, scallions, parsley, fennel, garlic, butter, and bread crumbs. It also likely contains Pernod or Herbsaint, brands of pastis that substitute for the absinthe that was almost certainly used in 1899. I have yet to see any research, though, as to why the spinach-based recipes with only 10 ingredients taste better. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/27/Oysters-Rockefeller-120.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/27/Oysters-1.73d8665cb440.mp3"
	},
	{
		"title": "Pan del Indio",
		"text": "Our recent trip to Patagonia included a few days on the big island of Tierra del Fuego, just across the Strait of Magellan from mainland Argentina at the tip of South America. The itinerary called for a couple of days of hiking; we spent Christmas Day 2004 exploring Tierra del Fuego National Park. I have nothing against a nice hike through the woods, and certainly these woods—bordered by shoreline with scenic views of the smaller islands nearby—were as pleasant as any I’ve seen. But the mosquitoes were also unusually persistent that day, some of the other folks in our tour group were getting on my nerves, and more than a few times the thought occurred to me that I could have had an equally enjoyable hike through the woods 10 minutes' walk from my home in San Francisco. The view, inspiring though it was, reminded me of British Columbia’s Gulf Islands, where I’ve frequently vacationed. What was so special about these rocks, these trees, or this water, besides the fact that they happened to be located here? These were the questions that went through my head as I hiked in the park. Beech Balls Before long, I had my answer. There growing on a tree was a clump of spherical orange globules, each about the size of a golf ball. In fact, not just one clump on one tree—they were all over the place. Some trees had dozens upon dozens of them. They looked like something created in a special-effects workshop for a sci-fi movie—truly creepy and otherworldly. Our guide told us that they were a type of fungus—Cyttaria darwinii, one of the many species described by, and named after, Charles Darwin. They grow on a type of southern beech tree native to the area; the infected trees, apparently as a defense mechanism, form huge knots on their trunks and branches—but these do not discourage the fungus’s growth. Our guide did not mention that the fungus was edible, and even though I like mushrooms, it would not have occurred to me to put something like this in my mouth. But the local name for this fungus is Pan del Indio, or Indians' Bread. The name comes from the fact that in centuries past, the fungus was a staple food for native Fuegians, normally consumed in its raw state. A couple who had visited the park earlier told us they’d tried the fungus. One said it tasted a bit like cheese, and the other said the texture, if not the flavor, was reminiscent of a lychee. Other sources I consulted said that the fungus is almost tasteless when young, but as it ripens, it becomes sweet and juicy. I’m sorry I didn’t get to try it myself, and I hold out little hope of running across it at my local market. Orange Globs for Everyone There are a few other fungus species that resemble Pan del Indio; these grow on related beech tree varieties in other parts of Patagonia and in Australia. But as I was researching this odd organism, I had the nagging feeling that it resembled something else too. Let me think: orange…spherical…tastes like cheese…squishy texture…Indians' Bread…aha! Only a couple of months before our trip, a friend who had spent several years living in Brazil turned us on to pão de queijo (literally “cheese bread”), a popular Brazilian snack. These are orangish, baked balls of tapioca starch flavored with cheese, and they’re addictively delicious. Coincidence? Undoubtedly. But much easier to come by—and more appealing to the gringo palate—than Pan del Indio. io. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/28/oranges-120.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/28/Pan.6271d7c2ba91.mp3"
	},
	{
		"title": "Café du Monde",
		"text": "It’s 3:00 a.m. and the streets of New Orleans are filled with fog. In some of the livelier areas of town, bars are still open, the last wave of sleepy patrons thinking they might stick around to hear the band play just one more tune before calling it a night. Here, however, on the fringes of the French Quarter, the streets are quiet. Steps away from the Mississippi river, outside a building near the French Market, a man hesitates, then approaches an open window. He exchanges a few words with the person inside, and hands over some money. A small bag is offered in return. The man, clutching his illicit purchase, hurries across the street to Jackson Square. He sits down on a secluded bench, looks around furtively, and opens the bag. Inside, all he can see is a white powder. As he reaches into the bag, he thinks to himself, “I know this is a bad idea. This stuff is gonna kill me some day, but I just…can’t…help myself.” A few minutes later, the bag is empty and the man is happy, having blissfully forgotten his reservations and guilt—and entirely oblivious of the growing effects of the toxins accumulating in his body. A telltale white residue on his upper lip, he stumbles home. Tomorrow he will repeat this ritual. Next time, he decides, he’ll order some coffee too. A nice hot drink might help to take the edge off of all that powdered sugar and grease. The man has just been to Café du Monde, a New Orleans landmark that’s open 24 hours a day, 7 days a week. His purchase was an order of beignets, a deceptively decadent type of doughnut that made this café famous. Make no mistake about it: enough of these will kill you, all right. But you will die very happy. Beignet There, Doughnut That Café du Monde is to coffee shops what In-N-Out is to burger joints. Its charm lies in the utter simplicity of its menu and the quality of its product. At Café du Monde, there is but one food item you can order—beignets—along with a limited choice of beverages. And that is enough: the place is nearly always packed with customers—tourists and locals alike. It has been like this since Café du Monde opened in 1862. The store is called a coffee stand, but it’s very large, with dozens of tables outside under the trademark green-and-white striped canopy, and more inside. On every table are plates of rapidly disappearing beignets. What exactly are beignets? Café du Monde’s marketing propaganda calls them “French-style doughnuts,” but I’ve always found that description a bit unsatisfying. The term “fritters” might be a bit closer. Like doughnuts, they’re basically deep-fried dough. Unlike doughnuts, they’re square—about 3 inches (8cm) on a side. They’re also very puffy, consisting mostly of air if you go by volume. They are served covered with powdered sugar, and I do mean covered. I have been served beignets with a sugar coating a good solid inch (2.5cm) thick. Thus, a few beignets and a large cup of coffee will supply your full daily nutritional requirements for the four major food groups (starch, grease, sugar, and caffeine). Café du Monde serves beignets in orders of three, and since that’s the only food item on the menu, it’s considered redundant actually to mention what it is you’re ordering. You simply say, “I’ll have an order and a café au lait.” If you arrive during peak hours you may have quite a wait in line before you get to place your order (even longer if you want a table). Follow the line around to the back of the building and you can watch through the window as the beignets are made. If you’ve ever been to a Krispy Kreme shop, this will be familiar to you, except that at Café du Monde, each beignet is tossed across the room by hand into a vat of hot oil. Au Lait, Can You See? Then there’s the coffee. Although you can order black coffee, orange juice, or even cola at Café du Monde, only one beverage provides the perfect accompaniment to beignets: café au lait. Most Americans—at least, those steeped in the Starbucks culture—know what a cappuccino or a latte is, but café au lait is relatively uncommon in North America. The recipe is simple: one part hot brewed coffee (not espresso), one part hot milk. At Café du Monde, though, café au lait is always made from a blend of coffee and chicory, giving it a much different flavor from ordinary coffee. Chicory is the root of the endive plant, and it is roasted and ground in much the same way as coffee beans. During World War II, shipments of coffee to the U.S. were disrupted, and chicory was used either as a substitute for coffee or as an additive to stretch the coffee supply. These days, most coffee purists look down their noses at coffee-chicory blends, because chicory was historically a cheap imitation of the real thing. Like substituting carob for cocoa, it simply doesn’t have the same taste. But different is not necessarily bad. Café du Monde’s chicory café au lait has a wonderfully smooth flavor, and it matches the beignets delightfully. Besides the original location on Decatur Street next to the French Market, Café du Monde has a number of other shops in and around New Orleans. This includes, I’m sad to say, several locations in shopping mall food courts. Objectively, the quality of beignets found in the newer locations is no worse than the original, despite being made using shiny new equipment and being located in close proximity to generic fast-food outlets. But the experience is just not the same. Roll Your Own (Dough) For that matter, the same can be said of beignets you make yourself. All over New Orleans (and, of course, online) you can find beignet mix and Café du Monde’s signature blend of coffee and chicory for sale. In fact, you can buy every component of the Café du Monde experience—their mugs, spoons, powdered sugar shakers, and even napkin holders with the authentic Café du Monde menu on the side. With modest effort, you could recreate the tastes, smells, and sights of Café du Monde at home. This can be a pleasant way to spend a Saturday morning—I’ve done it myself—but you’ll never get quite the same effect as visiting Café du Monde in person. Savvy locals will tell you, not without some scorn, that Café du Monde does not have the best beignets in town. That may be true, although the recipe is not one of great subtlety or sophistication, so variations are likely to be comparatively minor. Likewise, one could say that it’s not the best dining experience, especially considering the crowds and noise. But for my money, this combination works. Tasty (if artery-clogging) food, served instantly and inexpensively in a place with history and character: that’s my kind of café. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/27/sugar-cookies-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/27/Cafe-1.108dc76a8f4.mp3"
	},
	{
		"title": "Gumbo",
		"text": "I have watched a number of reality TV shows on which contestants were asked to consume extremely unappetizing foods. You know the sort of thing I’m talking about, I’m sure, so I’ll refrain from elaborating. Under circumstances of sufficient duress or social pressure, I’ll uncomplainingly choke down just about anything, however unpleasant it may be. But there are a few foods that I would find it difficult to get past my uvula no matter how many viewers at home were cheering me on or how many dollars were at stake. I am thinking, for example, of okra. Slime Me In the United States, okra is known as a staple of southern cuisine, and rarely seen elsewhere. A member of the hibiscus family, okra is a tall plant with yellow flowers and edible seed pods. If you look up okra in a dictionary, the one word that will invariably be used to describe the texture of these seed pods is mucilaginous. This word means “glue-like”—that is, viscous, sticky, and slimy. These are acceptable characteristics for adhesives, but not the sort of thing that feels good on my tongue. Having said that, I must now confess that I have personally, voluntarily cooked with okra, and enjoyed the results tremendously. That’s because context is everything. The one dish in which okra is not only unobjectionable but mandatory is gumbo. I first tasted gumbo several years ago on a trip to New Orleans. I decided to brave it, even knowing it contained okra, because it seemed like one of those quintessential Louisiana experiences everyone should have. I absolutely loved it. The surprising thing was that I could not detect any hint of that mucilaginous texture. When I later made my own gumbo, I figured out why. Okra is OK Gumbo is a hearty soup that is one of the cornerstones of Cajun cuisine in Louisiana. There are countless recipes and variations, but it invariably consists of a thick broth served in a bowl over a mound of rice. Some gumbo is made with chicken and andouille sausage; some is made with seafood; some is made with whatever meat happens to be handy. (Purists generally scoff at the notion of vegetarian gumbo.) Gumbo usually starts with a roux (a browned mixture of flour and oil or butter) along with diced, sautéed pepper, onion, and celery. Then a stock is added along with the meat and sliced okra; the resulting mixture is simmered for several hours before serving. When the okra is heated, its mucilaginous fibers begins to dissolve, and serve as a thickening agent for the soup. Depending on how fresh the okra was when you put it in, how small the slices were, and how long you cook it, there may be no visible remains of the okra at all by the time it’s served. If whole pieces remain, they are quite soft but not even slightly slimy—entirely edible. So the very quality that makes whole okra yucky turns out to be essential to making gumbo yummy. There are gumbo recipes that omit okra, but they miss the point. For one thing, the word gumbo is derived from the Bantu word kingumbo, which means “okra.” In other words, gumbo without okra is sort of like oatmeal without oats. For another thing, okraless gumbo just doesn’t taste right. The usual alternative thickening agent is filé, a powder made from dried sassafras leaves. Filé becomes gummy when it’s boiled, so it can’t simmer into the soup. It has to be added just before serving, or sprinkled on at the table. There’s nothing wrong with a filé-thickened soup, but it shouldn’t be called gumbo. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/23/Gumbo-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/27/Gumbo.6d0da531b910.mp3"
	},
	{
		"title": "Mate",
		"text": "I’m a coffee person. I wouldn’t say I’m addicted to it, but I do certainly enjoy drinking it on a more or less daily basis. Sometimes two or three times a day. In fact, now that I think about it, I could use a cup right now. Excuse me. (Time passes.) Ah, that’s better. I do not drink coffee for my health, although I am aware of studies suggesting that coffee consumption in moderation may reduce the risk of colon cancer, kidney stones, heart disease, and even Parkinson’s Disease. I don’t even, for the most part, drink it for the caffeine. Partly it’s the aroma that I find so appealing, and partly it’s just the soothing effect of a warm beverage sliding across my tongue and down my esophagus. Many of my friends, however, are tea people. I have nothing against a nice cup of tea now and then, and of course tea ably fills that hot beverage need. But in terms of aroma and both psychological and physiological impact, tea just doesn’t do it for me. Once again, tea’s supposed health benefits—of which there are, I admit, far more than those of coffee—don’t quite tip the scales. Maybe I’d be 5% healthier if I switched from coffee to tea, but then, maybe I’d also be 10% grouchier. A Drink to Die For I am always, however, happy to try new and unusual hot beverages, especially if they are reputed to have health benefits, a strong aroma, and a flavor frequently referred to as an “acquired taste.” And even more so if the beverage must be prepared and served in a highly ritualized way using special, single-purpose gadgets. So while in Argentina, I was enthusiastic about sampling, and acquiring the necessary paraphernalia to make, their national beverage, which is known as mate. According to one survey, mate (pronounced “MAH-teh”—and not to be confused with the Spanish word maté, which means “I killed”) is regularly consumed by some 92% of Argentineans—and by similarly large numbers of people in Uruguay, Paraguay, and Brazil. Superficially it appears to be a kind of tea, but appearances are deceiving. The true story is much more complex. For starters, there’s the nomenclature. The dried leaves that are brewed to make mate are known as yerba mate—the word yerba meaning “herb.” This is, however, a misnomer: the leaves come from an evergreen tree in the holly family, Ilex paraguariensis. The word mate itself comes from the Quechua word matí, which refers to a certain type of gourd (Lagenaria vulgaris) which, when dried and hollowed, is used as the serving vessel for the beverage. So depending on context, mate can mean the leaves, the container, or the infusion of the leaves in water. The latter sense appears to be the most common. Details, Details, Details Yerba mate plants must be carefully cultivated and their leaves harvested at just the right time. The leaves are briefly roasted to preserve their color and prevent spoilage, then dried thoroughly, coarsely ground, and left to age for nine months. Finally, they are crushed and packaged. One supermarket we visited in Patagonia had an entire aisle of mate—dozens of varieties, textures, blends, and package sizes. But even the highest-quality brands were inexpensive: a few dollars or so for a kilogram. The gourds come in every conceivable shape, size, and color, usually with a three-legged metal base (to prevent tipping, since the bottom is convex), and often with a metal ring around the hole in the top, to reduce wear. Although actual gourds are most common, we also saw mate pots made out of clay, ceramic, metal, and even cows' hooves and horns. Each gourd also requires a special accessory called a bombilla—basically a metal straw with a strainer at the bottom. Instead of filtering out the tiny leaf fragments when the beverage is brewed, drinkers use the bombilla to filter it as they sip. To prepare mate, one must begin with a properly “cured” gourd—one that has been soaked or cleaned in one of several ways to remove the residual oils that could adversely affect the flavor. The gourd is then filled about two-thirds full of yerba mate leaves, shaken, and tipped at an angle. A small amount of hot water is poured into the empty side, and after a couple of minutes, the bombilla is inserted and a larger quantity of hot water added. Each of the numerous books and Web sites I read that described mate preparation had different instructions for the precise method of creating an ideal mate—and in fact, many people prefer to leave this immensely important and challenging task to a cebador, a local expert in mate preparation. Every source I consulted, however, was in agreement that unlike tea, mate must never be made with boiling water. Mate has the somewhat bitter taste of tannins, much like tea. Because of the ratio of leaves to water, it is a very strong flavor. Some of my companions likened it to “grass,” “hay,” or “alfalfa.” I believe these descriptions were intended to be uncomplimentary. I felt about the taste the way I felt about coffee the first time: kind of bitter, not immediately appealing, but I’ll bet it could grow on me. Drink Me Mate is normally shared among several people. Each person takes a sip or two from the bombilla, passes the mate to the next person, and the cycle continues. When the liquid gets low, more hot water is added. Because such a large quantity of leaves is used, it takes a very long time for a single dose of mate to lose its flavor. The people we observed drinking mate appeared to be unconcerned about sharing germs, but apparently in some situations individual, disposable bombillas are used. Our guide did tell us, though, that according to legend when companions share a mate, they will also share their dreams. I did not check to see what other members of our group dreamed about the night after we shared our first mate, but it makes a nice story in any case. Purists drink their mate hot and unsweetened—just the way I like my coffee. But I read repeatedly that some segments of the population, such as women, children, and city dwellers (if you can believe such categories) prefer their mate cold and/or sweetened with sugar—and sometimes even prepared with milk. We observed locals drinking mate at all hours—in fact, pretty much constantly throughout the day—except with meals. The quantity typically ingested in a day puts my considerable coffee consumption to shame. In order to be assured of a ready supply of raw materials, some people carry around leather cases large enough to hold a gourd, a thermos full of hot water, and a large bag of yerba mate. Mate is a mild stimulant—when brewed, it has about half as much caffeine as coffee. Some people believe that unlike coffee, mate’s stimulant effect disappears very quickly when you stop drinking, so it can be consumed safely at bedtime. Mate supposedly functions as a digestive aid, which seems reasonable enough; it’s also used as a laxative. Other health claims abound: mate is said to curb the appetite, boost immunity, combat the effects of aging, and even return gray hair to its original shade—among many other benefits. How many of these effects are genuine, I can’t say. But I suspect its health benefits handily beat those of coffee. Argentineans who drink mate all day long take it very seriously—they must have just the right brand, prepared just the right way in just the right gourd. And of course, “just right” differs enormously from person to person. In this respect, the mate phenomenon is very much like the culture of coffee snobs in the U.S. I did bring home my own mate kit, and in fact my gourd is curing as I type this. Whether I trade my coffee fanaticism for mate remains to be seen, but if I suddenly seem younger and healthier, you’ll know why. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/23/mate-120.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/23/Mate.74b853414972.mp3"
	},
	{
		"title": "Cleopatra’s Wager",
		"text": "A news article mentioned a hotel bar in New York whose drink menu includes a US$10,000 drink called “Martini on the Rock.” That works out to about $5 for the gin, vermouth, and olives—and $9,995 for the loose diamond sitting at the bottom of the glass. Patrons must order the drink three days in advance, and meet with a jeweler to pick out the perfect stone. The first person to order this drink paid a bit extra—$13,000—and instead of a loose stone, selected a 1.85-carat diamond engagement ring. (His girlfriend said yes.) Perhaps unknown to the hotel’s proprietors, this extravagant beverage has a fascinating historical precedent. Et Tu, Cleo? The year was 41 B.C. Mark Antony, one of the rulers of Rome, summoned Egyptian queen Cleopatra VII for an audience at Tarsus (in present-day Turkey). Antony ostensibly wanted Cleopatra to answer charges that she had aided Cassius, who had conspired with Brutus to assassinate Julius Caesar. But most people believe the real reason for the meeting was that Antony wanted Egyptian aid for an upcoming military campaign, and besides, he had the hots for Cleopatra. Cleopatra arrived on her legendary barge, and proceeded to throw elaborate banquets for Antony and his officials for several evenings straight—nothing like a bit of wining and dining to smooth over political misunderstandings. So impressed was Antony at the lavish feasts Cleopatra had arranged that he accepted a friendly wager. Cleopatra bet Antony a large sum of money that she could host the most expensive meal in history. The next day, as the meal in question was nearing its end, Antony said that it had been terrific, but no more impressive than her other banquets—and certainly not worth the sum of money she had specified. At this, Cleopatra removed one of her pearl earrings and dropped it in a goblet of wine vinegar. Each of the pearls was so large and rare that it was extraordinarily valuable—estimates are usually expressed in extremely helpful terms such as “10,000,000 sesterces” or “100,000 gold aurei,” or “the value of 15 countries.” In any event, it was worth a fortune. The pearl dissolved in the vinegar, which Cleopatra then drank. Antony conceded defeat—the value of that single drink, let alone the banquet, had indeed been more than any meal in history. I’ve Got a Crush on You There are a number of different versions of this story, which originally appeared in Pliny the Elder’s Natural History. According to some versions, Cleopatra ground the pearl in a mortar before dropping it in the vinegar. That would have been a wise choice. Pearls, which are made primarily of calcium carbonate (the same material that forms stalactites, stalagmites, and tufa), will indeed dissolve in a mild acid such as vinegar, neutralizing the acid in the process. (This is how antacids work, by the way—check the label on a bottle of Tums and you’ll see that its main ingredient is also calcium carbonate.) However, this might take days for a whole pearl; a crushed pearl could dissolve in a matter of minutes. Not only did Cleopatra win the wager, she won Mark Antony’s heart. Antony left his wife and moved to Alexandria. But ten years later, Octavius led Rome in a war against Egypt. He defeated Antony and Cleopatra, both of whom committed suicide shortly thereafter. Meanwhile, according to legend, the pearl from Cleopatra’s other earring was later cut in two, with each half being placed in one of the ears of the statue of Venus in Rome. Rome fell, of course, soon thereafter. Coincidence? Probably, but all the same, I recommend against sticking antacids in your ears.. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/20/Cleopatra-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/19/Cleopatra.ec577ac71f93.mp3"
	},
	{
		"title": "The Passglas",
		"text": "I never cease to be amazed at how frequently the interesting things I merely imagine turn out to be real. For instance, my relentless research in the field of goblets and challenges led me to wonder whether there might be some special type of goblet used in drinking games. I turned as usual to the sacred oracle, the source of all wisdom in the universe, for guidance. And what Google told me, after a fashion, was that such goblets do indeed exist. In fact, depending on one’s willingness to stretch the definition of goblet, which in my case is boundless, there may be several very different sorts of goblets that figure in drinking games. For example, there’s a dice game played in Bolivia called Alalay. It’s quite similar to Yahtzee, in that it involves rolling five dice, with scoring based on the values of various number combinations. As in Yahtzee, the dice are placed in a small container and shaken before being thrown. In Alalay, this container, which is made of stiff leather, is called a goblet. Alalay is sometimes played as a drinking game, though the goblet itself is never used for alcohol; it wouldn’t do to get the dice wet. I’ll Drink to That But I found an even closer and more literal match for drinking-game-related goblets: something called a passglas (sometimes spelled pasglas)—a design that was popular in Germany, the Netherlands, Denmark, Finland, Estonia, and Sweden during the 16th through 18th centuries. A passglas is a tall glass—sometimes cylindrical but more often having six or eight sides—that looks suspiciously like a chemist’s graduated cylinder. It is tapered and stemless but, like all goblets, has a foot. And not unlike a graduated cylinder, it’s marked with glass rings or bands at regular intervals. Etymologically sophisticated readers will guess, correctly, that passglas means “pass glass,” and the name accurately describes its use. The glass was filled with beer (or, depending on the locale and the desired depth of inebriation, schnapps). The first participant drank down to the first mark and passed it on, but if he—naturally, it would be a “he”—drank too much and the liquid level dropped below the line, he would be obligated to drink all the way to the next line, and so on. Presumably one’s precision decreased as the liquid drained, increasing the rate of consumption. Depending on the number of participants and the type of alcohol used, several refillings could be required in order for all parties to reach a suitable state of intoxication. The Art of Drinking Despite the apparent ubiquity and popularity of the passglas in its heyday, it’s rarely mentioned in literature or depicted in artwork—but there are some examples. Seventeenth-century Dutch artist Adriaen van Ostade specialized in paintings and sketches involving peasants, drinking, and drinking peasants. One of his more obscure paintings, called Het dansende paar (“The Dancing Couple”), painted some time between 1680 and 1685, shows a man drinking from a passglas while the next drinker eagerly waits his turn. Nowadays passglases are sold as antiques or found in museums, and are little known outside the parts of Europe where they were once popular. This is too bad, because although modern drinking games may be more sophisticated in some ways, they rarely if ever involve a test of how skillfully one can actually drink. Precision drinking competitions could add an entirely new dimension to, say, New Year’s Eve celebrations—but a modern Pyrex measuring cup doesn’t match the simple elegance of the passglas. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/19/drinking.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/19/Passglas.6b0fa6980460.mp3"
	},
	{
		"title": "Wine Color Taste Tests",
		"text": "An article titled “Can You Tell Red From White?” in the online edition of Wine Spectator Magazine a couple of years ago began with this line: The New Yorker threw down the gauntlet. Wine Spectator rose to the challenge. Whatever else you may say about the two magazines in question or the qualifications of the authors they hire to write about wine, this much is clear: Wine Spectator missed a critical opportunity for an excellent pun. In fact, so blatant was their oversight that it casts grave doubts on the magazine’s editorial sensibilities. The Red and White Blues But linguistic flexibility is a much less serious matter than that which concerned humorist Calvin Trillin, who wrote an article titled “The Red and the White. Is it possible that wine connoisseurs can’t tell them apart?” in the August 19 & 26, 2002, edition of The New Yorker. Trillin claimed to have heard from multiple sources that wine experts—even those with degrees in enology from the University of California, Davis—routinely failed a blind taste test in which participants were asked simply to pick which wines (served at room temperature in black glasses) were red and which were white. If true, this suggests that the whole enterprise of tasting and judging wines rests on a shaky foundation at best. In the course of Trillin’s research, he discovered that the test he had heard of was most likely an urban myth, or at least a significant embellishment of a test where wines are judged by smell rather than taste. Nevertheless, he himself couldn’t reliably tell the difference. In an effort to show just how ridiculous it should be even to ask such a question, an enology professor subjected Trillin to an impromptu experiment with a pair of wines—one white, one red—and he guessed wrong. Volunteers on the staff of Wine Spectator fared much better in their own version of the test, correctly guessing color 40 out of 42 times. Fruity, with a Note of Imagination But the fact that anyone could fail such a test suggests that wines' aromas and flavors are not as distinctive as experts have led us to believe. It also reminds us that the experience of taste and smell—tightly connected as they are—may be quite subjective. Psychologists say that one’s perception of smell is strongly affected by one’s expectations—more often than not, we smell what we think we’re going to smell, or what someone tells us we’ll smell. So it’s entirely plausible that the smells and tastes we perceive in a glass of wine can be colored (so to speak) by the wine’s appearance. Meanwhile, experts ranging from Wine Spectator editors to UC Davis enologists admit that some wines have flavors that belie their colors—typically reds with an unusually low level of tannin or whites with an unusually high level. Without the standard cues of color and temperature, even a seasoned pro could plausibly suffer from a confused palate. Although I’ve been to several wine tastings, I have not developed the sophisticated palate or vocabulary necessary for describing the taste of a wine meaningfully. But then, if even such a basic distinction as a wine’s being red or white can be missed, I don’t feel so bad for not being able to detect that hint of raspberry, that faint aroma of vanilla, or even those strong oak overtones the labels declare so boldly. My test is much simpler: what color are your cheeks after drinking the wine? Red: good. White: not so much. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/19/wine.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/19/Wine_Color.1751f237efc8.mp3"
	},
	{
		"title": "The Great Cork Debate",
		"text": "When I was in high school, I had a darkroom in the basement. Because I didn’t do a large quantity of film processing, one of my biggest concerns was that the expensive chemicals would go bad before I had a chance to use them. Since it is primarily exposure to oxygen that damages photographic chemicals, I stored them in air-evacuation containers, which are basically plastic bags inside boxes. As you drain out the chemical through a special spout that sticks through the box, the bag shrinks, thus making sure no air gets in. This solution is simple, elegant, and effective. The very same laws of chemistry apply to wines, and that is why wine is sometimes sold “by the box” in air-evacuation containers. It keeps wine fresher longer, and is even less expensive, in many cases, than bottled wine. What’s not to like? And yet, boxed wine is routinely ridiculed as low-class. Everyone knows that any decent wine will be stored in a corked bottle. It’s just The Way Things Are. It’s not about oxidation, it’s about perception. You have to do things right. Buying wine in a box is tantamount to buying wine with a screw cap. It’s an indication of poor quality. Or is it? Recently I’ve been seeing an increasing number of wine bottles stoppered with a “cork” made out of plastic. And I confess that my initial reaction is invariably one of embarrassment. (“I should know better than to choose such a cheap wine.”) This is of course irrational; I know intellectually that the important thing is simply to keep air away from the wine. But I’ve discovered that there is in fact an intense debate raging in the wine industry over the best method of sealing a wine bottle, and the pros and cons of each approach are much different from what I would have thought. Here for your enlightenment and entertainment is a summary of the major positions in the debate. Cork: the traditional approach * Pros: Cork has a long history; it has been used as the sealing method of choice for over 400 years. Cork stoppers, because they are such a pain to remove, implicitly signal quality. When they work, they work well. They’re a renewable resource (the trees are not killed when the bark is stripped to make cork). They make a satisfying “pop” when removed from the bottle. They’re readily biodegradable. And they support an entire industry of corkscrews and other cork-removal products. * Cons: Corks often go bad. Estimates vary widely, but many bottles of wine are ruined due to corks that are tainted, ill-fitting, or deteriorated. (Depending on which figures you believe, as little as 1% or as much as 20% of all wine sold is “corked,” which is to say, damaged by a problematic cork.) Corks can be difficult to remove, and sometimes break off into the bottle. The world’s cork supplies are nearly maxed out, so cork prices are increasing. Plastic: the new cork * Pros: Plastic is immune to cork taint, so wine is much less likely to spoil. Plastic corks can be made more cheaply, and with much more precision, than cork stoppers. Depending on the vintner’s tastes, plastic corks can be made to look very similar to natural corks, or be molded in any imaginable designer color. They’re recyclable. And the same cork-removal equipment (along with its obligatory “pop” sound) can be used. * Cons: If the trees used to produce cork are no longer used for that purpose, they may be cut down to make space for more lucrative crops, thus endangering the habitat of various kinds of wildlife and altering the local ecosystem in unpredictable ways. If not recycled, plastic corks also pose a more direct threat to the environment. Some wine experts claim plastic corks unfavorably affect the flavor of wine. On the other hand, they don’t hold the aroma of wine well, making the ritual of cork-sniffing unsatisfying. The plastic may not retain its elasticity well over time, making it unsuitable for wines meant to age for decades. And most importantly, it’s just not right. Screw caps: a strange twist * Pros: Screw caps, like plastic corks, avoid problems of cork taint, and yet unlike plastic are much less likely to affect wine’s flavor or lose their effectiveness over time. They are less expensive than natural or plastic corks. And they can be removed without any special equipment. * Cons: As with plastic corks, screw caps imply environmental issues associated with the loss of cork farming. Cork sniffing, of course, is right out. And again, most importantly, it’s just not right. You shouldn’t be able to get at your wine as easily as you get at your cola. Crown seals: good enough for beer * Pros: Crown seals (the type of bottle cap used on most beer bottles) are basically screw caps without the screw part, so they have all the same advantages except ease of removal. * Cons: The downsides of crown seals are the same as for screw caps, with the additional issue of needing a bottle opener. Of these, crown seals came on the scene most recently and so far appear with the least frequency. Meanwhile, air-evacuation containers, which were previously used only for the cheapest wines, now sometimes hold fancier varieties. (No one seriously proposes distributing high-end wines in air-evacuation containers, since bottles are more durable and less likely to leak over a period of many years.) There are, I’m sure, any number of other equally sensible alternatives out there. But the habit of associating cork with quality is very hard to break. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/15/bottle_of_wine.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/15/Cork.da8cd3bb34a4.mp3"
	},
	{
		"title": "The Story of Ketchup",
		"text": "I can’t imagine a more quintessentially American meal than a burger and fries, and I can’t imagine a burger and fries without ketchup. Maybe that’s why I always thought of ketchup as the all-American condiment. Or maybe it was the fact that I grew up just a few miles away from Pittsburgh, Pennsylvania—home of the H.J. Heinz Company, a name synonymous with ketchup. In any case, the first time I saw the word “ketjap” on the bottle of a watery, soy-based Indonesian condiment, I jumped to the reasonable if anglocentric conclusion that I was looking at a loanword—a word borrowed from English into Indonesian, perhaps by way of Dutch—which inevitably changed somewhat in meaning along the way. It turns out I was half right: ketchup is a loanword, but not from English. And just as the name of this product has undergone countless changes in spelling, its composition has changed dramatically with time and geography. You Say Tomato, I Say Ketchup The first clue to the storied past of ketchup can be found in large, bold letters right on that Heinz bottle: it says “Tomato Ketchup.” Isn’t that redundant? Aren’t tomatoes the key ingredient? Why call attention to the fact, as though we should expect to find Beet Ketchup and Cucumber Ketchup nearby on the shelf, and need to make sure we’re buying the right kind? But this raises the question of what “ketchup” means in the first place. Some historical perspective may be helpful. Etymologically speaking, the English word ketchup, also spelled “catsup” and a dozen other ways, derives from the Malay (or Indonesian) word kecap (also spelled ketjap), which in turn was based on the Chinese word ke-tsiap. The Asian forerunner of ketchup was a type of fish sauce, which is to say fish (typically anchovies, and often fermented), dissolved in brine. When this sauce made its way to Europe in the 1600s, cooks began experimenting with different ingredients—besides anchovies, mushrooms, walnuts, oysters, and even lemons appeared in various ketchup recipes over the next couple of centuries. Salt was the only invariable ingredient; while some recipes included vinegar, few included sweeteners, and nearly all were quite runny. In the New World, tomatoes were known to be used in ketchup as early as the 1780s, though the first published recipe for tomato ketchup—created by James Mease, a physician and horticulturist from Philadelphia—dates only from 1812. But it was not until 1872 that Henry J. Heinz developed the recipe his company still uses today. In contrast to conventional ketchup-making wisdom at the time, Heinz used ripe tomatoes, increased the proportion of vinegar in the recipe dramatically, added sugar, and flavored it with onion and a special blend of spices. The result was an extremely viscous condiment that included all the major taste components—salty, bitter, sweet, sour, and umami (or savory). This winning combination soon became the American definition of ketchup; although competitors' recipes differ in the details, the public no longer accepts anything as “ketchup” that doesn’t fit the pattern of a thick, tangy, tomato-based sauce. Slow and Steady For more than a century, Heinz wisely followed a “don’t mess with success” policy; only bottle shapes and sizes changed significantly. Plastic squeeze bottles were perhaps the best thing to happen to ketchup since the tomato, and the latest trend, upside-down “Easy Squeeze” bottles, are a work of genius that should earn someone a MacArthur Fellowship. Of less certain distinction was the range of bright ketchup colors Heinz experimented with a few years ago. First green ketchup appeared on the shelves, then purple (my personal favorite), and even, briefly, blue, pink, orange, and teal. While claiming the colors were “very popular with consumers,” the company nevertheless discontinued them after a short time. Although they tasted just like red ketchup, I suspect too many people found the notion of blue tomatoes cognitively dissonant. Or maybe it’s just that kids quickly tire of novelty. For a brief period in 1981, the Reagan administration decreed that ketchup could be considered a vegetable for the purpose of satisfying nutritional requirements for school lunches. Because the government’s edict used the spelling “ketchup,” Del Monte found itself unable to sell its Catsup to schools, and quickly changed its spelling. Although public outcry soon resulted in ketchup’s removal from the vegetable list, Del Monte kept its new spelling. That appears to have settled the question of spelling once and for all, while leaving unresolved the puzzle of why ketchup wasn’t considered a fruit. But it could have been worse: if ketchup had maintained its original formula, it might now be considered a meat. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/15/ketchup.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/15/Ketchup.df96a42e8722.mp3"
	},
	{
		"title": "Fleur de Sel",
		"text": "In general, I don’t have very expensive tastes. I bought my TV for $10 at a garage sale, my home is furnished mostly in low-end IKEA, and I rarely wear anything fancier than jeans and a T-shirt. When it comes to food, though, there are some exceptions to this rule. Although I don’t usually eat like a gourmet, I do take my coffee and cheese pretty seriously, and I like to sample, at least, foods that are rare and unusual—if also somewhat pricey. So I was intrigued by a television show I saw about one of the world’s most expensive kinds of salt: Fleur de Sel (French for “flower of salt”). Fleur de Sel is produced in several temperate coastal areas around the world—but particularly in France, and within France, particularly in Brittany, on the north coast across the English Channel from Great Britain. It’s a type of sea salt, but a very expensive one indeed. Whereas you might pay US$0.25 for a pound (about 0.5kg) of plain table salt, Fleur de Sel will run upwards of $25 per pound. At 100 times the cost of table salt and ten times the cost of ordinary sea salt, it’s probably not something you’d want to use for everyday cooking. Fleur de Sel is not just any sea salt, though; it owes its price to a very special method of collection, about which more in a moment. Enriched with Minerals But let me take a brief detour to talk about sea salt in general, which is becoming increasingly popular in recipes and on store shelves. Why all the fuss? Well, apart from having a coarser texture, which some people prefer, sea salt has a much higher content of other minerals besides sodium chloride. It is, after all, produced by evaporating seawater, which contains a bit of pretty much everything. And the little bits of other stuff, apparently, enhance the flavor. Call me crazy, but I can’t help thinking twice about all those seemingly innocent little extra minerals. Do you know where this ocean has been? A lot of things live (and die) in the ocean, and a lot of waste of every imaginable kind gets dumped there—such as all the sewage from the city of Venice, just to pick a random example. It makes me wonder—in passing—whether this is something I really want to put in my mouth. To get Fleur de Sel, salt farmers living along the coast allow shallow pools to fill with fresh salt water. As the water evaporates, a thin layer of salt crystals forms on the surface, but the slightest breeze will cause them to sink, and they pick up a grayish color from the clay and minerals at the bottom of the pool. The resulting salt, called Sel Gris, is highly regarded, but there’s something even better. On a very clear and sunny summer day with no wind, the salt layer remains floating on the surface, and is harvested by skimming it off with a rakelike implement at the end of the day. Voilà: Fleur de Sel. Because conditions must be just right for Fleur de Sel to form, the yield is only about one pound for every 80 pounds of Sel Gris. Crunchy Sprinkles Fleur de Sel is composed of irregularly shaped grains of salt that are slightly moist and form flakelike clumps. This gives it a much different texture from ordinary salt. It’s crunchy and perhaps slightly less salty than ordinary salt—if that makes any sense. Personally, I can’t detect any other flavors, though some people swear it has the aroma of violets. It is almost always used as a garnish just before food is served; once the salt is dissolved and mixes with other flavors, the difference is even harder to detect. My cynical side says that the real reason for sprinkling Fleur de Sel on a dish at the table is to show off, but then, I’m no authority on such matters. In any case, I think of Fleur de Sel as the Kopi Luwak of salt—that is, slightly superior in taste to the ordinary varieties, but not to the extent suggested by its price. Then again, gourmet shops often sell it in small containers for as little as $5. Perhaps it’s just the thing for expensive tastes on a budget. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/14/Salt-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/14/Fleur.16eec4e421ce.mp3"
	},
	{
		"title": "Salzbergwerk Berchtesgaden",
		"text": "Nowadays, we take salt for granted. Sold for a pittance, the most common of spices, we think of it as an everyday thing, when we think of it at all. It wasn’t always so. In fact, great empires and fortunes rose and fell according to its supply. It is hard to imagine a modern war being fought over salt. But consider these historical events, as recounted in Margaret Visser’s Much Depends on Dinner: Morocco fought Mali in the sixteenth century for the mines of Taoudeni; the Venetians, whose salt interests are an historical study in themselves, destroyed Comacchio in the tenth century and the salt gardens of Cervia in the fourteenth; pirates throughout the centuries ambushed and raided the slow heavy convoys of salt ships. There are plenty of other examples—all of which seem outlandish to us today, considering that the biggest battles fought over salt have to do with whether it should be spread over icy roads in winter. Salt has lost its nobility, its historical power—but from the salt-starved Vikings to the salt-greedy Romans, salt has played an important role in human history. The Saltman Cometh Nowhere does this seem more obvious than in the salt-rich environs of eastern Bavaria and western Austria. The de facto capital of the region, Salzburg (or “salt town”) was built by its first archbishop in the eighth century with profits from salt mining, but the practice of salt mining goes back even further, to the civilization of the early Celts. In his book Salt: A World History, Mark Kurlansky describes the discovery by local salt miners in the 1600s of a “perfectly preserved body, dried and salted ‘like codfish,'” believed now to date to 400 B.C. Dressed in colorful fabrics, this “saltman” and two others like him were found with the tools of their trade near them, proof of an ancient salt mining culture. Salt of the Earth This salt mining tradition continues in the modern salt works along the German/Austrian border, and it’s possible to experience some of what those ancient miners might have felt, deep in the mountains of salt. Founded in 1517, the Salzbergwerk Berchtesgaden (“Berchtesgaden salt mine”)—located near Salzburg but on the German side of the border—once entertained only aristocratic visitors, but now welcomes the public to its underground facilities and caves. Berchtesgaden, erroneously linked in the public imagination with Hitler’s southern headquarters (they were actually located at Obersalzberg, a small settlement further up in the mountains) is a town that developed in proximity to the Augustinian monastery that owned the Salzbergwerk. In the early 1800s the monastery was converted into a palace for the Wittelsbachs, rulers of Bavaria at the time, and the entire area became associated with this colorful family. Mine Games Still operational, the Salzbergwerk is a joy to visit. Donning the traditional leather vests and helmets of the miners, you start to feel as if you are a miner yourself. This sensation is heightened when, after a short train ride, you are asked to slide down a wooden chute into the mine itself. After overcoming my apprehension, I slid into the dark, feeling even more like a miner heading to work. Our guide, a local man, explained the workings of the mine to us—or so I gathered, since I couldn’t understand his thick “Bayrisch” accent. This only added to the feeling of being in a different world, a world where life goes on underground. The most striking element of this topsy-turviness was the presence of a large underground lake in the mine. Gliding silently across its depths on a wooden platform boat, it was eerie to see the lights at its edges through the darkness, and to feel the oppressive nearness of the stone “ceiling.” I imagined myself gliding across the river Styx, and shivered in the damp air. Worth Its Salt Returning from the depths of the mine, it was hard to think of salt the same way again. It is, after all, the only rock that we eat, and with thousands of tons of it looming above your head, you don’t immediately think, “pass the salt.” Vital to the functioning of our vital organs, we would die without salt, yet we live in a salt-glutted world, so much so that we are told to reduce our intake, for the sake of our health. In their song “NaCl (Sodium Chloride),” folk singers Kate and Anna McGarrigle make a case for the worthiness of salt. Describing the meeting, mating and melding of a sodium atom and a chlorine atom in the primordial sea, they ask us to “Think of the love that you eat, when you salt your meat.” Silly, meant to be taken with a “grain of salt,” yet it expresses the mystery of salt, the serendipitous compound that protects our cells, and fills the ocean. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/14/mining.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/14/Salzbergwerk.740111300825.mp3"
	},
	{
		"title": "Sarlat La Canéda",
		"text": "For the past decade or so, I’ve been in the habit of reading every new Michael Crichton novel as soon as it’s released. I like the stories, but what appeals to me more is the depth of historical and scientific research he puts into his work. It’s often had to tell where reality ends and fiction begins, which I’m sure is exactly what he’s aiming for. Given my fondness for France, I was especially interested in his book Timeline, published in 1999 (and made into a disappointingly forgettable movie in 2003). Most of the book’s action takes place in the Dordogne river valley in southwestern France—partly in the 14th century and partly in the 20th. In particular, Crichton’s description of the town of Sarlat caught my attention. It’s the site of just one minor scene and is only given a passing mention. But what the book describes is a quaint town preserved as it was in medieval times—a place full of history and character. Guidebooks generally speak highly of the town too, and I thought it sounded like a great place to visit. On our first trip to France, in 2000, our schedule did not permit an excursion to Sarlat, but Morgen and I decided we’d do our best to go there the next time we were in the area. Getting There Is Half the Fun In June of 2003 we returned to France, and we hoped once again to visit Sarlat. We had left the last week of our trip deliberately unplanned to allow ourselves the option of doing whatever seemed most interesting at the time. When it finally came time to choose where to go, we were in the French Alps (on the east side of the country near the Swiss border). We discussed Sarlat as one of several options for our final destination. The friends we were staying with tried to talk us out of it. “It’s really touristy,” they said, “and very hard to get to. We can recommend lots of places you’d enjoy more.” So we agonized over the decision for a long time, but finally agreed that we wanted to go with our first choice, touristy or not. We went to the train station to figure out how to get there. When the ticket agent heard “Sarlat,” he rolled his eyes and sighed as if to say, “You can’t get there from here.” Actually that would have been an overstatement. You can get to Sarlat from the French Alps, but it requires taking five different trains and a bus—a trip lasting about 12 hours in total (and not an inexpensive one either). We decided to rent a car instead. Our trip across France by car took almost as long as it would have by train, as most of it involved twisty mountain roads. It was hot, too, and our car didn’t have air conditioning. By the time we drove into Sarlat, it was nearly 10 p.m., the time at which, we had been told, the front desk of the hotel where we were staying would close. We didn’t have a good map of the town, so we drove around searching for a while, and by the time we finally found our hotel (at 9:59 p.m. ), we were tired and very grumpy. And hungry too. Our first task after checking in was to find some food, which turned out to be very difficult because none of the restaurants was still serving dinner at that hour. After being rebuffed by a particularly snooty waitress, we finally found a pizzeria that consented, with some reluctance, to make us a pizza if we agreed not to eat it on the premises. When we got back to our room, pizza in hand, we were not feeling very favorably disposed toward Sarlat. The next morning, however, we did our best to approach the rest of our stay with an open mind. My top priority of the day was finding internet access, as I had some urgent business to attend to. For being a medieval town, there were plenty of cybercafés (at least three that I saw), which nicely boosted both my spirits and my impressions of Sarlat. I easily dispatched my correspondence and a pastry. With work out of the way for the moment, we set about exploring the town. Medieval Time Capsule What we had read about Sarlat La Canéda (the full name of the town, which is rarely used except on maps) was that, of all the towns in France, it was the one that looked most nearly as it would have in the 14th century. (That is to say, the old part of Sarlat, which had once been a walled city, looked that way—the outlying areas were just as suburban-looking as anywhere else.) Except for the central main street, the town was car-free and pedestrian-friendly—always a plus in my book. In addition, the signs of modern infrastructure—streetlights, neon signs, electric wires, and so on—were kept to an absolute minimum, or at least hidden. And most importantly, nearly all the architecture was preserved to look just as it did centuries ago. In all these ways Sarlat lived up to its hype, giving a fairly convincing illusion of stepping back in time. Fortunately, the effect was not so complete as to include, for example, raw sewage flowing in the streets or plague-infested rats, but it was close enough. The history of Sarlat can be traced back to at least the ninth century A.D., when a Benedictine abbey was founded there (later to be replaced by a cathedral, which is still in use). During the 13th through 16th centuries, Sarlat was prominently involved in a series of notorious conflicts and religious wars, not to mention a succession of natural disasters such as floods, plague, and famine. From the 17th century to the middle of the 20th century, Sarlat was largely overlooked by modern development and fell into a state of decay and disrepair. But thanks to a 1962 ordinance called the Malraux Act, it was designated a “protected area” and soon underwent massive renovation work. The result is a modern town that looks centuries old, but in fact is far more lovely and livable than it really was in medieval days. Duck, Duck, Goose! I was aware that the Périgord, as the French refer to the Dordogne region, was an area known for its foie gras, and even that local producers delight in giving public demonstrations of force-feeding geese and ducks to plump up their livers. I like foie gras and I’m not especially squeamish about that sort of thing, but what I was not prepared for was that virtually every second shop in the old town was a foie gras shop. This is barely an exaggeration. In a town with perhaps a hundred retail establishments in all, there were dozens of stores that specialized in foie gras, each with a nearly identical window display beckoning to tourists that theirs was the best, the most authentic, or the least expensive foie gras in town. It would be like going to a mall in the U.S. and finding 20 Mrs. Fields shops—however much you like the product, you can’t help thinking the market saturation point was passed long ago. Were there lots of tourists in Sarlat? You bet. But strangely, this didn’t bother me much, perhaps because I thought the town was authentic enough to merit the attention—that it wasn’t a cheap, Disney-style tourism. Or it could just be that given enough wine and foie gras, nothing will bother me. Sarlat is not the prettiest town in the region. Nearby Beynac, for example, with its majestic cliff-top castle overlooking the Dordogne is postcard-perfect, and you could spend weeks in the Périgord hopping from château to scenic château. But for sheer medieval character, nothing beats the coziness of Sarlat. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/14/france.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/14/Sarlat.509020776b55.mp3"
	},
	{
		"title": "Pastrami",
		"text": "Sometimes the ideas for interesting topics come to me in rather roundabout ways. For instance, I was trying to come up with just one more topic that could somehow be construed as involving things that are stuffed. As usual, I asked my wife, Morgen, if she had any ideas. She made a few suggestions, none of which really grabbed me. Finally she said she was stumped and apparently gave up. A few minutes later, however, she handed me a book by Patricia Volk titled Stuffed: Adventures of a Restaurant Family. That was, of course, a very promising sign. Then she pointed out that the author’s family had run a restaurant in New York called Morgen’s—spelled the same way as my wife’s name. A lovely coincidence. (Morgen, it turns out, is the maiden name of the author’s mother—and also the name of a beagle that Volk and her sister once owned.) Flipping a few pages ahead, my wife showed me a picture of the author’s great-grandfather, Sussman Volk, whose claim to fame had been that he “brought pastrami to the New World.” Now we were getting somewhere. All right, I understand that pastrami is not ordinarily stuffed or used to stuff anything else, but that’s not the point. The point is that I had never spent so much as five seconds thinking about pastrami before, but now that I knew there was at least one interesting story about it, I suddenly began to realize there were other questions to ponder too. Such as: What is pastrami, anyway? Meet the Meat Let me be candid here. I could probably count on both hands the number of times I’ve eaten pastrami in my life. It’s not that I have anything against it, I just never really think about it. When I walk into a deli—which is not all that often—I habitually gravitate toward the turkey and the roast beef. For all the times I’ve seen the corned beef, pastrami, and other cured meats sitting there, it has simply never occurred to me to order any. Nor, until yesterday, had it ever occurred to me to wonder exactly what it was; I vaguely realized that it was some sort of beef product, and that was pretty much that. But once I did start wondering, I found the answer kind of surprising. The dictionary informs me that pastrami is a “highly seasoned cut of smoked beef.” However, there are lots of cuts of beef, and surely not every one of them that’s highly seasoned and smoked is pastrami. Or is it? What Are You Smoking? One way to make pastrami is to smoke corned beef. This, of course, brings up the question of what corned beef is in the first place. Curiously, corn has nothing to do with it. Perhaps a clearer term would have been “salt-cured brisket.” Brisket is the term for beef that comes from the lower chest of a cow, just behind the front legs. To make corned beef, this meat is cured—typically by soaking it in a seasoned brine for a few weeks. The grains of salt traditionally used to make the brine were about the same size as a grain of wheat (or “corn” in British English)—hence “corned” beef. When corned beef is smoked (to add flavor), seasoned with more spices—and, in most cases, steamed—it is then known as pastrami. However, there’s more than one way to make pastrami. It need not start with corned beef—or indeed even with brisket. Pastrami can be made from other cuts of beef—such as the plate, which is located just behind the brisket. And rather than soaking it in brine, it can be dry-cured in a salt paste. Pastrami is often, though not always, covered with spices such as cracked pepper and coriander seeds before being smoked. In fact, there are so many different ways of making pastrami that the only thing you can really say for certain is that it’s a “highly seasoned cut of cured smoked beef.” So the dictionary was pretty close after all. However, similar methods are employed to make so-called “turkey pastrami,” “tuna pastrami,” and other beefless products. Coming to America But back to Sussman Volk…he had immigrated to New York from Lithuania in 1887 and set up a butcher shop. A friend asked Volk to store a suitcase in his basement while he traveled home to Romania for a few years. In exchange for the storage space, the Romanian friend gave Volk his pastrami recipe, and Volk began selling it at his butcher shop. It became such a hit that customers asking for pastrami sandwiches (on rye bread, of course) soon crowded the small shop. He moved a couple of doors down the street to a larger location with a few tables, and thus created New York’s first delicatessen. The term delicatessen, by the way, is German in origin and originally meant “edible delicacies.” It later came to mean the shops where ready-to-eat meats and other foods were sold. Meanwhile, the word pastrami comes via Yiddish from the Romanian word pastramă, a term apparently borrowed from Turkish and meaning “cured meat”; it may also be related to the Romanian verb a păstra (“to preserve”). So thank you, Morgen, for telling me about Patricia; thank you, Patricia, for telling me about Sussman (and another Morgen); thank you, Sussman, for delicatessens; and thank you, anonymous Romanian friend, for the pastrami recipe.anian friend, for the pastrami recipe. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/14/Pastrami.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/14/Pastis.efeb91fae3ad.mp3"
	},
	{
		"title": "The Foods of Sukkot. Stuffing and symbolism",
		"text": "My friend Mark is a rabbi, and although I’m not Jewish, we share similar opinions on many topics, both religious and secular. About this time last year, Mark sent me an email pointing out that in the celebration of Sukkot, the Feast of Tabernacles (which begins this evening), several stuffed foods are part of the standard menu. Nearly every cuisine around the world contains stuffed foods of one kind or another. In Italy, there’s gnocchi and ravioli; in China, stuffed wontons; in Greece, stuffed grape leaves; and in America, jelly doughnuts…just for example. So I had been intending to write something about this culinary phenomenon anyway, and I thought it was a remarkable coincidence that stuffed foods had special symbolic significance during a week when the site’s theme involved things that are stuffed. In honor of the occasion, I decided to repeat the theme and today’s topic this year. Take-Out Only Sukkot (also spelled Sukkoth or Succoth) is a Jewish harvest festival that lasts seven or eight days each fall. The translation “Feast of Tabernacles” or “Feast of Booths” refers to the sukkot, portable booths or huts the ancient Israelites lived in while wandering in the desert. The biblical reference (or, rather, one of several) states: Now, the fifteenth day of the seventh month, when you have gathered in the produce of the land, you shall keep the festival of the Lord…You shall live in booths for seven days; all that are citizens in Israel shall live in booths, so that your generations may know that I made the people of Israel live in booths when I brought them out of the land of Egypt; I am the Lord your God.—Leviticus 23:39-43 (and I hope you’ll pardon my Gentile spelling) Traditionally, Jewish families construct a sukkah (the singular form of sukkot) outside according to a strict set of rules that specify dimensions, building materials, and so on. The family then gathers in the sukkah to eat their meals together during the festival, which is generally considered to satisfy the requirement of “living” in the booth. The Stuff of Legend Although there are no explicit rules as to what foods must be eaten during Sukkot, stuffed foods are extremely common. These may include stuffed peppers, eggplants, or cabbage, stuffed fruits and pastries, knishes, kreplach, main-dish pies, or even ravioli. Though no one knows for sure, there are several theories as to how the metaphor of stuffing came to be associated with Sukkot. Some commentators liken the stuffed foods to miniature cornucopia, representing a bountiful harvest. The cornucopia originated in Greek mythology, so the terminology is not historically accurate, but the symbolism may nevertheless be correct. In terms of the harvest that Sukkot celebrates, produce such as peppers and eggplant will have been gathered recently, and Mark suggested that stuffing them with the other late-summer vegetables may represent the completion of the harvest. Sukkot also includes the notion of welcoming guests (both living and historical heroes) into the sukkah, thus “stuffing” them into a wrapper of sorts. As much as I enjoy symbolism and metaphor, it had never occurred to me to think of stuffed foods as anything other than a culinary convenience. (Or inconvenience—I once tried, unsuccessfully, to make stuffed carrots. Don’t ask.) But now, I don’t think I’ll ever look at a ravioli (or a stuffed turkey, for that matter) the same way. You can stuff foods with the bounty of the harvest, stuff your home with guests, and then stuff your guests with food (though overeating, Mark notes, is not encouraged). That strikes me as a beautiful image of the cycle of growth and regeneration. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/13/stuffed-pepper-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/13/Sukkot.7bdbb32abecb.mp3"
	},
	{
		"title": "The Mega Dog",
		"text": "Author’s Note: On November 17, 2005—a little more than a year after this article was published—the Westward Ho Hotel and Casino closed permanently after more than 40 years in operation. Although, sadly, you can no longer go there to get a Mega Dog or a 99¢ margarita, we’ll leave this article here for its historical value. Before I visited Las Vegas for the first time, a number of people warned me that I’d hate it. To be sure, there are any number of things about the city that one may find off-putting, and it can be quite an expensive place to visit—even if you don’t count money lost by gambling. But my first impression of Las Vegas was that it was like a giant amusement park. Everything was built on an absurdly large scale, but the excesses almost seemed to make fun of themselves. I found it absolutely delightful to go from one casino to the next, watching how much effort each establishment put into looking gaudier and more over-the-top than the next. Whether it’s better blackjack odds, looser slot machines, a faster roller coaster, or a flashier pirate show, every business has some gimmick to convince the tourists to spend their money there. And of course, like an amusement park, everything in Las Vegas is designed carefully to make you feel that the money you’re spending is well worth it; you’re experiencing one-of-a-kind attractions. More is Less Down at the unfashionable north end of the Strip, older hotels cater to families and travelers on a budget. Instead of competing to be more luxurious than the place next door, the casinos lure customers with an extremely effective marketing technique: really cheap food and drink. However much common sense may try to hold you back, it’s hard not to be drawn in by a sign promising a 27-ounce (0.8 liter) frozen margarita for 99¢. One of these signs is outside a nondescript hotel-casino called Westward Ho. This is as no-frills as a casino gets in Las Vegas. There are no celebrity performers or erupting volcanoes. Just slot machines, table games, and the cheapest (not to mention least expensive) food in the city. And they still think big when it comes to food. In our never-ending pursuit of kitsch, Morgen and I decided to check out Westward Ho’s margaritas a couple of years ago. It took us quite a while to find the bar that sold them, and let me be frank: they were awful. In that 27-ounce glass there was perhaps one microdroplet of tequila—it was basically a very sweet slushy lime drink with a faint hint of alcohol. So when we returned this summer, we brought our own supplementary tequila, which I must say enhanced the experience considerably (while still making the price a bargain). We needed something for that drink to wash down, so we went to the deli in the back corner that features the casino’s star culinary attractions. For 99¢ you can buy your choice of a shrimp cocktail or a basic hot dog. The shrimp cocktails were every bit as impressive as the margaritas: a small plastic glass filled with shredded lettuce and topped with a handful of baby shrimp and a dollop of cocktail sauce. A Matter of Size But if you’re willing to splurge, $1.49 will buy you the largest hot dog I’ve ever seen, a 3/4-pound (1/3 kg) Mega Dog. These are no mere foot-long hot dogs; using a dollar bill as a rough measure of 6 inches, I estimated the Mega Dog to be 14 inches (35cm) long—about the size of three standard hot dogs. Last year I couldn’t quite bring myself to purchase one, but on our most recent trip I decided it was one of those experiences I just had to have. The gentleman in front of me ordered his with the works—cheese, chili, and sauerkraut—and because of all the overflowing toppings it had to be cut in half just to fit on a plate. But those toppings cost extra; I was looking to get the most bang for my buck and a half, so I got a plain dog and added some ketchup and relish myself. Hot dogs are not one of my dietary staples, so I can’t say with much conviction how the Mega Dog stacks up taste-wise against its more compact cousins. I didn’t find it particularly objectionable, though, and certainly on a calories-per-dollar basis, you’re getting more than your money’s worth. Our biggest culinary disappointment at Westward Ho, in fact, was their advertised 5¢ cup of coffee—Nickel Nick’s Java Shop, alas, was closed late at night when we were there. That struck me as odd, since cheap coffee would seem to be a good way to keep patrons awake and gambling into the wee hours of the morning when they’ve had a few too many margaritas. Westward Ho is not the only place in Las Vegas that sells extremely cheap food, but it’s my favorite. Quality aside, the idea that you can get stuffed for less than $2 (and still have enough money left over to play nickel slots) is strangely reassuring in a town where money is so easy to lose. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/14/hotdog-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/13/Mega_Dog.dd927337f2f.mp3"
	},
	{
		"title": "The Story of Doughnuts",
		"text": "In the mid-1990s, I visited Las Vegas for the first time. I was there for an internet conference, and a friend of mine who had been there many times took it upon himself to show me all the standard tourist sites and make sure I got the complete Las Vegas experience. We walked down the Strip, taking in the obligatory pirate show, erupting volcano, and other spectacles. But there was one sight I had never heard of that was later to become a regular pilgrimage for me: the Krispy Kreme Doughnuts shop in the Excalibur hotel. At that time, Krispy Kreme hadn’t expanded to become the phenomenon it is today. The only commercial doughnut shop chain I had ever known was Dunkin' Donuts. But Krispy Kreme was definitely something special. For one thing, visitors could watch the doughnuts being made; a window ran along the side of the shop where the line formed. I was fascinated by the mechanism that flipped the doughnuts over in the oil when they were half-cooked, and watched in awe as they passed through a curtain of glaze. Although doughnuts are such a simple food, I felt I was watching something magical. Then I tasted one, and was even more impressed. I had never known what a fresh, hot doughnut was like—the difference from what I had experienced before is like that of fresh bread hot from the oven compared to week-old supermarket bread. It was light, soft, perfectly sweet—delicious. I couldn’t understand why Krispy Kreme hadn’t taken over the world yet; of course, it was only to be a matter of time. When a local newspaper ran an article about the history of doughnuts, it got me wondering how many other things about doughnuts I had been taking for granted all along. I decided to do a bit of research. From Oily Cakes to Doughnuts Doughnuts as we know them today originated in the mid-1800s. Their predecessor was the olykoek, a treat Dutch immigrants to the U.S. made by frying the leftover bits of bread dough in hot oil. Exactly how the name “doughnut” came to be used is the subject of some disagreement. According to some sources, the Dutch twisted their dough into knots, hence “dough knots”. Others point out that the olykoeken tended not to cook through in the very middle, so some makers would put nuts in the center (“dough-nuts”) to make them more palatable. The uncooked centers seem to have been, directly or indirectly, the reason behind the hole. According to several widely diverging accounts, the doughnut hole was the invention of a New England sea captain named Mason Crockett Gregory (or Hansen Gregory or Hanson Gregory, depending on who you ask) around 1847. Gregory’s mother Elizabeth made olykoeken and sent them with her son on his journeys to sea. The least likely but most colorful version of the story, and therefore the one I like best, is that Gregory needed a place to put his olykoek while he steered the boat, so he impaled it on one of the spokes of the steering wheel. Other sources say that Gregory came up with the idea in a dream or claimed to have received it from angels; some say he simply didn’t like the uncooked centers (or the nuts his mother filled them with) and poked them out; still others say he may have encountered a cake with a hole in the middle during his journeys and decided to adapt the idea to the olykoeken. Whatever Gregory’s real reason for adding the hole, it had the beneficial effect of making the doughnuts cook more evenly, and the idea quickly caught on. Success Rolls On Nearly thirty years later, in 1872, John Blondell received the first patent for a doughnut cutter. Doughnut technology advanced significantly over the next few decades. By the 1930s, automated doughnut-making machines were producing the treats in huge quantities. And in the 1940s and 1950s, chains like Krispy Kreme and Dunkin' Donuts sprang up, taking mass-produced doughnuts to the masses. In Canada, meanwhile, the name most often associated with doughnuts is Tim Horton, a former hockey player who lent his name to a nationwide chain of doughnut shops. Fond though I am of Krispy Kreme doughnuts, I have become increasingly aware that the doughnut illuminati don’t take them very seriously. I asked my friend Russ, a doughnut connoisseur, where to find the best doughnuts in San Francisco. Without any hesitation, he said, “Oh, Wirth Brothers Pastry Shop on Geary. They’re the best by far; I’ve been going there for years.” If there was something better than Krispy Kreme, I had to experience it for myself. In the interest of science, I set out on a field trip. Hole Is Where the Heart Is Wirth Brothers is a small, inconspicuous bakery; their doughnuts are barely even noticeable in the display case among the cakes and pastries. But I went in and ordered a few, assuring the owner that they came with the highest recommendation. She smiled knowingly; apparently she gets that a lot. The current proprietor is neither a Wirth nor a brother, but she’s been making doughnuts by hand for 28 years, following the recipe of the store’s original owner, who opened the business in the 1930s. She said the recipe is no secret, but that the key is the half-hour of hand mixing they do every morning, which gives the doughnuts their unique texture. “Come back at 8:00 in the morning,” she advised me, “to get them when they’re hot.” I then headed to the local Krispy Kreme, where even in the evening, the “Hot Doughnuts Now” sign was illuminated, signifying the availability of doughnuts fresh off the conveyor belt (as well as free samples for each customer). I carefully compared the Wirth Brothers doughnuts with the Krispy Kreme, trying to maintain a properly objective attitude. The doughnuts from the bakery were significantly larger, and much chewier. When I bit into one, my teeth met some resistance halfway through; I found this “al dente” quality quite pleasing. The Krispy Kremes, however, were uniformly light; it was like biting into sweet, slightly oily air. I repeated the experiment on another pair of doughnuts, just to be scientifically responsible. There was no doubt: Krispy Kreme was merely fantastic, compared to the heavenly perfection of the Wirth Brothers doughnut. To be absolutely sure, though, I will have to repeat this experiment at various times of day and at numerous outlets around the country. I love science. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/13/Doughnuts.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/13/Doughnuts.759485abf6bb.mp3"
	},
	{
		"title": "Silicone Baking Products",
		"text": "One of my favorite pieces of kitchen kit has always been a simple plastic pastry mat I received as a gift many years ago. It did an excellent job of keeping flour off the counter and was imprinted with circles showing how far dough should be rolled out for different sizes of pie and tart pans. The mat also made it easier to get pie crusts into a pan, because you could invert the pan onto the dough and then just flip the entire assembly over. Try that with a countertop! Well, a few months ago, my faithful pastry mat finally gave up the ghost, so I headed down to my favorite kitchen supply store to buy a replacement.\n\nKitchen stores are dangerous places for me, just like hardware stores and computer stores. Everywhere I look there’s some newfangled, high-tech gadget calling out to me, and my mind races as I consider all the new things I could create if only I had this or that new tool. I thought I would be safe in the cookie-sheet aisle, though: all I needed was a simple US$5 plastic mat. And there it was, right next to…wait, what’s this? A $25 fiberglass-reinforced, nonstick, heatproof, silicone pastry mat! Although I did not immediately grasp how this technological wonder would improve on the old-fashioned plastic mat, it was shiny and had an irresistible texture, not to mention lots of impressive-looking words on the box. Guess which one I left with.\n\nSticking Points\nOne of the major selling points of the silicone mat was that because it had a nonstick surface, it was not necessary to flour it before rolling out dough. I should have realized this claim was nonsense, though: I’ve found that moist dough sticks quite nicely even to a Teflon-coated rolling pin, whereas dry flour does not—making it harder in some cases, not easier, to roll out dough. The silicone mat behaves much the same way. Its slightly tacky surface keeps it from sliding around on the counter, which is good, but rolling out dough on the top is no different from rolling out dough on any other surface. The flour is still mandatory.\n\nHowever, the claim of nonstickiness is not exactly false either. Silicone is, as the package said, heatproof—it can live quite happily in a 500°F (260°C) oven. If you bake something on it—cookies or pastries, say—they will indeed slide right off. Unfortunately, the mat I bought is too wide for my oven, though many smaller mats of similar design are made for the express purpose of lining baking sheets. In other words, silicone baking mats function as reusable parchment paper, which makes sense because parchment paper, after all, is simply silicone-coated paper. The mats simply replace the paper substrate with, in most cases, a finely woven fiberglass mesh that helps the silicone to keep its shape and prevent tearing.\n\nNot long after I picked up the pastry mat, I began to notice an explosion of silicone baking products in kitchen stores: cake pans, muffin pans, cookie molds, oven mitts, spatulas, whisks, and so on. Silicone appears to be the trendy new kitchen wonder material. But is it really all that great? What makes it better than metal or plastic?\n\nVersatility, Thy Name is Silicone\nSilicone is not the name of a specific chemical substance but rather a whole class of polymers, all based on a particular arrangement of silicon and oxygen atoms. Unlike elemental silicon, the brittle material from which computer chips are made, silicone is generally flexible and translucent. Silicones vary in density and texture; some are liquid (used as sealants, adhesives, and lubricants), some are a gel (used in surgical implants), and still others, such as the ones used in baking products, are more solid.\n\nThree properties in particular make silicone interesting as a bakeware material. First, unlike metal, it’s a poor conductor of heat. (Or, to look at it the other way around, it’s an excellent insulator.) This prevents whatever’s on the other side from burning—whether it’s a cookie or your hand. Second, it can tolerate a huge range of temperatures—from freezer to oven—without melting or cracking, so it can be used in situations that would destroy conventional plastic or rubber. And third, it’s flexible, which means removing Bundt cakes, muffins, and the like is a simple matter of flexing the mold. The combination of flexibility and light weight also makes silicone products easy to store.\n\nSo are there any downsides to this miracle substance? Well, the very properties that make silicone useful can, in some cases, cause problems. Because it’s a good insulator, it inhibits not only burning but browning. So if you’re baking something that should be crispy on the outside, silicone is not your friend—stick with metal. Also, silicone’s flexibility can cause large molds to deform when filled with dense, heavy batters. And because silicone baking mats, pans, and molds are not rigid, you often need to put them on a regular baking sheet just to get them into and out of the oven without spilling their contents. On the other hand, a whole stack of silicone baking sheets could fall off a shelf without waking up your downstairs neighbor. It’s arguably the world’s quietest bakeware, and I’ll gladly pay a premium for that. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/13/siliconC.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/13/Silicone.a460526e02da.mp3"
	},
	{
		"title": "Tabasco Sauce",
		"text": "The fruit is picked by hand at the peak of ripeness, then crushed, fermented in oak barrels, and aged for three years before being bottled. The final product is a distinctive shade of red, and is served in fine restaurants all around the world. But it's not Cabernet, Merlot, or Burgundy. It's Tabasco® Sauce, the world's most famous red pepper condiment. It has been bottled on Avery Island, Louisiana by the McIlhenny family since 1868. And this little bottle is full of interesting stories. Avery Island is located 140 miles (225km) west of New Orleans. The term “island” is a bit misleading, as it's not surrounded by water so much as marshland. This 2,200-acre (900-hectare) mound of solid ground was originally called Petite Anse, and part of it had been inherited by a Baton Rouge judge named Daniel Avery. When Avery eventually purchased the rest of the property for his family, it was renamed Avery Island. Avery Island is in fact a huge mound of salt, and for many years salt mining on the island provided a significant source of income for the family. The First Pepper Is Free A banker named Edmund McIlhenny had married Avery's daughter Mary in 1859 and settled on the island. At some point he met a man on the street who gave him some red peppers, claiming he had obtained them in Mexico. McIlhenny liked them, and planted some of the seeds to grow his own pepper plants. Not long thereafter, though, the Avery and McIlhenny families were forced to move to Texas when their salt operation became a strategic target during the American Civil War. Following the war, in 1866, McIlhenny returned to the island. Although much had been destroyed during the war, his pepper plants remained intact. He decided to experiment with them and see if he could come up with a hot sauce recipe he liked. The peppers were a variety of Capsicum frutescens, originally from Panama but cultivated commercially in the Mexican state of Tabasco (and thus referred to as Tabasco peppers). McIlhenny eventually came upon a simple formula: pick the peppers at their very peak of redness, then crush them immediately and add Avery Island salt. The resulting mash was left to ferment, and after sufficient time had passed, it was blended with vinegar, strained, and bottled. McIlhenny originally used cologne bottles because they were the right size and had sprinkler tops that would allow the sauce to be shaken out one drop at a time. He called his product Petite Anse Sauce, but when the family complained, he renamed it Tabasco Sauce. McIlhenny produced just 350 bottles of his sauce in 1868; today, the company he founded produces half a million bottles each day. Born in the U.S.A. The McIlhenny Company likes to maintain the illusion that its sauce is made entirely on Avery Island—and it was, until the 1970s. But nowadays, 98% of the peppers used for Tabasco sauce are actually grown in Honduras, Venezuela, Mexico, and Columbia, though the seeds for these plants all come from peppers grown on Avery Island. The reason, of course, is cheaper labor—there is no automated way to pick the peppers, because they do not all ripen at the same time. The peppers are made into mash (using Avery Island salt, the company claims) the day they're picked; the aging and the rest of the production process takes place on Avery Island. McIlhenny was careful to trademark the name Tabasco. As a result, even if your last name is Tabasco and you produce a sauce containing Tabasco peppers grown in Tabasco, Mexico, you cannot legally use the word “Tabasco” in your product's name. For many decades, Tabasco was the only pepper sauce in widespread commercial production in the U.S. ; today, there are more than 1,000 brands. Within that range, Tabasco is not especially hot. On the Scoville scale of chile hotness (a measurement of the level of capsaicin, the compound that gives peppers their bite), Tabasco sauce rates about 5,000 heat units. For comparison, Cayenne scores about 50,000; a Habañero can go as high as 350,000; and police-grade pepper spray is 5,300,000. None of this, of course, diminishes Tabasco's popularity, and even with a Scoville score three orders of magnitude smaller than pepper spray, I am reliably informed that you do not want to get it in your eyes. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/13/tabasco-sause.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/13/Tabasco.f3bc65520a92.mp3"
	},
	{
		"title": "Fasting",
		"text": "Because of my abiding interests in food, cooking, and unusual stories, I was excited to discover the books of Margaret Visser. Visser achieved literary fame for her books on the culture of eating: Much Depends on Dinner and The Rituals of Dinner. But the first book of hers I read was The Way We Are, a collection of short essays on all sorts of interesting things, from the unexpected origins of words to the stories behind everyday customs and cultural artifacts—each one backed by a solid bibliography. Hmmmm, a series of short essays on interesting things. What a concept! Although I did not deliberately try to emulate Visser’s M.O. on this site, it certainly was an implicit inspiration. One of Visser’s topics in particular caught my attention: fasting. On a few rare occasions I had fasted for a day at a time, but Visser was talking about extended fasts—those lasting more than a few days. According to Visser and other sources I consulted, an extended fast has some fascinating characteristics I had never contemplated. For one thing, hunger is supposed to disappear after the first three or four days. The body adapts to the absence of intake and more or less goes about its business without complaining. Intriguingly, the mind purportedly becomes more alert, less sleep is needed, and thinking becomes clearer. On the downside (or perhaps not, depending on your point of view), sexual energy and desire diminish. Accumulated toxins are also released, which can be healthy for the body’s organs but has a side effect of significant body odor and bad breath. All this continues for anywhere from three to six weeks, depending on a variety of factors including the size of your body and overall health. At that point, hunger returns, signaling that you must eat soon in order to survive. Ignore this sensation, and your muscles, bones, and organs will rapidly deteriorate, leading to starvation. It’s Not Food, It’s Me Let me be very clear about this: I love food. Eating is more than nourishment for me—it’s a hobby, it’s entertainment, it’s educational. I enjoy cooking, trying unusual foods, and experiencing novel tastes, smells, and textures. And I like the rituals and trappings of a good meal, especially at a fine restaurant. I have been called many things but never anorexic. I’m reasonably fit but in no danger whatsoever of wasting away. In short, I have a good relationship with food and have every desire to maintain it. But as I read Visser’s description of fasting I found the idea strangely compelling. The promised clarity of mind, without a doubt, was a strong selling point. There were also any number of personal reasons for considering a fast. For one thing, it seemed like a good spiritual discipline, a way of refocusing my attention on more important things than I usually think about. I also felt I could stand to break some bad habits, such as excessive (even for me) consumption of coffee and chocolate, and a sometimes inappropriate ratio of food intake to exercise. Besides, I figured I had enough body fat to keep me going for a few weeks, at least, and that there would be no particular harm in having a little less. But what motivated me even more was simple curiosity. I like to have experiences—even if I don’t anticipate they’ll be pleasant ones—in order to learn, add to my collection of stories, and expand my horizons. Fast Times So I tried it, and in the last few years I’ve undertaken three extended fasts so far, ranging in duration from ten days to three weeks. (I have not attempted to go the proverbial 40 days and 40 nights without food.) The experience was indeed quite interesting and not nearly as unpleasant as I thought it would be. Each time, the overall pattern was about the same. The first two days were quite difficult; the third was excruciating. I felt intensely hungry, weak, and light-headed, and had tremendous difficulty concentrating. But by the fourth day, all these symptoms began to subside rapidly. By the time a week had passed, my body and mind alike had become accustomed to not eating, and it no longer felt strange. I also found myself needing less sleep, and as expected, feeling more alert and clear-headed. I don’t want to overstate this mental clarity: it wasn’t overwhelming, but definitely noticeable. I am reliably informed that my body odor and breath were not more objectionable than usual during my fasts, but then, I also did not consider it necessary to abstain from bathing, using deodorant, and brushing my teeth. When I started my first fast, I had the idea that I would consume nothing but water. After a while, however, I began to feel this was unhealthy and unnecessary. I did not have the luxury of taking time off from work and life for several weeks of contemplation, and I needed to have at least a modest amount of energy. So I took vitamins and fiber capsules and drank a small amount of fruit juice (or sometimes vitamin water). Some people would say that’s cheating or call what I was doing a “juice fast.” I would differ with that interpretation, but then, there are many views on what constitutes a “proper” fast and that is of no particular concern to me. The Food Conspiracy I did find a few things to be unexpectedly difficult. One was exercise. I don’t exercise heavily, but even a half hour of t’ai chi was exhausting. Specifically, I felt as though my muscles just didn’t have the strength or endurance they usually do. But the big surprise was social, not physical. Even though I normally eat at home, several times a week I found myself in some social situation in which eating was expected. For example, Fridays at work were Bagel Day, and there were often business lunches, birthday celebrations, and other events where food was served. Friends would invite us to have dinner with them, but felt awkward when I wasn’t eating like everyone else. I began to notice that so many of my social habits (“Let’s go out and…whatever”) assumed the shared consumption of food. To be unable to participate was frustrating. Then, of course, when I declined food and someone asked why, I had to explain that I was fasting. This is not easy to do. Fasting is extremely uncommon these days and therefore it’s regarded with suspicion. Was I fasting because of some medical test? No. Was it some sort of religious ritual? No again. Are you sure this isn’t just a thinly veiled weight loss strategy? Yes, quite sure. How long was I going to be fasting for? No idea—I’ll decide when I get there. And so on. I was hard-pressed to give satisfying answers. Returning to Food More than anything, though, I simply missed food. It wasn’t that I felt hunger pangs or cravings, I just missed the sensation of eating, as well as the social and logistical conveniences it provided. When I began to feel that the desire to resume a normal life outweighed the benefits of continued fasting, I started eating again. To the extent that fasting helped me to break bad habits, the reform was fleeting, but I still value the brief dose of perspective it gave me. And I fully expect I will fast again—perhaps as an annual ritual, a sort of internal spring cleaning. If you are thinking about fasting, it is prudent to talk to your doctor first, as some people are medically unable to fast. This is a matter of “do as I say, not as I do.” Under the type of health insurance most Americans have, casual visits to the doctor to chat about minor health questions are strongly discouraged—inconvenient and awkward at best. Don’t expect tremendous encouragement either—but it never hurts to double-check that you’re free of conditions that would make fasting dangerous. There are many good reasons to fast. Besides exercising discipline over your own body, it gives you a chance to exercise some social discipline as well, questioning the assumptions of our food-based culture. And it is, without question, an interesting experience. When you resume your relationship with food, it will be more intentional and circumspect—and more meaningful. ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/13/Fasting.35140a78381f.mp3"
	},
	{
		"title": "Rise of the Bagel",
		"text": "I love Friday mornings. It used to be that I looked forward to Fridays simply because they were the last work day of the week. Then I began working for an employer with the wonderful tradition of providing free bagels and cream cheese for the entire company every Friday morning. They were good bagels, too. Not only was this a great incentive to get to work on time, it put me in a proper frame of mind to be productive and happy for the rest of the day. Ever since then, I’ve carried this custom with me to other places I’ve worked, and even when “work” means my home office, I make an effort to get a fresh bagel on Friday mornings. It’s just the right thing to do. A Hole in the Story There are, by actual count, umpteen bajillion Web sites that proudly recount the history of the bagel—that is to say, a lovely and plausible story that explains everything except the crucial points. The story says that bagels were invented in 1683 by an anonymous Jewish baker in Austria. King Jan Sobieski (a.k.a. King John III) of Poland had just saved Austria from a Turkish invasion, and because of his legendary equestrian skills, bread in the shape of a stirrup (or bügel in German) was seen as an appropriate way to honor him. That’s wonderful and all, but the real mystery, which no one seems to have solved, is who came up with the idea to boil bagels before baking them, which is what gives them their characteristic texture both inside and out. (Depending on who you ask, bagels should be boiled for anywhere from a few seconds to six minutes before baking; in my opinion, longer is better.) Equally mysterious is how cream cheese, and later, smoked salmon, came to be intimately associated with the bagel. In any case, bagels were popular with Jewish immigrants to the United States at least as early as the 1880s. They slowly gained popularity, until in the 1960s mass-production techniques made them available to a national audience. Unfortunately, even as bagels were becoming a household word, their very nature was changing. The sacrifices in quality and authenticity that were made in order to produce and transport vast quantities of bagels across the country meant that what people were falling in love with was a far cry from what was found in New York delis. Only in the last decade or two have we started to see large commercial chains that make at least a reasonable effort to offer high-quality fresh bagels. Joe’s Guide to Bagel Happiness Let’s not mince words: the true bagel lover must be ruthless. This is serious business, separating the wheat from the chaff, and only those who are willing to take a stand and make sacrifices for what they believe in will emerge victorious. (Did I actually just say that?) Here, then, are my guidelines for selecting a bagel you can be proud of. 1\\\\. Buy your bagels from experts. The best place to buy bagels, of course, is a Jewish bakery, preferably one that only sells bagels. Failing that, at least make sure your bagels are freshly baked, and don’t be embarrassed to ask if they were boiled first. It matters. A lot. All things being equal, I’d trust a mom-and-pop store to get my bagels right before I’d trust a chain, but there are a few exceptions. 2\\\\. Always eat your bagels on the same day they were baked. You may be able to keep a loaf of store-bought bread around for a week and still find it edible, but bagels have an extremely short shelf life. With each passing hour they get drier and harder. If your bagel is more than 12 hours old, consider using it as a doorstop or a weapon, but not as food. For best results, eat bagels while they’re still warm from the oven. 3\\\\. Test your bagel for freshness. A well-made bagel is shiny and hard (but not crispy) on the outside, very soft and chewy on the inside. Squeeze the bagel lightly but firmly between your fingertips. It should squish almost all the way through. If you meet a lot of resistance, you’ve got an old bagel. 4\\\\. Do not eat bagels that have been frozen. If your bagel was frozen, chances are it was baked considerably longer ago than 12 hours. Even if it went straight from the oven to the freezer this morning, freezing has the remarkable tendency to dry out foods. And moisture, remember, is the main thing that makes a good bagel. Sorry, Lender’s fans, but frozen bagels just don’t taste like the real thing. 5\\\\. Do not toast your bagels. I know a lot of people disagree with me here, but think about it: your bagel has already been boiled and baked. Do you really need to cook it a third time? Well, if it’s a day or two old (or if it was frozen), then of course you need to toast it, because that softens it on the inside even as it makes the outside crunchy. But it also dries it out further, and almost completely eliminates the chewy texture. Fresh bagels not only don’t need toasting, they suffer when toasted. If you’ve gotten into the toasting habit because all you ever ate were frozen bagels, see what a really fresh one tastes like without. You probably won’t want to go back. 6\\\\. Adorn your bagel lovingly with cream cheese. Or don’t. Toppings are a personal matter, and with all these other rules to remember I don’t want to burden you further. But please consider: a bagel is not merely a vehicle for transporting cream cheese into your mouth. Too much of any topping and you miss experiencing the True Bagel Essence. To Bagel or Not to Bagel The first time I ever saw a bagel, it was covered with lacquer and had a magnet on the back. I couldn’t comprehend what made it any different from a donut, and when I heard that it wasn’t sweet, I thought, “Well, what’s the point then?” A few years later I tried a toasted frozen bagel and thought it was OK, but not particularly memorable. But eventually I found out what real bagels were supposed to taste like, and after that it was very hard to accept anything less. When I was living in Texas in the early 1990s, a nearby supermarket sold something they called “bagels” that were actually dinner rolls with holes in the middle. I was mortified to think that this is what the local residents thought bagels were really like. A few years ago on a trip to New York, Morgen and I made a pilgrimage to H&H Bagels, considered by many to be the world’s finest bagel bakery. I had a fresh, warm blueberry bagel—no cream cheese, no nothing—and my mouth was happy all day. Some customers became so attached to H&H that when they moved to other cities, they called and asked the store to FedEx fresh bagels to them. This has now become a major business for H&H; for a mere US$50 you can have two dozen fresh bagels (the minimum quantity for mail order) on your doorstep tomorrow morning. Of course, even the world’s best bagels will suffer a bit on an overnight flight, but they’ll still beat supermarket bagels hands-down. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/13/bagel-120.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/13/Bagel.e307c511a346.mp3"
	},
	{
		"title": "Sugar Alcohols",
		"text": "At lunch time one day a few years ago, I walked into a cafeteria near the building where I was working. I wasn’t in the mood for a salad or sandwich that day, so I looked at the hot entrees. Behind the glass was a heated serving pan full of rice, and next to it another pan containing a mixture I couldn’t quite identify, though there were some clearly recognizable vegetables and on the whole it looked fairly appetizing. The “daily specials” sign was missing, so I asked the server what it was. She looked down at the food, thought hard for a few seconds, looked back up at me, and said matter-of-factly, “Ingredients over rice.” Another few seconds passed and it was clear that was the only answer I was going to get. I said, “Fine, I’ll have some of that.” It was delicious—though to this day I have no idea what it was supposed to be. Sometimes I feel comfortable living in a state of blissful ignorance about the ingredients in my food. Other times—especially when purchasing heavily processed, prepackaged foods—I like to know that at least some part of what I’m eating originally came from a well-known plant or animal source. More and more food products, particularly dietetic foods, list something called sugar alcohols on their labels. Whatever that is, it sounds delightfully unhealthy, so what’s it doing in foods that are supposed to support good health? Sweet and Low-Cal A sugar alcohol (also known as a polyol) is any one of a class of sweeteners including sorbitol, xylitol, isomalt, mannitol, hydrogenated starch hydrolysates (HSH), and several other compounds. Despite their artificial-sounding names, each of these sweeteners occurs naturally in various plants. Some sugar alcohols can be just as sweet as sugar—and almost indistinguishable in taste. Their main appeal is that they have a lower caloric value than more common sugars such as sucrose and fructose. They also serve as texturizers, lending foods the same kind of moistness and chewiness they’d have if sugar were used. And they actually reduce, rather than increase, the incidence of tooth decay. All this without the potentially serious side effects of non-nutritive artificial sweeteners such as aspartame and saccharin. The reason sugar alcohols are lower in calories is that the body cannot digest them as quickly or as completely as sugars. Consumed in moderation, sugar alcohols have little or no effect on blood sugar level, making them appealing to diabetics looking for a sugar substitute. But this lack of digestibility also means that sugar alcohols can have a laxative effect, in severe cases even causing diarrhea. Carb-O-Rater The term “sugar alcohol” is somewhat misleading, as polyols are neither sugars nor alcohols. Technically, they are hydrogenated carbohydrates that, at the molecular level, have some of the structural properties of alcohols. But the fact that they are a type of carbohydrate has led to much debate among those concerned about carbohydrates in their diets. Some manufacturers subtract the amount of sugar alcohols in their products from the total quantity of carbohydrates to yield a much lower “net carb” figure for their labels. They base this practice on the fact that indigestible carbohydrates, such as fiber, cannot by definition have the same effect on the body as carbohydrates that are converted to glucose. But sugar alcohols are only partially indigestible. So some people feel they should be counted as carbohydrates in their entirety, while others feel that only half the sugar alcohol in a product should count as a carbohydrate. Then there are people who don’t believe in counting carbs at all. Personally, I have nothing against either sugar or carbohydrates. Or fat or salt, for that matter. I know, call me unhip or old-fashioned, but the principle “all things in moderation” has served me pretty well. So I might make a special effort to find chewing gum that contains xylitol, but I won’t be using it in my next batch of chocolate chip cookies. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/13/splenda.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/13/Sugar.71f4b1374bee.mp3"
	},
	{
		"title": "Muffin Tops",
		"text": "It’s all about dedication. In the course of my research for Interesting Thing of the Day, I have sometimes gone to great lengths to ensure the accuracy and completeness of the articles I write. If that means drinking absinthe or eating doughnuts or trudging through Paris museums, well, these are the sacrifices a responsible journalist must make. I even enlisted my wife’s assistance to undertake a tedious and grueling muffin-baking experiment, subjecting myself to untold nutritional perils to be sure that you, gentle reader, receive the most reliable information. And indeed, I now feel qualified to hold forth on the culinary mystery of muffin tops. Do You Know the Muffin, Man? Muffin tops are, as everyone knows, truly the upper crust of muffindom. Most people prefer the top to the stump—at least when you’re talking about those jumbo-sized, coffee-shop muffins, as opposed to the kind you make from a mix in your kitchen. But this fact suggests several questions. Why is the top so much better? How does one go about making a muffin with the kind of top beloved by Seinfeld partisans? And how can one obtain a high-quality top without wasting a perfectly good but less appealing stump? These were the questions I set out to answer. In my book, the ideal muffin has a top that protrudes significantly over the sides of the cup in which it was baked, thus looking rather like a giant mushroom. This large surface area is exposed directly to the hot, dry air of the oven and therefore becomes somewhat crispy, especially around the thin edges—unlike the outside of the stump which barely forms a crust because the sides of the pan hold in most of the moisture. It’s this large crispy surface that gives muffin tops most of their appeal. But most muffin recipes result in more modest, rounded-top muffins. The key, it turns out, is not to take the recipe seriously when it says to fill up the pan only halfway with batter. If you want a mega-top muffin, you have to fill the pan all the way—in fact, with a significant bulge on top. This means, of course, half as many muffins as the recipe calls for, as well as a longer baking time. A further refinement: sprinkle sugar generously on the surface of the batter before baking. This will result in a shiny glaze and a crisper, sweeter crust. Divide and Conquer But what you really want is a great muffin top without the bottom. Simply cutting off the bottom, while effective, is wasteful. The best solution so far has been muffin pans that are extremely shallow—only about 1/2 inch (1.25cm) deep. When loaded to overflowing with batter, these provide enough of a base for the top to rise reasonably well, while minimizing the stump. Muffin-top pans are, not surprisingly, quite popular, but they are still an imperfect solution because they don’t enable the top to get quite as large as a full-size pan does, and they still leave a partial stump. The alternative, which has met with mixed success, is to find a way to recycle the stumps. Obviously they don’t qualify as food, but technology now has a way to make oil from organic waste products. That seems to be our best hope for a muffin-stump-free future. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/13/Muffin.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/13/Muffin.7bc3653fbdfa.mp3"
	},
	{
		"title": "Crème Brûlée",
		"text": "The restaurants of America—especially those of the fast-food variety—have come under attack for, among other things, making portion sizes much too large. This, nutritionists say, is one of the main causes of obesity. But I think the biggest problem with large portions is that they make it that much harder for patrons to leave room for dessert. I believe deeply in dessert, and few things cause me as much grief as arriving at the end of a meal only to discover I’m so full that I couldn’t possibly consider even one wafer-thin mint. A sad state of affairs indeed. Being the sort of snob I am when it comes to French food, I have a special fondness for dishes—especially desserts—that are decadent, inventive, and spelled with an excessive number of accent marks. I can’t think of any dessert that fits that description better than crème brûlée. All things being equal, I usually prefer desserts that have a high chocolate content, but I do make occasional exceptions. What crème brûlée lacks in chocolate it makes up for in fat, calories, and general impressiveness. Don’t Cry Over Burnt Cream Crème brûlée (literally “burnt cream”) begins its short life as a custard—a sweetened mixture of cream and egg yolks that’s heated until it thickens. It’s then usually poured into shallow, single-serving ceramic dishes called ramekins and chilled until it becomes firm. But unlike similar custard dishes such as flan and crème caramel, crème brûlée undergoes an extra finishing step. The top surface is sprinkled with sugar and then subjected to intense heat for a few seconds to caramelize it, thus forming a thin, crispy crust. Although it is possible to use a broiler as the source of heat, the results tend to be uneven, and the inside of the crème brûlée often warms up, which is not the desired effect. So professional chefs typically use a blowtorch to melt the sugar, creating a nicely browned surface. Another approach requires a tool called a salamander that consists of a heavy metal disk attached to a long handle. After heating the disk over a burner, you place it on (or just above) the sugar to caramelize it. What makes a crème brûlée’s crust special, though, is not just its appearance but its sound. When I hear the distinctive “snap” of a spoon breaking through the crust of a well-made crème brûlée to reveal the creamy goodness underneath, I always smile and sigh as though I’ve witnessed something magical. If Bernard Pivot (or James Lipton) asked me what sound or noise I love, that would be the first thing I’d think of. It’s just one of those things. Pass the Torch If you happen to have a conventional propane torch lying around your workshop, that will do just fine for crème brûlée, as long as you’re careful to use properly heat- and flame-resistant dishes. But most crème brûlée enthusiasts prefer a more compact (and less scary-looking) butane kitchen torch, which can be found at respectable cooking stores for about US$40. That may seem like a costly tool for just a single recipe, but it can be used to add a finishing touch to many kinds of desserts, not to mention searing tuna steaks and defrosting your freezer. And it’s a small price to pay to impress your friends. As for my chocolate obsession, there’s nothing to say I can’t have my crème and eat it too: people can and do sometimes make chocolate crème brûlée. I’ve also had some excellent lavender crème brûlée, and I’ve seen recipes for many other flavors—including pumpkin and ginger. But although I don’t consider myself a purist, I must admit that the simple and elegant combination of eggs, cream, sugar, and vanilla works best for me. Now if you’ll excuse me, I’ve got to go burn my dessert. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/13/creme-brule.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/13/Creme.922cfb4e5206.mp3"
	},
	{
		"title": "A Perfect Baguette",
		"text": "Last spring my wife, Morgen, and I had the great privilege of spending a month in Europe. Our goal for that trip, unlike ordinary vacations, was not primarily to see lots of museums and tourist attractions; instead, we wanted to live like locals and see what ordinary daily life would be like in another part of the world. We rented an apartment in Paris so we could shop for fresh foods and cook our own meals rather than eating out all the time. What I was looking forward to most eagerly about this arrangement was the ready availability of fresh baguettes every day, direct from the bakery. Your Daily Bread In France, going to your local bakery to buy fresh bread every morning is as normal as putting your socks on before your shoes. How else would it be done? And yet this simple ritual is utterly foreign to most North Americans. Here, we expect our bread to be rectangular, pre-sliced, and treated with preservatives so that it will stay “fresh” (i.e., mold-free) for two weeks. We perceive this as a benefit, a convenience. After all, bread is not usually eaten by itself; the point of bread is to provide a vehicle for butter and jelly or to keep your ham and cheese off your fingers. It’s only proper that it be as bland and easy to use as the individually wrapped slices of the stuff we generously refer to as “cheese.” Not so in France, where people take bread very seriously, with high expectations of quality. Baguettes, the quintessential French bread, are by their very nature best when fresh out of the oven—or at least consumed within a few hours of baking. Within 24 hours, most baguettes are too hard and dry to eat. But this isn’t a problem that calls for a technological solution (or a loosening of standards); it’s just The Way Things Are. And it’s worth it, because a fresh French baguette is a truly glorious food. I have eaten many baguettes in my day, from countless bakeries and supermarkets. Amazingly enough, for such a simple food, very few bakers get it right. By “right,” I’m referring to the crucial combination of inside and outside texture. Contrary to what your local grocer may want you to believe, it is not sufficient that bread be long and skinny to qualify as a baguette. The inside of a baguette should be moist yet airy (with plenty of holes) and moderately chewy. But the crust is the most important part. It has to be, well, crusty. That is to say, firm enough that when you break the baguette in half, it makes noise, yet soft enough that it doesn’t break apart completely—you’re not looking for a giant breadstick. The crust of a fresh, properly made baguette is soft enough to chew easily without making a lot of crumbs, and hard enough that if you hold the bread horizontally by one end it won’t flop over. The Stuff of Legend It was with these exacting criteria that I searched the bakeries of Paris for baguettes. I found some real winners and also, sadly, a few serious losers. But my most memorable baguette experience was at a bakery called La Flûte Gana. The word flûte is another term for baguette, and Gana comes from Ganachaud, the family name of the owners. Isabelle and Valerie Ganachaud took over the business from their father Bernard, a legend by the time he retired in the late 1980s. We had heard about this bakery from an article written by Naomi Barry, a contributor to Gourmet magazine. She said they made the best bread in all of France, so we had to check it out. There was a long line, even in the middle of the day: always a good sign. We waited patiently, deciding we’d have to succumb to a pain au chocolat in addition to the baguette. We bought two of the eponymous Flûtes Gana, thinking we’d eat one while we walked and save the other for supper. Standing on the corner across from the bakery, we broke into the first baguette, which made the mandatory “crunch” sound. We started eating, a process that was accompanied by a great deal of moaning and sighing. It was such a perfectly delicious bread that to have added butter or cheese would have been an insult. Within minutes it was gone, so we immediately returned to buy another. The staff did not seem surprised to see us again; I’m guessing this sort of thing happens pretty often. That was a truly magical day. I was reminded of that experience recently when I saw, to my horror, a popular national brand of bread on the shelf packaged with the crust removed, presumably so your kids will eat it. What a sad thing: if bread is made properly and eaten promptly, the crust is the best part. I can’t even imagine a baguette without a crust. That would be like, I don’t know…maybe an M&M without the candy coating. Sort of missing the point. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/13/Baguette-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/13/Baguette.6b5bf3a3b700.mp3"
	},
	{
		"title": "Pastis. The noble successor to absinthe",
		"text": "It’s all Peter Mayle’s fault. Before I fell under his nefarious influence, I had very simple tastes. Food was food; a burger and fries eaten on the run was a perfectly satisfactory dining experience. But then I read A Year in Provence and its sequels, books that tell colorful tales about ordinary life in the southern French countryside. To hear Mayle describe life in Provence, every waking hour is concerned with acquiring, preparing, or eating food. His descriptions of wonderfully rich food and drink, enjoyed course after course in meals that stretch for hours, are sensual to the point of being called erotic. You can just taste the foie gras, the truffles, the escargots as you read. For impressionable minds like mine, there was only one possible outcome. I became a French food snob. And along my path to culinary enlightenment, I felt it necessary to sample—indeed, become somewhat expert on—a variety of French beverages. One drink that receives quite prominent treatment in Mayle’s books is pastis, which is as good a place to start as any. Pastis is a distilled spirit made from a blend of herbs. The flavor is predominantly that of anise, thus putting it in the same general class as sambuca and ouzo. It is commonly consumed as an aperitif—sort of a liquid, alcoholic appetizer—and in France, where it’s most popular, the custom is to dilute it at the table with about five parts of cold water. The ritual of adding the water, which causes the translucent yellowish liquid to turn cloudy, is part of the fun of drinking pastis. But the most interesting thing about pastis is its history. That it should exist at all is a bit of an accident. The Fate of the Muse Throughout the 1800s, the aperitif of choice in France (and in many other places) was absinthe. This potent drink was also distilled from herbs and had a strong anise flavor. Many artists and writers swore that absinthe enhanced their creativity, calling it “the green muse.” This unusual effect of absinthe was thought to come from its key ingredient, an herb called wormwood. However, absinthe was also thought to cause hallucinations, violence, blindness, and even insanity. Although no solid scientific proof of wormwood’s toxicity was produced, absinthe became an easy scapegoat for a large number of social ills. By the early 20th century, public opinion had turned against absinthe and it was banned in France and most other western countries. While this satisfied the prohibitionist urges of a vocal minority, there were two groups of people who were quite displeased with the ban: the millions of absinthe drinkers who suffered no apparent harm, and the distillers, such as Jules Pernod, whose plant produced thousands of bottles a day. Necessity, it is said, is the mother of invention. The combination of public demand for a legal but absinthe-like drink and the distilleries' desire to stay in business inevitably led to a substitute: pastis. It is made in the same manner—and from many of the same ingredients—as absinthe. However, the alcohol level is much lower and it does not include wormwood. Under such brand names as Pernod and Ricard, pastis rapidly rose to popularity in France, and within a few decades, absinthe was all but forgotten. Our Secret Recipe: Eleven Herbs and Spices Today, there are hundreds of brands of pastis, each with a unique formula. Among the most common ingredients are licorice, star anise, cardamom, fennel, and coriander—though some formulas contain dozens of different herbs. Colors range from clear to gold to green, and as with wines (or even colas), the subtleties in flavor provoke fierce loyalties. Having sampled perhaps a dozen varieties myself, I would venture to say that the similarities are greater than the differences, but tasting pastis is a sort of self-defeating exercise. After a few glasses it becomes difficult to distinguish one flavor from another—or, for that matter, up from down. Curiously, even though I don’t care for the flavor of licorice in food or candy, I find essentially the same flavor unobjectionable in pastis. I have several brands of pastis in my bar at home, but I much prefer the experience of enjoying it at a restaurant, before a good French meal. Although in France pastis is the most common spirit by far, it has not achieved a great deal of popularity in the United States. Almost every well-stocked bar and restaurant has at least one brand of pastis, but customers seldom order it. A while back, Morgen and I had dinner at Masa’s, an upscale San Francisco restaurant whose head chef, Ron Siegel, was the first American to beat an Iron Chef. We arrived a bit early and decided to order pastis at the bar while waiting for our table. The bartender knew what we meant and also confirmed that we wanted it served in the traditional French manner—not on the rocks, as is more typically American. He said it had been a long time since anyone had ordered pastis, and he seemed a bit surprised that we would know about it. I, on the other hand, knew we were in good hands at the restaurant if the kitchen staff knew their stuff as well as the bartender knew his (and they did). We Call it “Pop” in this Part of the Country Unfortunately, this restaurant is the exception rather than the rule. In my experience, a majority of bartenders and waiters in the United States have little or no familiarity with pastis, even in fancy French restaurants…even in very old and famously absinthe-centric locales…and even if they stock it in their bar. On our honeymoon in New Orleans, Morgen and I visited Antoine’s, the oldest French restaurant in New Orleans—in fact, the oldest restaurant under single-family ownership in the entire United States. Antoine’s is legendary for its excellent menu and outstanding service, and having already visited a couple of Emeril Lagasse’s restaurants, we were ready to be impressed. The menus were in French—always a good sign. As we sat down, our waiter asked if we’d like aperitifs, and I said, “Yes, please, two pastis with water.” The waiter gave me a strange look, so I repeated: “Pastis.” Still apparently confused, he nodded and disappeared into the kitchen. A few minutes later he returned, somewhat befuddled, with two glasses of cassis (a fruity liqueur made from black currants) and a carafe of water. His puzzlement was apparently due to the fact that it is quite strange to order cassis with water. I said, “No, sorry, I ordered pastis, not cassis.” He frowned and said, “Oh, I’m sorry. We don’t have pastis.” I was thinking: a legendary French restaurant doesn’t have pastis? Very unlikely. I took a deep breath, and restraining myself from lecturing him, tried my backup plan. “OK, then just bring us some Pernod.” The waiter brightened immediately. “Very good, sir.” I could only shake my head and sigh. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/13/Pastis120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/13/Pastis.dcab7f096e64.mp3"
	},
	{
		"title": "Peanut Milk",
		"text": "Every child who grows up in the United States hears the story of George Washington Carver, a former slave who became a botanist and agriculturalist. Carver is best known for devising over 300 uses for peanuts—from ink to glue to soap, not to mention a great many recipes for peanut-based foods. Although I’ve often wondered why I don’t see peanut paint or peanut insecticide at my local hardware store, I have the utmost respect for Carver’s discoveries and for the versatility of this humble legume. Peanuts have got to be one of my top ten favorite foods. I love peanuts in or on chocolate, ice cream, Pad Thai, satays, soups, sauces, and just about everywhere else. They’re especially good on airplanes (which otherwise tend to have a rather metallic taste). So when I heard about a peanut-based beverage that also reputedly had fantastic health benefits, I couldn’t wait to try it. The product in question is the suspiciously named Signs and Wonders brand peanut milk, developed right here in San Francisco. Although you can buy it from a number of small stores, the best place to get it is the KK Cafe near the corner of Haight and Divisadero Streets, where it was invented. It’s the Great Peanut, Charlie Brown The story goes like this. Jack Chang, who along with his wife Margaret owns a tiny burger joint/coffee shop called the KK Cafe, loved peanuts. But due to chronic gum disease he was unable to chew them, so he set about making a drink that would enable him to enjoy his peanuts in convenient liquid form. It took him months to get the recipe just right, but being a frugal person he felt obliged to drink all the failed batches. As he consumed increasing amounts of this concoction, he noticed that he felt more energetic, his allergies cleared up, and his gums returned to health. He even stopped losing his hair. There could be no other explanation than his peanut drink—well, that and God, but I’m getting ahead of myself—so the couple began recommending the stuff to all of their customers suffering from various kinds of ailments. Sure enough, this person’s arthritis went away, that person’s skin rash healed, and soon testimonials were pouring in and word began to spread that the Changs had invented a cure-all in the form of a tasty peanut drink. What Chang calls “peanut milk” is a nondairy product made primarily from ground peanuts and water, with some sugar, other grains, and a few herbs and spices. Interestingly, it tastes almost exactly like a mixture of ground peanuts, water, and sugar—which is to say, in my humble opinion, kind of gross. It was all I could do to get through a single 8-oz. (240ml) bottle—and remember, I’m speaking as a peanut lover here. Other people clearly differ in their opinion of the flavor, consuming, in some cases, several quarts per day. Or perhaps they’re too enthusiastic about its supposed health benefits to concern themselves with taste. In all fairness, it does certainly taste much better than, for example, a mixture of cough syrup, castor oil, and spirulina, to pick three ingredients completely at random. Suspending Disbelief The Changs are careful not to make specific health claims for their product in its labeling or advertising; all the same, they do point to the huge number of letters they’ve received as anecdotal evidence of peanut milk’s ability to confer on the drinker an astonishing range of health benefits. To be sure, the individual ingredients are nutritious. Peanut milk contains vitamins, minerals, and protein, and is relatively low in calories, so it’s reasonable to believe that it could provide energy and support one’s immune system, in addition to being a healthier drink than soda (or, for that matter, most other beverages). But the stories of its ability to cure everything from asthma to cancer are as hard for me to swallow as a suspension of ground peanuts. For Jack and Margaret Chang, the explanation of peanut milk’s seemingly magical powers is simple: their formula is a God-given miracle—hence the name “Signs and Wonders.” Personally, I’d feel a bit uncomfortable attributing a recipe to God, especially a recipe whose taste strikes me as, shall we say, less than heavenly—and which, we are adequately warned, could be deadly to those with certain allergies. I wouldn’t go so far as to chalk up all the alleged benefits of peanut milk to the placebo effect, but I would expect that if it really does have curative properties, similar benefits could be achieved by consuming the ingredients in more conventional forms. Milking Publicity Even though peanut milk didn’t impress me, increasing numbers of customers swear by it. With barely any advertising other than word-of-mouth and a few news stories, peanut milk has grown in popularity beyond the point where Jack and Margaret can produce enough on their own to meet the demand. So they’ve outsourced production to a factory across the bay in Hayward, California. A few years ago you could purchase peanut milk only at the KK Cafe, but it’s now available in dozens of stores in the San Francisco Bay area, with a deal for national distribution reportedly in the works. Surprisingly enough, not one of George Washington Carver’s peanut products was “magic peanut elixir.” But then, Carver did achieve considerable success, fame, and influence, and peanuts helped to propel at least one person to the presidency of the United States. You know, now that I think of it, maybe with a bit of chocolate that peanut milk wouldn’t be so bad after all. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/Peanuts-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Peanut.9bfa83ac179f.mp3"
	},
	{
		"title": "The Grolla",
		"text": "Every once in a while I spontaneously decide to adopt a new interest. I’m not the kind of guy who dabbles; if I’m going to do something, I do it right. So, for example, when I decided that I liked The B-52’s, I could not rest until I had acquired every single one of their recordings, heard every song, and fully understood the history of the band. You can imagine, then, the sort of trouble I was in for when I realized a few years ago that I didn’t have a clue when it came to alcoholic beverages. I vaguely understood that one was supposed to use a different type of glass for white wine than for red wine, but when it came to spirits, liqueurs, and mixed drinks, I was lost. I had no idea what anything tasted like, how it was made, or what to order on a given occasion. Clearly, this problem needed to be solved, so I set about reading books, stocking up a home bar, and taking impromptu lessons from a friend who had worked as a bartender. Slowly but surely, things began to make sense—at least, once the room stopped spinning. My more sophisticated friends were eager to help me in my quest, pointing out potions that were missing from my collection, explaining which type of glassware was optimum for each drink, and making sure I sampled some of the more unusual alcohols. One day my Italian friend Paola said, “I’ve got a liqueur I’ll bet you’ve never tried. Here, taste this.” It was something called Cynar, distilled from—of all things—artichokes. It was different…not my favorite, but not terrible. Then she asked if I was familiar with grappa. When I said yes, she replied, “Then you might find this interesting,” and produced a very oddly shaped, covered wooden bowl with several spouts around the outside. “It’s called a grolla,” she said. “They’re made in the part of Italy where I grew up. You pour in a mixture of coffee and grappa, pass it around, and everyone drinks from a different spout. It’s a sort of friendship ritual.” It conjured up an image of communion, but with coffee—an odd juxtaposition that somehow really worked for me. Holy Grolla As I began reading about the grolla, I discovered that communion was a very apt association. The word “grolla” is related etymologically to “grail,” and is believed to have been inspired by the Holy Grail itself (at least, by people who still believe the Grail was really a grail). Indeed, sometimes wine is used in a grolla, and its early origins were religious in nature. It was only more recently that the grolla ritual became secularized (and caffeinated). Grolle (the plural) originated in the Valle d’Aosta, a small region in the Alps of northwest Italy bordered by both France and Switzerland. The mountains—particularly the Matterhorn—are the main attractions in the area, whether for skiing, hiking, or just a scenic background. The grolla is considered an icon of the region, and a number of local craftspersons earn their living making them. Usually grolle are carved from a single block of wood, though some are made from pottery. Strictly speaking, a grolla is simply a covered wooden wine goblet, usually with four spouts, whereas a “friendship cup”—a similar but shorter design with five to eight spouts—is typically used for the grappa-and-coffee mixture. But in everyday speech the term grolla is often used generically for both designs, and of course there’s no reason either can’t be used with the beverage of your choice. Recycling Grapes If you’re wondering what grappa is, the easiest answer is that it’s the Italian name for the spirit called marc in French or Tresterbranntwein in German. In case you’re not up on your digestifs, allow me to elaborate. If you were to take ordinary wine and distill it, you’d get brandy, a strong, sweet, after-dinner drink. Grappa is a close relative of brandy, except that it’s distilled not from wine, but from the bits of the grapes that are left over after pressing: the skins, seeds, and stems (known collectively as pomace). The distilled liquid is then aged in oak barrels for several months before being bottled. Grappa is clear, high in alcohol (up to 50%), and less sweet than brandy. It’s normally served chilled—in small, tulip-shaped stemmed glasses—at the end of a meal. Another way of enjoying grappa is to mix it with coffee, and this is where the grolla comes in. All recipes agree on espresso and grappa (in varying proportions) as the two key ingredients; some people add another Italian liqueur called Génépy (or, say, Grand Marnier), sugar, and other spices as well. The mixture is heated well before being poured into the grolla, then set on fire. (This flaming coffee-grappa mixture, by the way, is known as Caffè alla Valdostana.) After a minute or two (during which the sugar, if any, will melt), the cover is placed on the grolla to extinguish the flame. Someone will then take a drink from one of the spouts and pass it to another person, who drinks from the next spout. The process continues in a circle until the grolla is empty, by which time, if enough grappa was used, all participants will be feeling an especially close bond of friendship, or a reasonable facsimile thereof. There’s an old Italian saying, Chi beve solo si strozza: “One who drinks alone will choke.” So I like to think of the grolla as a simple health maintenance product. (I also like to think of the caffeine as balancing the effect of the alcohol, which just goes to show you how finely honed my skills of rationalization are.) It may not be the Holy Grail, but it certainly is a pleasant way to enjoy both a strong, hot drink and the communion of friends. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/grolla.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Grolla.f8c25b41d8a3.mp3"
	},
	{
		"title": "Absinthe",
		"text": "Picture yourself at the end of the nineteenth century in France. The Bohemian movement is in full swing. Revolutions in art and literature are brewing, technology is advancing rapidly, and more and more people are putting their creative efforts into the expansion of culture. You walk into a Paris café and see someone sitting at a corner table, scribbling or sketching madly, eyes fiery with enthusiasm. More than likely you see on the same table a glass containing a cloudy liquid—absinthe, the legendary “green muse” to which many artists of the day attribute their creative insights. Absinthe is among the most popular drinks around this time—not only in France but across Europe and even in the United States. But it is more than just a tasty alcoholic beverage: it's a ritual. To prepare your absinthe in the traditional way, you begin by pouring about an ounce of the greenish liquid into a glass. On top of the glass you place a flat, slotted spoon on which a single sugar cube rests. You pour cold water over the sugar cube—slowly enough that it dissolves by the time your glass is full. As the water mixes with the clear liquid it turns cloudy—an effect called louching, caused by the oils in the absinthe. Finally, you stir the liquid with the spoon, then drink. (A more theatrical variation on this ritual, performed by Johnny Depp's character in the 2001 film “From Hell,” is to soak the sugar with absinthe first, then set it on fire, allowing the heat to melt the sugar before you mix in the water. ) Absinthesis What you are drinking is a spirit made by distilling herbs. But that could describe many drinks; what makes absinthe special is the presence of a particular herb—Artemisia absinthium, commonly known as wormwood. This concoction was invented in 1792 by a French doctor named Pierre Ordinaire. While living in Switzerland, Ordinaire was trying to create a patent medicine to cure stomach ailments. He tried wormwood in one of his recipes—along with anise and a variety of other herbs—and found it very successful. Eventually the formula became commercialized, and absinthe began to shift from an over-the-counter remedy to a refreshing drink, acquiring the nickname “the Green Fairy.” Absinthe has a high alcohol content—nearly 70%—and a slightly bitter flavor. Adding water and sugar before drinking it worked wonders in improving its mass appeal. Unlike other alcoholic beverages, which have a sedative effect, absinthe was reputed to provide exceptional clarity of thought. Artists relied on it for inspiration and imagery. Among those who swore by absinthe were Van Gogh, Degas, Toulouse-Lautrec, Picasso, Hemingway, and Edgar Allen Poe. Oscar Wilde was a fan too, and was famously quoted as saying: “After the first glass, you see things as you wish they were. After the second, you see things as they are not. Finally you see things as they really are, and that is the most horrible thing in the world.” Behind this wry commentary, though, was a troubling implication. An increasing number of people became convinced that absinthe was not a benign stimulant but a dangerous drug. Among those who drank absinthe excessively, there were numerous reports of hallucinations, convulsions, and even insanity. In 1905, public anxiety came to a head when a Swiss farmer named Jean Lanfray shot his whole family. The newspapers were quick to point out that Lanfray had been drinking absinthe, not bothering to mention that he had also consumed a great deal of wine and other spirits that day. This was the final straw for those who vilified absinthe, and political pressure to rid society of this evil quickly mounted. In the years that followed, absinthe was banned in most parts of Europe, as well as in the United States. The deleterious effects of absinthe were typically attributed to a substance called thujone, a component of wormwood. Nowadays, scientists believe there's little or no truth to the notion that it is a dangerous drug. Every modern study of thujone suggests that the amount required to harm human beings is many times that found in even the strongest brands of absinthe from a century ago. In fact, to ingest enough thujone to do any damage, you'd have to drink so much absinthe that you'd have died—or nearly so—from alcohol poisoning. Thus one common explanation for the disturbing behavior witnessed in absinthe drinkers is that they were simply drunk—a problem, for sure, but not one unique to absinthe. However, a more interesting explanation is based on evidence that unscrupulous absinthe producers in the nineteenth century, in an effort to lower their costs, added a variety of toxic chemicals to their absinthe—such as a copper compound used to provide a green color. The effect of these toxins—added to that of the alcohol itself—is a much more plausible cause of the legendary absinthe madness. In many parts of the world, absinthe is enjoying a comeback. The European Union now permits its manufacture and sale—as long as thujone levels are kept quite low. Many brands and formulations are available, with some trying to get as close as possible to the original taste, and others going in more trendy directions. (You can even find red, blue, and clear absinthe. ) Nevertheless, old habits die hard, and it's still illegal to import or sell any alcoholic beverage containing wormwood in the United States. On the U.S. Customs Service's list of items that tourists traveling abroad must not even think about importing, absinthe is prominently mentioned—right up there with Cuban cigars. The prohibition comes from an ancient Food and Drug Administration rule, which in turn was based on anecdotal evidence, questionable scientific studies from the mid-1800s, and long-forgotten political pressure. And yet it's a rule that will probably persist for a long time, due to sheer inertia. Absinthe Makes the Heart Grow Fonder Canada, meanwhile, never bothered to restrict the sale of absinthe because it was never perceived to be a social or political problem there. While I was living in Canada, I was able to spend some quality time with the Green Fairy. I can attest to a subtle, but noticeable, increase in the clarity and vividness of my thoughts shortly after drinking absinthe—a much different effect than I'd expect from alcohol alone. Then again, I couldn't say with complete certainty that the effect was not imagined, and there was an additional complication: the uncertain authenticity of the formula. The only brand of absinthe commercially available in Canada at that time was Hill's Absinth, made in the Czech Republic. Absinthe experts roundly dismiss Hill's as undrinkable—a pale imitation of real absinthe. Personally, I quite liked it—but then, I had no experience with other varieties to serve as a frame of reference. (I also found it mildly ironic that detractors should use the word “undrinkable” because that is exactly the definition of the Greek word from which the name absinthe is derived.) On my next trip to Europe, however, I'll make a point of sampling as many varieties as I can—in the name of research, of course. If my writing suddenly becomes much more poetic or prolific, you'll know why. If you want to find absinthe that more closely approximates what was available a century ago—minus the harmful toxins—reputable distillers in Spain, France, Germany, Portugal, and the Czech Republic produce a wide variety of brands. If you live in the parts of Europe (or elsewhere in the world) where absinthe is legal, numerous online retailers will be happy to ship you any of dozens of varieties of absinthe. Better yet, have it in a bar with the full ritual of water and sugar—and bring along a notebook in case the creative urge strikes. In the United States, your only legal option is a wormwood-free substitute. Pastis is a liqueur sharing many of the same ingredients as absinthe, most prominently anise. Brands of pastis such as Pernod and Ricard are common throughout the U.S. In addition, numerous companies now produce pastis with names suggestive of absinthe—brands like Absente, Versinthe, and La Muse Verte. I've tried all of these and many others, and some of them are quite good on their own terms. However, it's just not the same thing—comparing absinthe to, say, Absente is like comparing chocolate to carob. You can tell that they're in the same family and can be used in much the same way. But they just don't taste the same, or pack the same psychological effect. Until the law catches up with science, Americans will need to travel abroad to visit the Green Fairy. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/Absinthe-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Absinthe.ade3e8e5393f.mp3"
	},
	{
		"title": "Milk in a Box",
		"text": "I’ve managed to suppress most of the memories of my college days—quite wisely, I think—but every once in a while some random factoid springs to mind. For example, I remember very clearly the wonder I felt one evening in the mid-1980s when I walked into a New Jersey supermarket and saw a box of milk on the shelf. At first I didn’t comprehend what I was looking at. I had to study the package at some length before I grasped that this was not powdered milk or some milk-like non-dairy product. Sitting there quite happily at room temperature was a container of milk that, so the label claimed, would remain fresh without refrigeration for months. I couldn’t figure out how they’d managed to pull this off, but I was very excited. Just think of the convenience of not having to buy milk every few days, not to mention saving space in your refrigerator! I bought a box and tried it. OK, the flavor was a bit less than fantastic, but still…pour it on some cereal or in your coffee and you’d never know the difference. This revolutionary development seemed so obviously useful to me that I was certain all milk would be sold this way within a couple of years. Time passed. The boxes of milk, instead of multiplying on store shelves as I’d expected, disappeared almost entirely. I found this completely baffling. Why hadn’t this sort of milk caught on? I was even more surprised when I went to Europe and discovered that in many places, it’s much harder to find refrigerated milk than boxes or bottles of milk stored at room temperature. So clearly the technology to package milk this way was still in use…but did those Europeans know something that we didn’t? Or was it the other way around? I started wondering about this again recently and decided to investigate. Out to Pasteur In order for milk to stay fresh at room temperature, two things are required. First, it has to be completely free of any bacteria or other microorganisms; bacteria, after all, are what cause milk to spoil. Second, the milk must be packaged in such a way that it can’t be contaminated after the fact. The packaging must also keep out light, which can cause the breakdown of nutrients such as Vitamins A and D. To rid the milk of bacteria, dairies employ a process known as Ultra High Temperature pasteurization, or UHT for short. The specially treated milk is then stored in aseptic packaging, which preserves the sterility of its contents for long periods of time. Together, UHT processing and aseptic packaging give you milk with a shelf life of six to nine months, as long as the package is unopened. Pasteurization is simply a matter of heating something hot enough and long enough to kill pathogens—disease-causing germs. To pasteurize milk, you can heat it to about 140°F (60°C) for a half hour, or for faster results, increase the temperature to 163°F (73°C) and reduce the time to about 15 seconds. This makes milk safe for human consumption, and in the process, dramatically reduces the number of bacteria that cause spoilage—enabling the milk to remain drinkable for a week or so, as long as it’s refrigerated. Pasteurization has little or no effect on either the flavor of milk or its nutritional content. It does, however, leave some viable microorganisms, which multiply over time—especially after the milk is exposed to air. UHT pasteurization, on the other hand, destroys virtually all bacteria and spores. To do this, it heats the milk to a much higher temperature—around 275°F (135°C)—for about two seconds, then rapidly cools it back to room temperature. Because the exposure to heat is so brief, the milk is not damaged and remains nutritionally intact. However, UHT processing can have a noticeable effect on the taste. (I was tempted to say something about the added flavor coming from the corpses of millions of microbes, but that would have been…in poor taste. ) Meanwhile, the packaging itself must also be sterilized, and it must be filled with milk and sealed in a sterile environment. The most common form of aseptic packaging is a box made from layers of polyethylene, aluminum foil, and cardboard. The plastic keeps the package airtight, the foil keeps out light, and the cardboard provides structural integrity. This type of package is sometimes called a “drink box,” and is commonly used for fruit juices. But the boxes can be made in nearly any size or shape. More recently, specially designed opaque, aseptic plastic bottles have also come into use, though boxes use space more efficiently and are therefore easier to store and transport. Got Box? UHT pasteurization and aseptic packaging are becoming more and more common not only for fruit juices but for soups and broths, sport drinks, soy beverages, pasta sauces, coffee drinks, and other liquids. But if this technology is so wonderful, why do we so seldom see it used for milk in North America? According to one theory, it’s all about the taste: if the milk in a box doesn’t taste exactly like milk in a bottle, consumers won’t buy it. True enough, the taste is slightly different. But in defense of UHT milk, its flavor has improved quite a bit over the last two decades. As long as it’s refrigerated before it’s served, many people will be unable to distinguish it from conventional milk. Moreover (according to some tasters, at least), lower-fat varieties of UHT milk taste better than whole UHT milk—and North Americans certainly buy more lowfat milk today than they did when UHT milk first appeared. Furthermore, let’s be realistic: in the United States, at least, consumers overwhelmingly choose convenience over flavor—just look at the popularity of American cheese, instant soup, and frozen vegetables, to say nothing of the entire fast-food industry. In short, I don’t think taste is the real problem. Perhaps the issue is cost. UHT milk does cost more than refrigerated milk. This is due in part to the high cost of the equipment needed to package it, and in part to lower demand. Needless to say, if consumers adopted a preference for UHT milk, the price would eventually come down. After all, producers and supermarkets would save money in the long run on energy bills and transportation, as well as reducing waste due to spoilage. But even though higher costs may be part of the problem, I think the real issue is one of habit. Because we’re so deeply conditioned to believe that fresh milk is something that can only be sold in cold bottles, we regard anything else as suspicious. “What could this mean? Does it contain scary hormones? Was it treated with radiation? Will I spontaneously change my political affiliation if I drink it?” These are the sorts of worries that can only be alleviated by proper education, by which of course I mean good advertising. Hey, wait a minute—did I just say we need more advertising? I never would have said that back in college. Maybe there is something in this milk. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/milk-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Milk_Box.1e5d50e1b8a0.mp3"
	},
	{
		"title": "The Cheese Course",
		"text": "I recently stumbled upon the rather disturbing statistic that more than half the cheese consumed in the United States is American cheese. Yes, I know, this is tautologically true in that anything made in America is, ipso facto, American—but I'm talking about the particular dairy product that goes by the name “American cheese.” For readers outside North America, let me explain what this is. By law, American cheese must be labeled as a “pasteurized process cheese product” or words to that effect. To make it, manufacturers start with some innocent mild cheddar cheese, shred it up, heat it, mix it with water and emulsifiers, add some food coloring, and form it into a block— or, more often, individually plastic-wrapped slices. The net result is a shiny, rubbery substance that looks, from a distance, somewhat like cheese. When it's melted it even tastes approximately like melted cheese. In fact this is the major selling point for American cheese: it melts very smoothly without separating, making it easier to cook with than cheddar or most other varieties of cheese. Why do I find it disturbing that Americans eat so much American cheese? It's because American cheese was responsible for turning me off to cheese all through my childhood. When I was a youngster, if you had asked me whether I liked cheese, I would have given an unambiguous “no”—I had tried it once or twice and was quite certain it belonged in the “yucky” list right along with leafy green vegetables. And yet, as my parents were quick to point out, my favorite dish was macaroni and cheese. This seeming contradiction was due to the fact that the only cheese I'd ever tried in its unmelted form was American (or its close cousin Velveeta). The texture, flavor, and aroma of American cheese—though all rather bland—struck me as utterly gross, and if that's what cheese was, I wanted no part of it unless it was sufficiently doctored to hide its true nature. Only much later did I discover that what I'd been calling cheese all my life would have been barely recognizable as such in most of the world. Course of Study By the time I was in college, I had begun to reconcile with cheese, going so far as to put cubed mozzarella or cheddar on my salads, or munching cheese-topped crackers at parties. Then I began reading stories about life in France and encountered the curious notion of a cheese course—a commonplace part of a meal consisting, apparently, of nothing but cheese. I thought this was very strange and slightly troubling, but the idea gradually grew on me. I started sampling unfamiliar varieties of cheese such as Brie and chèvre, and shockingly enough, I didn't hate them. Now that I've been to France a couple of times, I find myself wondering how I spent so many years routinely eating cheese-less meals. It just doesn't seem civilized. In most parts of France, a traditional meal includes, at the very least, an entrée (what North Americans would call an appetizer), a main dish, and a cheese course—the latter either before, or in lieu of, dessert. Depending on where you go, what the local specialties are, and other seemingly random variables such as the phase of the moon, a cheese course may consist of anything from a single small round of cheese to a plate with three or four varieties—or even a large cart with dozens of selections from which you can choose whatever suits your tastes. A cheese course is often served with fresh bread, such as a sliced baguette—never crackers—and sometimes with fruit or nuts. But it's equally valid to serve cheese entirely on its own, at least if it's of a variety that has sufficient coherency to survive the trip from plate to mouth on a fork. When serving more than one cheese in a cheese course, it's customary to provide contrasts—softer and harder types, milder and more pungent varieties, and so on. Fancier dining establishments will carefully choose a wine (or even multiple wines) to pair with your cheese, and entire meals of cheese are not unheard of. The cheese course is not a phenomenon limited to restaurants, either. Some friends we stayed with in France for a couple days offered us half a dozen choices with dinner, which is not at all uncommon. We asked if this phenomenon was only applicable to afternoon and evening meals in France, since we hadn't been offered any cheese for breakfast. According to one of our friends, “Cheese at breakfast would be considered anathema.” But that's just in France—in other European countries, cheese is appropriate for any meal, though not necessarily served as a separate course. Coming to America Over the last few years, I've been delighted to see the cheese course trend catching on in North America as well. But here, cheese courses usually appear only at expensive French restaurants, and usually at an additional cost, whereas in France even an inexpensive prix fixe menu at a local café will nearly always include cheese, at least as an option in place of dessert. And in fact cheese courses make the most sense in the context of a planned, multi-course meal in which the other courses are kept to a modest size. If you've just stuffed yourself with a meal of typically American portions, you're not likely to have room for cheese afterward. Adding cheese courses to meals you serve at home is quite easy, as long as you do a bit of planning. There are plenty of books and Web sites that offer advice on selecting from among the many hundreds of cheeses produced in various parts of the world (not to mention recommended wines to accompany them), but it doesn't have to be that complicated. It's an art, not a science. Pick out two or three cheeses that look interesting, put them on a plate, and voilà! When selecting cheeses, the best results can be obtained by visiting a cheese shop, where someone knowledgeable can help you to make an appropriate choice. My advice: avoid anything that's shrink-wrapped and focus on cheeses that look as though some human may have been involved in their production. Contrary to popular wisdom, you generally don't need special implements or utensils if you don't already have them. I'm happy to say that my relationship with cheese has improved a great deal over the years. I'm blessed to have two fine cheese shops within walking distance of my home in San Francisco—nothing special in Europe, perhaps, but a rare find in North America. As with wines, I'm no connoisseur, but I have developed enough basic cheese knowledge to tell what I like. Words like “Asiago” and “Camembert” now describe meaningful categories for me, just as “Bordeaux” and “Cabernet” do. Alas, the category “pasteurized process cheese product” has also taken on new meaning, one I try not to think about too often. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/swisse.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Cheese_Course.b57015a19424.mp3"
	},
	{
		"title": "Mead",
		"text": "The first time I went to a Renaissance fair, I didn’t quite know what to expect. I understood from the ads that there would be jousting, music, crafts, and people walking around in period clothing, but that’s about it. In theory, a Renaissance fair is supposed to be a re-creation of 15th-century England. That sounded interesting, but I wasn’t entirely sure what it meant. As I explored the fairgrounds, playing primitive arcade games, sampling the crafts, and watching the shows, I was alternately delighted and annoyed by the ubiquitous displays of pseudoauthenticity. I smiled when a guy walked up to me and, wanting to know the time, asked “How stands the hour?” but just rolled my eyes every time I saw a merchant with a sign that read “Master Card and Lady Visa welcome here.” Everyone seemed to speak faux Shakespeare. Those in costume wore custom-made boots that looked believable until you saw the Vibram soles. And everything, of course, had a commercial gimmick. But no matter—it was still great fun. It was not long before I turned my attention to acquiring some authentic Renaissance food. The roasted turkey legs were quite popular, as was corn on the cob—both believable as period foods. I tried something called a “Scottish Egg,” which was a hard-boiled egg, rolled in batter, covered with ground pork, and deep-fried. Appalling—they might as well have called it Death on a Stick—but delicious. And of course, I needed something to wash all this down with. I couldn’t possibly bring myself to buy a Coke or a Budweiser (both readily available), so I looked for the most authentic-sounding drink I could find. Sure enough, some of the vendors were selling mead. All I knew was the name—I had no idea what was in it or what it tasted like—but I proffered my gold (card) and got a nice authentic plastic cup full of a pale yellow liquid. Honey, Would You Like Some Wine? Mead is a type of wine made from honey rather than grapes. To modern ears that sounds like a contradiction in terms, but almost any kind of sweet liquid can be made into wine, because the bacteria that cause fermentation aren’t especially picky about what kind of sugar they feed on. Mead looks about like white wine, and tastes like…well, it tastes like mead. I was about to say it tastes like honey, but that’s not quite right, any more than wine tastes like grapes. You can detect a family resemblance, sure, but the flavor is distinct. Furthermore, there are hundreds if not thousands of varieties of mead, and the flavors have as much variation as those of wine. Some are quite sweet while others are dry; some are fruity while others are earthy, and so on. It depends on the kinds and amount of honey used, the type of yeast added, the presence of other flavoring agents, details of the fermentation process, and numerous other factors. Mead-making techniques, and the resulting flavors, also vary from one part of the world to another. At our favorite Ethiopian restaurant, for example, we drink a type of honey wine called Tej, which is much different in character from English or American mead. Historically, honey wine is the first known alcoholic beverage, predating both fruit-based wines and beer. No one knows exactly where or when it was first invented, but it was certainly common at least as far back as 4000 B.C. in some parts of the world. Mead was known in the ancient civilizations of Mesopotamia, Europe, Africa, Australia, and the Americas. According to conventional wisdom, mead became popular not for its intoxicating effects but rather because the alcohol killed the microorganisms that would otherwise make water unsafe to drink. (In other parts of the world, of course, boiling water for tea was the preferred solution to the problem, though mead had the advantage of a longer shelf life. ) The Gods Must Be Happy Over the millennia, mead has found its way into legend, mythology, and literature countless times. Mead appears in Beowulf, the Aeneid, The Canterbury Tales, and ancient Greek, Roman, and Norse myths. Among its other sterling qualities, mead has often been considered an aphrodisiac, if not a magical potion. Scholars of Roman mythology suspect that the term “nectar of the gods” is in fact a reference to mead. And according to one popular—if possibly apocryphal—etymology of the word “honeymoon,” the ancient Babylonians had a custom whereby a newly married couple would consume mead every day for a month (that is, a “moon”) to ensure male offspring. Mead was eventually supplanted by beer and grape wine because the ingredients for both are cheaper and more plentiful than honey. But recently mead has been making a comeback, both commercially and as favorite project for home brewers. The very simplest kind of mead requires just three ingredients: honey, water, and yeast. To oversimplify greatly, you combine the ingredients and wait. Depending upon the recipe and the method, mead will take from one to several months to ferment, and after bottling, must age another few months for optimum flavor. I’ve enjoyed the few varieties of mead I’ve tasted, though more as a novelty than as a substitute for grape wine. I’m sure it won’t become my primary source of liquid as long as I have a safe water supply. Nevertheless, I do very much like the idea of mead—the notion that I’m drinking an ancient and mysterious beverage, quite literally the stuff of legend. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/mead.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Mead.a95f87ae8523.mp3"
	},
	{
		"title": "Raclette",
		"text": "The term cheesy in English can, and sometimes does, mean “containing cheese.” More often, however, it's used to mean “cheap,” “shoddy,” or “culturally infelicitous.” Sometimes these two meanings come together, typically in reference to a '70s-style electric fondue pot. Raise your hand if there's one in your cupboard that you received as a gift and haven't used in at least two years. That appears to be…yep, pretty much all of us. OK, put your hand back down; you'll need it to scroll. But please, for a moment, set aside any prejudice you may have about Swiss tabletop cheese-melting devices. Today I'd like to tell you about another one that is both more (in the good sense) and less (in the bad sense) cheesy. In Switzerland, the trains run on time—thanks, no doubt, to the seriousness with which the population treats clocks and watches. In much the same way, the Swiss take cheese extremely seriously. There is no such thing as “Swiss cheese” in the sense that Americans think of it—American Swiss cheese is a pale knockoff of Emmenthal, just one of hundreds of varieties of cheese produced by Switzerland's numerous (and apparently quite happy) cows. And for some of these cheeses, only one method of serving is considered appropriate—Tête de Moine must be shaved on a Girolle; Gruyère is typically melted in a fondue pot. But there's another type of cheese that requires an exacting preparation ritual, though it's little known in North America. The cheese is called raclette—a semi-soft, off-white, fairly mild cheese that melts extremely well. Scraping By Raclette usually comes in rounds (or “wheels”) that are about an inch and a quarter (3cm) thick and eight inches (20cm) in diameter—though you can find much larger wheels too. The cheese has been produced for centuries in the mountainous Swiss canton of Valais. According to legend, shepherds and herdsmen, short on ingredients, once heated wedges of raclette by an open fire, then scraped off the top layer of melted cheese onto pickles and boiled potatoes. This is, in fact, how raclette got its name: from the French verb racler (“to scrape”). In time the practice was refined, until it acquired an air of sophistication that has stayed with it to this day. A modern raclette meal uses the same basic ingredients, but trades the campfire for handy electric heaters. There are two types of raclette cookers. The raclette grill is by far the most common. It looks very much like any other tabletop grill, except that underneath the heating elements is a platform that holds six or eight individual trays. Participants put a hunk of cheese in a tray, pop it under the heat, wait a few minutes for it to melt, then use a special spatula to scrape it onto their plates. The top of the grill, meanwhile, can be used for meat, vegetables, crêpes, or anything else. A more modern design attempts to replicate the campfire experience more closely. A quarter or half round of raclette is held vertically by a small bracket, while an oblong quartz lamp shines down on the edge of the cheese. When you're ready to serve it, you swivel the cheese away from the lamp and scrape off a layer with a special knife. Getting Into a Scrape The melted cheese is usually accompanied by boiled potatoes, cornichons, or pickled onions. However, the specifics of raclette etiquette are apparently a subject of much debate in Switzerland. My Swiss friend Eveline insists that the only proper way to serve the raclette is to sprinkle paprika, pepper, or both onto the melted cheese, then scrape it directly onto the potatoes. Her husband Peter, on the other hand, says that this is an egregious violation of tradition—that spices must never be used, and that furthermore the cheese should be scraped onto an empty portion of the plate and combined with the potato only on one's fork. I witnessed a heated discussion on this topic, but luckily the couple avoided a meltdown. When it comes to the proper method of eating cheese, I understand that emotions can run high. From my earliest days of childhood, I put ketchup on macaroni and cheese. When I got to elementary school and did this in the cafeteria at lunchtime, my classmates regularly complained to the teachers that I was doing it just to “gross them out.” I was bewildered by this accusation; how could anyone enjoy macaroni and cheese without ketchup? I said, “You eat spaghetti with tomato sauce and cheese, right?” Heads nodded. I said, “This is the same thing, just in different proportions.” My argument, which I thought very logical and persuasive, appeared not to move my audience. Later, however, I lived in Canada for a few years and discovered to my delight that ketchup on macaroni and cheese was as normal there as gravy on French fries. (That is to say, completely normal, in case you were wondering.) I can't imagine anyone putting ketchup on raclette, but I wouldn't complain—I'd be too busy scraping. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/Raclette-dish.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Raclette.ed8dfb810094.mp3"
	},
	{
		"title": "Superautomatic Coffee Machines",
		"text": "There are those who believe half the pleasure of a great cup of coffee comes from the ritual of making it. The details of the ritual vary from person to person and place to place, but the desired effect is the same: a perfect cup of hot, rich, fresh coffee. “Perfect,” of course, is quite subjective. Among people who take coffee very seriously, there is a great deal of disagreement as to what types of bean, roast, and grind make the best coffee, how concentrated the grounds should be, whether the coffee should be infused into the water by dripping, steeping, or steaming, and many other details. Regardless of the precise outcome, however, coffee purists will insist that if you want coffee done right, you must make it by hand, with a great deal of care and attention to detail. I certainly count myself among those who cherish a perfect cup of coffee. And yet, I’ve never been much for ritual. All things being equal, I’d prefer to have my coffee with as little effort as possible. I was delighted to discover that technology allows me to have my café and drink it too, thanks to a breed of coffee maker known as a superautomatic. Coffee Making 101 First, a few background concepts about coffee brewing. The standard American method for making coffee is to allow hot water to drip through a filter full of ground beans and then into a carafe sitting on a hot plate. You’ll get eight or ten cups of coffee this way in about five minutes. While operating the coffee maker itself is usually just a matter of flipping a switch, that doesn’t include measuring and pouring the water, inserting the filter, measuring the ground coffee, or disposing of the used grounds. (Add another step or two if you grind your own coffee beans—which you should.) The end result is a relatively dilute coffee whose taste rapidly deteriorates as it ages and evaporates. The person who drinks the first cup often has a much better experience than the one who drinks the last cup. By contrast, espresso is made one or two cups at a time by forcing steam into a much finer grind of coffee and through a metal filter that allows slightly larger particles of grounds through than a paper filter would. This normally results in a stronger coffee, mainly because less water is used; if you kept forcing steam through the grounds for a longer period of time, the coffee would become increasingly weak, eventually reaching the strength most North Americans consider normal. Making espresso (and its milk-added cousins cappuccino and latte) is normally an exacting manual procedure, but one that results in a fresher cup because the coffee never sits around in a carafe becoming bitter. I’ll Have a Digital Cappuccino A superautomatic coffee machine uses the pressurized steam method of coffee production to make a single cup of coffee at a time, but without any of the manual steps. With the press of a single button, the machine grinds beans stored in an internal hopper; tamps them down into the filter assembly; squirts steam through them into your cup, then ejects the used grounds into a holding bin. The whole process takes about 30 seconds, and it produces a wonderfully rich, creamy coffee. Most superautomatics allow you to adjust a wide variety of settings, such as the coarseness of the grind, the amount of ground coffee per cup, and the volume and temperature of the coffee. With various combinations of settings, you can get a tiny cup of ultra-concentrated espresso, a large mug of American-style coffee, or anything in between. (My personal preference is Swiss-style café crema, which is stronger than American but weaker than espresso, served in a demitasse cup with a golden foamy finish. ) My wife’s favorite feature of our superautomatic is its automatic milk frother. This is not simply a wand that squirts steam into a container of milk (though you can do that too if you want). Instead, you drop a small hose into a container of milk, press a button, and the machine sucks in the cold milk and delivers hot frothed milk from a nozzle right into your coffee cup. This makes an excellent cappuccino a matter of pressing exactly two buttons. Depending on the model and manufacturer, superautomatics have a variety of additional features. Some have a built-in cup warmer, an internal water filtering system, or a second steam pump so that they can brew coffee and steam milk at the same time. Programmable digital models feature an alphanumeric display and one-touch access to popular features, to save your delicate fingers from having to physically move levers or knobs to adjust settings. You Can Put a Price on True Happiness Superautomatics don’t come cheap. A good mid-range model, with a digital display and most of the bells and whistles, will run in the neighborhood of US$1,500. A high-end commercial machine can go for as much as $6,000; on the other end of the spectrum, if you’re willing to forgo a few of the more esoteric frills, you can find a good basic unit for under $1,000. Unsurprisingly, superautomatics are a frequent cause of buyer’s remorse, which means some good bargains on lightly used machines can often be found on eBay or at dealers with money-back guarantees. The two best-known manufacturers of superautomatic coffee machines are Saeco (from Italy) and Capresso (from Switzerland). Both companies offer a wide selection of models in various price ranges, and both have excellent reputations for making high-quality products. However, don’t expect to find such machines on display at your local Wal-Mart. High-end kitchen stores like Sur la Table or Williams-Sonoma often carry superautomatics; apart from that, your best bet is usually an online retailer with a good return policy. Also be prepared to get picky when it comes to coffee beans. Shiny, oily beans are to be avoided; a dark but dry bean such as Illy will make your superautomatic purr. I Love the Java Jive and It Loves Me You may be thinking: My generic $25 drip coffee maker works just fine. Why should I spend such an outrageous amount of money on a fancy coffee machine? Sure, the coffee from these machines may be excellent, but is it really worth the difference in price? Speaking for myself, the answer is yes. The combination of outstanding coffee and one-button convenience is worth quite a lot to me, and I’ve never regretted the purchase. Needless to say, superautomatics are not for everyone. If you don’t drink much coffee or can’t tell the difference between instant and fresh-brewed, a superautomatic is a frivolous investment. On the other hand, if you are—or aspire to be—a coffee connoisseur, this marvel of engineering may lead you to wonder what you ever found so endearing about your beloved French press or copper coffee pot. Since I bought my superautomatic, my contributions to the Starbucks empire have fallen off dramatically. My kitchen may not have quite the ambiance of a local coffee shop, but the wireless network is faster and the coffee is better. That digital biscotti maker is still a dream, but I always know where to get a good cup of Joe ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/espresso-machine.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Superautomatic.8230172a1d7d.mp3"
	},
	{
		"title": "Skara Brae. House of sand and rock",
		"text": "The 2001 documentary Rivers and Tides showcases artist Andy Goldsworthy, who creates ephemeral works of art out of the natural materials around him. Whether it’s leaves, twigs, or icicles, Goldsworthy crafts them into breathtaking constructions that add to the beauty of the landscape while still remaining part of it. Although Goldsworthy invests significant effort in each work, after its completion he leaves it at the mercy of the natural processes of wind, rain, sun, and water, only taking a photo to document its momentary perfection. Some of Goldsworthy’s most arresting works are the ones he creates out of stone. The film follows the progress of a few such projects, including one in which he creates an egg-shaped structure out of split pieces of stone, and another where he works with stonemasons to create a long serpentine wall in a park in New York state. While the wall is meant to be a permanent installment, the egg-shaped structure Goldsworthy creates in the film is destined to be carried away by the rising tide, showing the vulnerability of a material that most people would take to be among the most solid. Although originally from England, Goldsworthy now makes his home in southwestern Scotland, finding inspiration for his work in the local landscape. At the other end of the country, in the Orkney Islands off the north coast of Scotland, once lived a people who similarly worked in stone, but whose work has lasted over 5,000 years. Miraculously protected from the elements for millennia, the settlement of Skara Brae is Europe’s best-preserved Neolithic village. Midden Earth The ancient settlement of Skara Brae is currently located on the edge of the Bay of Skaill, on the west coast of the largest Orkney island (called the “Mainland”), but at the time of its construction (thought to be around 3100 B.C.) it was situated far inland. Over thousands of years extreme erosion brought the coast to Skara Brae’s doorstep, and also created sand dunes that covered it and kept it hidden until relatively recently. In 1850, a severe storm removed some of the grass covering the mound of sand, revealing the existence of Skara Brae to the modern world for the first time. Some excavation work was done on the site at that time, but it was left untouched after 1868. In 1928 an excavation of the site showed the full extent of the discovery. Skara Brae had remained remarkably intact, providing an incredible glimpse into the daily lives of its ancient inhabitants. Besides the protection of the covering sand, the fact that a lack of wood in the area had forced its builders to use stone instead contributed to Skara Brae’s longevity. Most other Neolithic structures, created out of wood, have not fared as well. One of the fascinating aspects of Skara Brae is how it was constructed. To shield themselves from the cold, and to provide a stable foundation, the inhabitants of Skara Brae built their homes into a mound of midden, that is, the waste products of their community. While this may seem distasteful, their garbage was most likely similar to modern compost, made up of completely organic materials. Stones were laid on top of this foundation, creating an insulated and weather-resistant structure. The settlement consists of eight houses connected by covered alleys, which allowed the inhabitants to remain inside during cold weather. Another notable aspect of Skara Brae is that seven of these houses are strikingly similar, with features common to all of them including a central hearth, two stone box beds (meant to be filled with heather), a dresser/shelf, and a waterproof enclosure built into the floor which might have held fish for bait or for eating. Time and Tide Because it gives such a clear picture of what life was like for its ancient residents, Skara Brae has become world-renowned, and is part of the “Heart of Neolithic Orkney” UNESCO World Heritage site. While Skara Brae is being maintained and protected as much as is possible, ironically it is now threatened by the wind and water that once helped to preserve it, because of its proximity to Skaill Bay and the fact that it is exposed to the elements. It may have withstood the ravages of time for the last 5,000 years, but like the ephemeral stone sculptures of Andy Goldsworthy, it remains vulnerable to change and the destructive power of nature. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/Skara_Brae_house-2-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Skara.a5f619311bf4.mp3"
	},
	{
		"title": "Teatro La Fenice",
		"text": "Throughout the night of January 29, 1996, a fire raged in the center of Venice, Italy, and by morning it had consumed its victim: the Teatro La Fenice, often called simply La Fenice. Luckily, the fire did not travel beyond the walls of La Fenice, but the destruction was profound. One of the great opera houses of Europe was gutted, and the city of Venice lost a treasured civic landmark. Arriving by chance in Venice just days after the fire, celebrated author John Berendt set out to document the aftermath of the Fenice fire, interviewing local residents and city officials to find out what led up to the fire, and what long-term effect it might have on the city. As with his previous bestseller, Midnight in the Garden of Good and Evil, which centered around a lurid murder in Savannah, Georgia, Berendt found many colorful characters and community intrigues in Venice to write about in addition to his main story. The result of Berendt’s research is the 2005 book The City of Falling Angels. The fire of 1996 that Berendt details in The City of Falling Angels is a riveting event, a tragedy on a huge scale. But for the Teatro La Fenice, this recent catastrophe is yet one more chapter in its long and strange history. Fire in the Hall Translated from Italian, La Fenice means “the phoenix,” a reference to the mythological creature that is reborn from its ashes after it is destroyed. Long before the fire in 1996, La Fenice acquired this name because of another fire, one that burned down the Teatro San Benedetto in 1774. In response to the loss of the theater, a group of ex-proprietors of the San Benedetto, calling themselves the Noble Association of Boxholders, decided to sponsor the creation of a new theater, and invited proposals for its design. Completed in 1792, La Fenice was well received and greatly admired by the public and the media. Only a few years after the Fenice was completed, in 1797, the French army, under Napoleon’s command, invaded and occupied Venice, placing it under both French and Austrian control. Although ownership was retained by those who had built the theater, it in effect became a state theater. In accordance with this, in 1807, La Fenice played host to the now-Emperor Napoleon; a special loggia was built to accommodate him, and the theater was decorated in the imperial colors of blue and silver. Further changes to the theater were made in 1828, including the hanging of a new chandelier and additions of painting and sculpture. All this work put into the Fenice was destroyed on December 13, 1836, when the theater caught fire, reputedly sparked by a newly installed Austrian stove. The fire burned for three days and nights, and continued to smolder for another fifteen days. On the heels of this disaster, reconstruction began quite quickly, under the direction of the Meduna brothers, Tommaso and Giambattista. Disorder of the Phoenix After the major rebuilding of 1836, other refinements and renovations were made to the Fenice, most notably in 1854 and 1937. At the time of the 1996 fire, major restoration work was again being carried out on the Fenice, and according to The City of Falling Angels, many believed the chaos that existed inside the theater during this time contributed to its destruction. Indeed, the prosecutor charged with going after those responsible for the fire, Felice Casson, first focused on the city officials he felt were negligent in keeping order on the project. Examples of this negligence included the lack of restrictions on access to the site and the presence of equipment and flammable materials left scattered around the site by work crews. Most critically, response to the fire was hampered by the lack of water in the adjacent canal, drained as part of a canal improvement plan; valuable time was lost in routing water from another canal to the scene of the fire. Eventually, however, Casson charged two cousins—the owner and employee of a company hired to carry out electrical work on the Fenice—with arson, and both were found guilty of the crime. The motive for arson given by the prosecution was that the men were trying to avoid serious fines the company would have faced if it did not meet an upcoming work deadline. Out of the Ashes The mayor of Venice at the time of the fire, Massimo Cacciari, promised that the Fenice would be rebuilt “com’era, dov’era,” or “as it was, where it was.” This was easier said than done, considering the difficulties of construction work in the middle of a city without roads. All the building materials had to be brought in by boat, and a large platform was built in the main thoroughfare of Venice, the Grand Canal, upon which cement mixers and large equipment were stored. After stops and starts, and after the project had changed management mid-stream, the new Fenice hosted its inaugural performance on December 14, 2003. It was one more chapter in the history of this world-famous opera house, the setting for premieres of works by Verdi, Bellini, Stravinsky, and Britten, and the scene of many notable performances by opera superstars such as Maria Callas and Joan Sutherland. Like a phoenix, La Fenice twice rose from the ashes to continue its important role in the life of Venice. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/La_Fenice-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Fenice.3cb5544ce157.mp3"
	},
	{
		"title": "The Nazca Lines",
		"text": "I like a good murder mystery now and then, and despite the violence inherent in the genre, often find these movies and TV shows fascinating. There’s something satisfying about following clues to reach the answers to those vexing questions—how, who, and why. The first two questions can be engrossing, but the last is sometimes the most consuming. Once the means and identity of the killer are known, knowing his or her motivation is the last piece to the puzzle. If no answer to that question is forthcoming, it can be maddening. It’s human nature to want to know how the world works—and in the case of murder mysteries, to understand how another person thinks—when it is not obvious to us. This same phenomenon is at work when looking at history; there is no way, other than the evidence left to us, to know what was in the minds of those who preceded us. We see this gap in our knowledge clearly when we try to explain the existence of certain ancient human-made structures, such as Stonehenge or the statues on Easter Island. Another example is the Nazca Lines of Peru: a mystery 2,000 years in the making. Making a Good Impression The Nazca Lines are a series of negative geoglyphs—patterns drawn on the ground by adding (positive) or removing (negative) stones or soil. Other examples of geoglyphs include labyrinths, burial mounds known as intaglios, and so-called “hill figures”—shapes cut into hillsides to reveal the chalk beneath, most often found in England (such as the Uffington White Horse). The term “Nazca Lines” refers collectively to hundreds of large designs drawn on the surface of the Nazca Desert. They’re thought to have been created between 200 B.C. and A.D. 600 by the Nazca, a culture known for its distinctive pottery and intricate textiles. This desert, an arid plateau located between the Andes and the coast of Peru, has a very particular topography and climate that allowed for both the construction and the preservation of the figures. Instead of a sandy surface, the Nazca Desert floor is covered in a layer of pebbles made red through oxidation. Various designs, ranging from straight lines and geometric forms to intricate figures of animals, insects, and humans, were created by removing these pebbles, exposing the lighter-color soil beneath. The lack of wind and rain in the area meant that these figures were not disturbed since their creation thousands of years ago until they were rediscovered in the modern era. Eyes in the Sky A curious trait of the Nazca Lines is that they are difficult to identify from the ground; given their tremendous scale, they are much more recognizable from above. Thus it was not until the 1920s, when airplanes began flying over the area, that they were seen in their full aspect. This peculiarity led scientists and amateurs alike to ponder both the how and the why of these formations: How did the Nazca people create these large-scale designs without seeing them from above, and why would they have created them this way in the first place? An early attempt to answer these questions came from Paul Kosok, an American archeologist and his one-time assistant, Maria Reiche. Kosok, and Reiche after him, believed that the lines were a type of astronomical calendar, showing the alignment of different planets and stars as they rose above the horizon. Reiche, who took over the study and mapping of the lines after Kosok left the project in 1948, eventually became its premiere advocate and guardian. Born in Germany and educated in mathematics, geography, and languages, Maria Reiche first went to Peru in 1932 to work for the German consul in Cuzco as a nanny and teacher for his children. She began working with Kosok in 1940, and spent the rest of her life preserving and studying the lines, until her death in 1998. Although the astronomical calendar theory has raised doubts—including the observation that the multitude of lines and their varying orientations could be found to correspond with almost any trajectory and the fact that astronomical alignments have changed with time—Reiche made a huge contribution to the study of the lines. Her advocacy brought heightened attention to their existence, and resulted in their designation as a UNESCO World Heritage Site in 1995. Alien Flight Forms Reiche believed that the Nazca had created the lines using grids, making smaller versions of the drawings and then transposing them onto a larger design. She even found markings she believed showed this initial process near some of the figures. Although the use of this method cannot be confirmed, there is evidence that the Nazca used some form of surveying technique in their production of the designs. Wooden pegs, dated to the time of the Nazca, have been found near the ends of long lines, implying they were used as markers of some kind. The Nazca were very able weavers, and this ability could have translated into general pattern-making facility as well. Also, there is a similarity between figures they used on their pottery and some of the geoglyph forms. This seems to indicate their aptitude and predisposition to be the creators of the figures. Nevertheless, some have publicly doubted the Nazca’s ability to create such works, given their earthbound perspective. Chief among these doubters is the Swiss author and UFO theorist, Erich von Däniken, who claimed in his 1968 book, Chariot of the Gods?, that the Nazca Lines were in fact landing strips for alien spacecraft. Another attempt to explain how the Nazca could have created the lines, when they are only fully visible from the air, was made by Jim Woodman in the late 1970s. He believed that the Nazca could have constructed basic hot air balloons, using materials available to them, in order to survey their designs from above. To prove this point, Woodman and balloonist Julian Nott set out to create a prototype of such a balloon and to attempt flight. They created a balloon out of cotton fabric, inflated it using only the heat from a wood fire, and attached a reed basket to it as their gondola. They did manage to get airborne, but this success does not prove that the Nazca did so too. In response to this kind of speculation, Joe Nickell of the University of Kentucky set out to reproduce one of the Nazca figures (a 440-foot-long [about 130m] condor) without recourse to aerial observation. With the help of friends and family, and using a method of measuring points on a smaller version of the design to corresponding points on the larger design, in a matter of days he succeeded in producing a close likeness of the Nazca condor, sketched out in white lime on a Kentucky field. Walk the Lines While most scholars now believe the lines were created by the Nazca, most likely without aid from above, the question of their purpose remains unanswered. What was the motivation for this huge undertaking? Given their size and their complete visibility from the air, the lines may have served some religious purpose, made for the benefit of celestial beings. The recent discovery of the ancient town of Cahuachi, located near the lines, lends credence to this theory. Archeologists studying the site believe that the town was a pilgrimage center to which people would come before visiting the lines. Although there is no record of how the lines might have served in religious ritual, some now believe that ancient pilgrims might have walked along the lines as a show of devotion to a particular sacred entity, much as labyrinths were used in medieval cathedrals in Europe, and to a certain extent today. Some people believe that the lines correlate with underground water sources, a key piece of knowledge in such an arid environment; the religious ritual might even have pertained to ensuring adequate water supplies in this drought-prone area. Keep Off the Beaten Track Whatever their purpose, for the first time in their long history, the Nazca Lines are now threatened with serious defacement. Although prohibited, there has been extensive foot and vehicular traffic over the lines in recent years, particularly by looters stealing artifacts from the ancient tombs in the area. Also contributing to the problem is increased tourist activity and the nearby Pan-American Highway. Although economics plays a key role in the situation—too little funding exists to protect the site, and tourism and the artifact trade contribute to a depressed local economy—there is hope that the situation can be turned around. It would be truly unfortunate for these fascinating structures to be lost after resisting destruction for so many centuries. After all, they are not only a part of the rich cultural heritage of the area—which also includes the remains of the great Inca empire—but they offer a unique chance to put oneself into the minds of those who lived so long ago. This is what makes the Nazca Lines so fascinating for modern folk: their inscrutable mystery, which cannot be explained away by even the savviest of detectives. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/Nazca_monkey-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Nazca.795a454a039b.mp3"
	},
	{
		"title": "Highgate Cemetery. Toto, I don’t think we’re in London anymore",
		"text": "London has hundreds of popular tourist spots that attract millions of visitors each year. I admit, I did the whole Big Ben to Westminster Abbey to Buckingham Palace to Tower of London circuit and I enjoyed it. I loved being able to walk out of the hotel and onto a street that contained a 500-year-old house right down the block from a modern tube station and an Indian curry restaurant. But the intricacies of this city, like any city, are often found off the beaten path. Both my visits to London have included a hike up Highgate Hill and then a walk down the small, winding lane leading to Highgate Cemetery. Many are familiar with London’s abbeys and churchyards, but the real appeal of dead London is Highgate, often referred to as a Victorian Valhalla. Well, We Can’t Just Put Them on the Streets Highgate Cemetery was established in 1839. Around this time the church graveyards were becoming quite full, and rather than dump the dead out on the streets, Parliament established seven private cemeteries to be located within London proper. In 1954, when the popularity of burial at Highgate was at its peak, a second part of the cemetery was opened to accommodate all the new “arrivals.” This newer cemetery was coined the East Cemetery, leaving the older side to be called, naturally, the West Cemetery. During the bone yard heyday, both cemeteries had elegant parades of well-dressed mourners following caskets to elaborate tombs and mausoleums. Later, when cremation became legalized, the processions of ornate funerals halted and both cemeteries were maintained less and less. Eventually, in 1975, the West Cemetery was closed altogether and efforts were put into maintaining the East side. Luckily, a group called “The Friends of Highgate Cemetery” was formed and in 1981 procured both sides. To this day they are responsible for upkeep of the 37-acre sprawl encompassing both cemeteries. However, the West Cemetery, sometimes called a “maintained wilderness,” had become so overgrown that upkeep involved maintaining and restoring the tombs but only clearing the vegetation along the paths and around the nearer graves. A Garden of Dead People Highgate does manage to attract a few tourists due to its most famous “resident,” Karl Marx. Marx, along with Michael Faraday and other historical notables, is buried in the East Cemetery. This side, although it exhibits manicured lawns and moderately-kept headstones in some areas, has wooded stretches where the paths disappear into the trees, and headstones are crowded amongst ivy, moss, and each other. It resembles the scene of a ghostly movie; in fact, the cemetery has been the set of a few horror movies. And yet I found, even in this green expanse dedicated to housing dead people, a sense of tranquility, mixed with an overwhelming fascination. This place just exudes mystery. Even more mysterious is the West Cemetery. While access to the East Cemetery is open to the public (for a modest fee), the West Cemetery has tours by appointment only (for a slightly higher fee). The day I booked my tour it was overcast and gloomy, with an ever-present threat of rain, the perfect backdrop for a necropolis jaunt. The entrance to the West side is a daunting structure, once a chapel with two sides—one for Anglicans and the other for non-Anglicans (or “dissenters”). A tunnel runs under the lane that divides the cemeteries so a body would not have to leave consecrated ground on its way to be buried. For Your Mental Safety, Please Stay With the Group Our guide led us through the chapel gate onto the stones of a courtyard. It was eerily quiet here, making it hard to believe that we were still in London. From my vantage point, the cemetery itself was hidden; it was located up a tiny hill behind the chapel and beyond the courtyard. The trees, bushes, and overgrowth cleverly hid nearly all the signs of headstones. At the top of a stone stairway leading into the cemetery, a path began, and a stretch of graves ambled up either side among the tangles of vines and growth. The variety of graves was amazing. Small markers were ensconced amongst larger markers that bore angels and broken columns, crosses and torches. Many looked as if they would disappear overnight into a fit of ivy and other creeping vegetation. The path continued through the archway located in the middle of a foreboding stone structure. Flanking the arch were two sets of hulking columns. The guide explained that this was the entrance to Egyptian Avenue, a row of continuous family vaults that form an alley leading up to the Circle of Lebanon. The doors to the vaults were adorned with various funerary symbols signaling the passing of life into death, and as we walked on I got a creepy, tingly feeling. On other side of Egyptian Avenue was the Circle of Lebanon, another series of continuous vaults with an inner and outer circle. In the outer ring was a columbarium, a place for storing the ashes of those who have been cremated. In the inner ring, a large, sprawling cedar tree was perched in the soil above and between the vaults. The tree itself was here before the cemetery was even built, and its position high above the cemetery contributed to the spooky feeling. But Wait, There’s More Located behind the Circle of Lebanon was the tomb of Julius Beers, the largest and most ornate tomb in the entire cemetery. It was built to block the view of London from the terrace of the church directly behind the cemetery that Londoners often would enjoy after Sunday service. Under the terrace was a catacomb of tombs that was closed off to the tour. The vaults themselves could not be seen, and only a gated entrance led into the darkness under the stone. While listening to the tour guide explain the history of the tomb, we rested our backs against the cool stone of the terrace. I had my back to the gate of the entrance just to scare myself a bit. After a few minutes of listening to the guide, a dull thudding noise came from behind the gate. Apparently I wasn’t the only one who heard it, as the other members of the group looked nervously around. As we slid away carefully, we heard the noise again, only louder. Was the guide playing a well-timed prank on us? Along the eastern edge of the cemetery, more mausoleums and tombs stretched along either side of the path. At one time these tombs were ostentatious displays of wealth, but now they looked worn and frail. Near this part of the cemetery was where the dissenters were buried, in an area apart from the Anglicans. You Mean There’s Something Out There? Some subsequent Web searching revealed that, aside from the physical mysteriousness of the cemetery, there were a few stories of the supernatural. The most interesting of these is of the Highgate Vampire. In the late 1960s, following a string of alleged spectral sightings and the accumulation of blood-drained animals in the cemetery, rumors circulated that a vampire was roaming Highgate. Several people claimed to have either encountered or been attacked by the vampire. Various occult experts undertook rituals to purify the cemetery and rid it of the vampire, but conflicting accounts of these activities and their results led to feuds that persist to this day. Vampire investigations are reportedly ongoing. Needless to say, the entire existence of the Highgate Vampire is controversial, and the Friends of Highgate Cemetery would rather ignore it, in order to keep outsiders from breaking into the cemetery in search of the bloodthirsty apparition. Vampire or not, Highgate Cemetery is the most interesting cemetery I have ever visited. Its isolation, desolation, and eerie scenery make it akin to a real-life movie. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/HighgateCemetery-120.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Highgate.f8dc66c52b54.mp3"
	},
	{
		"title": "The Sinking City of Venice. Atlantis redux",
		"text": "Several years ago, Morgen and I visited Venice, that beautiful Italian city where the streets are paved with water. We were there for only a few days, but we enjoyed every minute of it. The place oozes history, and it’s wonderfully romantic. When we took the customary gondola ride through the city’s canals, our gondolier casually pointed toward a small house and said, “Marco Polo used to live there.” And we could believe it—if it were not for the constant noise of motor boats, it would be easy to imagine that the city looked much the same way centuries ago as it does now. But it’s not quite the same as it was in Marco Polo’s time. Whatever other changes have happened, the most significant one is that the city, as our gondolier reminded us, is sinking. Of course, the entire planet is doomed to be destroyed when the sun explodes in 500 million years or so, but I’m not losing any sleep over that. Why should I worry about Venice? It still looks OK to me, so it must be sinking very slowly, right? Well, not really. Venice is located in a lagoon on the edge of the Adriatic Sea. When Venice was founded in the year 421, the level of the Adriatic was about 5 meters (16 feet) lower than it is today. For centuries the water level rose very, very slowly, but in the last century or so the rate has increased dramatically. With each passing year, the difference between street level and water level shrinks faster. From time to time, the city gets a brief reprieve. On more than one occasion in early 2005, unusual weather patterns caused Venice to experience exceptionally low tides—so low that boats could not navigate most of the city’s shallower canals. Nevertheless, the clear trend, as observed over centuries, is in a decisively downward direction. If nothing is done and the trend continues, by 2055, a significant portion of the city’s walkways, plazas, and ground-level floors will be submerged all the time. That Sinking Feeling For a long time I was puzzled about just what it meant for Venice to be “sinking,” because that doesn’t fit into my categories of things a city is capable of doing. This is in fact a somewhat simplistic description of a complex problem. One part of the problem is that the city is not built on a solid foundation. Venice was originally a collection of muddy islands. In order to construct buildings, workers drove millions of pilings—thin, sharpened poles made of alder trees—through the mud and into the marginally more solid base of sand and clay beneath. Oak planks were placed on top of the pilings, and on top of the planks, several thick layers of marble (which is impermeable by water) formed the foundations of the buildings. From there on up, most of the construction was done in ordinary brick or wood. At the time the buildings were constructed, the marble was well above the high water line, so there was nothing to worry about. However, over the centuries, the weight of the buildings has driven the pilings deeper into the mushy seabed. In addition, at one time there were hundreds of wells in the city, removing water from deep aquifers. Unfortunately, these aquifers had acted as a sort of balloon of water propping up the city; when it was “deflated,” the city began to sink even faster. But the literal sinking of Venice, which averages something like a few centimeters per century, is only part of the problem. The other part is that the surrounding water level has been rising at an alarming rate. This is partly due to the effects of global warming and partly due to centuries of poor environmental management in the entire region. But in any case, the rising waters compound the sinking problem and make the net effect quite serious. When It Rains, It Pours Venice has always been subject to periodic flooding—mainly in winter, and especially at high tide. This is something that residents have come to regard as a fact of life, and not a terribly troublesome one; most of them get around in boats anyway. But whereas flooding used to be something that would happen a few times a year, now it happens on the order of a hundred times a year. Because the sea level has risen, even in a modest flood, the water level rises above the waterproof marble foundations of the buildings, rapidly wearing away the less-robust building materials. In November, 1966, a particularly bad storm caused a devastating flood that put much of the city under 2 meters (over 6 feet) of water. This caused extensive damage to both buildings and the valuable artwork they contained, and began to impress upon Venetians the need to take drastic action. In 1970, a plan was proposed that involved the installation of large, mobile gates at the three inlets of the lagoon; these would be raised as needed to keep out high water. But for the next 30 years, a series of excruciating delays prevented any significant progress from being made. There were, of course, significant engineering problems to be solved, not to mention the problem of financing such an ambitious undertaking. But political reasons, more than anything else, held up development. Many Venetians did not want to believe their city was in imminent danger—and even to the extent that they did, there was tremendous disagreement about how best to address the problem. Some wanted to address the problem at the base—to basically “jack up” the city and install new and improved foundations. Others wanted to build a series of dikes and locks around the city—the so-called “Dutch solution”—or use a different mechanism to hold back high waters. Holding Back the Sea At the end of 2001, a plan was finally put in motion to keep back the high waters. Nicknamed “Project Moses,” the plan calls for the construction of 79 steel gates, hinged at the bottom, to be installed along the sea floor at the three inlets to the lagoon. The gates, which are hollow and normally filled with water, measure 20 meters wide, 3.6 meters deep, and 20 to 30 meters high. When water levels appear to be rising dangerously high, compressed air will be pumped into the gates, causing the ends to float up to (and slightly above) the surface. In effect, they will form a dynamic dam that will appear only when needed. The gates will be tall enough to hold back water quite a bit deeper than the 1966 flood. Although construction has begun, there are still numerous problems ahead. One problem is where the 3 billion euro (about US$3.5 billion) budget will come from; the government does not currently have adequate reserves to pay for the project. There are also significant environmental concerns; the project was vigorously opposed by numerous environmental groups. Among the concerns is that any interference with normal tides will increase the levels of toxic chemicals such as mercury in the waters of Venice, seriously threatening both marine life and the health of people who consume the local fish. There are also basic worries about health and sanitation. Venice has no sewer system; household waste flows into the canals and is washed out into the ocean twice a day with the tides. No one is certain quite what effect the gates will have on the city’s natural waste treatment system. An Uncertain Future Under the most optimistic prediction, Project Moses will be operational by 2009, but given the city’s history of delays, few expect it to be finished that soon. And even if it works perfectly, it is not a complete or final solution. The city will continue to sink and the water level will continue to rise. Sooner or later, the gates will no longer be able to protect the city from deterioration. In the meantime, Venice faces an uncertain and paradoxical existence. While tourism increases to record levels, the population of the city itself has plummeted. There were 184,000 residents in 1950; today, there are fewer than 60,000. A shocking percentage of Venice’s glorious old buildings stand vacant as owners move to more stable surroundings, yet real estate prices remain astronomically high, discouraging an influx of new residents. With no one to renovate and maintain the buildings, they will fall apart faster; but the more the city deteriorates, the fewer people are willing to live there and do anything about it. Project Moses may keep the floods out, but will it enable Venice to keep its head above water? ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/Venice-canal.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Venice.3cfbec6c4787.mp3"
	},
	{
		"title": "Père-Lachaise Cemetery",
		"text": "Those who follow Interesting Thing of the Day closely will by now have noticed more than a passing tendency for topics to involve decay, France, or—when possible—both at the same time. Undoubtedly some very troubling explanations could be advanced for this phenomenon, but in fact there is no sinister plot afoot, as far as I know. The old is often more interesting than the new, and as for France, well, it happens to have quite a lot of old things—as well as some truly excellent food and drink to enjoy before and after looking at them. It’s a natural destination for seekers of interesting things. On each of our trips to France, we made a point of visiting one of the most famous, interesting, and quiet attractions in Paris: Père-Lachaise Cemetery. Père-Lachaise owes its celebrity primarily to the large number of writers, musicians, politicians, and other famous people buried there. Among the cast are Frédéric Chopin, Eugène Delacroix, Marcel Proust, Gertrude Stein, and Oscar Wilde. The cemetery, which is also the largest park in Paris, has more than 70,000 plots. The sheer size, along with its hilly terrain, twisting roads, and thousands of trees, makes navigation a challenge, and most people purchase maps for a few euros before entering the site (which is free to the public). Name That Tomb The cemetery was named after the Reverend Father François de Lachaise d’Aix, a Jesuit priest who was the confessor of King Louis XIV from 1689 until the king died in 1709. The story goes that the Jesuits had built a retreat house on the hill that was once called Champ-l’Éveque. When the king visited the area, the Jesuits, at a loss for an appropriate gift, renamed the hill Mont-Louis in his honor. The residence at Mont-Louis was later to be home to Father Lachaise, and the entire hill eventually took on the priest’s name. The site was first used as a cemetery in 1804, but after three years, there had been only 106 burials. At the time, the cemetery was an inconveniently long distance from the center of town, and Parisians did not want to walk so far during funeral processions. While corpses were piling up in the city, the directors of the cemetery were concerned about having enough income to make their considerable investment in the land worthwhile. Napoleon undertook a large publicity campaign on the cemetery’s behalf, part of which involved moving the remains of numerous famous people to Père-Lachaise. But his efforts had little effect and the cemetery remained underused. Where government power failed, fiction succeeded. Honoré de Balzac wrote a number of serial novels that were published weekly in Paris gazettes. In the stories, important characters who died were buried at Père-Lachaise. So compelling were the descriptions of both the characters and the cemetery that tourists began flocking to see the real place where fictional characters were supposedly buried. A Prestigious Address The gravesites at Père-Lachaise range from a simple, unadorned headstone to towering monuments and even elaborate mini chapels dedicated to the memory of a well-known person or family. A lot of the tombs are about the size and shape of a phone booth, with just enough space for a mourner to step inside, kneel to say a prayer, and leave some flowers. It’s a beautiful and tranquil place—full of history and death, yet somehow strangely uplifting. Unlike, say, the Catacombs, Père-Lachaise is an active cemetery. We saw graves as recent as a month or two, as well as a funeral ceremony in progress. The cemetery manages to squeeze an increasing number of bodies into a finite and already crowded space. One way it does this is by combining the remains of multiple family members in the same grave. In many parts of North America, such a custom is unheard of, as each body is presumed to have its own casket, vault, and plot of land. But at Père-Lachaise (as in many other places), it is not uncommon to reopen a grave after a body has decomposed and add another one. Some family (or multi-family) tombs contain dozens of bodies, often in several separate (but contiguous) graves. Although the tombs of Père-Lachaise date back as far as 200 years, they are not all equally well maintained. Each family or estate is responsible for the upkeep of its own monuments, and while some are in excellent condition even after centuries, many have not been touched in decades. So it is very common to see tombs that have collapsed or otherwise fallen into disrepair. Often the engravings are completely worn away, making it impossible to tell who was buried there or when; maps of the cemetery show only the most famous occupants. In relatively recent times, Père-Lachaise has adopted a standard practice of issuing 30-year leases on gravesites, so that if a lease is not renewed by the family, the remains can be removed, space made for a new grave, and the overall deterioration of the cemetery minimized. He’s Dead, Jim The strangest and saddest thing about Père-Lachaise Cemetery is that a huge majority of its 1.5 million annual visitors are there primarily to see Jim Morrison’s grave. Morrison was lead singer for the Doors until his inauspicious death in 1971 at the age of 27. He was found dead—apparently from heart failure due to a drug overdose—in a Paris hotel. During his brief career, he attracted an immense number of fans, and in the more than three decades since his death, the mystique surrounding this charismatic, rebellious rock star has led to ever more followers—many of whom weren’t even alive in 1971. We saw the grave on our first visit to the cemetery and felt no need to see it again—it is one of the simplest markers in the entire cemetery, though it’s frequently adorned with flowers, candles, gin bottles, and graffiti. A security guard is usually nearby to discourage visitors from defacing Morrison’s grave (or others); this has been a tremendous problem in the past, and has caused considerable grief for the families of other people buried nearby. Because of the prevalence of 30-year leases on grave sites, there was great speculation a few years ago that Morrison’s remains might be moved elsewhere, and clearly that would have pleased a great many Parisians. However, Morrison’s grave has a perpetual lease, and as far as anyone knows, his bones will remain at Père-Lachaise permanently. As we were getting ready to leave the cemetery on our most recent visit, having agreed that there was no reason to visit Morrison’s grave, a twenty-something American girl stopped us and said, “Excuse me, but do you know where Jim is?” Alas, we did—as did everyone else. We pointed out the spot on our map. And I couldn’t help thinking: another pilgrim seeking the real location of a kind of fiction—history repeats itself. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/Edit-Piaf-grave-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/PereLachaise.8244eee5e89c.mp3"
	},
	{
		"title": "Pat O’Brien’s",
		"text": "In December, 2003, a New Orleans bar called Pat O’Brien’s celebrated its 70th anniversary. Although not old by New Orleans standards, Pat O’Brien’s is an icon of the French Quarter, a location to which nearly every tourist makes a pilgrimage. Numerous explanations could be advanced for the bar’s persistent popularity, but I think it comes down to a simple formula: strong drinks, reasonable prices, and atmosphere. Their motto since 1933 has been “Have Fun!”—not especially clever or inventive, but to the point. Truth be told, it’s a euphemism for “Have Rum!” At Pat O’Brien’s, the distinction between the two is vague at best. Just Add Rum A lot of bars opened in 1933; it was the year Prohibition was repealed in the United States. B. H. “Pat” O’Brien had been running a speakeasy called Mr. O’Brien’s Club Tipperary, but he turned the operation legit when the law allowed. In 1942, he moved the bar to its current location, a building erected in 1791 as the first Spanish theater in the U.S. But Pat O’Brien’s is best known for its signature drink, the Hurricane. This is a serious drink by anyone’s standard: a tall, ice-filled glass containing 4 ounces of rum and 4 ounces of a sweet, red passion fruit syrup—garnished with a slice of orange and a cherry. The name comes from the shape of the glass, which looks like a hurricane lamp. According to legend, the Hurricane was the brainchild of a liquor salesman in the 1940s who wanted to convince the bar they needed to buy a great deal of rum. (A variation on this story gives credit to a bartender looking for a creative way to deal with excess inventory of rum and grenadine. ) But you can buy a Hurricane anywhere in the city, and every gift shop sells Pat O’Brien’s Hurricane Mix so you can make them at home. The drink is only part of the equation; atmosphere and an indulgent attitude are the rest. There is, I have been told, indoor seating at Pat O’Brien’s—including two separate bars and a dining room—but I’ve never seen it. The several times I’ve gone there, everyone who’s anyone was seated out on the Patio—a large outdoor courtyard, at the center of which is a flaming fountain. I have never figured out how they engineered this thing so that the water doesn’t extinguish the fire, but it’s extremely impressive. Likewise, rumor has it that the establishment has a respectable kitchen, but I can’t recall seeing anyone eating. Food, after all, would tend to dull the effects of the alcohol. Come to think of it…that could explain why I can’t remember seeing any food. Steal This Glass Your waiter will hand you a booklet featuring photos of all their specialty drinks—concoctions with names like Cyclone, Squall, Breeze, and Typhoon—each in a distinctive glass. The booklet explains why each drink appears to cost about $3 too much: the bar assumes most patrons will want to take their glass home as a souvenir. Rather than policing the customers and charging shoplifters a fine, they do the reverse: offer you a refund if you turn in your empty glass at the counter. If you take it with you, an attendant outside the restaurant will package it in a cardboard holder for safekeeping. Pat O’Brien’s has franchises in Cancun, Orlando, Memphis, and San Antonio, as well as a thriving online business selling glasses, drink mixes, t-shirts, and tchotchkes of all kinds. But for the best and most authentic Hurricane experience, go to the source. And don’t forget to steal your glass. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/Pat-O-Brien.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Pat.4bc73aeec7af.mp3"
	},
	{
		"title": "New Orleans Cemeteries",
		"text": "There are few cities with as great a reputation for decadence as New Orleans. If you want rich, fatty, and extravagant foods, you can hardly do better than the Crescent City. Alcohol flows freely, too, and almost any desire of the flesh can be indulged for a modest fee (sometimes payable in cheap plastic beads). But decadence in the original, non-metaphorical sense is also a regular fixture in this city whose past is littered with pirates, devastating fires, and horrific murders. There has been a lot of death and destruction in New Orleans, and the associated signs of physical decay—whether of buildings or of bodies—are everywhere. Particularly striking to many visitors are the city’s numerous old cemeteries filled with creepy-looking aboveground tombs. Whereas death is usually kept hidden, buried out of sight, New Orleans gives residents and visitors constant reminders of the impermanence of life. The Dead Shall Rise Again Why aren’t the dead in New Orleans buried underground as they are in most of the rest of the country? Tour guides are fond of explaining (and sometimes embellishing) the practice to shocked tourists. The main issue, they explain, is that New Orleans is actually located slightly below sea level. Because of this, the water table is quite high. When early European settlers put coffins under six feet of earth, they found that the water level would often rise above them, especially during the city’s frequent floods. Since the coffins were filled with air, the water sometimes pushed them up through the earth, causing both a gruesome sight and a health hazard. To keep the coffins underground, holes were drilled in the lid to let air escape, and the coffins were weighted down with rocks and sand. But this was only partially successful, and in any case the saturated corpses did not decompose properly, leading to unsanitary conditions. The only solution was to bury the dead above ground. Tour guides seldom mention that above-ground burial was a common practice in both France and Spain, where many of the early settlers were from. Even without the resurfacing coffins—which, by the way, were the exception rather than the rule—this practice may well have been adopted simply to keep with tradition. In any case, this method is still widely used today, even though the water table has dropped considerably over the past two centuries as nearby marshes and swamps were drained. A Bone in the Oven The first cemetery in New Orleans designed for aboveground burial was the St. Louis #1 cemetery, which opened in 1789. Some accounts claim it was modeled after Paris’s famous Père-Lachaise cemetery, and there can be no doubt that the two bear a strong resemblance to each other. But Père-Lachaise wasn’t used as a cemetery until 1804, so that resemblance may be coincidental. Be that as it may, there is a significant difference that goes beyond the superficial similarities. At Père-Lachaise, the visible structures are, for the most part, just monuments; the bodies themselves are usually placed in vaults in the floors of the tombs. In New Orleans, however, bodies are usually placed inside the walls of the tombs. Because of the hot, subtropical climate, the tomb then effectively becomes an oven, and the high heat causes the body to decompose rapidly in a process that has been compared to a slow cremation. Within about a year, only bones are left. Just as an oven would not be constructed to bake a single loaf of bread, the tombs in New Orleans cemeteries are used again and again. The specifics vary depending on the exact design of the tomb, but a typical scenario is that after a year, the bones of the departed are swept into an opening in the floor of the tomb, which is then ready for its next occupant. It is a common practice to bury all the members of a family—or multiple families—in the same tomb, with names and dates added to a plaque or headstone as necessary. This procedure is not only sanitary and efficient; it also avoids the problem of growing real estate needs as time goes on. No Walk in the Park St. Louis #1 (there are, by the way, a #2 and #3 as well) is the oldest and most famous of about 15 aboveground cemeteries in and around New Orleans. Just as Jim Morrison’s grave attracts visitors to Père-Lachaise, St. Louis #1 has its own star: Marie Laveau, the Voodoo queen. Or, I should say, it has a tomb that many people believe contains her remains—no one is quite sure. But this uncertainty doesn’t stop legions of admirers from leaving offerings and marking the tomb with X’s in a supposed Voodoo ritual that is in fact apocryphal. This is just one of the cemetery sites associated with Voodoo practices—some genuine, some not. While you may not encounter any ghosts or Voodoo rituals in the cemeteries of New Orleans, you are very likely to encounter thieves, drug dealers, and other ne’er-do-wells. Every single brochure, visitor’s guide, and concierge will warn you, repeatedly and in the strongest possible terms, not to enter the cemeteries alone or at night. Some careless tourists have unwittingly become permanent residents—enough said. That’s not to say you can’t safely visit the cemeteries, just go in a group with a tour guide, during daylight hours. The cemeteries of New Orleans are often called “cities of the dead.” Not only do the tombs look like buildings, but the cemeteries are organized with streets (and street signs) much like the cities of the living. And it seems somehow appropriate that in New Orleans the decay of death faintly mirrors the decadence of life. That continuity between this life and the next is strangely comforting. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/NO-cemetery.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Cemeteries.b59e59c5e2af.mp3"
	},
	{
		"title": "Paris Sewers",
		"text": "Ah, Paris. It’s one of my very favorite places, not least because its ITSKI (Interesting Things per Square Kilometer Index) is off the scale. There are, of course, the very touristy sights like the Eiffel Tower, the Louvre, and Notre Dame, as well as thousands of cafés, shops, and bakeries that tantalize and inspire. There are also a great many lesser-known places of historical interest, including one where I spent an afternoon on each of my past two visits to the city: the sewer system. OK, the aroma wasn’t quite as pleasing as that of a fresh baguette, but the Paris sewer system—part of which has been turned into a museum that’s open to the public—is vast, intricate, and surprising in many ways. You may think of a sewer as nothing more than a conduit for waste, but in Paris, there’s more to the sewers than meets the nose. The tunnels that make up the Paris sewer system are mostly very large—almost the size of a subway tunnel. In most cases a central channel, wide enough and deep enough for a boat, carries waste and runoff water; on both sides are broad, paved walkways with enough headroom for most people to walk comfortably. Overhead are pipes that supply the city’s fresh water, telecommunications cables, and pneumatic tubes, among other things. But it’s the length and complexity of the tunnels that make them so intriguing: they almost exactly follow the layout of the streets above—in fact, every corner within the sewers has a street sign on it that mirrors the one on the surface. Where a wide boulevard runs on the surface, a wide sewer tunnel (or two) runs beneath; smaller streets have smaller sewers, and even side streets and alleys are duplicated underground. In all, there are about 1,300 miles (2,100km) of sewer tunnels underneath Paris. Wasting Away Up through the Middle Ages, Paris had a very rudimentary water-supply-and-waste-disposal system: the Seine River. Water was drawn from the river and waste deposited there, but the population of the city was still small enough that the river could purify the waste biologically. However, waste on its way to the river was a problem even then—it flowed through open sewers and gutters on nearly every street. The odor became, in many places, unbearable—but there was a worse problem: disease. The unsanitary conditions in the city were indirectly responsible for the plague, which wiped out a huge percentage of the population in 1348–1349. Precursors of the current sewage system date back as far as 1200, when the streets were first paved; a drainage channel down the middle reduced pedestrians' exposure to wastes. In 1370, Hugues Aubriot built a 300-meter stone-walled sewer under rue Montmartre, and in the late 1600s Louis XIV undertook additional sewer construction in certain areas. In the early 1800s, Napoleon ordered the construction of a network of sewer tunnels totaling 19 miles (30km.) But as the population of the city continued to swell, the primitive sewage systems could not keep up with it, and the Seine—still used for both intake and disposal—became absurdly polluted. A major outbreak of cholera in 1832 finally galvanized the city to find and implement a lasting solution to the problem. Flush with Pride In 1850 an engineer named Eugène Belgrand was hired to design a complete system for water supply and waste removal. The result was the current design, which by 1878 had reached a length of 373 miles (600km). In 1894, a law was enacted that required all waste to be sent to the sewers; the local saying at the time was that the city was completing its long transition from “tout à la rue” (all in the street) to “tout à l’égout” (all in the sewer). The sewer system was hailed as a technological marvel, a brilliant achievement that helped to usher Paris into the modern age. Paris sewers have been a tourist attraction since 1867, when the first public tours were offered. From 1892 to 1920, visitors rode through the sewers in a locomotive-drawn wagon. In 1920 the wagon was replaced with a boat, which floated tourists along until 1975. Today’s sewer tour consists of a very small portion of the sewers which has been turned into a museum. In order to read all the signs describing the timeline of sewer construction, visitors have to stand on a metal grating over an active sewer channel; this arrangement serves to keep traffic moving at a lively pace. Exhibits also show the machinery and techniques used to dredge the sand and solid waste from the channels and the computerized monitoring system, and of course restrooms are conveniently provided at the end so visitors can try out the system personally. The Stuff of Legend Apart from their relatively mundane primary function, the sewers of Paris have provided fertile material for a number of writers over the years. Victor Hugo spent about 50 pages of Les Misérables describing the sewers based on information he received from his friend Emmanuel Bruneseau. Bruneseau was the sewer inspector Napoleon commissioned to explore the tunnels and create an exhaustive map of the sewers as they existed in the early 1800s—until that time, the sewers had been assembled bit by bit, without a plan or written record, and were widely regarded as a mysterious and dangerous maze. Indeed, Bruneseau found a number of interesting artifacts during his explorations, ranging from lost jewels to the skeleton of an orangutan that had escaped from a zoo several years previously. Thus Hugo’s description of Jean Valjean’s adventures in the sewers, through which he carried Marius after he had been wounded, was based on factual information and is still considered historically significant. The sewers also play a role in Phantom of the Opera and in Umberto Eco’s novel Foucault’s Pendulum. Along with the sewers, Paris has a great many other underground passages, including an immense subway system, catacombs, and the crypts near Notre Dame. Although ordinary citizens do not normally have access to the sewers and most of the other tunnels, it is hard not to believe that they are used for, shall we say, secondary purposes from time to time. Imagining great escapes, secret meetings, and the occasional vampire makes a visit to the Paris sewers all the more fascinating. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/paris-sewers.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Sewers.1d9f33a14f66.mp3"
	},
	{
		"title": "Sutro Baths. Diving into the past",
		"text": "At the intersection of the Boulevard St. Michel and the Boulevard St. Germain, in the heart of Paris’s Latin Quarter, a ruin of brick and stone walls, vaguely recognizable as rooms or chambers, is being unearthed. This spot was once the site of Roman public baths, a place of leisure for local residents in the first to third century A.D. These baths were destroyed in the third century, and the property was later bought in 1330 by the Abbot of Cluny, who built a new structure alongside the ruins. During the French Revolution, the property passed out of the church’s hands, and had various owners (one of whom covered the bath ruins in six feet of soil) before being bought by Alexandre du Sommerard, a collector of medieval antiquities. Today, both of these sites are part of the Musée National du Moyen Age, a museum dedicated to the arts and history of the Middle Ages. Besides the relative novelty of visiting ancient (and surprisingly intact) Roman ruins below the streets of a 21st-century city, the baths give a fascinating insight into Roman culture. These baths consisted of a series of pools: the tepidarium (lukewarm), caldarium (hot), and frigidarium (cold). Guests normally moved from the lukewarm pool to the hot pool, then to the cold before retiring to rooms designed for socializing with other guests. Roman baths of this type were open to everyone, and were an important part of life in ancient Roman towns. Water, Water Everywhere Almost two thousand years later, in 1896, San Francisco entrepreneur and mayor Adolph Sutro opened his own public baths, albeit on a much grander scale. At the time, Sutro owned almost 1/12 of the land in San Francisco, and he decided to build his baths on part of that property, near his own home on Sutro Heights. Built to house 25,000 bathers, the three-acre complex included three restaurants, an amphitheater, an outdoor tide pool, and five saltwater pools of various temperatures—a design similar to the Roman baths. These pools were filled and emptied by the movement of the tide, the sea water moving into and out of the pools through a large tunnel. Sutro conceived of the baths as a benefit to the public, much as the Roman baths were intended for everyone. In fact, when he learned that train operators were charging seaside visitors two fares to reach the baths, he built his own rail line to bring people there for the price of one 5-cent fare. This was in keeping with Sutro’s general concern for the public welfare; in 1869 he successfully agitated for the construction of a tunnel linking various Comstock Lode mines in Nevada to ensure better working conditions for miners (although he did also benefit financially from the completion of the project). Road to Ruins After its heyday in the first half of the 20th century, the baths fell into disuse, and in fact were in the process of being demolished when a fire gutted the property in the 1960s. This left a sprawling mess of concrete foundations and melted metal. By the time I first visited the site, in the 1990s, it looked incredibly aged, its former bathing pools choked with algae, and its metal pilings eaten away by the tide. But despite this decay, or maybe because of it, the scene was incredibly picturesque, with a gorgeous view opening out onto the ocean, and white calla lilies dotting the upper slopes of the property. At the time I didn’t know the history of the place, but was fascinated by its glorious state of decay. After visiting the Cluny baths in Paris, I immediately thought of the Sutro ruins, and was surprised to realize that the Sutro Baths appealed to me on the same level as the Roman baths, despite having been built almost two thousand years later. There is something mysterious and melancholy about any place that has outlived its use, and a modern visitor is similarly drawn to imagine what it once was like, whether it has been abandoned for a hundred or a thousand years. On the one hand, this shows the limits of human memory, that anything that occurs before our lifetimes seems foreign and unknowable, but on the other, it highlights our own sense of mortality, and the hope that our works will be remembered and wondered over when we are gone. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/sutro-baths-120.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Sutro.5d401607d78e.mp3"
	},
	{
		"title": "The Skin Project. Short story as body art",
		"text": "Here in San Francisco, if you want to appear inconspicuous in public, the best way to do so is to wear leather, dye your hair in fluorescent colors, and have all your visible skin tattooed, pierced, or both. I exaggerate, of course—but let’s just say that body art is big in this town. Personally, I don’t find the notion of permanently altering my appearance appealing. My tastes in clothing, hair styles, and so on change over time, so I don’t want to lock myself into a look I might feel less enthusiastic about in a few years. There’s also the whole issue of pain, which, all things being equal, I prefer to avoid. If I ever were to have a tattoo, though, it would have to be both discreet and very meaningful—something more than mere decoration. One artist is using tattoos on human skin as a medium for literature rather than images, and in an extremely unconventional manner at that. New York author Shelley Jackson has written a 2,095-word story titled “Skin,” which she refers to as a “mortal piece of art.” By the time the project is finished, each word of the story will have been tattooed on a different person’s body; over 1,700 of the tattoos had been completed by late 2004, using participants from around the world. I Give You My Word Someone who encounters one of the “words,” as she calls the participants, will be able to read at most one word, along with any adjacent punctuation. Volunteers must sign a contract stating that they will receive a tattoo of whichever word Jackson assigns them (in black ink and in a classic book font) and that they will send her a photograph of the finished tattoo as well as a portrait of themselves that does not show the tattoo. Jackson further stipulates that if a volunteer receives a word that could be considered a body part (“back,” say), that word must be tattooed on another part of the body. Only after the tattoo is finished does the participant get a copy of the entire story, which, according to the contract, must be kept secret. Jackson’s intention is that the complete story never be published or revealed to the general public in any fashion; only those who receive the tattoos get to read the entire piece. However, when the work is finished, Jackson hopes to arrange portraits of the participants (not showing the tattoos) in the order in which their words appear in the story, complete with paragraph breaks. When a “word” dies, according to Jackson, the story will change—and she will attempt to attend the funeral, though she expects most of the words to outlive her. When all the words have died, the work as a whole will be dead. Going With the Flow The idea for Jackson’s human work of literature came partly from the art of Andy Goldsworthy, the subject of the 2001 documentary Rivers and Tides. Goldsworthy uses only natural materials for his pieces, including icicles, leaves, rocks, and dirt. Many of his works melt within hours, disappear with the next tide, or float away in the river (hence the film’s title). And yet the ephemeral nature of the art is precisely what he means to explore. In Jackson’s story, meanwhile, not only is the work as a whole temporary, but all of its components are also autonomous. Although my tastes in art tend toward the conventional—and I still do not have the slightest interest in getting a tattoo myself—I find something about these organic works of art strangely compelling. If Jackson decides to do an even more ephemeral sequel called “Nails” or “Hair,” perhaps I’ll volunteer to become a word myself. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/tattoo-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Skin.c91074b97414.mp3"
	},
	{
		"title": "New Orleans Walking Tours",
		"text": "The first time I visited New Orleans, I didn’t know anything about the city except that it was legendary for its Mardi Gras celebrations. But the more I learned about New Orleans, the more I came to love it. The history of the city is immensely colorful and complex. New Orleans has some of the most distinctive cuisine in the United States, a well-earned reputation as a center of music and culture, and a vibrant nightlife. But what I find most interesting about the city is its rich collection of legends and myths. The best way to learn about them is to take one of numerous walking tours of the French Quarter. The Spanish French Quarter The French Quarter—the focal point of the city for most tourists—is a well-defined area about 13 blocks by 7 blocks, bordered by the Mississippi River on the south. This was the original city of New Orleans, established by French settlers in 1718 and controlled by France until 1762, when it was given to Spain. The city remained under Spanish rule until the early 1800s, when it was secretly returned to France, only to be immediately turned over to the United States as part of the Louisiana Purchase. The French Quarter is so named because for many years it was the district in which the majority of the French-speaking population lived. However, much of the original city was destroyed by massive fires in 1788 and 1794. Since Spain was in control during that time, the new buildings for the most part reflected Spanish architecture, and that is what survives today as the French Quarter. Most buildings are only three or four stories high. Wrought-iron balconies extend over sidewalks in the business district, and louvered shutters cover most windows and doors. The French Quarter has the feeling of being very old—for a North American city—largely because of strict construction rules designed to protect the historical character of the buildings. But it’s not just the old buildings that give the French Quarter its unique vibe. The traffic usually consists more of pedestrians and horses than cars. Every other door seems to lead to a restaurant or bar, and people walking down the street without a beer or margarita in their hands seem out of place. You never have to walk more than a few blocks to find a voodoo shop, antique store, or “gentlemen’s” club. As I was wandering around the French Quarter during my first visit to New Orleans, I kept seeing signs and brochures for walking tours—particularly “ghost” tours. I thought a tour might be a good way to get to know a bit about the city, and I was curious about the whole ghost angle. So I showed up at the designated location one evening, paid my US$15, and set out with a guide and about a dozen other tourists to see what mysteries we could uncover. We visited a number of historical sites and heard about the many groups of people who shaped the city’s culture: the French and Spanish, Cajuns, Creoles, and free people of color. But New Orleans has also been a hangout for pirates, slave traders, and rogues of all stripes. As a result, a great many gruesome murders have taken place in the city, not to mention infamous suicides, executions, and deaths caused by the great fires. So it’s little surprise that many of the buildings in the French Quarter are said to be haunted. Spirits and Spooks The typical tour guide spiel includes a heavily embellished history of a building’s former owner, the events leading up to the significant deaths, and anecdotes about recent sightings of ghosts, mysterious sounds, or curses that have supposedly kept buildings uninhabited for decades. The stories are all entertaining, even though it’s sometimes difficult to tell at what point the history becomes myth. But not all the tales are apocryphal, and some are really quite chilling. At one point, our tour guide stopped us and said, “Notice that blood-red house across the street. This building was once home to one of the most notorious characters in New Orleans history: Richard Simmons.” Plenty of companies offer walking tours of the French Quarter, each with its own twist. Some are highly theatrical, with tour guides dressed as pirates or vampires; others offer a more conservative approach that emphasizes historical accuracy. There are ghost tours, vampire tours, witchcraft and voodoo tours, cemetery tours, and so on. There are also walking tours of the city’s Garden District across town, where the main attractions are lavish houses and beautiful landscaping. I’ve taken perhaps half a dozen different walking tours in New Orleans. Some were better than others, and there were certainly instances of overlap and contradiction. But judging by the number of interesting things encountered per hour (or per dollar), walking tours are the perfect way to combine education and entertainment as you explore New Orleans. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/new-orleans.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/New_Orleans.acf6f0c03761.mp3"
	},
	{
		"title": "The Musée Mécanique. Good old-fashioned interactive multimedia",
		"text": "Fog, as I have said for many years, is my all-time favorite weather condition. Other than its impact on driving, I like everything about fog—the coolness, the dampness, the way it muffles sounds, and especially the mysterious, spooky quality it gives its surroundings. So the first time I took a streetcar out to San Francisco’s Ocean Beach years ago, I was delighted to discover that, more often than not, the entire area is covered with fog. Morgen and I walked along the beach and up a hill to a building called the Cliff House, a restaurant with a majestic, sweeping view of the mist—and, occasionally, bits of the ocean and nearby Seal Rock. The Cliff House is a favorite tourist destination—not so much for the food but for the view, the gift shops, and a few other attractions nearby. The attraction we had gone there to see was located inconspicuously around the back, downstairs in the basement of the Cliff House—and advertised only by a small, folding wooden sign on the sidewalk near the restaurant that said, simply, “Musée Mécanique.” The Old Machine and the Sea The Musée Mécanique (or Mechanical Museum) looked like something that belonged a century in the past—an effect enhanced considerably by the fog. Inside a large room with peeling paint and a crumbling ceiling was a collection of hundreds of very old mechanical toys, games, and other amusements. For example, there were dozens of automatons—machines in which small figures walk, dance, or otherwise move around when you insert a coin. There were fortune-telling machines, games to test your strength (the electric arm-wrestling machine was frighteningly strong), flip-card “movies,” a player piano, and all sorts of other mechanical shows and diversions. The amazing thing was that all these machines—ranging from the very campy to the very sophisticated—were fully functional. Admission was free, but nearly every machine required a quarter (or two) to operate it. The money was well worth it, though: you just can’t get this kind of entertainment anymore. In the days before electronic toys and games, designers accomplished some impressive feats of engineering and miniaturization using simple motors, gears, levers, and springs. The result was an arcade that, while lacking video screens and digital controllers, was much more interesting and engaging than a modern gaming venue. The point of dropping in your change was not, in general, to win anything; it was simply to marvel at the skills of the machines' designers. The March of Quarters The Musée Mécanique houses some of the last remnants of an amusement park called Playland at the Beach, which operated along San Francisco’s oceanfront from 1928 to 1972. When the park closed, a collector named Edward Zelinsky purchased its mechanical games from owner George Whitney, Jr. Zelinsky had already been collecting antique gadgets of this sort for decades, and had taught himself how to repair and maintain them. Shortly after acquiring the Playland machines, he put the bulk of his collection on public display in the basement of the Cliff House, and along with his son Dan has kept it going as a labor of love ever since. The Musée Mécanique is now the world’s largest private collection of antique coin-operated arcade machines, and other than being updated to use quarters rather than the original pennies or nickels, the machines have kept all their original charm. Returning to the Musée in early 2002, I saw a sign on the window that troubled me. It said the museum was likely to close permanently within a few months. I talked with the manager about it, and then a few weeks later, read a more detailed account in a local newspaper. The story was that the building, which is managed by the National Park Service, was badly in need of renovation. Following the repairs, the park service wanted to put a more profitable business in the spot where the Musée had been. They hoped to construct a new building nearby at some point in the future that could house the Musée’s collection, but there were no funds at the time for such a building, and in any case, there was no other space available for the Musée in the meantime. Left with no home for the machines, Zelinsky was considering whether to put the collection into storage indefinitely or simply auction it off. The Musée Lives On When the newspaper article was published, public outcry was immediate and overwhelming. Within a couple of weeks, more than 20,000 people had signed petitions asking the park service to save the Musée—to assure it a temporary home, as well as permanent housing after the Cliff House renovations were complete. Shortly thereafter, a follow-up article reported the good news: the park service had assured the owners that they would find a way to keep the Musée open. The Musée Mécanique is currently housed at Pier 45 on San Francisco’s Fisherman’s Wharf, where it will remain until its new home is complete—whenever that may be. The renovations on the Cliff House were completed several months ago, and now the National Park Service says it plans to build a new visitors' center nearby, which is to include space for the Musée. However, it’s anyone’s guess when this will happen. The Fisherman’s Wharf location lacks the dilapidated charm of the Cliff House basement and is not nearly as foggy. On the bright side, it’s right in the thick of the city’s most densely touristy area, so it’s bound to attract more visitors. Admission is still free, but take a roll of quarters for a great value in entertainment—and nostalgia. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/mechanical-museum.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Musee.23875742a458.mp3"
	},
	{
		"title": "Oradour-sur-Glane. Ghost of a massacred French village",
		"text": "History was always my least favorite subject in school. The endless lists of names, dates, and places did nothing but make me sleepy. Events that took place hundreds or thousands of years ago in Mesopotamia, or Rome, or Russia may be extremely important, but I could never picture them, never really come to grips with what they were like. Besides, the problem with history is that there’s just so much of it. There’s no way I could keep it all straight. So about 20 years ago when the topic in class was World War II, I managed to absorb just enough information to get through the exams, and then promptly forgot most of it. I understood the broad outlines—or so I thought—but the details mostly eluded me. I knew, for example, that France was occupied by the Germans, that the Allies landed on D-Day and routed the invading army, and that this was a deciding moment in bringing the war to an end. But the simplified image I had was that of a huge, definitive victory, as though a day after the landings in Normandy, the occupation was over and France was back to normal. That may have been a close enough approximation to get me by in high school, but it was very far from the truth. Four days after D-Day—June 10, 1944—the German army was still firmly in control of most of France, and it was then that one of the most notorious atrocities of the war took place in the quiet French village of Oradour-sur-Glane. The End of Obscurity Oradour had only about 650 residents and no particular claim to fame. It was a cheery, modern village with all the necessary amenities: butcher shops and bakeries, cafés, hair salons, schools, tailors, a church, a Renault dealership, and even an electric streetcar connecting the village to nearby cities. But it was neither a commercial power nor a tourist destination—just another small village. Oradour was notably insignificant in another way, too: it was not known as a center of the French Resistance against the Germans. It was, or should have been, small enough and obscure enough to stay out of trouble, and indeed, for the most part the occupying German troops had ignored it. But after D-Day, Resistance fighters stepped up their efforts to impede the travel of German troops from across France to reinforce the Normandy contingent. On June 7, not far from Oradour, they blew up a railway bridge, killed several soldiers, and took a high-ranking SS officer prisoner. There is some evidence that the Resistance may also have attacked a German convoy carrying gold, making off with the cargo. The enraged Germans felt obliged to retaliate, and they chose to take their frustrations out on Oradour. The reasons Oradour was chosen have never been entirely clear. It may have been the Germans believed their missing gold was hidden there; it may have been that it was small and easily contained; or it may have been random. The Oradour Massacre In any case, the German army decided they were going to wipe out an entire town. On the morning of June 10, troops surrounded Oradour. They went from building to building, systematically rounding up all the inhabitants of the town and herding them into the public square. Then the women and children were taken to the church and locked inside, while the men were divided into groups and taken into various barns and garages. The soldiers set off a bomb in the church. The women who were not killed by the blast tried to break out to escape the smoke, but they were immediately shot by soldiers waiting outside. Meanwhile, other troops used machine guns to mow down the groups of men, and then calmly stepped through the heaps of bodies, shooting anyone who still moved. In all, 642 people were killed—men, women, and children—all of whom had carefully kept their distance from the events of the war. The Germans did not stop there, however. They were ordered to disfigure the faces of the dead so they could not be identified, and then burn the bodies. After looting the houses and stores, they then burned every one of the village’s 328 buildings. When they left the following day, Oradour was entirely obliterated—a lifeless, smoking shell where a vibrant village had stood the morning before. The Aftermath The story of Oradour is known from a handful of people who managed to escape. Two women and one child climbed out of the church through a broken window, though only one woman survived her injuries; five wounded men escaped from one of the barns; and one child ran when he saw the soldiers in town. Other than those seven, the only survivors of Oradour were about 20 people who fled when they saw the approaching troops and residents who were out of town for the day. The French government decided not to rebuild Oradour, but to leave the remains of the old village as a monument to the dead and a reminder of what had occurred there. Nine years later, in 1953, a new village of Oradour, adjacent to the former site, was opened. That same year, members of the SS who had participated in the Oradour massacre were tried for war crimes, with several of them being sentenced to death or a lifetime of hard labor. Meanwhile, a debate was taking place regarding French citizens who had been forced to serve in the German army: should they, too, be punished for their roles in the war? A week after the guilty verdicts were handed down, France resolved that issue by passing a general amnesty law, freeing all those who had been convicted. This infuriated the survivors and the families of those who died in Oradour, and strained relations between the new Oradour and the national government for many years. The Ghost of Oradour We drove into Oradour on a hot, cloudless day in June, a last sightseeing stop in France before heading back to Paris for our flight home. The only entrance to the old village is through a modern visitors' center, with an extensive exhibit detailing the events leading up to the massacre, a video featuring stories from the survivors, and a description of the bitter aftermath. After taking in the sobering history, you walk through a tunnel into the town. For the most part, everything that was made of wood or glass was destroyed—roofs, floors, windows, doors; only stone walls, sidewalks, and metal fixtures remain intact. Small signs indicate the function of each building and the name of its former owner. I was surprised at how large and spread out the village was; the scale of the destruction was truly astonishing. On the edge of the village is the cemetery, which for me was the most striking part of the town. It was deeply disturbing to realize that the entire town is buried here, and more disturbing still to read, again and again, “Died June 10, 1944.” Unlike the sites we had visited in Paris where the nameless dead of centuries ago were interred, this cemetery struck much closer to home. Though I have no personal connection to anyone from Oradour, I somehow felt as though this could have been my village, my friends, my family listed on the roll of the dead. It’s hard not to be affected by the randomness and ruthlessness with which so many innocent people were killed. Despite the controversy over amnesty for those who took part in the killings, the overall message conveyed to Oradour visitors is not merely to remember, but to remember with equanimity. The massacre of Oradour, after all, was one of retaliation; the only purpose revenge would serve would be to perpetuate the cycle of more retaliation. The world does not need more terror, death, and destruction—whether in an idyllic French countryside, in the Middle East, or anywhere else. The only way to stop that cycle is to take the bold and audacious step of countering violence with peace. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/Oradour-sur-Glane-Church-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/09/Oradour.d4299804b1a5.mp3"
	},
	{
		"title": "Carbon Dating. Decay rates create debates",
		"text": "It has become my custom here at Interesting Thing of the Day to choose topics that I think will be unfamiliar to most readers—a sort of implicit “I’ll-bet-you’ve-never-heard-of-this” test. I think it’s fair to say that any educated person over the age of 10 or so has probably heard of carbon dating. But I realized the other day that even as an adult with a fair amount of scientific knowledge, I could not articulate exactly how or why carbon dating works. So I did a bit of research to fill in the gaps in my understanding, and not surprisingly I found the details to be quite interesting. What did surprise me was the huge number of Web sites and books vigorously attacking the legitimacy of what I had thought was a fairly straightforward, uncontroversial test. Apparently carbon dating is right up there with evolution in terms of the disdain it evokes from certain religious groups. As is often the case, the controversy over this topic is at least as interesting as the topic itself. Carbon Copies Carbon dating begins, logically enough, with carbon. High in the atmosphere, cosmic rays strike nitrogen atoms, producing a radioactive carbon isotope known as carbon-14 (or 14C); this is why it’s technically known as radiocarbon dating or, sometimes, carbon-14 dating. Carbon-14, along with the more common, stable (nonradioactive) carbon isotopes carbon-12 and carbon-13, combine with oxygen to produce carbon dioxide. In the process of photosynthesis, plants “breathe” this carbon dioxide, convert the carbon into carbohydrates for fuel, and then release the oxygen into the atmosphere as a byproduct. So some of the residual carbon in plants is carbon-14. Animals, in turn, eat the plants (or eat other animals that have eaten the plants), and thus the carbon-14 atoms propagate throughout the food chain. The result is that everything that is alive, or once was, contains some number of carbon-14 atoms. Although the number of carbon-14 atoms varies from one organism to another, the proportion of carbon-14 atoms to carbon-12 atoms is basically constant—and roughly the same as the proportion found in the atmosphere. Carbon-14 decays (loses its radioactivity, converting back to nitrogen-14) at a known rate; its half-life, or the time it takes for half a given number of carbon-14 atoms to decay, is about 5,730 years. When an organism dies, it stops acquiring new carbon-14 atoms. Given that the ratio of carbon-14 atoms to carbon-12 atoms in a living thing is a constant, one can determine the number of each in a sample of organic matter (using sensitive equipment to detect the amount of radiation remaining), and then do a little bit of math to determine how long it’s been since the organism expired. For example, if a sample emits radiation indicating the presence of 10 carbon-14 atoms and we know from its mass that it originally must have contained 20, that means the plant or animal from which the sample was taken died about 5,730 years ago. Eventually, however, all the carbon-14 atoms will decay—or at least enough of them will that the amount of radiation they emit can no longer be distinguished from ordinary background radiation. So for all practical purposes, carbon dating is useful only for samples up to about 50,000 years old (though this depends somewhat on the mass of the sample—and some advanced techniques can reliably measure carbon-14 levels low enough to indicate an age of 100,000 years). Thus, carbon dating would not be useful in, for example, assessing dinosaur bones. Constants and Change There are other limitations in carbon dating too. For example, with a few exceptions, the technique can only be applied to once-living items such as bone, leather, wood, and cloth—not, say, rocks or metal. More importantly, though, the accuracy of carbon dating rests on several crucial assumptions. For one thing, the rate of carbon-14 production in the atmosphere (and thus the level of cosmic ray activity) must have been pretty much constant for the past several dozen millennia. Likewise, the proportion of carbon-14 to carbon-12 in the environment must have remained fairly constant. And in any given sample, one must be certain that contaminants from other time periods are not present—a sometimes-tricky issue. As a matter of fact, increased hydrocarbon emissions over the past century have greatly increased the amount of carbon-12 in the atmosphere, while nuclear detonations during the past 50 years or so have increased the amount of carbon-14. And at other points in history, climatic changes and other large-scale global events have altered the picture in other ways. So scientists performing carbon dating routinely calibrate their findings to adjust for these known issues, using other dating techniques (such as counting the rings on old trees) to corroborate their findings and help them fine-tune the scale. But these and other seeming sources of uncertainty have been seized upon by some very vocal groups of creationists as loopholes, allowing them to challenge the validity of carbon dating. According to some people, a literal reading of the Bible (taking into account all the genealogies and so forth) yields a creation date of around 7,000 years ago. Thus, any scientific finding that seemingly assigns an older date to any object must be mistaken—and carbon dating, critics suggest, if it is to be believed at all, should be calibrated to the Bible. Creationist arguments against carbon dating (and every other scientific statement that suggests an older Earth) are extensive, passionate, and very impressive-sounding—though they are most often made by people without actual scientific credentials, and therefore dismissed (with varying degrees of refutation) by the scientific community. As an outsider to this debate, I find it all rather amusing, in a sad sort of way. Discussions between creationists and mainstream scientists typically have an apples-and-oranges character, much like discussions between “pro-choice” and “pro-life” advocates or politically “liberal” and “conservative” partisans. Each side has unshakeable beliefs and therefore insists on bending any available evidence to support them, so very little real discussion takes place. Speaking as a layperson, rather than a professional in science or theology, I find the evidence supporting the reliability of carbon dating vastly more compelling than the evidence supporting a 7,000-year-old Earth. But then, I don’t have an axe to grind, and even I did, carbon dating couldn’t tell us how old it was. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/Carbon.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Carbon.ea77d3bd36d5.mp3"
	},
	{
		"title": "Pennsylvania Coal Fires",
		"text": "There are a bunch of little facts that I sort of half-learned in elementary school, and have had a hard time remembering ever since. I remember the terms “Dromedary” and “Bactrian,” for example, but that crucial bit of information about which camel has one hump and which has two just didn’t stick. The same thing goes for names of cloud types—cirrus, cumulus, nimbus—I know the names but I forget which is which. And then there’s coal. I vividly recall learning about anthracite, bituminous, and lignite coal as a child in Pennsylvania, a state legendary for its coal production. But which type had which properties? It’s all a blur now. Since I did not pursue an education or profession in which this knowledge was needed, my brain apparently decided to delete those records to make space for really important information, such as Star Trek trivia. I do remember, though, that when I was quite young my father took me to a coal mine that offered tours to the public. I thought it was absolutely the coolest thing ever. Getting to ride in that train down into the dark tunnels, seeing all that amazing machinery, and imagining the life of a miner was exciting and mysterious. I’ve always had a fondness for caverns and tunnels—maybe that’s where it all started. As an adult living in California, I rarely think about coal mines. I do, however, think about wildfires and forest fires, especially in the dry months of late summer. Everyone understands that these things just happen—due sometimes to natural causes, sometimes human causes (accidental or intentional). And when they occur, vast firefighting resources are unleashed to contain the fires in order to minimize the risk to homes and businesses. After all, they pose an imminent threat, plain for all to see (and smell). Of course they have to be stopped. I learned recently that Pennsylvania has the distinction of being home to the largest number of underground coal fires in the United States. And further, that some of these fires have been burning continuously for upwards of 40 years; that they’ve obliterated entire towns; that they vent an unimaginable amount of carbon dioxide and other gases into the already overburdened atmosphere; and that, for the most part, very little is being done about them. All these facts astonish and disturb me, but none more than the very possibility of the fires' existence. How can a fire rage underground for decades? The answer: very easily. Fire in the Hole Picture an abandoned coal mine—there are thousands of them in Pennsylvania. Although much of the coal has been removed, plenty still remains—perhaps just not in a configuration that’s easily extractable. Miles of tunnels, their ceilings shored up with columns of unexcavated coal, lie empty. Though the entrance to the mine may have been sealed, that seal was by no means complete or airtight. And suppose some of the coal lies very close to the surface—or is even visible in an exposed seam. Now something happens to ignite the coal. It may be a natural cause—lightning, for instance, or even spontaneous combustion given the right conditions. Or maybe a forest fire, or someone burning garbage. Once the coal begins burning, it feeds off the air in the tunnels and the ventilation shafts that were used to supply air to the miners. Still more air seeps through natural cracks in the rock. Coal burns very easily, requiring only a tiny amount of oxygen—and with millions of tons of fuel handy, it soon spreads beyond the existing tunnels and into the thick strata of coal that lie under immense tracts of land. When enough of the coal burns through, the ground above it collapses—an effect known as subsidence. The newly formed cracks or pits allow more air in, accelerating the fire’s spread. Meanwhile, carbon dioxide, smoke, and steam escape, killing plants and making the area’s air unsafe for humans and wildlife. Our State Insect: The Firefly (no kidding) No one can say for sure how many such fires currently rage in Pennsylvania, but the number is unquestionably in the dozens. The number is hard to pin down because coal fires that seem to be out can smolder at very low temperatures for years and then flare up again; the process of checking to see whether they’re still going carries with it the risk of making matters worse by adding more air. The largest and most infamous of Pennsylvania’s coal fires is under the town of Centralia. It started in 1962, apparently due to someone burning garbage in the town dump. For decades, a combination of bureaucratic delays, funding shortages, and ineffective containment efforts permitted the fire to grow to the point that the entire town (formerly home to 1,100 people) was condemned and basically shut down. A handful of residents remain, despite repeated government orders to evacuate. They enjoy peace and quiet for the most part, but worry about the ongoing threats of subsidence, toxic fumes, and careless tourists injuring themselves. Down and Out Underground coal fires are notoriously difficult to extinguish. If it were a simple matter of pumping water (or some other substance) into the old mine tunnels to suffocate the fire, it would have been out long ago. Part of the problem is simply getting to the spots that are on fire; another part is pushing out all the oxygen, given the very porous nature of the coal and the rock in which it’s embedded. And then there’s the scale: the volume of underground space affected by the fire is immense (and growing all the time). Conservative estimates put the cost of containing (not extinguishing) the Centralia fire alone at well over half a billion dollars. And, of course, that’s just one fire—there’s always another. Since that sort of money is nowhere to be found, officials throw up their hands and say, “We’ll just let it burn out.” How long will that take? Experts think there’s enough coal to keep it going for another 250 years. Pennsylvania is by no means the only place with unquenchable underground coal fires. Similar fires burn in other parts of the U.S., as well as China, India, Indonesia, and elsewhere around the world. Under Australia’s Burning Mountain Nature Preserve is a coal fire that has been burning for at least 2,000 years, and possibly as long as 5,500 years. In all, there may be hundreds of thousands of active coal fires, and only in rare cases are any serious efforts being made to stop them. By some estimates, coal fires are a bigger contributor to global warming than cars—a truly staggering thought. Although fighting them is difficult and expensive, very little money has been spent looking for technological solutions. And one of the biggest reasons is simply that the fires are, for the most part, invisible. While a California wildfire may be an obvious threat requiring immediate action, it’s hard to convince governments to put money into solving a problem that can’t be seen—especially when it’s relatively cheap simply to relocate residents and put up fences and warning signs. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/Coalsludge-Pensilvania-120.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Coal.c85ae1e31d3c.mp3"
	},
	{
		"title": "Modern Mummies",
		"text": "We have all heard of people who had their bodies cryogenically preserved after death in the hope that some day, medical science will be able to bring them back to life and cure whatever illness caused their demise. That hope may be overly optimistic, but I can at least respect the logic behind the decision. Unlikely though it may be, I can’t say categorically that such a restoration is beyond the reach of some future science. With that single exception, however, I have never understood the ages-old practice of keeping dead bodies from decaying naturally. It’s not that I’m some soulless pragmatist, but I believe that death is the point at which a body becomes superfluous to its erstwhile owner—keeping it intact thereafter seems superstitious and creepy. Of course, that’s just my opinion. Some of my best friends are superstitious and creepy, and I don’t hold it against them. Grave Concerns Each culture has somewhat different beliefs about what should happen to a corpse. In North America, the majority of the deceased are embalmed so that they’ll look lifelike for a funeral several days later; they are then buried in airtight caskets inside concrete vaults or grave liners. Some people may derive comfort from the notion that a departed loved one is still somehow whole, but in ancient Egypt, much more was at stake than the feelings of the bereaved. During the centuries when the art of mummification was practiced, it was based on a deeply held belief that only if the tissues of one’s body were kept intact after death would the soul survive throughout eternity. To oversimplify greatly, the goal of Egyptian mummification was to rid the body of moisture so that it would not decay. They had to start with the internal organs, which have the tendency to remain moist for a long time after death, providing a fertile breeding ground for bacteria. Some of the organs were deemed important enough to preserve separately; others, like the brain and kidneys, were seemingly useless and were discarded. The empty cavities were filled with a desiccant salt called natron, which also covered the outside of the body. After a period of a month or more, when it had absorbed all the moisture from the flesh, the salt was removed. The body was then stuffed with spices and sawdust to restore a more natural shape, covered with long strips of linen bandages, and buried in a sarcophagus. Preservation Reborn Thousands of years later, mummification is making a comeback. In 1994, Bob Brier, a professor at Long Island University in New York, performed an Egyptian-style mummification on a man who had died and left his body to science. Brier followed the historical procedures as closely as he could determine, in an effort to learn details about the process that could not be discerned simply by studying mummies that had been sitting around for millennia. At the time, Brier’s project was the subject of numerous news reports and even a National Geographic documentary. But now he has been upstaged by a new, high-tech method of mummification that is available to the general (dead) public—for a price. Summum is a religious group based in Salt Lake City, Utah, founded in 1975 by Summum “Corky” Ra (né Claude Rex Nowell). Among other things, Summum teaches the importance of preserving the body after death—and conveniently, they offer just such a service. For about US$70,000, your body will be carefully preserved using a patented process that inhibits decay without drying out the flesh. Your mummified body will be placed into its own custom-made bronze sarcophagus, which can then be buried or entombed just like any other casket. Hundreds of people have already signed up for the service, but none of these people has died yet—so far, Summum has only mummified pets. As enticing as this deal is, I can make you a better offer. For only $50,000, I would be happy to sit down with you and help you to feel better about the natural process of decay. I’ll even throw in a trip to Egypt and a large batch of my homemade chocolate chip cookies, which are guaranteed to make you happier in life (and, I’m sure, well beyond). ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/09/Ramzes-mummy.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Mummies.dbf75a50ac65.mp3"
	},
	{
		"title": "Deyrolle",
		"text": "When we were in Paris last year, a large number of transit and public utility workers were on strike. I am reliably informed that strikes of this kind are extremely common in France; a week when no one is on strike would be considered strange. In any case, a lot of people weren’t showing up for work, either because the subways weren’t running or because they were participating in demonstrations on the streets. As a result, museums and other attractions were forced to scale back their hours of operation. After leaving the Musée d’Orsay early, we had some time to kill on the left bank, and we took the opportunity to look up a nearby shop Morgen had read about. In Paris to the Moon, Adam Gopnik describes the five years he spent living as an expatriate in Paris along with his wife and young son. One of their favorite places to go on rainy days was a strange and fascinating shop called Deyrolle on the Rue du Bac. Deyrolle could be described as a taxidermy shop, but that doesn’t begin to do it justice, and besides, taxidermy shops are not exactly a dime a dozen—especially in Paris. The Dead Zone When we arrived at Deyrolle, we couldn’t determine if it was even open for business. At street level, there are large glass display cases on either side of the door; beyond that, a dark foyer. There was no sign saying “Ouvert,” no lights on, no people, no signs of life. In fact that last point should have been the tip-off that everything was normal. We tried the door; it opened. There was a creaky old staircase ahead of us, and we tentatively mounted the stairs. When we got to the top we were greeted by the reassuring glow of fluorescent lights, and the somewhat less reassuring sight of a moose staring at us. I had always thought of taxidermy as a craft marketed rather narrowly to hunters wishing to display their prized trophies. At Deyrolle, no animal is too exotic, or too ordinary, to be stuffed. You’ll walk past a zebra, lions, tigers, and a giraffe, not to mention a polar bear, a warthog, a chimpanzee, and a kangaroo. But you’ll also find every imaginable barnyard animal, as well as birds, deer, rabbits, and—most surprising of all—quite a few dogs and cats. The animals are scattered throughout the store as though they were customers, and they are for the most part extremely lifelike, sometimes eerily so. Some of the more exotic animals are for display only, but most are available for sale or for rent. That’s right: you can rent a dead zebra, elephant, or bear for your next party. Take This Pet and Stuff It The shop was founded in 1831 by Emile Deyrolle, and it moved to its current location—the former home of Louis XIV’s banker—in 1881. It is now owned by a company called Le Prince Jardinier that runs a number of specialty household goods stores. Most of the people who walk into Deyrolle are there mainly to browse, though the store does a fairly brisk business in mounted butterflies, beetles, and other insects, as well as rocks, fossils, and a variety of educational products. It is, however, a functioning taxidermy operation, and for a few hundred euros you can have your household pet stuffed when it expires. (The cats and dogs around the store were for the most part abandoned by their former owners, who sent them to be “reanimated” and then never returned to claim their pets.) Deyrolle politely declines requests by humans to have their mortal remains stuffed and mounted; I heartily agree with the wisdom of this policy. Deyrolle looks as if it has changed little in the last hundred-plus years. Like its products, it seems to be in a perpetually immobile yet lifelike state. Current laws make it virtually impossible for a taxidermist to obtain the kinds of large, exotic animals that were once Deyrolle’s main trade. That’s probably just as well; it’s a rather discomfiting notion given modern sensibilities about wildlife preservation. But the store is still well worth a visit for the sheer strangeness of it all. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/Archaeopteryx-model.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Deyrolle.6bb740544a59.mp3"
	},
	{
		"title": "La Chose Intéressante du Jour. Interesting Thing of the Day moves to France",
		"text": "On July 1, 2007, the entire staff of alt concepts—that’s Morgen, me, and our cat, Zora—left San Francisco and moved to Paris. If you’ve been wondering why our sites have been a bit thin on new content in recent months, that’s the reason. But I’m pleased to say that we’re settled in our new home and once again actively writing about interesting new things. Lots of people have asked us what we’re doing in Paris, and it’s a question we have some difficulty answering. I suppose the short answer is that we’re doing the same things here we were doing in San Francisco, except with a view of the Eiffel Tower and better bread. As to what induced us to move, that’s a bit more involved. Interesting Continent of the Decade In the spring of 2000, Morgen and I took a three-week vacation to Europe. Morgen had been to Germany as a teenager but I’d never seen any of Europe. I’d read lots of books set in France, and was especially interested to visit Provence. We also scheduled stops in Paris, Monaco, Venice, Innsbruck, Munich, and Bern, as well as numerous other spots in between. It was a whirlwind trip, to be sure, but it made quite an impression on me. It was on that vacation that I first encountered the Girolle, superautomatic coffee machines, Neuschwanstein Castle, and The Musée des Arts et Métiers, among numerous other things I later covered on Interesting Thing of the Day. In fact, the idea for the site itself occurred to me during our visit to Bern. Of all the places we visited, though, Paris made the deepest impression on me. I’m addicted to discovering interesting new things, and as I’ve remarked here in the past, Paris has an extraordinarily high ITSKI (Interesting Things per Square Kilometer Index). So we returned to France for another three weeks in 2003, and spent two of those weeks in Paris. Once again, I found that I felt happier, more content, and more energized than just about anywhere else I’ve been—and I’ve been to a lot of places. It wasn’t merely the fantastic food, the architectural beauty, or the ubiquitous signs of a long and fascinating history. In some ineffable way, I was enchanted by the very vibe of the city— the subtle logic behind the ways people think and act here…I don’t know, somehow it just clicked with me. Although Morgen would probably tell the story a bit differently, she had similar feelings of fondness for France in general and Paris in particular. Home Is Where the Heart Is Back home in California, we gradually found ourselves growing restless. I’d be the first person to tell you that San Francisco is a wonderfully interesting city, and without question the years we spent there enriched our lives immensely. But at a certain point we began feeling that we’d run out of new things to experience there, that life was pleasant enough but somewhat dull. The cost of living was high, and I suppose we felt that we weren’t getting our money’s worth in a way. We frequently remarked about things that weren’t quite working for us in ways they would have in France. Like the bread, for example: I’m sorry, but even the best bakeries we could find in San Francisco—expert though they may be at making sourdough bread—simply couldn’t produce an authentic-tasting baguette. Over a period of a couple of years, we talked about this growing sense of discontentment frequently on our customary long walks. We brainstormed about places we could move (within San Francisco or elsewhere), as well as other changes we could make to get ourselves out of the rut we seemed to be in. But none of the proposed solutions felt right, and the conversations always ended up right where they started. Then one day around the beginning of 2006, on yet another long walk, Morgen finally said, “I know what we have to do. We have to move to France.” I remember thinking, in rapid succession, that she had hit upon the only correct answer (which should have been obvious), that such a move would be outrageously difficult if not impossible, and that we had no choice but to try. Almost immediately we agreed that this was our new plan; it was just a matter of figuring out how to make it happen. We also quickly concluded that Paris was where we should plant ourselves, at least initially. Making The French Connection We spent months reading books and Web sites about how one goes about moving to and living in France. The process is long and complex, especially if you’re not a resident of the European Union, don’t have a job offer from a French employer, and want to stay in France for more than three months—our situation exactly. For starters, you need a special visa. The requirements you need to meet before you can apply for it, and the paperwork required to document everything, are intimidating, to say the least. As is typical of the French bureaucracy, the process involves several different cases of “you need A in order to get B, but having B is also a prerequisite to getting A.” It was maddening. (And the madness doesn’t end once you get here, either: plenty more administrative hassles await us.) Crucial tasks like finding an apartment, setting up a French bank account, and getting appropriate health insurance presented loads of challenges. There was also the matter of figuring out what to do with all our possessions. Although any move is a lot of effort, a move across the ocean in which you can only take a limited amount of stuff introduces more complications. It took us several months of concerted effort to determine how to sell, store, give away, or pack everything we own. We had to jump through a number of hoops to deal with issues relating to our business, taxes, and other financial matters. And, for good measure, we had to go through yet another long process to bring our cat with us—yes, we really are crazy. I can’t begin to tell you how busy and stressful our lives were in the couple of months leading up to the move. Besides all the paperwork and logistics, we both had our regular, paying work to deal with. We got very little sleep and experienced entirely new levels of grumpiness. It’s easy enough now to look back and pretend it wasn’t that bad, since it’s all over with, but really: it was that bad. And, in the process, we had to sacrifice a number of things, not the least of which was keeping up with writing new articles on our Web sites. A loaf of bread, a jug of wine, and us Now, however, we’re officially back in action—living our version of the dream in Paris and ready to get back to the sorts of work we enjoy. We have a lovely apartment with a suitably fast Internet connection and half a dozen good bakeries within a boule’s throw from our door. There’s UHT milk and pastis in our cupboard, and we’re more or less within walking distance of La Flûte Gana and Père-Lachaise Cemetery. We eat a lot of cheese, and waitresses ignore us unless our table is on fire. We’re happy. We don’t know how long we’re going to be here, but I estimate that it will be somewhere between a year and forever. That is to say, we’ve got a one-year lease on our apartment—so we could decide to go somewhere else next summer—but it’s virtually certain we’ll stay in France, and highly likely that we’ll stay in Paris, for the foreseeable future. We’ll continue working on Interesting Thing of the Day and our other sites—and in fact, we expect to have a lot more time to devote to them now that we don’t have to deal with moving. (And no, don’t worry: this move doesn’t mean that all the interesting things from now on are going to be French!) We’re also working on a new site that will be all about our lives as expats in France. As always, we thank you for your kind support. More interesting things are ahead! ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/Notre-Dame-de-Paris.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/France.da14c14fd34f.mp3"
	},
	{
		"title": "The Fourth Anniversary of ITotD",
		"text": "Sunday, April 1, 2007, was the fourth anniversary of Interesting Thing of the Day. In honor of the occasion, I’d like to interrupt our regular programming and provide a small glimpse into the history and thinking behind the site for the benefit of new readers and old friends alike. This Is Joe’s Brain on Interesting Things My original idea for this site was simply to have a series of pages describing cool things I’d come across in my travels that captured my imagination and that I thought other people might enjoy knowing about too. Literalist that I tend to be, I chose the title “Interesting Thing of the Day” because I couldn’t think of any clearer description of what this was: a thing—any kind of thing—that’s interesting (according to me), every day. I decided I didn’t want to cover people or news events, and I’ve tried to choose topics that will still be interesting years in the future, but other than that, pretty much anything is fair game. Astute readers will have noticed that the site’s name has become a bit of a misnomer in that we no longer have a new thing every single day, but I’ll say more about that in a moment. I quickly realized that what I found interesting was not just the things themselves, but how they fit into my experience. So I started using personal stories to introduce most articles. If you’re looking for an encyclopedia, this is not the site for you, but most readers seem to find the stories entertaining as well as informative. I’ve written the majority of the content myself, but I’m always delighted to publish contributions from guest authors. (My wife, Morgen Jahnke, has become such a frequent contributor that she no longer gets the “guest author” byline. ) Coloring Outside the Lines: For better or worse, Interesting Thing of the Day has always defied categorization. Is it a blog or not? I don’t know. Is it a reference site or an entertainment site? Is it about food, travel, technology, or triva? Yes and no to all of the above. The site doesn’t fall into any well-defined box. But then, neither do I. Good to the Last Click Lots of people make a habit of coming to the site every day; lots more get our news feeds using an RSS reader or other news aggregator. If you haven’t taken the time to examine every pixel and link of the site—not that I blame you!—you may not be aware of some of our lesser-known, but still groovy features: * Each article is also available as an audio recording (click the link just below the main body of any article). * For a wafer-thin fee, you can also opt to receive Interesting Thing of the Day by email; paid subscriptions also include access to full-text, ad-free RSS feeds with podcasts of every article. * If you want to learn more about any day’s topic, see the “More Information” section at the end of each article, which contains references, related items such as books and movies, and other resources. * For lists of related articles on this site, of which there are usually quite a few, check the sidebar. Interesting Factoid: The music that plays at the beginning and end of each Interesting Thing of the Day podcast was composed by my sister-in-law, Cat Jahnke, and her partner, Darren Johnston. I didn’t realize it at the time, but their anniversary is the same as that of this site—April 1, 2003. Please go buy her CDs! A Brief History of Things Working on this site has certainly been a learning experience. (You can read more about the site’s history on my personal blog in Further Thoughts on ITotD’s 4th Anniversary.) The site has gone through a couple of significant redesigns as well as numerous smaller updates, all of which have had tremendously positive results. During the past ten months or so, we’ve worked much harder at promoting Interesting Thing of the Day. We’ve also launched a couple of new blogs, SenseList and The Geeky Gourmet, which have led to a lot of helpful cross-pollination. Readership has grown rapidly, a fact that pleases me tremendously. I want to say, too, how grateful I am for those of you who have written to me with comments, suggestions, praise, and constructive criticism. When I get an email from someone who says they’ve enjoyed reading an article, it really makes my day. It’s easy to think of stuff on a Web site as being isolated from an actual human author, but we truly do thrive on praise, and it means a lot to me whenever someone takes the time to write in. That little boost makes this sometimes difficult work much easier! The biggest challenge has been solving the familiar equation of time and money. Writing these articles takes a lot of time, but doesn’t generate a lot of income. That means I have to spend most of my time making money in other ways, which for me means writing books and articles about computers. That’s a nice profession too, of course, but my “day job” is so time-consuming that I often have little time left to devote to this site. And round it goes. It was only to preserve my health and sanity that I cut back from daily articles to one or two a week. Which brings me to… Show Me the Money When I launched Interesting Thing of the Day, I had a dream that one day it would become my full-time job. Although years have passed and that hasn’t happened yet, that’s still my dream. I’d love to go back to posting new articles every day (or at least every weekday) and devote my full attention to the site, but the site’s income will have to increase significantly before that can happen. So, in the best tradition of all those annoying fund drives on public radio and TV stations, let me put it to you this way: if you like what you see here and want to see more, make a donation today! [My apologies: that link was broken earlier, but is now fixed!] (Any amount is appreciated, but in honor of our fourth anniversary and the 4th of April, $44 would be an especially nice figure.) It’s not tax-deductible and we can’t send you a free tote bag as a thank-you gift. But you will have our undying gratitude, and you’ll significantly increase the likelihood that I’ll spend more time writing about interesting things here. Instead of making an outright donation, or in addition, you can subscribe to the audio edition of Interesting Thing of the Day or buy some spiffy ITotD merchandise. Thanks for your support! Introducing Spectatrix With that business out of the way, today I’m pleased to announce the latest addition to the alt concepts family: Spectatrix, a new blog that looks at the world through the eyes of a (passionate) introvert. Spectatrix is Morgen’s project, and although I may pop in to comment from time to time, she’ll be doing the vast majority of the writing. If you’ve enjoyed her articles here, I suspect you’ll like reading what she has to say about life from an introvert’s point of view. The notion of an introvert running a blog may seem cognitively dissonant, but speaking as an introvert myself, it makes perfect sense: it’s a way to be with people without actually being with people—the best of both worlds! I myself am often mistaken for an extrovert, especially when I’m giving a presentation in front of a crowd or promoting my latest book in a radio interview. But the fact is, I’d almost always prefer to be alone than with other people. And I’ve often been frustrated that extroverts—the majority of people out there—don’t understand my frequent need for silence and solitude. So I couldn’t be more thrilled that we introverts now have a blog to rally around (quietly and calmly, of course). If you’re an introvert, or if you have trouble understanding a friend or family member who is, you’ll appreciate Morgen’s insights. The last four years have been exciting, exhausting, and interesting. As always, we have even more impressive things planned for the future. We’ll see you there! ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Anniversary.b1ef9cbb3fa.mp3"
	},
	{
		"title": "Mystery Park",
		"text": "Several years ago, a Swiss friend of mine told me excitedly about a new theme park that was under construction near the city of Interlaken. He sent me a magazine article about it, and even went so far as to buy me a 10-Franc stock certificate for the park, giving me some trivial sliver of ownership in this hot new property. Ever since then, Mystery Park has been on my list of things to write about, but for one reason or another it had never managed to percolate up to the top of the list until now. Which is a pity: the park closed permanently on November 19, 2006, due to a shortage of visitors (and, therefore, money). At least I no longer have to wonder how much that stock is worth today: that and a couple of euros, as they say, will buy me a cup of coffee. I’d like to say, at least, that it was interesting while it lasted. That, I’m sure, is a matter of opinion—and, clearly, not enough people’s opinion to make the park profitable. Nevertheless, Mystery Park was nothing if not unique, and its story is worth telling. The Gods Must Be Crazy Mystery Park was the brainchild of Erich von Däniken, a Swiss author perhaps best known for his 1968 book Chariots of the Gods?, which alleged that aliens visited Earth thousands of years ago, bringing with them the technology needed to create such artifacts as the Nazca lines, the Antikythera mechanism, the pyramids in Egypt, and the statues on Easter Island. Although the book was popular, no one with any scientific credentials took it seriously, and von Däniken was immediately pigeonholed as, shall we say, a fringe theorist. (On the other hand, the book did provide the inspiration for a number of science-fiction movies and TV shows, including Battlestar Galactica. So clearly some good came of it! ) The lack of credibility didn’t stop von Däniken from authoring more than two dozen additional books and selling tens of millions of copies worldwide. After a few decades as a bestselling author, von Däniken had some cash to play with, and he decided to design a theme park that would explore the world’s great mysteries. Not just any mysteries, of course, but those for which von Däniken implied the answer “aliens did it.” The park, built on the site of a former military air base, would be an interactive, hands-on way to spread his ideas in the guise of history, science, and entertainment. Planning began in 1997, and Mystery Park welcomed its first visitors on May 24, 2003. One Ring The park, which was tiny as theme parks go, consisted mainly of seven pavilions or “theme worlds” arranged in a ring. Each pavilion focused on one particular ancient culture and its mysteries. The Vimanas pavilion explored flying machines said to be used in north Indian temples. In the Maya pavilion, visitors learned about the Mayan timekeeping systems, which von Däniken believed to track the calendars of other worlds. The Orient pavilion examined the construction of the Great Pyramid of Giza, while Megastones looked at Stonehenge. There was also a Nazca pavilion, a Contact pavilion about cargo cults, and a Challenge pavilion dealing with space travel to Mars and beyond. An elevated sphere in the center of the park served as an observation tower. Although von Däniken repeatedly asserted that the park’s goal was to provide questions, not answers, he certainly tried to steer visitors toward accepting his interpretations of things. He helped design the attractions, sold his books at the park, maintained an office on the premises, and regularly interacted with visitors. Critics pointed to his well-known biases as a reason the park didn’t draw more people; even to the extent that some of the exhibits were reasonably objective, skeptical would-be visitors frequently assumed they’d be getting a full dose of UFO mania and little more. After trying unsuccessfully to stave off creditors for months, the park eventually declared bankruptcy and closed. Analysts blamed everything from an underperforming stock market to the fact that the exhibits never changed, discouraging repeat visits. But a large part of the reason for the park’s failure seems to have been that there’s only so much to say about von Däniken’s theories and so many people who will listen to them, no matter how entertaining the multimedia presentations may be for their kids. There’s still a chance, however remote, that the park may reopen at some point—under new management, presumably, and with significant changes. But I wouldn’t hold my breath. Since I never got to visit Mystery Park myself—and haven’t read any of von Däniken’s books—all my opinions have been formed second-hand. To be sure, I’ve got to give props to anyone with the resources, vision, and influence to create his own theme park. As for the content, what can I say? I liked The X-Files as much as the next person; conspiracy theories and stories of alien visitors are nothing if not entertaining. But I enjoy those stories as fiction, and I hope I know enough to separate entertainment from reality. It sounds to me as though that’s exactly where von Däniken failed with his Mystery Park. Or it might have been sabotaged by aliens. You just never know. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/mystery-park-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Mystery-Park.aa29283bf941.mp3"
	},
	{
		"title": "Aquanomy",
		"text": "A few years ago when we were in Patagonia, I had the chance to sample a very rare beverage. After hiking for about an hour or so on the Perito Moreno glacier, our guide called for a rest. We stopped near a pool of water, and we all gathered around to take a closer look. Its blue depths were mesmerizing, but our guide cautioned against getting too close if we didn’t want to sink all the way to the bottom of the glacier. He did recommend that we try the water, though, which we did eagerly, and I can still remember its taste—so pure and amazingly cold. Of course, the rare part of the experience was drinking the water straight from the source. “Glacier water” is easy to obtain nowadays and comes in handy plastic bottles with no need to freeze your hands; still, there was something special about that Perito Moreno water. I usually find it incredibly difficult to drink the recommended amount of water every day because I feel like I just don’t have a taste for ordinary water; this glacier water was somehow different. Maybe I was manifesting the first signs of aquanomy, or the “connoisseurship” of water, I’ve recently been reading about in Mireille Guiliano’s book French Women Don’t Get Fat: The Secret of Eating for Pleasure. Water Water Everywhere As gastronomy is to food, so aquanomy is to water; the delight in and cultivation of knowledge of that particular subject. In her book, Guiliano mentions aquanomy in the context of the growing worldwide interest in bottled water, something long part of her life as a native Frenchwoman. She notes that there is a restaurant in Paris, Restaurant Colette, that now serves 80 different varieties of bottled water to its customers, making it possible for them to find new options to tempt the palate. This may seem like decadence to those used to drinking water straight from the tap, or a huge luxury when even clean water is a rare commodity in much of the world. However, I agree with Guiliano in her praise of this trend; we spend much more money and resources on beverages that aren’t healthy for us, what’s wrong with enjoying the experience of drinking something that’s actually good for us? Waterworld That sentiment seems to fuel the FineWaters Web site—launched when its founder, a former wine connoisseur, stopped drinking wine because of a medical condition. Filled with information about the best temperature at which to drink water, the right kind of glassware to use, and which water to pair with what food, it is extremely useful for the would-be water connoisseur. While it may seem strange to pay such attention to water, the site makes a good case for true differences between waters, including mineral content, pH value, and size of bubbles. In fact, the Web site features the FineWaters Balance scale, a measurement of a bottled water’s bubbles, ranging through bold (large bubbles), classic (medium-sized), light, effervescent, and still. FineWaters also notes the trend of upscale restaurants and bars featuring larger selections of water, and in some cases, employing a water sommelier to help with choosing the most suitable water for the meal. Listing establishments in Tokyo, Montreal, New York, and Paris among others, it shows that the water connoisseurship trend may just be beginning. Going With the Flow Although I’m not one to follow trends blindly, I do think there is some merit in the rising appreciation of water. I wouldn’t buy a brand of water simply because it’s the current rage, or because it has a nice bottle, but I could imagine experimenting to find bottled water that tastes good to me. I still need to drink those eight glasses of water a day, and a bottle of designer water is cheaper than a plane ticket to Patagonia. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/water.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Aquanomy.e4b0962af883.mp3"
	},
	{
		"title": "The Martini",
		"text": "As a San Francisco resident, I like to brag that my city is where Important Things were invented. The television. The jukebox. Bay windows. Denim jeans. The slot machine. Cable cars. The fortune cookie. Chop Suey. And yes, Rice-a-Roni. It’s also reputedly the birthplace of quite a few alcoholic beverages, including Irish Coffee, the Mimosa, the Mai Tai, and the Martini. Although the martini is apparently less than 150 years old, records of its invention are sketchy at best, and several other municipalities would like to take credit for it. A great many widely divergent stories about the drink’s origin are in circulation, each one as plausible as the next. But since this is a question that cannot be answered definitively, I choose to believe the story I like best. That story says that in the mid-1800s, a miner about to board a ferry in San Francisco for the trip across the bay to his home town of Martinez asked a bartender to whip up an interesting drink for him. The resulting mixture was named after the traveler’s destination, and years later, when the drink had become more popular, the name was shortened to “martini.” This story, I hasten to admit, may be entirely apocryphal, but it does at least seem likely that the name “martini” is in fact derived in some fashion from “Martinez.” Mixed Messages In addition to the drink’s uncertain provenance, no reliable documentation of its original recipe exists. Among the ingredient lists I found claiming to be the original are these: * 4 parts sweet vermouth, 1 part gin, dash of bitters, two dashes of Maraschino, slice of lemon * 3 parts gin, 1 part sweet vermouth, 1 part dry vermouth, dash of orange bitters, slice of lemon * 3 parts gin, 1 part dry vermouth * 2 parts gin, 1 part sweet vermouth, (sometimes) dash of orange bitters * 1 part gin, 1 part dry vermouth (In addition to the ingredients listed, every martini is mixed with ice to chill it; the ice is strained out before serving. ) You will notice, of course, that all these recipes contain gin—not vodka—and vermouth (a type of wine flavored with herbs and spices). Vodka martinis are a more recent invention (and, according to some, an egregious misuse of the very term “martini,” since vodka is all but tasteless). The same is true of the ubiquitous olive garnish, which is suspiciously absent from early ingredient lists. But the uncertainty of the recipe is precisely what’s at issue here. Since there is no canonical reference as to what the “one true” martini should contain, anyone who gets uptight over the fact that a certain martini recipe is “wrong” is arguing from a position of ignorance. (More on this in a moment. ) How Dry Am I? In any event, it is clear that over the last century, the commonly expected ratio of gin to vermouth has steadily increased to the point that some martini aficionados consider even an extra-dry 8-to-1 ratio too “sweet.” If you want to be extremely hip, you can buy spray bottles designed expressly for “misting” a few microdroplets of dry vermouth onto cold gin to give your hyper-desiccated martini the mere suggestion of a hint of vaguely vermouthish essence. This change is apparently no accident. Some sources claim that the gin commonly available a century ago was much more bitter than what we have today, that the purpose of the vermouth was to mask this bitterness, and that the decreasing proportion of vermouth has thus been nothing more than a natural adjustment to expose more of the gin’s flavor. Shaken, Not Stirred? But the biggest (and silliest) martini controversy is, of course, whether they should be shaken or stirred. Everyone knows James Bond’s choice, and I’ve read countless criticisms that Bond orders his martini the “wrong” way—that a sophisticated international spy ought to know better. One could perhaps justifiably criticize Bond (or, to be more accurate, Ian Fleming) for preferring a vodka martini, since the one thing we can say with certainty about the traditional recipe is that it uses gin. But surely the manner of combining the alcohols is of little consequence? Well, you’d be surprised. Putting the ingredients (including ice) in a covered container and shaking will result in a colder beverage—ordinarily considered a benefit. But purists never seem to tire of saying that shaking a martini bruises the gin, as though this were a self-evidently ridiculous thing to do. You cannot bruise gin. You can bruise yourself or even a piece of fruit, but you simply cannot damage gin in any way merely by shaking it. OK, say the critics, maybe “bruise” was a poor choice of words, but by shaking gin with ice you do change it—you aerate it (a tiny little bit) and you probably melt a little more of the ice, diluting it a smidgen more than you would by stirring. The presence of air bubbles (and perhaps a few ice fragments) can in fact make the martini slightly cloudy, but this appearance dissipates quickly. The real question is whether you can taste the difference between a shaken martini and a stirred one, and let’s just say that innumerable blind taste tests have yielded inconclusive results but a lot of bruised feelings. Even if a shaken martini does taste different from a stirred martini, who’s to say the difference is objectionable? Some people like carbonated water better than still water. Some people like Pepsi better than Coke. Some people like their orange juice without pulp. These are all merely preferences, not matters of right and wrong. And so what if Bond, for whatever fictional reason, preferred his martini shaken? The point is that he knew stirred martinis were the norm—otherwise, there’d have been no point in ordering his specially. So he’s not betraying ignorance, but rather expressing a preference. Or maybe he was doing it for his health. As crazy as it sounds, the British Medical Journal published a study showing that shaken martinis have measurably higher antioxidant properties than stirred martinis. Higher enough to make any real difference? Probably not. But at least when your know-it-all friends give you a dressing down for being clueless about proper martini preparation, you’ve got a great comeback. By the way…the right way to make me a martini is to use 2 parts gin and 1 part sweet (yes, sweet) vermouth, shake with ice, and garnish with a twist of lemon. Cheers! ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/martini-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Martini.cf84263a8f10.mp3"
	},
	{
		"title": "Orgone",
		"text": "Back when I wrote about the Sedona energy vortexes, a friend of mine said I should look into something called “orgone”—apparently some sort of healing energy discovered by a certain Dr. Wilhelm Reich. I spent a couple of hours reading the Web sites my friend recommended, by the end of which time I was completely baffled. I had read things about alien encounters, inscrutable contraptions that were supposed to impart various vague health benefits, and other claims so bizarre that I simply couldn’t make any sense of them. The material was so opaque and confusing that I couldn’t even produce a coherent definition of orgone, much less write an article on the subject. Many months later, after my article on the Egely Wheel, the same friend again suggested I write about orgone, so I once again spent some time on the Web, trying to make heads or tails of it. Again, I failed. Then, one day recently, I happened to notice that Cecil Adams wrote about Reich and his theories several years ago in “The Straight Dope.” The quote that caught my eye was: “Reich was a nut.” At last, a clear and concise statement I could comprehend. Perhaps there was hope after all—I just needed to look in the right places. Now, of course, I’ve biased you already: you’re going to think that what I’m about to describe is pure hogwash. And frankly, I think you’ll be right. As much as I try to maintain an open mind—and a charitable attitude toward those with beliefs much different from my own—I have my limits. But the story of orgone, despite its dubious claims, is nevertheless quite interesting. The Force May Be With You Wilhelm Reich was born in Austria in 1897. As an adult he became a psychoanalyst—a friend and colleague of Freud, in fact. In the late 1930s, as a result of his research in psychiatry, Reich claims to have discovered a type of energy he labeled “orgone” (pronounced “ORG-own,” not “OR-gone,” by the way). He believed it was a kind of life force, a “primordial cosmic energy” that permeates the entire universe. Within the body, he claimed, a good flow of orgone produced health, while blockages produced disease. In those terms, it sounds very much like the Chinese notion of ch’i (or qi), a sort of internal energy. But Reich, who related the notion of orgone in its physiological context to the libido, took the concept much further. All matter in the universe, he claimed—both animate and inanimate—came from orgone, and orgone is responsible for life. Orgone is even, supposedly, what gives the sky its color. By constructing a box made of alternating layers of metal and organic matter, Reich made what he called an “orgone energy accumulator.” Sitting in one of these boxes allegedly cured (or at least improved) conditions ranging from depression to skin burns to cancer. Reich also made machines he called cloudbusters, which could allegedly either produce or inhibit clouds and rain. Orgone with the Wind None of these claims, of course, was ever proven in a way satisfactory to the scientific or medical establishment. Reich’s position was that conventional scientific instruments simply were not designed to detect or measure orgone. By the 1950s, when Reich was living in Maine, his work drew the attention of various U.S. government agencies, which investigated his work extensively over a period of several years. Of particular concern were Reich’s claims that his devices produced medical benefits. After disobeying a court order to refrain from shipping his products across state lines, Reich was convicted of contempt of court and sent to prison, where he died of a heart attack the following year. Reich and his supporters felt—justifiably, it seems—that the government persecuted him far out of proportion to his actions (going so far as to confiscate and destroy much of his equipment and notes). The intense crackdown also had the unfortunate effect of making Reich a martyr of sorts—people believed he must have been on to something incredibly important to arouse such a passionate response from the government. In the years since Reich’s death, incredibly, the “science” of orgonomy has attracted a significant number of followers, many of them credentialed physicians. There are orgonomic societies, conferences on orgonomy, and even an American College of Orgonomy, which trains and certifies members in “medical orgone therapy.” Although there are plenty of true believers, there is still no proof that such a thing as orgone exists. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/Wilhelm-Reich.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Orgone.72efbd27bdad.mp3"
	},
	{
		"title": "Kitty Genovese Syndrome. The problem of the guilty bystander",
		"text": "In March, 1964, a New York City woman named Catherine “Kitty” Genovese was raped and stabbed to death as she returned home from work late at night. According to a newspaper report published shortly thereafter, 38 people had witnessed some or all of the attack, which took place in two or three distinct episodes over a period of about a half hour—and yet no one did anything to stop it; no one even reported it to the police until the woman was already dead. Although the murder itself was tragic, the nation was even more outraged that so many people who could have helped seemingly displayed callous indifference. And so the failure of bystanders to intervene became known as “Kitty Genovese Syndrome”—or, sometimes, just “Genovese Syndrome” or “Genovese Effect.” Social psychologists sometimes call it the “bystander effect.” Later analysis of the Genovese case would show that the media misrepresented the facts somewhat. It’s not as though 38 people stood calmly watching a brutal murder in broad daylight and simply went on about their business. This attack happened in the middle of the night when it was dark, most people were in bed, and no one had a clear view of the entire event. Some of the witnesses, for example, had merely heard yelling and thought it might have been nothing more than an argument. At least one person apparently did call the police immediately, but without realizing that the woman had actually been stabbed—so the police didn’t respond with any urgency. And perhaps, even if an ambulance had arrived 5 minutes after the initial attack, Kitty Genovese would still have died. So it’s plausible, at least, that this particular case was not an example of apathetic bystanders—and that Kitty Genovese Syndrome is a bit of a misnomer. But it hardly matters what you call it or whether this single tragedy could have been mitigated. The bystander effect, by whatever name, is a very real and common occurrence. The Victim and the Bystander I’ve experienced it myself—both as a victim and as a bystander. In the late 1990s on my first trip to Costa Rica, I was walking alone in downtown San Jose. It was still light out, and I was in an area with plenty of pedestrian traffic. As I turned a corner, I noticed a group of young men gathered around an older man who was lying on the sidewalk. My first impression is that the old man was ill or injured and they were trying to help him. As I got closer, I saw that they were actually going through his pockets. My instincts said I should try to help the man, not run, so I kept walking toward them. But the next thing I knew, the young men jumped me. One squeezed his arm around my throat, making it impossible to breathe or call for help. The rest of them took my watch, wallet, passport, and anything else of value they could find. I felt pretty sure at the time that I was going to die. But then they threw me down in the gutter and ran away. When I finally staggered to my feet, dazed and bruised, I looked around and saw lots of people walking down the street—maybe glancing curiously at me, but otherwise seemingly indifferent. The muggers clearly had known they could count on the public not to get involved. I managed to convince a couple of people to help me, and they pointed out some police standing about a block away. The police searched the area and found my passport, hotel key, and a couple of other items (though not, of course, my money). Then they drove me back to my hotel. I was extremely shaken up, and had to make several phone calls—to Morgen (my girlfriend at the time), to my mom, and to the bank to cancel my stolen credit cards. My room didn’t have a phone, so I called from the lobby. While I was on the phone, the desk clerk called out to me for help. “That woman just stole my leather jacket and ran out!” she said. So I put down the phone, ran out of the hotel and down the street, confronted the thief, and retrieved the stolen jacket. In retrospect, I can hardly believe I did that. Even having been through what I’d just experienced, I am not normally one to get involved. I think the reason I did was that the clerk asked me personally and specifically for help. The Pot and the Kettle In the years since, I’ve encountered a few other situations in which I might have been able to help someone in trouble, but didn’t. When I see or hear something happening—or possibly happening—I feel confused, afraid, frustrated. Maybe I don’t understand what’s really going on. Maybe the person isn’t in danger at all. Can I do anything about it if they are? What about my own safety? Surely one of these other bystanders is better qualified to help. Surely someone else has called the police. And then, having stood there doing nothing while everyone else was thinking the same thing, I feel tremendous guilt. By my inaction, I’ve just experienced the Kitty Genovese Syndrome. As I’d discovered in that San Jose hotel lobby—and earlier, just after I was mugged—crowds of people are much less likely to intervene than individuals, especially if those individuals are asked directly for help. This is the crux of Kitty Genovese Syndrome: a kind of mutual buck-passing that occurs within a group when no one emerges automatically as the “right” person to help. Everyone assumes that someone else will be the one to help. Although fear for one’s safety often plays a part, that fear shouldn’t prevent someone from, say, making a phone call. No one, of course, wants the inconvenience of being dragged into someone else’s problem. But I think nearly all of us would be willing to endure some inconvenience to save a person’s life. What makes Kitty Genovese Syndrome so insidious is that the apparent strength in numbers is actually a weakness that discourages any individual from taking on personal responsibility to intervene. International Bystanders When I saw the film Hotel Rwanda, I left the theater very upset. The genocide in the early 1990s that left 800,000 Rwandans dead occurred with very little intervention from either those within Rwanda or the international community—a profound example, as several commentators have pointed out, of Kitty Genovese Syndrome. I simply couldn’t fathom that anyone could know what was going on and do nothing. And yet, paradoxically, I can imagine no other response—with so many other people in the world, surely this must be someone else’s problem. Someone wiser, more powerful, or closer to the situation. What could I have done anyway? I have my own problems. But then, so does everyone else. There’s no cure for this problem. Even knowing about this effect as I do, chances are, I’ll someday be an unhelpful bystander once again. But just maybe I’ll have the presence of mind to realize that the person best qualified to help is the one willing to take action in the face of confusion and doubt. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/KittyGenovese-120.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Kitty.95eed543c92f.mp3"
	},
	{
		"title": "Disappearing Island Nations",
		"text": "It seems that every time I turn on the TV or open a newspaper or magazine, I see another story about global warming. It’s not only the big environmental issue of the day, it’s one of the big issues, period. Maybe it doesn’t feel quite so frightening or quite so urgent as terrorism or outbreaks of deadly diseases, but certainly it’s right up there. The condensed version of this story—the one that has most thoroughly worked its way into the public consciousness—says that global temperatures have risen much more rapidly during the industrial age than they did before; that they will continue to rise; that worldwide emissions of greenhouse gases such as carbon dioxide are largely to blame for this situation; and that the resulting changes in weather, climate, sea level, and so forth will—sooner or later—be utterly devastating in one or more of several ways. Meanwhile, the United States, which is responsible for some outrageous percentage of the world’s greenhouse gases, is apparently disinclined to reduce those levels, on the grounds that hypothetical long-term problems are outweighed by actual short-term problems such as the extreme inconvenience and cost of reducing emissions. Burning Rage Naturally, I’m incensed at all this, especially when I read stories about the apparently imminent disappearance of several entire island nations due to the rising sea levels that are, in turn, a result of global warming. And, assuming that global warming is in fact caused by greenhouse gases (as most people do), it is astonishing that people continue driving gas-guzzling SUVs and smoking cigarettes and, you know, generally showing contempt for the future inhabitants of the planet as a whole and those island nations in particular. And yet, the reality is much more complex than the sound-bite-friendly version of this problem you hear about on TV. The prevailing notion seems to be that warmer temperatures will melt polar ice caps and glaciers, thus sending more water into the ocean and uniformly raising its level. And though there is a certain amount of truth to that, it is a simplified and misleading picture at best. So I thought it would be interesting to look briefly at some of the facts and controversies surrounding the islands that appear to be sinking into oblivion. Taking a Dip in the Ocean The islands most frequently mentioned as being at risk are those closest to sea level. Take the Maldives, for instance—an island nation in the Indian ocean. The highest point in the entire chain of islands is only 2.4 meters (8 feet), and most of the land is much lower. So it doesn’t take much of a change in sea level to wipe out vast amounts of land, and if there’s a bad storm or an unusually high tide, the resulting floods can be devastating—covering the vast majority of the land, fouling fresh water supplies, and wiping out crops. Unfortunately, such floods have been occurring more and more frequently in recent years. The nation’s government has for several years been working on the construction of an artificial island nearby, called Hulhumale, which will be able to serve as a new home for many of the residents if an evacuation becomes necessary. There’s also Tuvalu, in the Pacific ocean between Hawaii and Australia, with a maximum elevation of 4.6 meters (15 feet). Although the nation has fewer than 11,000 citizens, they are sufficiently convinced of its imminent disappearance that they have already begun to evacuate. New Zealand has agreed to grant “environmental refugee” status to 75 Tuvaluans per year, but according to some estimates, the nation may be entirely covered with water in as little as 50 years. Some of the other island nations most seriously at risk are Kiribati, the Marshall Islands, and Tonga. Causes and Effects The evidence that these islands could disappear is fairly plain to those who live there: they’ve seen the waterline move farther and farther inland in the past couple of decades, experienced more and worse storms than previously, and endured flooding that in some cases covered entire islands. And in fact, few people dispute that these nations are in danger to one degree or another (though some would say the danger is rather remote). But it’s tricky to prove the connection to global warming and the further connection to greenhouse gases. For one thing, even granting that global warming can and does increase sea level to some extent, measuring sea level is a difficult and inexact science—partly because the sea doesn’t like to stay put very long, and partly because any measurement requires a fixed frame of reference (such as land). But the land itself can rise or fall for various reasons, including seismic activity and subsidence due to water table depletion—meaning the appearance of a rising sea level may be due partially to the fact that an island is actually sinking. Furthermore, unusual weather patterns, such as El Niño, can cause dramatic local changes in sea level. Maybe global warming is responsible for the wacky weather and maybe not. But the point is that global warming may be only an indirect cause, or a minor contributing factor, to the shrinking islands. As for the carbon dioxide connection, that’s also in dispute. Yes, carbon dioxide levels are higher now than in the past; yes, average global temperatures are also higher now than in the past; yes, increased carbon dioxide in the atmosphere can raise the temperature; and yes, human activity produces an enormous amount of carbon dioxide. But some people say that the average global temperature also rose in centuries past when cars and factories could not have been to blame (and then fell again)—causing doubt that human activity is responsible for our current problems. I find such statements suspiciously convenient, coming as they frequently do from parties that have the most to gain and the least to lose from continued fossil fuel consumption. Be that as it may, none of this changes the fact that more and more of the Maldives finds itself underwater every year. One way or another, the whole situation is rather depressing—especially if you happen to live on one of the islands that is most seriously affected by flooding. By the time the world’s luminaries have reached a unanimous agreement as to whether the planet really is warming up, whether carbon dioxide emissions really are responsible for this problem, and whether we’re collectively willing or able to do anything about it, some of the nations in question may already be long gone. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/lake_house-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Island.d8f3c1902cca.mp3"
	},
	{
		"title": "Interesting Burger Joints. Where the beef is",
		"text": "Many of my friends and relatives are vegetarians. And I respect those who, for reasons of conscience, health, or religious convictions—or perhaps paranoia about Mad Cow Disease or genetic engineering—opt not to eat animal products. I myself eat meat only occasionally and am generally content with a healthy diet of fruits, vegetables, grains, and chocolate. But when it comes to hamburgers, I must confess a special weakness. I could pass up a steak without a second glance, but I can’t easily ignore a well-made burger. Hence my ongoing search for great—or at least interesting—hamburger joints. Here are a few of my current favorites. In-N-Out To many people, In-N-Out is just another chain of cheap restaurants in the western U.S. To me, it’s a model of elegant simplicity. The menu contains exactly four food choices: hamburger, cheeseburger, double cheeseburger, fries. There are shakes and the usual beverage assortment—but that’s it. No salads, fish sandwiches, designer chicken pieces, or trendy desserts. Just the basics. If you have to wait in line, it isn’t because the person in front of you can’t decide what to order—and yes, you can shorten the process even further by ordering a combo. The burgers themselves are merely average. Subjectively, though, I feel better about eating an In-N-Out burger because I know all the ingredients are fresh and unadulterated. The chain uses no freezers or microwaves. The beef is fresh; the lettuce is merely broken, not shredded to within an inch of its life; the cheese and shakes are actually made of dairy products. The potatoes used to make the fries were peeled and sliced while you were standing in line, and each burger is made to order after you order it. Every time I visit In-N-Out, there’s a long line, both inside and at the drive-through. Speaking of which: the ubiquitous two-step drive-through process—first place an order through an intercom, and then drive up to a window to retrieve your order—was In-N-Out’s invention. Fatburger The first time I saw a Fatburger restaurant in Las Vegas, I wondered how a company could get away with a name like “Fatburger.” How brazen! How politically incorrect! How delightful! I couldn’t wait to try it. Fatburgers are very tasty hamburgers—certainly the best fast food burgers I’ve tried. They’re an order of magnitude better than In-N-Out, and compared to the major chains, well…there is no comparison. Like In-N-Out, Fatburger uses never-frozen beef, real cheese, and lettuce that can be identified without using a microscope. But Fatburger uses significantly more beef—in fact, more of everything. And although it’s technically “fast food,” Fatburger cooks are clearly in no particular rush to throw your order together. It takes as long as it takes, deal with it—we’ll bring it to your table when it’s ready. In other words, there’s much more attention to detail. As for the whole “fat” thing…the story is that in 1952, when Lovie Yancey founded Fatburger, the word “fat” was a slang term that meant, basically, “good” or sometimes, “fortunate.” That association never occurred to me on my first visit to Fatburger; I assumed they were using “fat” in the straightforward sense of “plump”—which is certainly true of their burgers—rather than “made of triglycerides,” which is less true; their beef is in fact extremely lean. Mel’s Drive-In Mel’s Drive-In on Van Ness Avenue in San Francisco is not only not a drive-in, there’s not even anywhere to park nearby. This is not so much of a problem at Mel’s other six locations in San Francisco and Los Angeles, but it did give me pause. How can a place called a “drive-in” not cater to customers in cars? This required careful consideration over a burger, fries, and a malt. For me, the quintessential diner food is the cheeseburger, which you know will be prepared with greater care (and, invariably, more beef) than at any fast-food restaurant. Mel’s is exactly what you’d expect in this regard—good food, reasonably priced. But it’s the story behind the restaurant that makes it interesting. The first Mel’s Drive-In (named after co-owner Mel Weiss) opened in San Francisco in 1947. It was hugely popular and soon became a small chain. But after a couple of decades, competition from fast-food places drove Mel’s out of business. Just before the original store was to be demolished, George Lucas discovered it, and decided to use it as the setting for his famous 1973 film “American Graffiti”—a nostalgic look at the car-centered teen culture of the 1950s, in which the drive-in restaurant played a crucial role. After filming was completed, the restaurant was torn down, but in 1985 Weiss’s son Steven decided to give Mel’s another go, this time capitalizing on the popularity of the movie. Although the chain has not yet grown to its previous peak of 11 outlets, the diners are extremely popular despite (or perhaps because of) the increased presence of nearby fast food restaurants. Everything about Mel’s—from the food to the décor to the menus—is supposed to be an authentic reproduction of a '50s diner (namely, the Mel’s of 50 years ago). But in fact, what you see is not so much authentic 1950s as reproductions of memorabilia from “American Graffiti,” which in turn was a reproduction of 1950s California. Everywhere you look there are posters and stills from the film. So they’re not selling the 1950s diner experience but rather the “American Graffiti” experience. Burger Joint Burger Joint is a small chain of three restaurants in San Francisco at which I’ve had uniformly outstanding burger-eating experiences. I found it slightly interesting that each of the few items on the menu (burgers made of beef, chicken, or vegetable products, plus hot dogs) came with fries. You can order fries by themselves, though not a sandwich by itself. The food’s quality is excellent, but after a while, it seems a bit preachy to go on about the virtues of simple menus and fresh ingredients—I’m sure you have, by now, caught on to the fact that these are rules number one and two in Joe’s Hamburger Happiness Handbook. But while looking at Burger Joint’s delightfully sparse menu, it suddenly hit me. At the very top of the menu were the helpful words: “all burgers served with mayonnaise, lettuce, tomato, red onion, & pickles.” This menu thus follows one of the most important principles of user interface design: it tells you what to expect without requiring any tedious guessing or exploration. At most fast-food restaurants, the exact composition of the burgers is a mystery. Without toppings listed on the menu, customers wonder whether the restaurant follows an additive model or a subtractive model. In the additive model, which was once the norm at Wendy’s, the default burger (“Just give me a Double”) consists of meat and bun; to get anything else on the sandwich you have to ask for it explicitly. In the more common subtractive model, burgers come with a predetermined list of toppings, and if you don’t want one of these, you have to ask for it to be removed (“Hold the onion”). Some restaurants use a hybrid model, whereby certain toppings are supplied automatically but you can also add extras (“No tomato but add bacon”). The problem with the implicitly subtractive models is that every transaction needs to start with the customer asking, “What does that come with?” followed by a list of ingredients, a moment of decision, and a request for any desired alterations. Inefficient and annoying—and also a likely cause of customer dissatisfaction if the ritual is not performed and the final burger is not to one’s liking. So listing default toppings on the menu is a Good Thing. Fatburger also lists the default ingredients on their menu, as do many other quality burger joints. That’s now number three in my handbook. But back to those ubiquitous fries…Burger Joint has the right idea: A great burger needs to be accompanied by great fries. The French fry is such a conceptually simple food, it astonishes me that anyone can mess it up. And yet I’ve had lots of lousy fries. It is very, very easy to make good fries. Rule four, then, is to make French fries right. By “right” I mean: Slice fresh, unpeeled potatoes. Deep fry in hot oil until crispy on the outside, soft on the inside. Sprinkle with salt. Serve immediately. So there you have it—the ingredients of a great burger joint. Keep your menu simple. Deliver high-quality products at a reasonable price, and be kind to your customers by telling them exactly what to expect. Oh, and don’t forget the importance of a killer side dish. Hmmm…besides fast-food establishments, this crazy approach could also apply to computer manufacturers, Web sites, car companies, and most other businesses. It’s so crazy, it just might work. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/Burger-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Burger.b62444a6eed2.mp3"
	},
	{
		"title": "Slow Food",
		"text": "When Morgen and I lived in San Francisco’s trendy SoMa (South of Market) area, we were frustrated that there were no markets within easy walking distance of our home—not so much as a convenience store. Buying groceries was quite a hassle. Today, however, the situation is different, and when visiting our old neighborhood recently, we saw a great many large, shiny retail stores that had opened since we moved—including a Whole Foods Market. The contrast could not have been more stark between this store and the generic supermarkets where we usually shop. Here, the produce was fresh and healthy-looking rather than faded and bruised. Here, any kind of grain, flour, nut, or legume we could imagine was available in bulk—even red lentils, which we can’t seem to find anywhere else these days. Here, everything from the prepared foods at the deli counter to the seafood to the granola bars had the appearance of quality and wholesomeness (as the store’s name suggests). We gleefully loaded up our shopping cart, excited to be able to stock our pantry with food we could actually feel good about eating. Then, of course, we saw how much all this was going to cost—a small fortune. Not to mention the cost of renting a car to drive across town. For people on as tight a budget as we are, that really hurts. Leaving aside the political correctness of buying free-range, genetically unmodified, grass-fed, hormone-free, pesticide-free, organic…carrots or whatever, many consumers find that the price of those attributes overshadows the quality and other virtues by a significant amount. When I see a gallon of organic milk sitting right next to a gallon of regular milk that costs half as much, I know that I’m paying for a concept—I’m paying for what I believe in much more than what I will taste on my cereal. I say all that to put today’s topic into context. The Slow Food movement is, as you might guess, an attempt to promote the opposite of fast food—to emphasize quality, nutrition, flavor, variety, sustainability, and many other worthwhile things. As someone who loves good food and who despairs at the depths of blandness and laziness to which our society has sunk, this is a concept I truly wish I could get behind. But let me give away the punch line: I think it’s missing a few crucial ingredients. The Fast-Growing Slow Movement An Italian journalist named Carlo Petrini started the Slow Food movement in 1986, when he saw the first McDonald’s being built in Rome. Petrini worried that smaller food producers would be pushed out of business by giant international corporations, that local specialty foods would be replaced by dull burgers that taste the same everywhere in the world, and that attention to flavor and quality would disappear as cultural values. At the same time, he felt that fast food threatened family and community by erasing time spent together eating, talking, and building relationships. The Slow Food movement aims to reverse all that. Now boasting more than 80,000 members in over 100 countries, the Slow Food movement is organized into local chapters called convivia. Each convivium holds seminars, tastings, visits to local food producers, and other events. Slow Food practices include using fresh, whole ingredients rather than processed foods; purchasing ingredients from small local or regional suppliers, and where possible, directly from the source; supporting ecologically responsible, sustainable food production, and promoting gastronomic culture—including social interaction around a dinner table. “Slow” food is not necessarily food that takes a long time to prepare or eat, though using fewer processed ingredients and paying more attention to how food is cooked and eaten will typically result in longer meals. But the point of the movement is less about time than it is about quality. Let Them Eat Slowly I believe deeply in long, leisurely meals made with fresh, local ingredients and enjoyed in the relaxing company of friends. Every time I’ve experienced such a meal, I’ve enjoyed it thoroughly. And if every single meal could be that way, I’d be thrilled. It’s just that…I don’t have an extra hour, or two, or three every day to cook and eat; my schedule is full already. And I can’t afford to buy fresh, organic, locally produced food all the time, to say nothing of the US$60 annual membership fee for Slow Food International. The problem is not that I need to be convinced of how worthy this cause is; the problem is that my lifestyle and income make it impossible for me to participate fully. If I had a job that paid very well and also gave me loads of spare time, I’d be all over slow food, but however much I might desire such a thing, it’s just not that simple. And that’s speaking as someone squarely in the middle class; to truly low-income individuals with even less time and less money than I have, slow food would probably make about as much sense as a gold-plated toilet. That this should be the case is a sad, sad commentary on what modern western culture considers acceptable. And OK, it’s not the fault of the Slow Food movement. Their goals are nothing if not admirable. But in this day and age, especially in North America, there are prerequisites to slow food, namely, leisure time and disposable income. The Slow Food movement can’t tell you how to achieve these things, but until you do, you’re outside their target audience. In all fairness, Slow Food is not an all-or-nothing affair. No one is insisting that every meal and every grocery purchase has to live up to these standards, or that one must never consume fast food. Surely the mere awareness of the issues and the options facing us all as consumers can lead to small but meaningful changes. And for those who are constantly busy out of habit rather than necessity, the virtues of Slow Food may be an enticement to adopt a healthier lifestyle. All the same, I’d feel a lot more enthusiastic about joining a movement dedicated to shorter work weeks, higher pay, and less stress for everyone, even if it came with fries and a Coke. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/food.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Slow-Food.7345adec397.mp3"
	},
	{
		"title": "Cascading Style Sheets",
		"text": "An old saying goes: “There are two types of people: those who divide people into two types and those who don’t.” I am definitely in the former group. For example, I might say there are two types of people: those who read Web pages and those who create them. Of course, some of us do both, but the vast majority of the Web-using public doesn’t know or care about the messy underpinnings of HTML, Web servers, browser compatibility issues, and all the rest. They care about just one thing: the information on the page. If a page loads too slowly, if the fonts are too small, if the graphics overlap the text, or if any of a thousand other things goes wrong, the average Web surfer will simply move along to the next page—there’s nearly always another source for any piece of information, and life is too short to waste it on poorly designed Web sites. Strangely, this fact seems to be lost on a great many Web developers. I’m surely not alone in having made many purchasing decisions based on the clarity, accessibility, or convenience of a company’s Web site. And when I list URLs for related pages at the bottom of an article on this site, I exclude sites that play music incessantly, that don’t show up correctly in my browser, or that otherwise annoy me. I figure they’ll annoy you too. This is a shame, because the whole point of the Web was to make information available to as many people as possible—and clearly, on some level at least, that goal is still not being achieved. There are many ways of designing Web pages, but among these are certain widely recognized “best practices.” One such practice is the use of something called Cascading Style Sheets, or CSS for short. If you’re a Web developer, this technology is very old news; if not, your eyes may even now be glazing over as you anticipate a description of meaningless codes and standards that will have no effect on your life at all. I’ll keep this as non-technical as I can; I mainly want to make three points: first, CSS is a wonderful and magical thing; second, any Web site that doesn’t use CSS, should; and third, most sites that do use CSS—including this one—could do a better job. Effective use of CSS improves the Web for everyone—reader and creator alike. I’m not going to tell you how to make a style sheet or why they “cascade”—there are lots of places to learn that. What I want to tell you is why Cascading Style Sheets are interesting—and why they are so badly needed. In the Beginning There Was the Page The first Web pages were mainly concerned with presenting straightforward subject matter to a technically competent audience, not advertising all the world’s books or trying to sell you a car. The people who decided how Web pages should be made—the World Wide Web Consortium, or W3C—designed the original specifications to reflect the needs of early users who worked with simple and highly structured information such as technical papers, outlines, bibliographies, and tables. As the Web became more commercialized, a whole new group of people began creating Web pages. The new Web designers were, on the whole, neither academics nor programmers, but ordinary people who thought Web pages should mimic the layouts found in other media. Unfortunately, the early W3C specifications didn’t provide any way for these new designers to exert the level of control they wanted, so two things happened. On the one hand, companies that made Web browsers started “coloring outside the lines,” so to speak, implementing features that were not part of the official specification. And second, Web designers began to use parts of the specification in ways that were never intended—let’s be bold and call it “cheating”—in order to trick browsers into displaying exactly what they wanted on the screen. To some extent this cheating worked, but not all browsers performed the same sets of tricks or in the same way—nor did all designers use exactly the same methods of cheating. The result was pages that looked fine in one browser but not another, or on one computer but not another. In order to deal with the chaos, the W3C said fine, let’s update the specification to officially sanction many of the unorthodox cheats. Then at least everyone will be doing the same thing. And so, over the years, the specification went through many revisions, as did browsers, and as did the aesthetic sensibilities of Web designers. Today, on the whole, things are better than they were a few years ago, but there’s still a significant problem. Many Web pages are only friendly to a small group of people—typically, English-speaking people with good eyesight, large monitors, modern browsers, fast computers, and even faster internet connections. And the problem with that is that there are billions of people in the world who aren’t in that group. So if such a Web site provides information, some people can’t read it; if it sells something, there’s an artificial limit on the number of potential customers. Orthodoxy and Reform The W3C realized years ago that the specifications for creating Web pages were on a slippery slope, and began taking steps to bring sanity back to Web design. Their first step was to invent a good way for designers to separate the content of a Web site (the text and images) from its form (its layout and visual characteristics). They created two new specifications: one, called XHTML, for the way the content and structure of a site are represented—things like titles, headings, paragraphs, quotations, images, and so on—and a second, known as Cascading Style Sheets, for the way visual elements should appear, including text size, colors, spacing, and layout. And they basically said: “Follow these rules, and there will be joy.” The specifications were cleverly designed such that if Web designers followed them, all the older browsers that didn’t know anything about the newer specifications would still display the pages adequately—not beautifully, sure, but all the content would be readable. (Web pages that do this are said to “degrade gracefully.”) Cascading Style Sheets are a bit like the styles you can define in your word processor so that you can change many aspects of a word or paragraph’s appearance all at once, while keeping that appearance consistent throughout your document. When a Web designer uses CSS (and uses it correctly) rather than using the old cheats, several interesting things happen. First, Web pages become viewable on a much wider range of devices, including some very old ones. Second, some very nifty typographical and design tricks that were difficult to achieve before are now a piece of cake. Third, Web pages can be understood much more easily by computer programs—for example, search engines that extract parts of Web pages when they list their results, programs that read Web pages to people who can’t see them, programs that create summaries or perform automatic translation, and programs that determine whether a Web page meets governmental requirements for usability. Fourth—and perhaps most significantly—using CSS means that a designer can dramatically change the appearance and layout of dozens or thousands of pages instantly, simply by modifying a single text file. And yet, for all these benefits, far too many sites haven’t bothered to implement CSS. Of those that have, many have done so in an unhelpful way that follows the letter of the law but not the spirit of the law—erasing many of the system’s advantages in the process. But only part of the blame falls on the sites' designers; even the most current Web browsers differ significantly from each other in the way they interpret and display CSS information. Although a designer can use CSS to compensate for bugs or quirks in individual browsers that negatively affect a page’s display, having to do all that fine-tuning harks back to the bad old days of proprietary browser standards. Even so, the mere exercise of separating form from content—and in the process, thinking carefully about the structural elements of a page—is a huge step toward returning the Web to a more useful and accessible state. Look for the Union Label Many Web sites—including this one—that make a serious effort to follow the W3C standards include little badges saying “XHTML” or “CSS.” Technically speaking, these indicators may mean little to the average person, but in effect they’re a way of saying, “We care.” By supporting sites that support these open standards, you show that you care too. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/cascadin.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/CSS.1e2a16c0f776.mp3"
	},
	{
		"title": "Bread Pudding",
		"text": "Given a menu listing a dozen dessert items, I invariably gravitate toward one of the two or three choices on the list that include chocolate as a main ingredient. I don’t think of this as a boring or predictable preference; on the contrary, life is short, and I feel one must not miss an opportunity to experience one of Earth’s great pleasures. You can imagine my feeling of disappointment, then, when at restaurant after restaurant in New Orleans, I arrived at the end of the meal only to find such chocolate-free choices as bananas Foster, pecan pie, and bread pudding on the dessert menu. Suppressing my instinct to jump up and shout, “That’s not really dessert!” I chose to give each of these local specialties a fair chance. Or several. (Dessert) Space: The Final Frontier Truth be told, I have nothing against any of these desserts; in fact, I’m quite fond of bread pudding in particular. The only problem is that it’s extremely filling, and if you’ve just finished a Cajun or Creole meal, you are unlikely to have the tiniest space left in your stomach. With some careful planning (and belt-loosening), I was able to try several different bread pudding recipes. The variety of bread puddings surprised me; they differ greatly in density, sweetness, texture, and flavor. The only bread pudding I had ever known was a very generic (though still tasty) recipe such as you’d find at a buffet or a potluck dinner. But in New Orleans, every restaurant has its special twist, and toppings like a creamy whiskey sauce are quite common. For those unfamiliar with this dish, bread pudding is typically made by soaking bread cubes in a mixture of milk, egg, and sugar; adding raisins and spices; and baking. So it’s not that much different from French toast, except much moister and usually served in a bowl. Of course, one’s choice of bread, the addition of optional ingredients, and the details of preparation can make one bread pudding shine where another merely glows. The possibilities are endless. Bread Publishing A couple of years ago, I got an email from my friend Paola asking if I was interested in bread pudding. (She knew the answer already: I’m interested in everything, especially if it’s dessert.) There’s a magazine all about bread pudding, she told me, and she wondered if I thought it might be sufficiently interesting to buy myself a subscription and then share it with her. You gotta love friends like that. I went to the relevant page on Amazon.com, where I found that a “subscription” to Bread Pudding Update consists of only one issue, at a cost of US$5. That was odd, I thought, but I figured I could hardly go wrong for $5. The ad promised “a review of the myriad ways one can take leftovers and liquor to new heights” and mentioned ingredients like “brandy, sherry, bourbon…oozing caramel sauce…seasonal fresh fruits.” Good enough. I placed my order. Several weeks later an envelope arrived via Airborne Express. It contained exactly two photocopied pages. The first page had the words “Bread Pudding Update” in large letters at the top. I couldn’t believe my eyes. The “magazine” consisted of a grand total of three bread pudding recipes and a copyright notice. No articles or commentary; not even so much as a paperclip to hold the pages together. And, by the way, no mention of liquor, caramel sauce, or fruits (seasonal, fresh, or otherwise). The magazine (wisely) came with a “no refunds or cancellations” policy, so I returned to Amazon.com and left an extremely uncomplimentary review (adding it to several others already present). Shortly thereafter, the listing for the magazine was removed, only to be replaced by another one, this time without the editorial promises—or my review. But now the price has gone up to $12.95. (I guess those courier services can get expensive. ) The story has a happy ending, however. Some time after this happened, my mother mentioned to me that her mother used to make bread pudding all the time. I don’t recall ever having eaten Grandma’s bread pudding, and my mother said she doubted the recipe was ever written down before Grandma died. Not long thereafter, though, I got an email with the happy news that my mother had located Grandma’s recipe for bread pudding on the back of a card in her recipe box. Final score: Bread Pudding Update, 0—Grandma, 1. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/Bread-pudding-1-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Bread-Pudding.ba2632a5ff61.mp3"
	},
	{
		"title": "Groundhog. The strange ritual of marmot meteorology",
		"text": "On February 2 of each year, everyone in the U.S. (and in numerous other countries) who reads, listens to, or watches the news is guaranteed to encounter at least one story about Groundhog Day. The stories will be exactly the same as the ones from last year, the year before, and every year for the past few decades. At around 7:30 a.m., Punxsutawney Phil emerges reluctantly from his comfy quarters in a small Pennsylvania town and, with a crowd of tens of thousands watching, either sees his shadow or doesn’t. The crowd, now informed as to whether or not they must endure six more weeks of winter, celebrates for a few hours and heads home. The news stories repeat, for the umpteenth time, that this ritual has been going on since 1887, though it has been a public event only since 1966. They often point out that the rodent called “groundhog” (Marmota monax) is a type of marmot also known as the woodchuck or whistle pig. They also, without fail, mention the 1993 romantic comedy staring Bill Murray and Andie MacDowell in which Murray’s character gets stuck in a bizarre time loop that forces him to relive Groundhog Day dozens of times in a row. The stories may even reiterate the obviously false official proclamations that there has only ever been one Punxsutawney Phil all these years (despite the fact that a groundhog’s average lifespan is only about 10 years in captivity and half that in the wild); that the predictions are not rigged in advance; and that Phil is always correct. Profit from the Prophet I’d like to tell you how interesting I think this all is, but here at Interesting Thing of the Day we have higher standards. Let’s face it: this story has gotten kind of old. If this odd ritual occurred less frequently—say, every seven years—then perhaps it would be more interesting. If that which is predicted were of greater moment—say, a nationwide famine or bumper crop—that would be much more interesting. And, of course, if there were some ineffable scientific or metaphysical principle on display—say, a genuine 100% accuracy rate—that would be very, very interesting indeed. None of these things, alas, is true. This silly event is just for fun, and few people bother to pretend otherwise. After perusing dozens of Web sites, though, I was able to piece together a single factoid that makes me go “Hmmmm”—but it will require some explanation. The factoid is this: Phil’s predictions are statistically significant—the odds that they’ll be wrong are far greater than would be the case if they were completely random. In other words, bet against Phil every year, and over the long run you’ll turn a tidy profit. As you may have guessed, it’s not quite that simple. The legend gives us two options: the groundhog sees his shadow, in which case winter will last another six weeks; or the groundhog does not see his shadow, in which case spring will arrive soon. Clearly, there are other possibilities. Winter may last for another five weeks, or four, or seven. The temperature may rise for a week but then fall again. Or it may hover in that ill-defined gray zone between “winter-like” and “spring-like” for weeks on end. How exactly does one determine definitively whether, or when, “winter” has ended (apart from looking at a calendar)? And supposing we work that out, how do we judge the results? If Phil predicts six more weeks of winter and there are five, was he right or wrong? What if he does not see a shadow but spring does not arrive in full force until three weeks later? Obviously, this indeterminacy enables groundhog fans to spin the facts in any way that pleases them. Nevertheless, numerous news organizations, in a heroic attempt to create novel content about this ritual, have applied a variety of logical and meteorological standards in order to tease meaningful statistics out of the past century-plus of prognostications. The results—depending on how the calculations were performed—show that Phil has been right, on average, between 25% and 39% of the time. That, if you ask me, is a truly extraordinary negative correlation. Considering it’s the weather we’re talking about, I’d take those odds. Grounds for Dismissal The myth of Groundhog Day is rooted in old Scottish and English rhymes involving Candlemas Day, which falls halfway between the winter solstice and the vernal equinox. According to the Continental tradition that gave rise to these rhymes, if the weather is cold and clear on this day, the cold will last; if it’s cloudy, the weather will soon turn. Groundhogs looking for their shadows are nothing but a convenient, folktale-friendly proxy. Supposing this story is somehow based in fact, it clearly must be a climate-specific fact. What may have been true centuries ago in Scotland, for example, may be all but meaningless in central Pennsylvania today. As a matter of fact, the very opposite appears to be much closer to the truth. But then, from what I can tell, the presence, absence, or clarity of an actual shadow is sort of a moot point on Gobbler’s Knob in Punxsutawney on February 2. Phil provides his prediction in “Groundhogese”; the guy in the black top hat renders the official “translation.” Most of the time, the verdict is yes: there was a shadow; six more weeks of winter. Giving Phil and his handlers the benefit of the doubt here, and supposing complete shadow-reporting integrity, we might guess that Phil’s startling inaccuracy is a simple matter of geography. Some of Phil’s counterparts, after all, such as Chester in St. Louis and New York’s Staten Island Chuck, boast accuracy rates of up to 85%. But there may be a more insidious explanation. I think Phil really does know the score but purposely lies, in protest for being dragged out of bed and into the cold. Either that or some human speaks very poor Groundhogese. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/groundhog-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Groundhog.5367edde43b9.mp3"
	},
	{
		"title": "Malaria. Bad air, good vegetables.",
		"text": "Malaria, as most people know, is a very nasty disease caused by a parasite that’s transmitted by mosquitoes. The disease is sometimes deadly, and always extremely unpleasant. The word “malaria” comes from the Italian mala aria, “bad air.” When the term was coined, it was commonly believed that malaria was caused by breathing in bad air—namely, the foul vapors emanating from swamps, latrines, and so on. It was a mere coincidence that the stagnant water that provided a breeding ground for mosquitoes also frequently contributed to bad air. More importantly for our purposes, however, this classic misnomer gives me an excuse to tell a story. As I have mentioned once or twice before, malaria and I go way back. How I Spent My Summer Vacation When I was 19, I spent the summer in a remote area of Indonesia. One morning I started feeling a bit ill, and by mid-afternoon I had a high fever, uncontrollable chills, severe aches in delicate body parts, and a general feeling of complete yuckiness. My companions debated whether or not it could be malaria. The symptoms were correct, but I had been taking an antimalarial drug faithfully and there was some question whether I’d been there long enough for the parasite to incubate. After a day or so I went to a local clinic, had a blood test, and was told for certain that it was indeed malaria. I had expected to run into scary foods, treacherous hiking trails, and maybe even a cannibal or two, but I had never seriously entertained the thought that I might contract a serious disease on my trip. How interesting. On the advice of an American doctor with whom we were in contact by shortwave radio, I began taking a different medicine, plus more of what I had already been taking. The doctor asked that I provide him with periodic blood samples so he could tell when the malaria had been sufficiently knocked out. This would involve putting a drop of blood on a slide, sending it out with the mail by a tiny airplane to the medical center, and then waiting for results back by radio. After a few days I regained enough strength that I could continue my travels, and I flew to a small village where I was to live for a week with a missionary family—John, Wendy, and their three young children. Giving the Finger When it came time to send in my next blood sample, I was far too squeamish to prick my own finger, so Wendy reluctantly offered to do the honors. She swabbed off my finger, unwrapped a sterile lancet, and stabbed lightly. Yowch! She had applied enough pressure to cause plenty of pain, but not enough to break the skin. She tried again…and again…and again. Four tries, and the best she could do was to lacerate the epidermis. It is hard to say which one of us was having more trouble with the procedure, but success was not at hand. So Wendy called her husband in to help. John was amused at the situation, and assured us both that he could handle the job. I offered my other hand, John stabbed, and…more pain, but no blood. He tried a second time, then a third, and a fourth. Finally, with considerable squeezing, we were able to get one tiny drop of blood out on the last try. It’s a good thing, too, because I was beginning to feel that the malaria wouldn’t have been as bad as the blood test. We sent off the blood sample, hoping for results soon. That evening at dinner, there was a bowl of cooked carrots on the table. I didn’t take any. Wendy said, “Aren’t you going to have any carrots?” I replied, “I really don’t care for them, thanks.” She said, “Well, I’m going to have to insist that you eat some. You see, I don’t like cooked carrots either, but if I don’t set a good example, my kids won’t eat them. And if I have to eat them, so do you.” I suppressed my distaste and took some cooked carrots. Cooking Up Revenge The following week, I was at a conference in another town. John and Wendy were there too with their family. Meals were served cafeteria-style, and one evening at dinner cooked carrots were on the menu. I wasn’t sitting at the same table as Wendy so I needn’t have taken any, but I looked over and saw that she had a few on her plate, and was clearly trying to avoid eating them. I felt bad, so I took a large helping of cooked carrots myself. Then I walked over to Wendy’s table and scraped my carrots onto her plate. I smiled, remembering my sore finger; she gave me the Glare of Death, but couldn’t say anything because her kids were watching. Meanwhile, the results of the blood test still weren’t back, and I was getting antsy. Each day I checked the mailboxes at the conference center for an envelope addressed to me, but nothing appeared. The following evening, however, there in the “K” box was an official-looking envelope with my name on it. I opened the letter and read the typewritten report: Mulia Medical Center Test Results Result of Blood Test: Severe Deficiency of Vitamin A Best source of Vitamin A: Cooked carrots Recommended treatment: 3-4 large bowls of cooked carrots daily Sample medicine enclosed. And inside, wrapped in foil, was a small piece of cooked carrot. I eventually made a full recovery. But ever since then, I’ve eaten my cooked carrots, just as a precautionary measure. You can never be too careful when it comes to malaria. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/mosquito-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Malaria.a2fec6f6d06c.mp3"
	},
	{
		"title": "Weblogs Revisited",
		"text": "By internet standards, I’m an old-timer. I began using the internet in the early 1990s, which must be about a century ago in computer years. That was before the invention of the World Wide Web, back when “commercial internet provider” was an oxymoron. When I saw my first Web browser, I didn’t get it. I thought, “What’s the point of this? I already have an email client, a news reader, and an FTP program.” After a year or two, though, the buzz increased so much that I decided I should check out that Web thing again. This time, I found a lot more sites and a lot more useful information. I liked the idea of the Web so much I decided to learn a bit of HTML and put together a personal home page. The first version of my page was pretty basic—just a few facts about myself, my work, and my hobbies—but over the years it grew until it became a virtual autobiography. Eventually I felt it was too much work to maintain, and I got rid of about 90% of it. But at its peak, I updated it every few days with news about what I was reading, where I would be traveling soon, and all sorts of other tidbits. Friends and family found it a convenient way to keep up with my busy life. In a way, that home page was a primitive forerunner of what would today be called a blog (short for “weblog”). When I first wrote about blogs on Interesting Thing of the Day in mid-2003, I thought they were already sort of old news. Then 2004 was called “Year of the Blog,” with blogs figuring prominently in political races and increasingly influencing public opinion. But as recently as late 2005, when I mentioned the word “blog” to a friend in passing, she said, “Does that have something to do with computers?” My friend is no dummy, but her world doesn’t revolve around technology the way it does for many of us. And she’s not alone. Even as the internet extends its tentacles into segments of society traditionally on the fringes of technological sophistication, there’s still considerable confusion as to what the term “blog” actually means. Lost in a Blog Notwithstanding the fact that lexicographers have come up with definitions for blog, if you asked a few dozen bloggers what makes a blog a blog, you would probably get a few dozen answers. Speaking very generally, most blogs are basically Web pages containing a series of dated, titled text entries, displayed in reverse chronological order. The first weblogs, circa 1998 or so, were literally Web logs, which is to say, records of noteworthy Web sites the author had visited recently, along with a commentary on each one. Assuming you trusted the taste and opinions of the blogger, these early sites were a good way of finding useful pages from among the thousands of new Web sites being published every day. But as weblogs caught on, and as the tools for creating them became easier to use, their character began to shift significantly. Although blogs come in many different forms, what you see most commonly is something resembling an online diary or journal: an entry every day or two, consisting of a few sentences or a few paragraphs about whatever is on the author’s mind at the time. Some blogs are written by famous authors, actors, or other celebrities, giving readers a voyeuristic glimpse into their thinking and activities. Others focus on a particular topic, such as computer programming, gadgets, political rhetoric, or relationships. But while the details vary, blogs almost always stick to the basic format of brief, dated entries in a long list, most recent entries first—making it easy to see just the latest additions with little or no scrolling. To Blog or Not To Blog You might think that as someone who used to keep every detail of his life on a Web page, I’d be very fond of the idea of blogs. But until relatively recently I deliberately stayed away from blogs. I had two main complaints about the blogs I’d seen. First, I couldn’t understand why I should care about some random person’s thoughts. How do I know that the person writing a blog is an authority on a given topic, or even a good writer? Without some a priori way to filter blogs, I couldn’t get any sense that reading them would be worth my time. I needed a weblog (in the original sense) about blogs to help me separate the wheat from the chaff (and sure enough, such meta-blogs are now quite popular). My other complaint was the lack of editorial quality. I’m all for free speech, and I appreciate the ease with which blogs allow people to express themselves. But I’m used to reading (and writing) books and magazine articles in which the content is checked for things like spelling, grammar, punctuation, accuracy, and relevance. With blogs the path is straight from the author to the reader, and for all the virtues of such a system, I found it painful to read blogs that just weren’t well-written. Imagine my dismay, then, when people started referring to Interesting Thing of the Day as my “blog.” I bristled at the very idea; it was almost insulting. For one thing, the format’s all wrong—I don’t write just a few sentences at a time, I write articles long enough to be encyclopedia entries. I don’t list them all on a single page. And the content is not journal-like; for the most part, the articles are expository rather than editorial in nature, and there’s usually no particular reason for a given topic being published on one day rather than another. And everything posted on the site undergoes at least some editing by a person other than the author. All that to say: whatever this site was, it didn’t fit into my personal notion of a blog, and I didn’t want other people thinking of it that way either. Peer Pressure Strikes Again But I eventually warmed to the idea of blogs, for several reasons. First, I saw some blogs with truly excellent writing; this helped to restore my confidence in the medium. At the same time, it reminded me that anything that encourages practice and discipline in writing is probably a good thing. Second, blogs usually focus almost exclusively on text, rather than flashy layouts, graphics, and animations. This suits my own sensibilities extremely well; I’m tired of Web sites that hide their limited content behind marketing-heavy gimmicks. And even though this site was not originally designed to fit into the blog format, it was easy enough to rearrange the existing data into a new template, meaning I can offer the site’s content in blog format for those who prefer to read it that way, and in the classic one-article-per-page format for those who don’t. (You can switch between Standard and Blog editions using the links in the upper-right corner of the page. ) In mid-2004, having finally admitted to myself that my personal home page was a sorry-looking relic of the '90s, I redesigned it as a blog. Unlike many bloggers, I don’t update my personal site daily with every trivial thought that goes through my mind, nor do I position the entries as an authoritative voice about anything other than myself. But I’ve still found this format tremendously useful, because it gives me a convenient forum in which to tell stories, talk about my life and work, and share other information with the public that would be out of place in the media where my professional writing appears. It doesn’t entirely fit the blog mold, but then, the entire brief history of blogs has been one of evolution. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/Steves-Blog.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Weblogs.603676831e6.mp3"
	},
	{
		"title": "The Color Purple. Shades of royalty and mythology",
		"text": "When I was a small child, my favorite color was purple. It didn’t require any deliberation for me to make that choice; purple was self-evidently the most attractive color in a box of crayons—anyone could see that. In fact, I remember being perplexed at people whose favorite color was something other than purple, and downright shocked when someone claimed not to like purple at all. But the early days of childhood were ones in which we were too young to make serious value judgments. Everyone had a different favorite color, shape, animal, or song, and all choices were equally good. Feeling Blue About Purple But by the time I was halfway through elementary school, I had begun to realize that not everyone adopted an attitude of tolerant acceptance when it came to one’s choice of favorite color. “Purple is for sissies,” my classmates insisted, and made fun of me for having such an unhip favorite color. (Had I been more confident and quicker on my feet, I might have countered, “Oh yeah, then why do kings always wear purple?” I probably would have regretted saying that, though, as soon as someone produced a picture of a king wearing tights. Children can be cruel.) As a measure of self-preservation, I decided the only safe course was to change my favorite color. I was at a loss to know what a reasonable second choice would be. I asked my mother what her favorite color was, and she said, “Blue.” I thought about that. I figured blue was a pretty OK color too, and it was definitely a safe and culturally acceptable favorite color. So right then and there, I decided to convert. For the next ten years or so, I proudly and persuasively claimed that my favorite color was blue. When I got to college, however, I began to learn how to think for myself. My cousin Jeff, who was a senior at the same college when I was a freshman, was my inspiration. He always—always—wrote in purple ink. And yet he was popular and well-respected. I briefly considered that he got away with this only because he was imposingly tall, but eventually realized that he had simply never accepted the unwarranted criticism of his color choices and had made a habit of standing up for his beliefs. Emboldened, I recanted my errant allegiance to blue and restored purple to its rightful place as my favorite color. There was just one problem: in those days, purple pens were not easy to locate. I asked Jeff discreetly about his supplier, and he said that his mom kept him in stock. About a week later, a care package arrived from Aunt Janice: a year’s supply of purple pens. You may be wondering what, other than this endearing autobiographical story, is actually interesting about purple. I’m glad you asked. Shrinking Violet The most surprising thing about purple is that it does not exist objectively. That is to say, there’s no single wavelength of light that can properly be called “purple”; humans only perceive purple when a mixture of blue light and red light hits their retinas. This seemingly counterintuitive fact makes more sense if you look at a spectrum; you’ll notice that red is on one end and blue is close to the other end. There’s no point where the two overlap to form an intermediate shade, unlike the green that appears between yellow and blue. Spectrally speaking, you can’t have a single wavelength that is a “reddish blue” or a “bluish red.” But what about violet? Violet has its own band on the spectrum, on the other side of blue—and isn’t violet just another name for purple? Well…yes and no. Technically, the poem is correct: “Violets are blue.” Violet is really nothing more than a very dark shade of blue, just as indigo is a light shade. By definition, violet can’t have any red in it, even though we commonly talk as though it does. Frustratingly, dictionaries are misleading on this subject. In Webster’s Revised Unabridged Dictionary, one of the definitions of violet is “a color produced by a combination of red and blue in equal proportions; a bluish purple color,” while in the same dictionary purple is defined similarly as “[a] red and blue color.” True enough, you can mix red and blue paint or pigment and see purple, but if you’re going to be nitpickingly accurate, you can’t call any mixture of red and blue “violet,” and you must be willing to accept that what you see as “purple” is really an illusion created in your brain. Purple Reigns That’s not to say that purple (illusory though it may be) doesn’t appear in nature. According to an ancient Roman legend, in about 1500 B.C., Hercules was walking his sheepdog on the beach one day. After biting into a mollusk, the dog’s mouth turned an unusual color. The mollusk, known as murex, was the first source of purple dye for fabrics—a pigment called Tyrian purple. The process by which the coloring agent was extracted, which required salt, heat, and water, was difficult and labor-intensive. In addition, each mollusk produced such a small quantity of dye that thousands were needed for a single garment. This is why purple was so expensive and came to be associated with royalty—generally the only people who could afford such extravagance. As recently as the mid-1800s, purple dye was still very hard to come by. Fabric dyes, based as they were on plant and animal products, for the most part produced colors that were bland and subject to fading. Synthetic dyes were invented by a happy accident. In 1856, an 18-year-old chemistry student named William Perkin, working in his home lab, was trying to synthesize quinine, an antimalarial agent. One of his experiments failed, but produced a beautiful powdery residue, which when dissolved served as a brilliant and colorfast purple dye. Perkin’s dye came to be called “mauve,” and in almost no time it was extraordinarily popular. Other synthetic dyes soon followed, and now form the basis of almost all fabric coloring. There is an important lesson to be learned here. If you ever felt tempted to ridicule someone whose favorite color is purple, consider that your blue jeans, red shirt, or green jacket would probably have been a dull gray were it not for the innovative and lucky discovery of William Perkin. Purple, in other words, deserves your respect and admiration. To this day, I still write with a Passionate Purple pen. So I won’t take offense if someone calls my writing “purple prose.” ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/Flag_of_Tokyo-purple-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Purple.a2e94978ee61.mp3"
	},
	{
		"title": "Paying It Forward. Spreading the good deed meme",
		"text": "Although I certainly have my malevolent moments, I generally try to treat other people in a courteous and helpful manner. I do this not out of a sense of guilt or duty, or because I expect some reward; it’s simply a habit—albeit one that has served me pretty well over the years. My impression is that people tend to behave more pleasantly toward me when I’m pleasant toward them, so I suppose my own behavior could be considered self-serving to some degree. What confounds me is when someone expresses surprise at polite behavior on my part. Quite frequently, for instance, someone who has read one of my books will write to ask me a technical question, and I write back as promptly as I can—even if it’s just to say I don’t know the answer. When I get a note back thanking me effusively and expressing amazement that I bothered to respond at all…that’s when I boggle. Has the world become so full of rude people that answering a simple question by email is now a shocking anomaly? Part of the problem is that most of us feel an unconscious mandate to maintain a balance of good and evil deeds. If someone invites me over for dinner, I must extend that person a similar invitation—or repay the favor in some other way. Otherwise, there seems to be an imbalance: I feel that I am somehow in debt to the other person, and that only by doing something equally kind in return can balance be restored. On the other hand, if someone harms me, I (or—in more serious cases—the government, acting on my behalf) must punish that person. To allow an injury to go unpunished is unthinkable, because it leaves the universe in a perilously unstable state with more evil deeds than good. And asking a favor of someone—especially someone you don’t know—is also problematic, because it means putting yourself in debt to that person. Except I don’t buy any of that. There aren’t any cosmic scales of justice, no divine tallies of who owes what to whom. If anything, the Buddhist notion of karma may be closer to what I’ve observed. Good deeds tend to generate goodwill that leads to more good deeds, and evil deeds do the opposite. If this is even approximately correct, it implies that no one ever owes anyone anything—neither help nor harm must be repaid. But the notion of doing good without any expectation of reciprocation or reward is a hard sell in western culture. So hard, in fact, that not even the Oscar-caliber likes of Kevin Spacey, Helen Hunt, and Haley Joel Osment could prevent the 2000 film Pay It Forward from being roundly panned, espousing as it did just such a view. Count to Three, Change the World For those who haven’t seen it or read the novel by Catherine Ryan Hyde on which it was based, the story revolves around a young boy named Trevor. When asked by a social studies teacher to come up with an idea that could change the world, Trevor decides he’ll do favors for three people. The twist is that instead of repaying him, each of the people he helps is required to “pay it forward”—to help out three other people. Each of those people, in turn, is obliged to do favors for three more people, and so on—so that, if everyone follows through with their good deeds, pretty soon everyone in the world is helping out other people without expecting anything in return. A lovely scenario, if sappy and implausible. I enjoyed the film and found it moderately inspiring, but I understand why so many people had a strong negative reaction. Apart from a predictable script and unexceptional acting, the story itself is difficult to stomach. In a nutshell: it just doesn’t work that way. For one thing, human nature being what it is, the probability that someone will “pay forward” a favor, no matter how profound or life-changing, is vanishingly small. For another, the film pretty transparently imposes its morality of selfless behavior on the audience. It feels uncomfortable to be told so blatantly how to act, especially when the film itself was clearly made for financial gain. Back in the real world, the idea of “paying it forward” has caught on here and there. Following the release of the film and novel, Hyde established the Pay It Forward Foundation, which promotes educational programs based on the pay-it-forward principle. And there is a modest Pay It Forward Movement—though based on its official Web site, it does not yet appear to have gained a great deal of momentum. Certainly it has not come anywhere near the explosive popularity predicted by Trevor’s school project. And oddly enough, the more I think about it, the less enthusiastic I am about the idea too. One Step Forward, Two Steps Back The biggest objection I have to the notion of “paying it forward” is that I don’t want to impose an obligation on anyone—even if that obligation has nothing to do with repaying me. If someone did a favor for me and then demanded that I do favors for three other people, I’d naturally resist. The favor would seem tainted, because the request to pay it forward amounts to an imposition of guilt, a placing of three weights on the negative side of that metaphorical balance. If I must now go out and do good deeds out of obligation to the person who helped me, those deeds are no longer genuinely selfless, no longer karmically pure. I don’t “practice random acts of kindness”; I don’t “follow the Golden Rule.” I just try to be nice to other people most of the time. If I did it all the time, I’d be a saint; if I “paid it forward,” I’d be an activist. Not that there’s anything wrong with that, but I’d just as soon not increase the world’s guilt quotient. ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Forward.e52d1a483b42.mp3"
	},
	{
		"title": "Falling Back",
		"text": "In most parts of North America and Europe, among other regions, this weekend marks the last day of Daylight Saving Time, sometimes called “summer time.” On Saturday night we will all set our clocks back, enjoy an extra hour of sleep (or partying, depending on one’s disposition), and wake up to a slightly brighter morning. We will all be 3% happier, offsetting the 3% loss in happiness we experienced when we had to set our clocks forward and lose an hour of sleep back in the spring. Two Steps Forward, One Hour Back The mnemonic “spring forward, fall back” is meant to remind us which way to set our clocks for a given season (assuming they don’t have the intelligence to figure it out themselves, as they increasingly do). But this trick works well only in North America. In British English, the word fall is rarely used to mean “autumn.” And of course, outside the English-speaking world, where the homonym “spring/spring” does not exist, other memory aids must be employed. Although I find “spring forward, fall back” helpful, an even more useful mnemonic would be one that reminded us when these changes happen. I’ve never managed to internalize the pattern; last week I mistakenly sent a bunch of people an email message reminding them to change their clocks, only to issue a retraction minutes later when someone pointed out my error. The sheer arbitrariness of it all trips me up; it took me years just to get that “30 days hath September…” thing straight. I could go into a long discussion about this time change: the argument over whether it should properly be called “Daylight Savings Time” instead of “Daylight Saving Time”; the history of its implementation and the various dates on which it has started and ended; the reasons places such as Hawaii, American Samoa, Guam, Puerto Rico, the Virgin Islands, Saskatchewan, and most of Arizona choose not to observe it; the variations between “summer time” as observed in other parts of the world and Daylight Saving Time in North America; and so on. But such a discussion seems more appropriate at the beginning of Daylight Saving Time, when we adopt the fiction that the next seven months are a mere temporary variance from the “standard” time we observe during the other five. In the spring, we can ponder why we do not “spring forward” from the aberrant “winter time” into the normal reckoning of time. Be that as it may—and despite this season’s association with ghouls, tricksters, and also matters unrelated to elections in the U.S.—I often find this artificial ritual of clock adjustment an occasion for reflection on progress, opportunity, and priorities. Fall Guy The phrase “falling back” can mean several different things depending on the context of its use, and I was just reflecting on the fact that most of them could apply to me right now. There’s the literal sense of falling backward, which may occur to someone who has spent quite a few consecutive near-sleepless nights working on various urgent projects, as I have recently. Falling back could be construed as “falling behind,” which can come from insufficient progress during the aforementioned sleepless nights. In a military or police operation (or even some sports), “fall back” can mean “retreat” (in order to regroup, preserve one’s safety, or simply find a more strategic position)—just as I may do when feeling overwhelmed by too many different demands. This, in turn, is closely related to the “fall-back plan,” a backup strategy for when one’s primary course of action is not viable. My fall-back plan for when I have too few functioning brain cells to research a proper article is to write about things that require little thought. Although I always try to avoid making overt political statements in this forum, allow me humbly to propose a modest exercise. On this date when most of us undertake a minor change, consider whether there are features of your customary routine that might also benefit from a small change—things you have become, perhaps, slightly dissatisfied with. In my case, certainly the change of a few less calories ingested and a few more burned through exercise would yield welcome results. A wee bit more sleep; maybe a wee bit less TV. Fewer projects, more time socializing with friends. These are not huge, New-Year’s-resolution kinds of changes, just small ones to offset the small damages done in recent months or years of slight excess or laziness. And then, gentle reader, if you also find yourself slightly dissatisfied with the quality of life or the priorities of government in your city, state, or nation, make yet another small change on Election Day. The merest swipe of a pen, flick of a switch, or tap on a screen—perhaps in a spot just slightly different from where habit may tempt you—could be that little change that produces the most meaningful and beneficial results. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/clock-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/Falling-Back.72575c0867e7.mp3"
	},
	{
		"title": "The French Meal-Payment Ritual",
		"text": "My official job description only requires me to deliver articles about “things,” which I have intentionally defined as broadly as possible. So if, say, the way a waitress treats me seems interesting, that should be fair game. Thus I present for your consideration an interesting thing that happened at lunch one day last year while on vacation in France. Around noon on this day, Morgen and I walked into a café near the Pompidou Center in Paris. We were shown to a table and given menus; a few minutes later, our waitress returned to take our order. We waited a while longer and our food came; it was delicious, just as we’d expected. This pattern of enter-select-order-eat is, with few and minor variations, common all over the world, and I have repeated this ritual an untold number of times in a variety of languages. But in France, as any travel book will tell you, the expectation is that you will want to savor your meal, perhaps have dessert and a relaxing cup of coffee, and then remain at your table for a further hour or two enjoying the company of whomever you’re with. There is no notion whatsoever of rushing patrons out to make space available for the next customer; in France, once you’ve claimed a table, it’s yours for as long as you care to stay—even if you consumed the last of your meal hours ago. This attitude, I must say, strikes me as wonderfully civilized, and I can think of two or three North American countries that would do well to adopt the same custom. Do Not Disturb I’ve had plenty of long, leisurely meals at restaurants in France, so this approach to interacting with customers is by now familiar and comfortable. And yet, there is one aspect of the restaurant ritual in France that I find completely inscrutable—namely, the process whereby you attract your waiter or waitress’s attention to tell them you’re ready for your check. The check won’t arrive automatically; that would be a faux pas, because it would make the patrons feel rushed. No, you are supposed to ask for it when you’re ready, which is fine—this is the norm in lots of countries. What the travel guides and phrase books tell you is what to say to request your bill—“L’addition, s’il vous plaît.” That’s easy enough. What the books don’t tell you is how to convey this phrase to the waitress who is 20 meters away in a noisy restaurant with her back turned to you. In North America, on the rare occasion that your bill doesn’t arrive by itself within three seconds of the time your dessert is served, getting it is a simple matter of making eye contact with a waiter, who will have been trained to scan his tables every few minutes to see if there’s any possibility of encouraging their occupants to leave. In France, after dessert and coffee, the wait staff assumes that you want to be left alone, so signaling that you want something can be quite tricky. After we had finished our dessert and coffee and the obligatory one-hour after-lunch conversation, we were ready to get on with our sightseeing, so I tried to make eye contact with our waitress. Over a period of about 20 minutes, I stared intently in her direction, plaintively sending out “look at me” vibes, but to no avail. It’s not that she was ignoring us, either. Every few minutes she did in fact scan the restaurant and make eye contact with me, but the duration of eye contact was so short—I’m going to say, about 1/12 of a second—that there was not enough time for me to wave my hand in a “bring us the check” gesture or even raise my eyebrows. A Burning Question This was not the first time we had encountered this difficulty; it was the norm at the majority of restaurants we visited in France. Morgen and I pondered the logic behind this rapid-scanning move and, amazingly, came up with the same explanation independently of each other. We concluded that the rate of eye movement was carefully calculated such that the amount of time spent looking at any given table was just enough to determine if it was on fire. Flames, we agreed, would register during 1/12 of a second and prompt the waitress to take action; mere eye contact would not, presumably because French waitresses are used to being stared at. I asked Morgen if she had any matches; she did not. Then it dawned on me: this must be why so many people in France smoke. It’s the only way you can be assured of having a ready supply of waitress-attracting combustible materials. Fortunately, though, our very failure to light up cigarettes apparently stood out after a while, and I was able to attract the waitress’s attention for the crucial 1/3 of a second it took me to raise my eyebrows. Then she smiled and mouthed “l’addition?” from across the room—which I’ll bet she does with all the male customers—and I smiled and nodded back. Luckily, the service was already included with the bill, otherwise I wouldn’t have known whether to tip less for failing to pay attention to the customer, or more for doing a truly excellent job of unobtrusive fire detection. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/08/matches.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/08/French-Meal.7d7ffc03198b.mp3"
	},
	{
		"title": "The Experience of Things. An editorial aside",
		"text": "On December 31, 2000, I was in New York City. I went there because I wanted to attend the New Year's Eve festivities at Times Square; having watched the spectacle on TV for years, I felt it was time I experienced it for myself. Time and time again, people warned me not to go. “I've been there; it's horrible,” someone would say. “You can't see anything, you can't hear anything, the crowds are crazy. You'd have a much better time if you just stayed home.” And each time I replied, “I believe you. I want to go anyway.” I hate crowds, yet there were bound to be close to a million people there. I hate the cold, and it was well below freezing—a major snowstorm had just blown through. I hate noise and chaos; the scene was likely to include both. In spite of all these things, I went, even knowing for certain in advance that it would be unpleasant, and knowing I could choose not to go. Sure enough, the experience lived up (or down) to my expectations. In addition to the hundreds of thousands of noisy people crowding on all sides and extremities numb from the cold, my bladder was painfully full as I stood there for more than six hours in what can only be described as complete discomfort. I couldn't see or hear what was happening on the stage several blocks ahead, and when the ball dropped and the police barricades were moved aside, I could not have been less interested in staying to celebrate. Warmth, food, and a lavatory—not necessarily in that order—were foremost on my mind. Later, when the people who had warned me off in the first place asked if I'd do it again, I said, “I've done it once; I don't need to do it a second time. But if I could go back in time and choose again whether or not to do it the first time, I'd choose the same experience.” Why? Because no description of an experience can ever really tell you what it's like. If you want to know, you have to find out for yourself. Seeing for Yourself The kind of knowing you get from experience is qualitatively different from what you get by reading about something or hearing a story. This is why people travel instead of just reading travel books. However much you may trust other sources of information, they can't provide what your own senses can. And just as some foods are worth eating even though they don't taste good, some potentially unpleasant experiences are worth having. From Descartes, who said, “I think, therefore I am,” through phenomenologists like Husserl and Heidegger, who tried to create a rigorous science of experience, philosophers have time and again reaffirmed the importance of one's own experience in understanding the world. Yet it is a tacit principle of modern western culture that only pleasant experiences are worth pursuing, that any experience you can't reasonably expect to enjoy should be avoided if possible. This attitude effectively puts the evaluation of experiences in other people's hands, but other people will never experience things exactly the way you will. You may enjoy an experience someone else does not, and even if you don't, you may appreciate the value of collecting that knowledge for yourself. I know a number of people who have gone to Hawaii on vacation. Some of them have told me it's a wonderful place, full of beauty and culture; others have told me it's overcommercialized, touristy, and generally a waste of time. And the fact is, they're all right—each from a different point of view. No two people can have exactly the same experience of the same thing, place, or event. There are too many variables, not the least of which is the attitude with which you approach an experience. Your background, tastes, expectations, and many other factors will influence your interpretation of any experience. I haven't visited Hawaii. I don't have an opinion about it, but I am curious. Perhaps one day I will go there and find out for myself what it's like—at least for one person, with one background, at one time. Whatever else can be said about the experience I eventually have, it will be unique. It's Just a Sensation While any experience, good or bad, can trivially be called a “learning experience,” I don't necessarily have learning in mind when I think of experiencing things I may not like. I think, more generally, about approaching new experiences with equanimity (to the extent possible), trying to detach myself from an immediate value judgment. When I practice t'ai chi and my legs hurt, I try to think: “It's just a sensation. Not everything that's painful is necessarily bad.” And even things that are bad usually have some positive value. I had malaria once and it was terrible; I wouldn't wish it on anyone. I can't pretend I liked it, but I do have a story now that I wouldn't have had otherwise, and I have a piece of knowledge that most Americans don't have: I know what malaria actually feels like, while others just know the clinical list of symptoms. There are some experiences I choose not to have—for legal, moral, or philosophical reasons. I avoid experiences I consider likely to cause harm to myself or anyone else; I also avoid some experiences about which I simply have no curiosity at all—not everything can be interesting to everyone. Nor do I value every experience equally—for example, I certainly cannot say I have no regrets. I can, however, say that even my stupidest and most selfish choices have, at least indirectly, resulted in some eventual good. The Decade of Risk When I turned 30, I gave a little speech at my birthday party. Among other things, I declared that the following 10 years would be my “decade of risk.” I didn't mean that I planned to take up sword swallowing or start investing in pyramid schemes. Rather, I meant that I would try to be more open to experiences that don't fit into my world view, that may change me in unexpected ways, that lack assurances of enjoyment but offer the potential for enlightenment, in some small way. In short, I would seek to have more experiences for their own sake. I've fared pretty well, and there are still a couple more years left until I move on to my “decade of wealth and influence” (or whatever the next decade turns out to be). There are plenty more interesting things to experience and report. In the meantime, get out there and experience things. Try it, you'll like it—or maybe not—but you'll know something you didn't know before. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/NY-new-year.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Experience.e9d0ec979eb1.mp3"
	},
	{
		"title": "Paris Plages",
		"text": "August in Paris is traditionally the time when residents head off for their month-long annual vacations. However, the city is by no means empty. For millions of residents and tourists, life goes on as usual, but there’s still that seasonal urge to spread out a towel on the sand and soak up some sun. Paris is nearly 125 miles (200km) from the coast, but every summer since 2002, a full-blown beach has appeared right in the center of town, courtesy of the city government and corporate sponsors. Paris Plages is the collective name of a series of sites set up around the city for summertime activities; they’re in operation for roughly a month each year from late July to late August. The idea was the brainchild of Paris mayor Bertrand Delanoë, who has taken numerous steps to make the city more accessible to pedestrians and cyclists. The original and best-known Paris Plage is constructed along the right bank of the Seine River, running almost 2 miles (3km) from the Louvre to Pont Sully (the Sully Bridge). What is normally the Georges Pompidou Expressway is closed to traffic (much to the dismay of commuters) and turned into a pedestrian walkway. Along the side of the road farthest from the river the actual beaches are installed—3000 tons of sand trucked in and trucked back out every year. In between sections of faux beach are areas devoted to other activities for both adults and children, such as rock climbing, rollerblading, and even t’ai chi. There are also restrooms, showers, first aid and police stations, and several mist zones where people can stand in a constant fine spray of water to cool off. Summer Barbecue Mostly, though, people do what they normally do on beaches: lie on the sand or in hammocks in their swimsuits and get sunburned. The crowds are often dense, and those who arrive late in the day, especially on weekends, may have trouble finding a spot. Unlike other crowded beaches, though, the one thing you will not see is people going in the water. Apart from the fact that the beach is separated from the river by a wall and a road, it’s not the sort of place you would want to swim, wade, or simply get your toes wet even if you could. It would be easier, safer, and probably more hygienic to take a dip directly in the sewers. However, if you go down the river a bit farther, you’ll find another Paris Plage location that features La Piscine Joséphine Baker, a huge swimming pool that actually floats in a barge on the river. So you can swim in the river, in a manner of speaking, without risking your health. At other spots in the city you can enjoy everything from beach volleyball or rugby (in front of the Hôtel de Ville, or City Hall, just steps from the central Paris Plage) to canoeing and kayaking (at the Bassin de la Villette). Surf’s Up Another thing you can do at any of the Paris Plage locations is, appropriately enough, surf—on the internet, that is. That’s right: the whole area has free Wi-Fi service. Which, I’m sure, was a very thoughtful and modern and generous notion on behalf of the organizers, but…seriously? I walked the entire length of the Paris Plage along the Seine and didn’t see a single laptop in use. Apart from the obvious fact that electronics don’t tend to get along well with sand, water, and bright sunlight, people really do go to the beach to relax. I’m teasing a bit: Wi-Fi is useful for numerous gadgets that are more beach-friendly, and there are certainly some dry, shady, and sand-free spots near the beach that would make a lovely spot to sit and type for a while if that’s your thing. But I know I wouldn’t choose a beach based on its internet connectivity. Well, for that matter, I pretty much wouldn’t choose a beach at all. My personal preference is to enjoy those nice sunny days and the beautiful scenery from the comfort of a cool, dark, and uncrowded room somewhere. The Catacombs are lovely this time of year. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/seine.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Paris-Plages.78966bf4f845.mp3"
	},
	{
		"title": "Hikaru Dorodango",
		"text": "Children, I have observed, seem to have an innate affinity for dirt. No matter how recently a parent has dressed the child in freshly laundered clothes, no matter how carefully the parent has attempted to keep the child geographically separated from any substance that might soil or stain, it is just not possible to keep a child clean for more than 60 seconds. I use the word “affinity” advisedly, because it implies not merely a liking, a preference, but a chemical attraction. Kids clearly have a talent for finding dirt, but also, dirt finds them. If you’re a parent, you know what I’m talking about. Eventually, having spent a sum equivalent to your monthly grocery budget on moist towelettes, you give up on keeping the child perpetually clean and set a new, lower but potentially reachable standard of not-entirely-covered-with-mud. Mud, of course, is that particular species of dirt that children seem to find most fascinating (and which apparently finds them fascinating as well). As far as kids are concerned, mud is cool because it’s gooey and squishy and feels neat and adheres very effectively to your sister’s dress when flung from across the yard. Grown-ups find mud icky for exactly the same reasons, and dried mud, well, that’s somehow an even greater insult to cleanliness—it’s just so…unsightly. Among the words not commonly associated with mud are smooth, shiny, and beautiful. But that’s changing now, thanks to the renaissance of a traditional Japanese art form known as dorodango, shiny mud balls (or, more specifically, hikaru dorodango, ultra-glossy mud balls). Parents are now not only actively encouraging their kids to play in the mud, they’re getting their own hands dirty too as they spend hours refining ordinary dirt into elegant sculptures. Putting the Shine On It seems odd to think of mud as something that could become shiny or even smooth. Polished rocks are one thing, but mud wouldn’t seem to be hard enough or dense enough to be polished. With the right technique and a lot of patience, however, it can be. The full procedure has numerous important details, but essentially the idea is this. You start with a lump of mud, squeeze most of the water out of it, and slowly and gently add layers of ever-finer dry dirt on top, all the while shaping into as perfect a sphere as you can and smoothing off any rough spots or irregularities. Over a period of hours, as the ball dries and you continue refining the surface, a hard shell (or “capsule”) forms on the outside. If you’ve executed the procedure just so and timed it correctly, this surface can be buffed to a high gloss with an ordinary rag. The result should be an orb about the size of a billiard ball, and just as shiny; its color depends on the kind of soil used, but can vary from nearly white, through yellow, red, and brown, to nearly black, with subtle shadings that make it look more like a fine marble carving than what was recently a mixture of dirt and water. Having a Ball In the past several years, the art of dorodango has enjoyed a surge in popularity—first in Japan, and more recently in the United States. The renewed interest is largely due to the work of a developmental psychologist at the Kyoto University of Education named Fumio Kayo. Kayo developed a simple method of making dorodango that could be taught even to young children, and besides keeping them occupied quietly for long periods of time, this activity enabled Kayo to study aspects of children’s play that had gone largely unnoticed, and which have interesting implications for his academic work. One of Kayo’s most striking observations was that children invariably become deeply attached to the mud balls they’ve spent so many hours creating, even if they’re misshapen or otherwise flawed. (Not a surprise to me: I knew that kids get attached to mud, or vice-versa.) Adults who have tried the procedure have reported similar feelings. Children who spend their afternoons making dorodango do, I’m afraid, end up with dirty hands and clothes. But they also have a stunning work of art to show for it, and that’s got to count for something. I have yet to try dorodango myself, but I love the idea that you can make something so beautiful with three ingredients (dirt, water, and a rag) that virtually anyone in the world can obtain for free. As any child knows, mud is one of life’s simple pleasures. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/dorogando.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Dorodango.837caf2b778d.mp3"
	},
	{
		"title": "Cow Sharing",
		"text": "Humans have been raising cows and drinking their milk for thousands of years, and for most of that time there was only one form that the milk came in: straight from the cow. Different cultures developed ways of transforming that milk into other foods, from yogurt to cheese to butter, but the original liquid stayed the same. However, when you visit an average supermarket in Europe or North America these days, you are faced with a plethora of choices in the milk aisle. You can have your milk homogenized, that is with the butterfat distributed throughout the milk, or you can buy only the cream skimmed from the top. You can have it in a low-fat or high-fat form, and you can buy it with part of the lactose removed for those who are lactose-intolerant. Despite all these choices, there is one type of milk that you will be unlikely to find: raw, unpasteurized milk, or the kind that comes straight from the cow. It is now the standard for milk commercially sold to be pasteurized—heated to a high temperature to destroy pathogens—and in some cases, particularly in Europe, it may even undergo UHT (Ultra High Temperature) pasteurization. In fact, many states in the U.S. and governments in other countries do not allow the sale of milk that hasn’t been pasteurized, citing public health concerns. In response to this, consumers who prefer raw, unpasteurized milk have found a novel way to obtain it: through the practice of cow sharing. A Raw Deal Cow sharing, although different in many ways from car sharing, has some of the same principles. A group shares the benefits of a car or a cow without having individual responsibility for it. Cow sharing can take many different forms, but it usually involves a farmer selling “shares” in a cow, and as a kind of dividend, shareholders receive fresh milk at regular intervals. Many of these arrangements also require shareholders to pay additional fees for the upkeep of the cow—for its feeding, housing, and milking. The number of shares per cow varies; it is often dependent upon how much milk the cow can produce, and how much of that milk is tied to each share. In areas where the sale of raw milk is prohibited, cow sharing can be a legal way for people to obtain it. There is usually no prohibition on dairy farmers consuming raw milk themselves, since they are not selling it, and in the same way, shareholders are not buying milk, but are owners along with the farmer. Even in areas where the sale of raw milk is allowed, cow sharing appeals to people who want a more direct connection with the source of their food. And why is raw milk in such demand? Raw milk proponents claim that the process of pasteurization kills not only unhealthy organisms, but destroys beneficial enzymes and vitamins present in milk’s natural state. Some also argue that the pasteurization requirement favors large-scale dairy operations over small farms that would benefit from being able to sell directly to the public. Others are drawn to raw milk because of its versatility; they want to make their own butter or cheese, which isn’t possible with highly processed milk. Some simply think it tastes better. The Heat is On As passionately as raw milk proponents feel about the issue, there are similar strong feelings on the other side. Opponents of the consumption of raw milk point to statistics showing that it has caused outbreaks of E. coli and other food-borne illnesses, and argue that pasteurization is necessary to protect the public from these types of outbreaks. Several cases in recent years have highlighted the divisiveness of this issue, including that of Michael Schmidt, a dairy farmer in the Canadian province of Ontario. Schmidt, who runs a cow sharing operation, had his property seized in November 2006 and was charged with operating a milk plant without a license. His case gained a lot of attention when he went on a month-long hunger strike (broken only by a glass of raw milk daily) to protest the charges. In my opinion, both sides in this controversy have valid points; it is important to maintain public safety when it comes to food products, but if people decide they still want to drink raw milk after hearing about its potential health risks, I don’t think they should be prevented from doing that. As for me, I can only be a bystander to this debate since I am lactose-intolerant; is there such a thing as raw soy milk? ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/cow.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Cow-Sharing.d1467fee6d89.mp3"
	},
	{
		"title": "The Vienna Vegetable Orchestra",
		"text": "The 20th-century American composer John Cage was well known for his experimental approach to making music. His most famous composition, titled 4’33” (four minutes and 33 seconds), playfully widens the boundaries of what is considered music. The piece consists of four minutes and thirty-three seconds of structured silence (although it was written to be performed for any length of time), during which time listeners are drawn to discover the ambient sounds going on all around them. This idea that music can be found in unlikely circumstances has resonated in the works of other composers who followed Cage. In a similar, but unique vein, a group known as the Vienna Vegetable Orchestra, or more simply the Vegetable Orchestra, creates music from an unlikely source: fresh vegetables. Playing with Food The orchestra, consisting of 11 musicians, a sound engineer, and a video artist, was first formed in 1998. Since then, the group has released two CDs and given concerts all over Europe as well as in Asia. Their work is influenced by many different styles of music, including classical, jazz, and electronic/techno music. In fact, their most recent CD, Automate, contains their versions of songs by the influential German electronic music group Kraftwerk. In a creative melding of the organic and the digital, the group recorded samples of their vegetable instrument sounds, and then assembled them to create digital compositions. And what do vegetables sound like? Like any orchestra, the instruments of the Vegetable Orchestra produce different categories of sound based on their shape and the method of playing them. There are percussion instruments: celeriac bongos, a clapper made from an eggplant, pumpkins to be pounded upon, and dry beans that are shaken to provide rhythmic effects. There are strings (a leek violin), woodwinds (a carrot recorder), and versions of brass instruments (a trumpet made from a red pepper). Of course, the orchestra is also continually coming up with new instrumental creations, determined by their need for a specific sound or a new discovery at the market. From the Raw To the Cooked Unlike other orchestras, the members of the Vegetable Orchestra must remake their instruments every time they perform. In preparing for a show, the group begins at a local market, where finding the perfect specimens is crucial. Once they have procured the produce they need, they set to work crafting their instruments, improvising as needed. Because the group’s members are drawn from a variety of artistic backgrounds, including the visual arts and architecture, the making of instruments is also part of their creative work. Some instruments take very little time to prepare; others, such as the carrot recorder, can take as long as half an hour to make. Later, during the performance, the interaction between the musicians and the vegetables continues. As some instruments tend to dry out as time goes on, they must be moistened, and some instruments may disintegrate completely. This aspect of chance adds to the improvisational quality of the orchestra’s performances, although most of their pieces are composed, not improvised. In their concerts, the orchestra aims to engage the audience’s senses fully—from the sounds they create, to the video images projected behind them on the stage, to the smell of the vegetables in the air. And finally, as an encore, the audience is invited to taste the instruments, in the form of vegetable soup available to all. I’m Decay, You’re Decay This full cycle from fresh produce to soup also addresses another theme important to the orchestra, that of decay. In this sense, it reminds me of the work of Andy Goldsworthy, who creates art out of objects found in nature. Once he has created a work, Goldsworthy photographs it, but then lets it degrade as it will. Working with an ephemeral medium, be it vegetables or icicles, is itself an artistic statement, in that it favors the process of creation over the finished product. What is left is the memory of a moment in time that can be savored like a warm bowl of vegetable soup. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/vegetables-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Vienna.1e4ce8e2d87f.mp3"
	},
	{
		"title": "Shipping Container Architecture",
		"text": "In the years I’ve lived in San Francisco I have seen more than my fair share of cargo shipping containers—sometimes being hoisted by cranes in the busy Port of Oakland, other times filling the decks of gigantic freighters passing through the Golden Gate. They have become so ubiquitous that I almost don’t see them at all; they are just one part of the Bay area landscape. When I have noticed them, it has only been to ponder the immense scale of the global economy, and to imagine the variety of goods they may be carrying. Although I may view them only as vehicles of commerce, there are some who have re-imagined these behemoths in an exciting new way. They have looked at shipping containers and said, “I could live in one of those.” While the mention of people living in shipping containers may bring to mind horrible images of would-be immigrants forced into appalling living conditions by leaders of smuggling rings, I am not talking about that kind of living arrangement. Instead, I am referring to savvy architects and planners who have seen the benefits of incorporating shipping containers into their designs for homes, schools, youth centers and live/work complexes. Shipping News The use of modern shipping containers first developed in the mid-fifties in Denmark, Canada, and the United States. These containers soon became invaluable, as their use streamlined the transportation of goods between ports and inland destinations via railroad cars and large trucks. They were created to be easily stackable and made sturdy to withstand wind and water, and these same attributes are what make shipping containers so attractive to architects and builders. In addition to their sturdiness and flexibility, shipping containers have other benefits. Designers looking for more environmentally friendly construction methods can practice recycling by using decommissioned containers from shipping companies. These containers are also much cheaper than standard building materials (sometimes by as much as half), and with their use, buildings can be assembled in much less time, with lower labor costs. Another advantage to shipping containers is that they are easy to transport, having been designed expressly for that purpose. This can facilitate their use in disaster situations, allowing re-purposed containers to arrive quickly in areas where temporary housing is desperately needed. It also means that containers can be worked on in one location, and then easily transferred to the actual building site in another area when needed. Contain Yourself While building with shipping containers may make economic and environmental sense, who would want to live in a windowless metal box? Designers have gotten around this limitation in a variety of ways, most notably by incorporating containers into larger construction projects, cutting and shaping the existing containers as necessary. However, there have also been exciting projects created with only one shipping container, such as a “sauna box” developed by a Toronto design firm; a portable utility module that provides remote locations with water, power, and heating capabilities; and a girls' athletic facility in South Africa. The next level up from the single container structures are private homes designed using multiple containers. Zigloo Domestique, built using eight containers, was created by designer Keith Dewey in Victoria, British Columbia. The containers form the frame of the unique house he shares with his wife and daughter. Another example of this type of structure is a Redondo Beach house, designed and currently under construction by DeMaria Design Associates. According to their Web site, the new home will be “mold proof, fire proof” and “termite proof.” Come Together The most ambitious projects undertaken using shipping containers are large-scale housing and office complexes, such as Container Cities I and II in London. Designed by Urban Space Management, Container City I is located at Trinity Buoy Wharf in London’s Docklands district, and comprises 12 work studios and three live/work apartments. Amazingly, it only took four days to install, and 80% of it is made from recycled material. Following the success of Container City I, Container City II was built adjacent to it in 2002. Notable for its ziggurat shape and bright colors, Container City II hosts 22 studios on five floors. This development, as well as many others being designed and built around the world, may herald the shape of things to come. With its economic, environmental, logistical, and practical benefits, shipping container architecture provides a compelling alternative to conventional building methods. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/cargo-shipping-containers-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Shipping.10ab114b62dc.mp3"
	},
	{
		"title": "Freecycling. Finding your stuff a new home, painlessly",
		"text": "In a couple of months, Morgen and I are going to be moving. Naturally, we’ve got a million details to worry about, but one of the biggest is what to do with all our stuff. The usual answer is simply to pile it all in a moving van and unload it at the next place—or, if your new home is too small, put the extra stuff in storage. We’ve done this numerous times before, and frankly, we’re tired of moving so much stuff around. Sure, we’ll take some things, sell some things, and store some things, but there’ll still be a lot left over that we don’t know what to do with. So this time we’re going to try something different: freecycling, or free recycling. As middle-class Americans go, we’re not very good consumers. We rarely buy things we don’t actually need, and we haven’t accumulated anywhere near the volume of possessions that most of our peers have. But still: we have too much stuff. Stuff that’s perfectly good, but which we simply no longer need. Random small appliances and electronic gadgets. Lots of books we’ve read and won’t read again. Years worth of National Geographic magazine. A tire pump. Tools. Plastic coat hangers. The list goes on. These kinds of things would be too much bother to sell on eBay, and they’d make little or no money at a garage sale. But we don’t want to simply throw them away, either, because they could be useful to someone. But who needs these things? Freecycling, the latest fad in ownership transfer, has the answer. Yours for the Asking The idea of freecycling is simplicity itself. You join an email list in your local region. When you have something to give away, you send a message to the list. Anyone else on the list who wants it sends you a reply—and arranges transportation, if necessary. There are no trades or barters, and no strings attached. Everything is completely free, period. And, of course, if you need something that hasn’t already been posted on the list, you can ask for it. Maybe you’ve moved into a new apartment that doesn’t have an ice cube bin, and someone else happens to have one, but didn’t think to list it. Or maybe it’s something larger or stranger, like a wheelbarrow, a rocking chair, or a 50-foot Ethernet cable. You never know: someone just might have what you need. As long as you can pick it up yourself, it’s yours. Freecycling began in Tucson, Arizona in May 2003 as a way to help reduce the quantity of waste sent to landfills. Since then, it has spread to thousands of local groups in more than 50 countries. From what I’ve read, though, it sounds like most participants aren’t doing it for the environment. They’re doing it because it’s a convenient and free way to get rid of things you don’t need or acquire things you do. If it happens to keep landfills from overflowing too, hey, that’s a lovely bonus. Free As in Beer, Not As in Speech But all is not peace and goodwill in the world of freecycling. For starters, there’s the term itself, which I have been blatantly misusing for the last several paragraphs. The word Freecycle is a trademark of The Freecycle Network, the nonprofit organization based in Arizona that started the movement. Any local chapter that wants to be part of the network—as in being listed on the Freecycle.org Web site’s search page—must follow strict guidelines about the use of the term Freecycle and the Freecycle logo. One must not, for example, use Freecycle or freecycling as a verb, or without a capital F. The Freecycle Network has not only enforced these regulations somewhat heavy-handedly, but has taken legal action against groups that were not officially part of the network and used some variation of the word “freecycle” in their names. In going out of their way to protect their trademark, they’ve limited the spread of a valuable public service simply to exercise a right that should not, given the organization’s nonprofit status, result in any profit anyway. Another result has been the creation of several other free recycling networks that perform virtually the same function but are separate simply to avoid having to conform to rules that are perceived as excessively strict and unreasonable. All of this makes the process more confusing for the people who want to use it. It’s a pity—and a great irony—that a notion built on the free exchange of stuff for the benefit of the environment is hampered by needlessly self-imposed legal restrictions. Growing Freely But whether under the auspices of The Freecycle Network, as part of another organization, or informally among members of a school, church, or other group, the freecycling concept is gaining momentum. It could be the next Craigslist—a great idea that starts off small and soon becomes a way of life for its participants. In some urban areas, I’m sure you could furnish an entire apartment in a week or two by freecycling, not only saving money but doing a great favor to the people who need to get rid of their stuff. Increasingly, too, I’ve been seeing a backlash against consumerism and its associated clutter, as people begin to realize that they’re actually happier with less stuff than with more. Even though I don’t buy a lot of merchandise, I am a bit of a pack rat, which is why moving can be so painful. As I look around at any room in my home, I realize that I’ve only used, or even thought about, maybe 10 percent of its contents in the last year. Do I really need the other 90 percent? Knowing that I’m going to have to pack and carry every one of my belongings I wish to keep, moving time makes me think long and hard about how much sense it makes to continue owning so many items that don’t actually enrich my life in any way. So instead, I’ll let them enrich someone else’s life. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/Recycling.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Freecycling.509cdf05a9df.mp3"
	},
	{
		"title": "Royal de Luxe",
		"text": "The story of Lemuel Gulliver, as told by satirist Jonathan Swift in his book Travels into Several Remote Nations of the World (also known as Gulliver’s Travels), has been a favorite of mine since childhood. One image that has always stuck with me from the story was the description of how the tiny residents of Lilliput lashed the much-larger Gulliver to the ground, and how Gulliver eventually pulled himself free from these restraints. I remembered this scene recently when a friend sent me a video link from YouTube; in it, a curious little girl wakes up, gets dressed, and sets out to see the world around her. However, this “little girl” is actually a giant marionette, and her movements are determined by people pulling her strings from below and above. But, unlike Gulliver, these men and women dressed in crimson livery are not pinning her down, but instead seem to be freeing her, making her appear amazingly life-like and real. I later learned that the events I was watching were part of a larger production called The Sultan’s Elephant, which took place at various points around London in early May of 2006. This four-day, large-scale performance was created by Royal de Luxe, a street theater company based in Nantes, France. Seemingly well known everywhere but in North America, Royal de Luxe has been presenting highly creative street theater pieces in France and around the world for almost thirty years. Giant Fans Founded in 1979 by current director Jean Luc Courcoult, Didier Gallot-Lavallée, and Véronique Loève, Royal de Luxe staged a series of popular street theater productions in the 1980s, several of which they took on tour to various parts of Europe, Africa, and South America. In 1989, Royal de Luxe moved its operations from southern France to Nantes, a city in western France, and in 1993 embarked on a new phase of its history, when it presented the first of its “giant” pieces. Featuring a doleful-looking gargantuan figure named Le Géant (the giant), the piece was called Le Géant Tombé du Ciel (“the giant falls from the sky”), and to date has been followed by five other giant-related shows: another version of the first show (Le Géant tombé du Ciel: Dernier Voyage); Retour d’Afrique (“return to Africa”), which introduced the giant’s son, Le Petit Géant (“the little giant”); Les Chasseurs de Girafes (“the giraffe hunters”), again featuring the little giant; The Sultan’s Elephant, which introduced the giant’s daughter, La Petite Géante; and The Hidden Rhinoceros, which debuted in Santiago, Chile, in January 2007. These shows all feature enormous human and animal figures, built primarily by company member François Delarozière, and although rigorously choreographed, give a sense of spontaneity, as the figures move about in their surroundings and interact with bystanders. They all follow a simple story, since according to director Courcoult, it should be one that children can understand. The company reveals few details before a show opens, wanting to surprise its audience and to increase the chance that viewers will just “happen” upon the spectacle. Indeed, Courcoult finds it preferable that viewers don’t see everything that takes place, just participating in the performance as it happens. Taking it to the Streets When Royal de Luxe made its debut in the UK with The Sultan’s Elephant, a project that took four years of planning, this randomness was ensured by the diverse settings in which the events of the performance occurred, including Waterloo Place, the St. James' neighborhood, Trafalgar Square, and Horse Guards Parade. These settings served the purpose of the story, for which the French name of the show provides a helpful outline: La visite du sultan des Indes sur son éléphant à voyager dans le temps, or “Visit from the Sultan of the Indies on his Time-Traveling Elephant.” The sultan of the story is looking for La Petite Géante (the little girl giant), who landed in Waterloo Place in a gigantic space rocket inspired by the works of Jules Verne. In fact, Jean-Luc Courcoult created the show in honor of the centenary of Verne’s death, and it was first performed in Nantes and Amiens, Verne’s places of birth and death respectively. While I’m sure the elephant in the show was truly impressive—an intricate machine powered by hydraulics and motors, and weighing 42 tons—based on the video I saw, I think I would have found the little girl giant more fascinating. As she moves around doing ordinary things (getting dressed, licking a lollipop, sleeping), all the wires and people around her seem to fall away, and it’s as if you are watching a real giant girl do these things. It tickles me to know that on her sojourn in London she also did not-so-ordinary things, such as “sewing” cars onto the road, and stopping to take a pee out in the open. It’s clear that the minds behind Royal de Luxe want to fire the imaginations of spectators, reminding them of childhood dreams and reveries. In an interview with Jean-Christophe Planche from 2005, Jean Luc Courcoult even remarked on this, responding to how people react emotionally to the shows, saying “I have seen adults crying as the giant leaves…I don’t believe they are crying because he is leaving but because of the loss of their imagination.” As the image of Gulliver and the Lilliputians reminded me of my childhood, when fairy tales seemed very real, so can these epic images of giants inspire those same memories in others. In a very powerful way, Royal de Luxe makes these fairy tales come to life again. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/royal-de-luxe-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Royal.bf046d3b78d7.mp3"
	},
	{
		"title": "826 National",
		"text": "San Francisco has no shortage of trendy restaurants and interesting shops. If you want to get a good taste of what the city has to offer, and especially if you don’t want to spend lots of money doing it, head to the historic Mission District and stroll up and down Valencia Street. Amidst the art galleries, taquerias, and retro furniture stores you’ll find all sorts of quirky little gems with that quintessential San Francisco character. Perhaps the best example is a store named after its location: 826 Valencia. Its unassuming exterior gives you little clue as to what’s inside, and even after you start looking around, it may take you a few minutes to figure out that you are standing in a pirate supply store. It’s true: if you need to get an eye patch, a Jolly Roger flag, a spyglass, or even a bucket of lard for—well, whatever pirates use lard for—you’re in the right place. At first, everything in the store seems to be completely serious, as though they expect real pirates to sail in on a daily basis for provisions. A closer inspection reveals that they’re having a good time at their own expense. Take, for example, the signs scattered around the store, such as “Have You Got Scurvy?” (with a list of symptoms), “Goals for the Voyage” (Plunder. Meet new people. Learn valuable new skills. ), and even a helpful list of suggested uses for that lard (including “mast greasing” and “fingernail softening”). There’s also a little curtained-off area with a handful of old movie-theater seats facing a large aquarium; you can sit there for as long as you like and watch the residents, including a puffer fish named Otka. Buried Treasure Odds are, if you have even the slightest appreciation for whimsy, you’ll think 826 Valencia is a very cool place to browse. Once you know the joke, it’s great fun to go there just to watch the expressions on people’s faces as they walk in for the first time and realize where they are. But you’re also likely to wonder, “How exactly does a pirate supply store stay in business—even in San Francisco?” If you come at the right time of the right day, you may also wonder, “What are all those kids doing with those computers in the back of the store?” The answers to these two questions are connected: 826 Valencia is really a nonprofit organization devoted to helping children aged 8–18 learn how to write, and the store is just the front portion of a large area that’s mainly classroom space. The organization offers free, volunteer-led workshops and tutoring in creative writing, expository writing, and English as a second language. The pirate store helps raise money, as well as being a very effective gimmick for drawing the attention of children and adults alike to the writing center. The 826 Valencia organization was founded in 2002 by novelists Dave Eggers and Vendela Vida (who, incidentally, were married the following year). It rapidly took off, and has attracted the support of numerous other well-known authors. In fact, in just a few brief years, the organization has been such a runaway success that people in several other parts of the country wanted to create similar programs. So 826 Valencia started an umbrella organization called 826 National, under which several local 826 chapters operate. Most of these chapters have their own weird theme stores. The New York chapter, for example, is home to the Brooklyn Superhero Supply Co. (“featuring fully serviced capery”!). 826 Chicago runs a secret agent supply store called “The Boring Store” (everything is sold in plain, boring wrappers so as not to give away any secrets). There’s also the Echo Park Time Travel Mart (Los Angeles), the Greenwood Space Travel Supply Company (Seattle), and Monsters Union Local 826 (Ann Arbor, Michigan). More chapters are under development. Not that anyone should need an excuse to open a store catering to superheroes or secret agents, but if you must have an ulterior motive, teaching kids how to write is certainly a good one. Yes, you could argue that 826 National encourages children to participate in piracy, but at least they’re doing their part to fight plagiarism. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/retro-store-120.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/826-national.39980d5b0764.mp3"
	},
	{
		"title": "Sears Modern Homes",
		"text": "In the lot immediately behind my home, a new house is under construction. My bedroom happens to be on the side of the house facing the construction site, so nearly every morning for several months, I’ve been awakened by the sounds of hammering, sawing, and yelling. From the look of things, this will probably continue for several more months. Day after day, I look out the window, trying to assess what that day’s racket has accomplished, and most of the time, the visible changes are quite small. Although I know relatively little about construction, the thought has occurred to me more than once that there’s got to be a quicker and easier—not to mention quieter—way to get the job done. And perhaps a cheaper way, too. Small, unassuming two-bedroom houses in my San Francisco neighborhood routinely sell for upwards of $800,000 (which is why we rent—I can’t imagine ever being able to afford to buy a house here). Although the land itself is expensive, as are building materials, a great deal of the price of any new home goes to pay for labor; people aren’t going to hammer, saw, and yell for nothing. Had I been born 100 years earlier, I might well have decided to save myself both time and money by building my own house from a kit purchased by mail order from Sears Roebuck & Co. Along with clothes, housewares, toys, and tools, Sears catalogs in the early 20th century featured entire houses. For well under $1000 for a basic model, you could purchase a complete kit for a house—including everything from the lumber to the nails and paint—that you’d assemble yourself (with the help of family and friends) or hire a contractor to assemble for you. Mail Me a House Sears had been selling building materials by mail order since 1895, but they’d found it unprofitable. In 1908, in an effort to revitalize that business, they began offering plans and kits for houses. In addition to featuring them in their general catalog, Sears offered a separate catalog just for houses: the Book of Modern Homes and Building Plans. Prices that first year ranged from $495 to $4,115—equivalent to roughly $9,800 to $81,000 in today’s dollars. A customer placed an order, and within as little as two weeks, the 30,000 or so pieces of the new home arrived in two boxcars at the train station nearest the house’s intended destination. (Transporting the materials to the building site was the customer’s problem.) Each kit came with a 75-page instruction manual, and by all accounts the instructions were excellent, even for people without extensive construction experience. Because Sears had already built a solid reputation as a mail-order supplier, their new business took off rapidly. In 1911, Sears even began offering its own mortgages. The applications asked how much money the borrower could pay up front and per-month, as well as the person’s occupation, but required no further documentation. For all practical purposes, if you had a job, you got a mortgage. In 1915, Sears made another innovation: thanks to the two lumber mills Sears was now running, the kits featured pre-cut lumber, with every piece already fitted. That change significantly reduced construction time and made the houses an even better value. Ups and Downs Although Sears never claimed to be a trendsetter, they certainly took advantage of the latest building innovations. What made Sears Modern Homes modern was the use of new building materials such as drywall and asphalt shingles and the option to include amenities such as electricity, indoor plumbing, and central heating, all of which were somewhat novel for typical residences of the time. Throughout the 1920s, housing sales brought tremendous profits to Sears. But when the Depression hit, large numbers of homeowners defaulted on their easy Sears mortgages, and the company lost millions of dollars. In the years that followed, housing sales dropped considerably. By 1940, Sears realized the business was not sustainable and reluctantly stopped selling their catalog homes. Sears claims to have sold over 100,000 houses in 447 styles between 1908 and 1940, and some estimates put the number as high as 110,000, but the actual figure may have been closer to 75,000. All the company’s records pertaining to house sales were destroyed in the 1940s, so the number may never be known for sure. Regardless, Sears sold a significant number of their catalog homes, many of which are still standing today. Re-fab Housing Sears was not the first company to offer consumers kits to build complete houses, but they sold more units, in a wider variety of styles, than any of their competitors and are the best-known mail-order house retailer. Even in the Sears Modern Homes era, though, kits weren’t the only way to obtain an easy-to-build house. Prefabricated houses were available as far back as the mid-19th century, and continue to be sold today. To create a prefab house, factories preassemble entire walls, trusses, and other major components and ship them to the construction site, where builders put them together—a much simpler and quicker process than building everything from scratch or even from a kit. Because these modules are built in quantity on an assembly line, costs are lower. Of course, buyers still pay a premium over the simple, pre-cut pieces; customers must choose from a limited range of sizes and designs; and prefab houses can’t be used on certain kinds of lots. Be that as it may, the idea of catalog homes keeps cropping up in new forms. For example, Swedish home-furnishings giant IKEA recently began selling their own houses in several European countries, with designs that sound like a cross between the Sears kits and fully prefabricated houses. Although IKEA supplies all the components in a form that can be assembled relatively easy, they’re not consumer-friendly kits. The houses require assembly by contractors (and considerably more tools than an Allen wrench); the idea is that they’ll be sold in much the same way as conventional houses, but at considerably lower cost because of their standardized, modular design and lower construction costs. And yet they’ll be attractive and trendy, much like the furniture IKEA hopes you’ll buy to fill your new home. One thing Sears couldn’t include in their kits, of course, was real estate, and empty parcels of land are quite a bit harder to come by now than they were a century ago. In addition, modern building codes are stricter than they once were, and mortgage applications are just a wee bit more complex. For these and many other reasons, catalog houses like those Sears once sold are unlikely to make a comeback. But it was a great idea while it lasted, and you never know—someone just might come up with a way to recycle it. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/home-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Sears_.e1dbd556fe34.mp3"
	},
	{
		"title": "Kite Sails",
		"text": "We’re well into the 21st century, and one of the big things on the minds of the world’s technologists is improving propulsion. Cars, trucks, and buses are moving from conventional gasoline-powered internal combustion engines to hybrid engines, diesel engines running on vegetable oil, and fuel cells. Airplane manufacturers are designing better and more powerful jet engines. Submarines are being built with engines that require no moving parts. And rocket scientists are trying to figure out the best means of propulsion to use for sending spacecraft to Mars and beyond. High-tech solutions to get from point A to point B with greater efficiency and lower cost are appearing constantly. And yet, sometimes the best way forward is to go back. Steam power for cars is making a comeback, for example. What was thought to be a dead-end approach a century ago has turned out to have some redeeming qualities after all, now that technology, materials, and engineering methods have caught up with it. The latest blast from the past, though, really blows my mind. The brightest and best in the field of marine propulsion have come to the startling conclusion that if you want a reliable, inexpensive, and efficient way to move ships across the ocean, you might try…the wind. The twist is that instead of using conventional masted sails, you can send the whole sail aloft, tethered to the ship by a rope—just like a kite. Using kites to pull vehicles along isn’t new; it’s been done for everything from surfboards, skis, and rollerblades to buggies and small boats. Such kites are known as power kites or traction kites. But multiply the size of these kites by ten or even a hundred times, add some sophisticated deployment and control mechanisms, and you have something else entirely: a kite sail, which can pull a large yacht or even a cargo ship. Mastless Transit My first thought on hearing about kite sails was that the idea was reasonable enough, but why not just use regular, masted sails—a tried and tested technology? That just goes to show you how little I know about ships and sailing. Masted sails, apart from being complex to build and operate, place a number of constraints on a vessel. It must have adequate ballast to offset the weight and pull of the masts and sails, for one thing. If carrying cargo, the masts and rigging can seriously complicate loading and unloading, not to mention reducing available storage space. And for vessels over a certain size, you run into problems of geometry and physics; sails would have to be unworkably huge to move the ship at all, and could never propel it at the speed of a petroleum-powered engine. Kite sails, by contrast, take up almost no space. They attach to the deck, and the only real space required is for the deployment mechanism—typically a telescoping mast that lifts the kite up into the wind and later retrieves it. The whole process is automatic. Once flying on its own, the kite isn’t entirely at the mercy of the wind. It’s shaped like a parafoil and has numerous steerage lines connected to a control unit. By selectively shortening or lengthening the lines, the controller can alter the shape of the sail—and thus its direction and pull. And because the kite sail isn’t constrained by a mast, it can fly high enough to take advantage of winds that are often stronger and less turbulent than those closer to the water’s surface. Of course, kite sails do require the wind to be blowing, and you’ll need a healthy breeze to move a ship of any serious size at a reasonable speed. The wind should also be blowing in approximately the right direction—the closer to your direction of travel that the kite sail is being pushed, the more efficient the power transfer will be. However, depending on conditions and the kite sail design, the direction of the kite’s motion can be as much as 130° off in either direction from the desired direction of travel. In other words, unless the wind is blowing almost exactly the wrong direction, you’ll get some benefit from it. Some kite sail installations use a computerized system to plot the best route for your ship based on the direction of the winds in the area, which might take you on a somewhat roundabout course but at least saves fuel. On Sail Kite sails are not intended to replace conventional engines, but to supplement them. So why would the owner of a ship spend hundreds of thousands, or even millions of dollars, to retrofit an existing ship with a kite sail? Two words: oil prices. Manufacturers claim that kite sails can reduce fuel usage, and its associated costs, anywhere from 10 to 35 percent, and in ideal circumstances, by as much as 50 percent for a brief period of time. Given the rapidly rising cost of fuel and the attendant rise in shipping costs, that savings—if it proves to be real—would be enormous. But only time will tell. Although kite sails for large vessels have been successfully installed and tested, commercial deployment is still a couple of years in the future. Meanwhile, the technology is being put to good use on smaller craft, such as racing yachts, where it has been shown to be reasonably effective but where fuel savings are not at issue. Needless to say, using less fuel will be better for the environment, too, though I doubt that greener shipping is foremost in the minds of those considering the use of kite sails. But it’s a case where economics and environmental considerations happen to coincide nicely. And a kite sail might even serve as an inexpensive backup engine, enabling a ship with mechanical problems to get to port. It’ll be interesting to see if the idea catches on. If it does, it’ll give a whole new meaning to the expression “Go fly a kite.” ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/kite-sails.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Kite.e3c45e391a39.mp3"
	},
	{
		"title": "Doble Steam Cars",
		"text": "Back in the mid-1980s when I was in college, I had a car whose gas mileage routinely reached 40 miles per gallon. At that time, most people assumed that as technology advanced, cars' average mileage would steadily improve. But of course, that didn’t happen, and today, except for hybrids and a few other small cars, the sort of fuel efficiency I got 20 years ago is the exception rather than the rule. I’m well aware of all the technological, political, and financial issues that have combined to create this reality, but every time I think about it I just shake my head. History could have unfolded differently, and high-mileage, low-emissions vehicles might have been the norm today. More than 80 years ago, you could buy a car that was highly fuel-efficient (even by today’s standards), produced almost no pollution (again, even by modern standards), required very little maintenance, and was virtually silent. It used kerosene as fuel to power a steam engine, and even though the car weighed more than today’s average SUV, it accelerated rapidly and handled smoothly. The car would have been one of several Doble steam car models designed and manufactured by Abner Doble and his three brothers. Fill It Up…with Water In the early years of the 20th century, some cars were powered by steam engines, based on the same tried-and-true technology that had already powered locomotives for a long time. The newfangled internal combustion engines rapidly stole the show, though. Unlike steam engines, which sometimes took as long as a half hour to heat up before the car could even move, internal combustion engines started immediately. They didn’t require the driver to stop every hundred miles to refill a water tank, and they generally had fewer mechanical problems. By around 1910, the only major steam-powered car still in production was the Stanley Steamer—and its days were numbered. The battle had been decided. Not everyone was convinced, though. Abner Doble was a San Francisco native who had moved to Massachusetts in 1910 to attend M.I.T. He dropped out after just one semester and, along with his brothers, began working on improving the design of steam engines for cars. Doble’s first major innovation was extending the steam car’s range. All existing steam-powered cars lost a lot of water and had to be refilled frequently. Doble made innovative changes to the condenser system that recirculated water; in so doing he increased the car’s range to as much as 1500 miles (2400km) with a full 24-gallon (91 l) water tank. Full Steam Ahead After building a couple of prototype vehicles, the Doble brothers moved to Detroit in 1915, where they set up shop as the General Engineering Company to design and build steam-powered cars. Doble’s next challenge was to solve the long start-up problem. He did this by using a flash-steam generator rather than heating a huge tank of water, and adding ignition and carburetor systems similar to those used by internal combustion engines. With these improvements, his car could start in as little as 30 seconds. This design also had the side-effect of reducing leaks and making the steam engine safer. The Dobles began advertising their car—the Doble Series C, also known as the Doble-Detroit—long before they’d worked out the rest of the design and manufacturing issues. Although the Doble-Detroit got a lot of press and generated thousands of orders, very few were built. (Some sources say only 11 were manufactured, others as many as 80—but in any case, it was just a handful.) Doble blamed his company’s failure to produce cars on steel shortages caused by World War I, but ongoing engineering difficulties were the real problem. By 1918, the Detroit operation had shut down. In 1921, after the death of John Doble, Abner and his two remaining brothers moved back to California to give the car business another go, this time as Doble Steam Motors. They solved most of the outstanding engineering problems and added several more innovations, increasing the car’s acceleration and improving its reliability. Unlike other steam cars—and most internal-combustion-engine cars—their new Series E car could start almost instantly even in freezing weather, and could go from 0 to 75 miles per hour (120kph) in 10 seconds. Because steam engines produce a great deal of torque at almost any speed, the car required no transmission, clutch, or gear shifting. And because the kerosene fuel was burned at very high temperatures but low pressure, almost all the waste carbon was consumed, while other common pollutants were never generated in the first place. Driven to Perfection And yet, for all those innovations, Doble cars were still hindered by two major problems. First was the price: the chassis alone cost $9,500; add the body, and the price nearly doubled. In the 1920s, that sort of price made the car a luxury item that only the very wealthy could afford. The other problem was Abner Doble himself: he was such a perfectionist that he was seldom willing to stop tinkering and tweaking and actually release an automobile for sale. The first Doble Series E was sold in 1924, and Doble Steam Motors continued to manufacture steam-powered cars—very slowly—for the next seven years. The total number produced before the company went out of business in 1931 has been reported variously as 24, 42, or 43. A few of those cars are still on the road, having racked up hundreds of thousands of miles. But despite the cars' reliability, Doble simply couldn’t compete against the cheaper mass-produced internal-combustion-engine cars. Although today most people think of the steam engine (an external combustion engine) as a quaint artifact of history, it’s nothing of the sort. In fact, BMW is reportedly working on something they call a turbosteamer, which supplements a regular gasoline engine with modern steam technology to improve gas mileage. I’d like to think that one day we’ll see new, fully steam-powered cars that live up to Doble’s 80-year-old standards. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/Ford_Model-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Doble-Steam-Car.f9c4ae13912b.mp3"
	},
	{
		"title": "Cruise Ship Condos",
		"text": "My home town of San Francisco was recently rated the 3rd most expensive city in the U.S. and the 34th most expensive worldwide. These rankings change frequently, but clearly this is among the places that put household budgets to the test. It’s also one of those places where conventional real estate wisdom breaks down: ordinarily it’s cheaper to buy a house than to rent—but not here. I couldn’t begin to afford a monthly mortgage on my current home, and that doesn’t even take into account the down payment. Although my wife and I have fantasized about buying a home, our income would have to rise dramatically to make that a possibility in this town. This is equally true when talking about houses or condominiums, but condos hold little appeal for me anyway. Even though they might cost a bit less, you pay monthly fees for maintenance of the building and common areas; yet you get less privacy and have less flexibility in how you can use or modify the space. On the other hand, I love to travel, though the high cost of housing limits the number and length of trips we can take. So I was intrigued by a notion that has sprung up in several forms over the last few years: selling cruise ship cabins as condos. Roughly speaking, the sales pitch is that for just a bit more money than you’d pay for a luxury condo, you can travel the world in style without leaving home—or spending extra on airfare and hotel accommodations. In other words, if you were thinking about buying a condo anyway, if you like to travel, and if your work and lifestyle don’t tie you to a particular location, you can have your cake and eat it too. Liquid Assets I oversimplify, of course. For one thing, your average working middle-class couple—an ideal target market for a conventional condo—might run into difficulties living on a ship beyond merely paying for it. Most jobs require employees to show up at a particular location, for instance, and a ship could be less than ideal if you’ve got school-aged children. So retirees and the excessively rich are among those most likely to purchase a condo on a ship. On the other hand, living aboard a ship for a month or two at a time is well within the means of many ordinary, working citizens, and in some cases one can buy fractional ownership of a cabin—very much like a timeshare. Even those who purchase a cabin outright generally maintain land-based homes as well, and spend only a few months of the year on the ship. When I say “cabin,” by the way, don’t think I’m talking about an ordinary ship’s cabin—as in a smaller and less comfortable hotel room. On the contrary, the homes you can buy on a ship range from simple studios to expansive penthouse suites with four bedrooms, four and a half baths, sweeping verandahs, and every conceivable amenity. Most units have kitchens, though of course you’ll be somewhat limited in where you can shop for groceries. But naturally each ship has numerous restaurants as well, so you needn’t do your own cooking at all. As just one of 200 or so owners, you’ll have little if any influence over the ship’s itinerary. You can be assured that, over the course of two or three years, your home will visit nearly every major port on the planet, though. Some residential ships make a point of being in Cannes for the annual film festival, in Rio for Carnivale, or in other seasonally appropriate locations. But between ports, tenants may find the range of activities onboard a bit limiting; these ships have fewer shops, shows, and other diversions than vessels of similar size that cater to vacationing tourists. In addition, you’re bound to miss certain conveniences of home, such as a choice of medical and dental facilities, your favorite local businesses, and the proximity of friends and family. On the other hand, you won’t need a car, and you can hardly offer a more attractive vacation getaway for visiting guests. A Titanic Investment As of 2006, only one residential cruise ship is already sailing the seven seas: a ship called The World, which launched from Norway in 2002. Several of its units are still available—with prices ranging from US$825,000 to $7 million, plus a 6% annual fee to cover maintenance, utilities, landing privileges on the ship’s helipad, and so forth. If you’re not ready to commit to ownership, you can rent a unit for anywhere from $1,200 to $4,200 per night. The ship features the usual luxuries, such as a casino, a theater, upscale restaurants, and a spa. Unlike ordinary cruise ships, The World typically spends two to five days in each port, giving tenants plenty of time to explore the world off the ship. The itinerary changes each year. Three other major residential ships are in various stages of preparation. The Four Seasons, a ship owned by and named after the hotel chain, is selling units now with plans to launch in the fall of 2007. Prices go as high as $15 million. On the Orphalese, scheduled to set sail in 2008, you can buy a small, two-bedroom suite for as little as $1.8 million (plus $2,500 monthly); their largest and most luxurious four-bedroom units start at $8.8 million (plus $5,500 per month). And a ship called The Magellan is already selling condos even though construction hasn’t yet begun; the 200 units are priced from $1.8 million to $8 million (with a fractional one-month ownership for as little as $156,250). One perk on the Magellan I find quite appealing is an observatory with an astronomer on staff. Because I’ll probably never have the sort of money that would make owning a cruise ship condo even a remote possibility, I can’t say whether it would be worth the expense. In some respects, you undoubtedly get what you pay for, but then, I don’t really want or need to be surrounded with luxury all the time. If someone came up with a middle-class condo ship that a mere mortal such as myself could afford, though, I’d certainly consider taking my home with me as I travel the globe. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/Cruise-Ship-120.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Cruise.f49c52e884d4.mp3"
	},
	{
		"title": "Project Habakkuk",
		"text": "H.L. Mencken has been famously quoted as saying, “There is always an easy solution to every human problem—neat, plausible, and wrong.” Or, as the saying is often misquoted, “Complex problems have simple, easy-to-understand, wrong answers.” Either way, it’s true that simple solutions are often overlooked, and equally true that seemingly simple solutions often turn out to be infeasible. Such was the case with an ambitious project undertaken by the Allies in World War II: building gargantuan ships out of ice. As silly as this may sound at first blush, the idea was meant to address a set of very serious problems. Supply ships on their way across the North Atlantic from Canada to the U.K. were frequently intercepted and sunk by German U-boats. Planes could protect the ships, but only within a limited distance from land, as there was nowhere to refuel in the middle of the ocean. Aircraft carriers would have helped, but they required enormous quantities of steel, which was in short supply. What was needed was a way to land aircraft in the mid-Atlantic without overtaxing the steel supply. A Prophetic Voice In 1942, a British scientist named Geoffrey Pyke—an adviser to Lord Mountbatten, Chief of Combined Operations—came up with the idea of cutting off a large piece of an arctic iceberg or ice floe, leveling its surface, and towing it into the ocean to serve as a landing platform. The platform would melt eventually, of course, but Pyke believed that a large enough piece of ice would last at least a few months—longer if it were insulated on the outside and cooled from within by a refrigeration system. Better yet, the platform couldn’t be sunk; even if it were damaged by torpedoes or bombs, repairs could be made simply by freezing new chunks of ice into place. Mountbatten sold the idea to Winston Churchill, who gave it his enthusiastic support. Pyke called his operation Project Habakkuk (frequently misspelled as “Habbakuk”), after a verse from the biblical book of Habakkuk: “Look at the nations, and see! Be astonished! Be astounded! For a work is being done in your days that you would not believe if you were told.” (Habakkuk 1:5, New Revised Standard Version) The full-size aircraft carrier Pyke envisioned was to be 2,000 feet (about 600m) long and 300 feet (about 90m) wide—hollow, with walls 40 feet (about 12m) thick. That would have made it almost two orders of magnitude heavier than other aircraft carriers of the period. It would be slow, however, with a top speed on the order of 6 knots, and have limited maneuverability. With the ship’s enormous size and weight came other complications. For one thing, ice is brittle; keeping a huge piece of it intact on rough waters was going to be a challenge. For another, ice deforms under pressure, which means that a large vessel—particularly a hollow one—would sag and likely crack over time. To find ways of dealing with these and other problems, a team of workers in Canada began research and experimentation, going so far as to build a small prototype vessel—60 feet (about 18m) long by 30 feet (about 9m) wide—on Patricia Lake in Alberta. The prototype was a wooden frame filled with chunks of ice and covered with insulation. A cooling system much like an air conditioner sent super-chilled air through a network of pipes in order to keep the ice’s temperature well below freezing. Better Than Ice Meanwhile, in early 1943, two researchers at the Polytechnic Institute of Brooklyn, New York, made a fortuitous discovery: by mixing wood pulp, sawdust, or cotton wool with water and freezing the slurry, they could create a substance that still floated nicely but was much stronger and less brittle than plain ice. This material was dubbed pykrete (or Pykecrete) in honor of Pyke. Experiments showed pykrete to be highly resistant to compression, chipping, and even bullets. It could be shaped with ordinary woodworking tools, and even better, it melted much more slowly than ice. This new material was quickly seen as key to the success of Project Habakkuk, which by that point was seeming increasingly problematic based on the results of the Patricia Lake tests. According to a popular (but probably apocryphal) story, Mountbatten showed up at Churchill’s home one day while he was bathing and dropped a block of pykrete into the hot water. When the pykrete didn’t melt, Churchill was convinced that the new substance was just what they needed for Project Habakkuk. Most accounts frame the story as Churchill’s introduction to the notion of aircraft carriers made of ice, but if it happened at all, it would have been well after the project in its original form was underway. Down the Drain Despite the seemingly miraculous properties of pykrete, however, the project was going nowhere fast. One problem was money: the first Habakkuk carrier would have cost about $100 million. Likewise, the complexity of building, insulating, and refrigerating such a large structure would have required time and manpower that none of the Allies could afford. And even though wood pulp was more plentiful than steel, that, too, was in short supply. On the other hand, aircraft range was improving, while conventional aircraft carriers were increasing in number. All these facts made Project Habakkuk seem like a waste of resources, and by early 1944, research was halted—before construction of the full-size carrier even began. In the years since, pykrete has remained, for the most part, a curiosity of history. Other than perhaps the odd ice hotel here and there, potential uses for a bulletproof, buoyant, frozen building material don’t immediately leap to mind. It’s a clever solution in search of a problem, and it may be searching for a while. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/Project-Habakkuk-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Habakkuk.16fe6af1f152.mp3"
	},
	{
		"title": "Pontcysyllte Aqueduct",
		"text": "If you’re like me, with just enough knowledge of engineering to set up a camping tent successfully, then you may have had the experience of nodding politely during a conversation about, say, cantilevered bridges. Sure, I’ve heard of them, but how do they actually work? Not a clue. One category of those things about which I have a passing knowledge is aqueducts. I understand that they have something to do with transporting water, but what do I know beyond that? Being relatively ill-informed about these things, I would assume that an aqueduct would be used to bring water to an area in which there is very little. But, when I looked into it further, I found that is not always the case. In fact, aqueducts have been constructed in areas where there is plenty of water—such as a river valley. On Gard One example of this is the first-century A.D. aqueduct system constructed by the Romans in Southern France to carry water from the Eure spring in Uzès to a water tower in Nîmes, about thirty miles (fifty kilometers) away. In this case, it was the spring water in particular that the Romans coveted, using it to supply the fountains, sewage systems, and spas of the flourishing town. As part of the aqueduct system, the Romans built the now-famous Pont du Gard, a bridge that enabled the channel of water to cross over the Gard river and to continue on its way to Nîmes. In a way, it was like they built a river (or stream, if you will) above another river; rather remarkable to a non-engineer like me. The Pont du Gard is remarkable for a number of other reasons, including: its longevity, having remained largely intact over the last two thousand years; its size, being the highest aqueduct ever built by the Romans (at 49 meters in height); and its incredible engineering, being composed of large stones that fit together without the use of mortar. Now it’s a UNESCO World Heritage Site, and every year large numbers of visitors from around the world come to see this amazing construction. Originally built to serve the social and business interests of Nîmes, the Pont du Gard now serves as a potent reminder of human ingenuity. Channeling Ideas A slightly less famous and considerably younger version of the Pont du Gard can be found in Northeast Wales. The Pontcysyllte Aqueduct, built from 1795 to 1805, was created to carry the Llangollen canal over the valley of the River Dee; another river-over-a-river construction. In this case, the Llangollen canal, which connects three major rivers—the Dee, the Severn, and the Mersey—was originally part of the Ellesmere canal, a route built to connect the coalfields and ironworks of the town of Wrexham with the sea. The creation of the Pontcysyllte Aqueduct (about which more in a moment) was one among a series of large-scale construction projects that began in the late 1700s and continued into the 1830s. These projects were sparked by the opening of the Bridgewater canal in 1761, created by the third Duke of Bridgewater (a great example of an aptonym if ever there was one) to provide an efficient means of transporting coal from his coalmines in Lancashire to the booming industrial city of Manchester. This canal, which included a large aqueduct over the River Irwell, proved so profitable to the Duke that it encouraged many others to build canals of their own. Canal Knowledge Before the development of railroads, canals were the first means of mass transport of goods in Britain. The canal-building craze started by Bridgewater helped to fuel the so-called Industrial Revolution, which saw a change from a primarily agrarian society to one in which trade and manufacturing could be undertaken on a massive scale. The reason for the incredible success of the canal system lay in its great improvement over the traditional method of transporting goods. While Britain had always relied upon waterways as a means of transport, being surrounded by water and possessing many large navigable rivers, those areas of the country not in proximity to a body of water could only be accessed by road. However, roads at that time were mostly built of mud, and could become impassible in bad weather. In addition, there was a limit to how much cargo could be transported by horse and cart, usually around one to two tons. In comparison, the new canals could accommodate boats carrying 30 tons, with only one horse needed to pull the load as it walked beside the boat on specially created towpaths. This dramatically increased the rate at which goods could be shipped, and brought incredible profits to the companies that operated the canals. There were limitations to this mode of transport, though; in order to save costs, canals were often built quite narrow. This meant only specially designed “narrow boats” could navigate the canals. In addition, because canals are constructed bodies of water with no current, the speed of travel was limited to the speed of the “horsepower” involved, although this problem was less prominent in later years as steam and electric powered boats were developed. Gradually, with the rise of the railroad, the canal system came to be less and less economically viable. Although the canals were still in commercial use well into the 20th century, their dominance was greatly overshadowed by other modes of transport. Unlike other European countries, such as France, Germany, and the Netherlands, which modernized their canal systems to accommodate larger vessels, the British system did not undergo the same kind of overhaul and fell more and more into disuse. Fortunately, the canal system in Britain was reborn in the 1960s and '70s when it came to be associated with holiday travel. Now these historic canals are frequently used by boaters and tour operators seeking a new form of vacation activity. Canal Retentive The first commercial canal built by Bridgewater was designed by James Brindley, a man with very little formal education, but who nonetheless went on to become one of the best-known engineers of the 18th Century. Following in his footsteps, Thomas Telford was only four years old when the Bridgewater canal was opened, but came to prominence after he oversaw the construction of the Pontcysyllte Aqueduct from 1795 to 1805. The aqueduct has many notable features, including its great length (1007 feet; about 300m), its structural ingenuity (in its use of tapered support columns), and the construction of the metal trough in which the water is carried. In order to reduce the weight of the masonry pillars, they were built wider at the bottom than at the top, allowing the aqueduct to reach a great height. The masonry was held in place by a mortar made of lime, water, and ox blood. The metal trough carrying the water (and the boats) was built from cast iron sections joined together and caulked using flannel dipped in boiling sugar, and then sealed with lead. Canal Plus In 2005, the Pontcysyllte Aqueduct celebrated its 200th Anniversary, and in recognition of its cultural importance, was submitted to UNESCO as a potential World Heritage Site. Like the Pont du Gard, it receives many visitors and has become a significant tourist attraction. Boat rides along the aqueduct are popular, often traveling to and from the town of Llangollen, the site of the International Eisteddfod, a music festival that takes place every year in July. As with the Pont du Gard, a purely commercial endeavor has now become something to celebrate. Although the canal system, including the Pontcysyllte Aqueduct, no longer drives the economic engine of Britain, the ingenuity of those who designed these marvels continues to amaze and inspire all who see them. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/aqueduct-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Pontcysyllte.9519cb26a4f2.mp3"
	},
	{
		"title": "Breathing Liquid",
		"text": "It’s funny the way random little factoids stick in my head, even after many years. When I was in eighth grade, I did a report for my science class on Pascal’s Law, a description of the way fluids behave in a closed system (and the basis of all hydraulics, among other things). And in the course of researching that project I came across a tiny piece of information that blew my 13-year-old mind: the word fluid is not a synonym of liquid; a fluid can be a liquid or a gas. Really? I’ve been breathing a fluid all my life? I just couldn’t get over it. Neither could my friends—I thought my endless recitations of trivia made me look smarter, but they found it annoying. Years later, I read a Star Trek novel in which the crew of the Enterprise encountered a race of humanoid beings who breathed a liquid; the book went to great lengths to describe what that experience was like for one of the humans who had to interact with them. Although this fictional liquid was compatible with human lungs, the psychological shock of breathing a liquid was pretty intense. Later still, the very same concept showed up in the 1989 film The Abyss. But hey, that’s all just science fiction, right? Amazingly enough, humans can indeed breathe certain very special liquids. Fluid Thinking In order for any fluid to work for human respiration, it has to perform two main functions very well: delivering oxygen to the lungs and removing carbon dioxide. Air obviously does both quite well; so do some other combinations of gases (such as those used in diving). But it’s reasonable to think some liquids may be able to do the same thing. The first experiments involving respiration of a liquid took place in the 1960s. Mice were made to breathe a saline solution with a high concentration of dissolved oxygen. The mice survived for a little while, but although the solution delivered enough oxygen, it was ineffective at removing carbon dioxide; over time, it also caused damage to the lungs. A few years later, researchers began experimenting with perfluorocarbons, or perfluorinated hydrocarbons—liquids similar to freon that (despite being unfriendly to the ozone layer when they evaporate) are able to dissolve both oxygen and carbon dioxide readily. Initial results were much better than with the oxygenated saline solutions, and mice were able to return to normal gas breathing afterward. Over the next several decades, the formulas for breathable perfluorocarbons (PFCs) have been refined further. The best-known liquid of this kind is called perflubron, also known by the brand name LiquiVent. Perflubron is a clear, oily liquid with twice the density of water. It has the ability to carry more than twice as much oxygen per unit of volume as air. And it’s inert, so it’s unlikely to damage lung tissues. Because it has a very low boiling point, it can be cleared from the lungs quickly and easily by evaporation. You may be thinking: it’s great that humans can breathe a liquid, but why would anyone want to? Divers Uses The primary application of liquid breathing is the medical treatment of certain lung problems. For example, babies born prematurely often have underdeveloped lungs. Because perflubron can carry more oxygen than air, it can help relieve respiratory distress until the lungs are able to function with regular air. But it has also been used for adults with acute respiratory failure, whether due to disease, trauma, burns, or the inhalation of smoke, water, or other toxins. The liquid encourages collapsed alveoli to open, washes out contaminants, and provides better exchange of oxygen and carbon dioxide for lungs that are not fully functional. In clinical use, the lungs are usually not filled completely with the liquid; instead, liquid ventilation is usually used in conjunction with conventional gas ventilation. The other potential use for liquid breathing is in diving. Ordinarily, divers must breathe heavily pressurized gases to prevent their lungs from collapsing deep underwater, but this requires decompression on the way up and carries the risk of nitrogen narcosis and numerous other problems. If the lungs were filled with a liquid instead, most of those problems would simply disappear. This would, in theory, enable divers to reach greater depths, ascend more quickly, and experience somewhat lower risks. Despite what we see in the movies, this technique is not yet ready for prime time, but with advances in equipment, fluid formulas, and training, liquid breathing could someday change the nature of diving dramatically. For all these amazing benefits, liquid breathing still involves one major difficulty: it’s much harder for human lungs to move liquid in and out than it is to breathe air. Even though perflubron is so much better than air at carrying oxygen and carbon dioxide, that advantage can be lost if you don’t circulate it rapidly enough. Without the use of a mechanical ventilator, this is going to be especially problematic for someone who’s ill, and even a diver in top condition could get very tired of such laborious breathing during a deep and strenuous dive. So I won’t be making plans to live at the bottom of a PFC-filled swimming pool, but it certainly is intriguing to think that a lung full of liquid could prevent me from drowning. ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Breathing.a16c70d7f6e3.mp3"
	},
	{
		"title": "Living Streets",
		"text": "The Dutch word is woonerf, which sounds like it should be a type of foam ball; its plural is woonerven, which sounds a little bit like “unnerving.” Curiously, both of these notions strike amazingly close to the heart of this novel concept for making roads safer for pedestrians (including, naturally, children at play). Often translated into English as “living street,” “living yard,” or “home zone,” a woonerf is a paved street area shared by cars and pedestrians. Counterintuitively, its safety is a byproduct of its ambiguity; despite (or, rather, because of) an almost complete absence of signs, traffic signals, road markings, or even curbs, cars drive more slowly and fewer accidents occur. Safety in Danger When I first read about this concept in Wired several months ago, I had a hard time wrapping my brain around the notion that one could make roads safer by making them appear to be less safe. But the idea isn’t new, and it isn’t just some crazy theory. Since at least the 1970s, towns in the Netherlands and elsewhere in Europe have been successfully modifying their roads and sidewalks to conform to this new model of traffic management, and in more recent years, the idea has begun to take hold in more and more North American cities too. Some early Dutch woonerven employed signs, speed bumps, and obstacles (such as benches or large planters) to force cars to slow down, and though that worked, drivers found these measures annoying. Modern versions of the concept follow a “less is more” principle that respects all users of a street and encourages (positive) interaction between motorists and pedestrians. When a car approaches an intersection with no crosswalks, signs, or other indications of where exactly to go, its driver becomes confused—and slows down in order to figure it out. When a street or intersection is designed in an intentionally ambiguous manner, drivers automatically look for cues in the faces of people standing, cycling, or sitting nearby. This eye contact enables all the road’s users to negotiate their turns and positions in the flow of traffic. It replaces strict rules and separation with psychology—and it works. In many of the cities where living streets have been developed, fatalities and serious injuries from traffic accidents have decreased dramatically. In the Zone Traffic engineers who have studied the effectiveness of these “second generation” traffic-calming measures suggest that the clear separation between car areas and pedestrian areas—along with the extensive signs, lights, signals, and lines that are so ubiquitous on the roads—have contributed to a false sense of safety. Whatever traffic laws may say, drivers are easily lulled into an impression that they always have the right of way. And that is one of the reasons so many pedestrians are injured; drivers can simply zone out. (I am speaking, by the way, as a pedestrian who was hit by a car a few years ago due to a zoned-out driver.) Without that illusion of safety, drivers are forced to pay more attention. A living street is certainly not always an appropriate design. A heavily traveled eight-lane thoroughfare in a downtown urban area is not going to yield to this approach, nor will a freeway. And that’s as it should be. Cars are very good at getting from place to place quickly, and no one is suggesting that children should be able to play safely in the middle of an interstate highway because the cars are only going 15 mph (25kph). However, in residential neighborhoods, small towns, and reasonably confined urban and suburban areas, living streets may be a better solution than photo radar, speed traps, and rigidly enforced traffic signs. The challenge is changing our assumptions about how roads are designed—and accepting the uncertainty that follows from a lack of rules. For most of America, that’s a hard sell. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/traffic_congestion-120.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Living-Streets_.f6bab1c3ab3.mp3"
	},
	{
		"title": "Operation Migration. Follow that airplane!",
		"text": "The exact techniques migrating birds use to find their way across thousands of miles to exactly the same spots year after year are only partially understood. Watching for landmarks is clearly part of it—but equally clearly, it’s not the whole story. Certain types of birds have been shown to rely only minimally on vision, in some cases apparently getting their bearings from the Earth’s magnetic field. Be that as it may, some bird species have strong migratory instincts, while others (including geese, ducks, and cranes) must be taught the way to and from their winter homes. A single demonstration is enough to program the route into a bird’s memory, but what happens when a bird never gets that first demonstration? It has no idea where to go, and as a result, its survival is threatened if it can’t find enough food when the seasons change. This situation poses a unique problem for certain birds raised in captivity, such as the whooping crane (Grus americana)—the tallest flying bird in North America, with a height of up to 5 feet (about 1.5m) and a wingspan as wide as 8 feet (about 2.5m). By the middle of the 20th century, the worldwide population of wild whooping cranes had dipped to only 15, bringing the species perilously close to extinction. (A century earlier, there had been about 1,400 of them—and even that was a dangerously small number.) As a result of diligent conservation efforts, those few remaining birds were protected in the wild, and their numbers gradually began to increase; today, that flock numbers about 200. Meanwhile, some of their eggs were hatched in captivity to breed a “backup” flock, in case some natural disaster (such as a hurricane) wiped out the others. After several years of careful breeding and release, a non-migratory flock of nearly 100 is now living in Florida. However, what everyone wanted to see was the reestablishment of another migratory flock—a group of whooping cranes that spent their summers in Wisconsin and their winters in Florida, just as other flocks had done decades earlier. But although the birds could be bred and released successfully, there was no apparent way to teach them a safe way to fly from one home to the other. Flight Leader William Lishman, a sculptor and filmmaker living in Ontario, wanted to be a military pilot but, being color-blind, couldn’t pass the required vision exam. So instead, he took up hang gliding, and soon moved on to fly one of the first ultralights—an aircraft that was basically a hang glider with a frame underneath that supported a small engine and propeller. After seeing a film in which geese followed a boat, Lishman wondered if they might also follow an ultralight. After three years of experiments, he finally managed to lead a small flock of Canada geese on a flight near his home in 1988. Within a couple of years, the scientists working with whooping cranes contacted Lishman and proposed that he use the same technique to teach the cranes how to migrate south for the winter. The first step was to try teaching a flock of Canada geese (which are not endangered) how to migrate over a long distance; that way, if anything went wrong, at least the losses would be less severe. In 1993, Lishman and fellow ultralight pilot Joe Duff led 18 geese from Ontario to Virginia, 400 miles (about 650km) away. In 1994, those geese found their own way back to Lishman’s home in Ontario, proving that the system could work. That year, Lishman and Duff founded a nonprofit organization called Operation Migration to oversee and raise funds for the much more significant effort of teaching whooping cranes to migrate. (Meanwhile, Lishman assisted in the development and making of the 1996 film Fly Away Home, a fictional story based on his life and work.) In 1997–1998, Operation Migration performed another migration experiment, this time with sandhill cranes (a non-endangered relative of the whooping crane). One of the things they learned in this process was that cranes imprint strongly on humans. The result was that the birds were more interested in finding and staying with people than in returning to their homes—not the result Operation Migration was looking for. So they refined their techniques to make the humans invisible to the birds; the process begins just after incubation. Are You My Mother? Even before the eggs hatch, the cranes hear recordings of an ultralight’s engine, so that they’ll become accustomed to and comfortable with that sound. When the chicks hatch, the first thing they see is a hand puppet that looks like a crane—so they imprint on that. All the humans who interact with them are dressed in baggy white costumes that thoroughly disguise their form; they also carry one of the puppets at all times and avoid talking. That way, the cranes may have the impression that their “parents” are rather funny-looking, but not that they’re human. Shortly thereafter—before they’re old enough to fly—the birds are trained to follow a rolling machine that looks (and sounds) like an ultralight. Eventually they begin following a real ultralight, and when it takes off, the birds follow it into the air. After several weeks of training, the birds are ready for their big trip. The first attempt to teach whooping cranes to migrate took place in 2001. Three ultralights led a flock of eight birds over 1,200 miles (about 1,900km) from Wisconsin to Florida. One of the birds died after hitting a power line in a storm, but the other seven made it safely—and returned without any assistance the following spring. The effort has been expanded in the years since, and now more than 40 whooping cranes are migrating on their own in this new flock. Although more chicks are bred and released using aircraft-assisted migration every year, the overall effort is a matter of “three steps forward, two steps back.” A number of the birds have been killed by predators; others die from illness or other injury. So although the flock continues to grow, the pace is slow. Still, Operation Migration (along with several partner organizations) continues to improve their techniques with the goal of enabling an ever greater number of whooping cranes to fend for themselves. In time, the whooping crane may make it off the Endangered Species List, and they’ll have an airplane to thank for it. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/birds-migration-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Migration.8db00fc2df6e.mp3"
	},
	{
		"title": "The Wet Collodion Process",
		"text": "Intellectual-property lawsuits may seem like a thoroughly modern phenomenon, but the struggle to assert one’s rights over a creative work is very, very old. Patents, copyrights, and other formal claims of authorship exist largely—in theory, at least—to guarantee that a work’s originator has the greatest opportunity to profit from it. But ethical and legal complications arise when more than one person claims to have created something first, when the scope of someone’s claim is unclear, or when a creator’s interests are potentially at odds with the public good. The outcomes of such cases (one way or the other) can have a profound impact on technological progress, not to mention the financial success of both individuals and entire companies. In the mid-1800s, a grand battle took place between a patent holder and someone who we might today call an open-source advocate. As it turned out, both sides lost, but the public gained. The technology under dispute was nothing less than a method for creating multiple, clear copies of a photograph from an original—something we take for granted today, and without which, the world of media would be very different. Picture Imperfect The earliest days of photography were both exciting and frustrating. The daguerreotype, for instance, invented in 1837, made a beautiful, sharp image on a copper plate coated with light-sensitive silver iodide. But creating just one picture required extensive preparation, an exposure as long as 20 minutes, and development using toxic mercury vapors. Because the end result was a positive image on metal, there was no way to make a copy. A less-expensive, competing process called the calotype was patented in 1841 by William Henry Fox Talbot. A calotype began with a negative image printed on light-sensitive paper. To make a positive, one sandwiched the negative together with a second sheet of the paper and exposed it to the sun. Because Talbot’s process was repeatable, one could make numerous copies of a single image. But the images weren’t very sharp, because the irregularities in the paper itself caused distortions; calotypes also took much longer to create. Holy Colliding Colloids! Frederick Scott Archer was an English sculptor who liked the idea of working from a photographic image of his subjects. But the limitations of both daguerreotypes and calotypes made them less than ideal for his work, so he set about to create a solution—a process with all the sharpness and contrast of the former and the reproducibility of the latter. In 1848, he struck upon the idea of using a recently invented substance called collodion. Collodion is a thick, sticky, clear, gelatinous substance. To make it, you start with pyroxylin—also known as “gun cotton”—which is created by treating cotton or wood pulp with nitric and sulfuric acids. Dissolve the pyroxylin in ether with a small amount of alcohol, and it turns into an adhesive of sorts. (The Greek word from which collodion is derived means “glue”; the same root gives us the word colloid, any of a class of gelatinous substances of which collodion is just one example.) At that time, collodion was used primarily to dress wounds. Archer’s innovation was to coat a glass plate with a mixture of collodion and potassium iodide, and then dip the plate into a silver nitrate solution to make it light-sensitive. (In fact, it was very sensitive—exposures could now be as brief as a few seconds.) Because the plate had to be placed in a camera, exposed, and developed immediately—while the coating was still wet—Archer’s method was known as the “wet collodion process” (or, sometimes, the “wet plate collodion process”). The result was a sharp, durable, glass negative that could be used to make any number of prints. In other words, it was a direct ancestor of modern negatives. Nice Guys Finish Last? Archer did not patent his process, but instead published a detailed description in the March, 1851 edition of The Chemist—making it freely available to all comers. It was an immediate success. Almost overnight, the daguerreotype and the calotype became obsolete; the wet collodion process went on to dominate photography for nearly 30 years. Although later discoveries would eliminate the awkward need to work with wet plates, Archer’s invention opened entirely new doors for the young art of photography. One person, however, was highly chagrined at this turn of events: William Talbot. Talbot held that his calotype patent covered all silver-based photographic processes, and that therefore anyone who used Archer’s wet collodion process owed Talbot a licensing fee. For three years, Talbot waged intense legal battles, driving some photographers out of business. This made him an extraordinarily unpopular figure in the photographic world, and eventually the courts ruled that those who used Archer’s process were not in fact violating Talbot’s patent. So Talbot lost, but so did Archer. Because he didn’t patent his own process, he earned virtually nothing for his efforts. When he died in 1857—at which point his invention was still just taking off—he was penniless. This little tale does not have a nice, neat moral. We want to be thankful to Archer for his selflessness while at the same time lamenting his foolish lack of foresight; we feel angry at Talbot for being mean-spirited and vindictive, while respecting his prudent choice to patent his invention. So I suppose the lesson I take away is: “Be smart, but also be reasonable.” ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/Bendingtrees-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Collodion.165fc5887c7d.mp3"
	},
	{
		"title": "Biodegradable Plastic",
		"text": "In the mid-1990s, a certain mail-order computer retailer announced that it was abandoning Styrofoam (polystyrene) packing peanuts in its shipments and switching to environmentally friendly cornstarch peanuts instead. The new filler material, they explained, was not merely biodegradable, it would dissolve almost instantly in water. Some of my coworkers and I wondered if that meant you could eat them too. So, naturally, when our next order arrived from that company, the first thing we did was to pop the cornstarch peanuts in our mouths. All right, in retrospect, I suppose that was a bit stupid. It did not cause any ill effects as far as I can tell, but still…who knows where that cornstarch has been? So I do not recommend that you try this yourself. Nevertheless, we’d proven that this new packing material did, as advertised, dissolve quite readily, and we were all happy that we’d no longer drown in a sea of Styrofoam. Remarkably, even though cornstarch packing peanuts are much more common today, most of the packages I get in the mail are still filled with Styrofoam. I suppose the charitable view is that I’m watching recycling in action: no doubt these very pellets have been used countless times before, and (if I keep with the program) will be used countless times again. But even if true, that’s somehow unsatisfying. I really don’t want the burden of storing (or recycling) the filler from every box I get. I’d like it all to go away—preferably, in some responsible manner. Having a Breakdown Resistance to decomposition is often a virtue; you don’t want, say, your garbage can to disintegrate in the rain. But for items that are intended to be used only briefly, this robustness can be a problem. Hundreds of years from now, empty plastic bottles—not to mention discarded electronic devices, toys, and everything else—will still be pretty much intact deep in landfills all over the world. And although recycling helps considerably, it’s simply not practical or reasonable to expect that no recyclable goods will ever end up in the trash. So the next-best thing—and, in many instances, the very best thing—is plastic that will decompose. But allow me to digress for a moment. Words like “decompose,” “disintegrate,” “degrade,” and “biodegrade” do not all mean the same thing. Suppose you put a piece of plastic in a compost heap and found no visible trace of it six months later—does that mean it has biodegraded? And if so, can we safely say we’re talking about an environmentally safe product? The answer to both questions is “not necessarily.” Some so-called “biodegradable” plastics, for instance, are made of a blend of starch derivatives and conventional petroleum-based polymers. The action of bacteria in warm, moist soil breaks down the starches in these materials, but leaves countless tiny particles of plastic that have a mass only slightly less than that of the original product. And all those parts that don’t break down continue taking up space without contributing any nutrients to the soil—in fact, they may actually contribute toxins. So what we’re looking for in a truly “green” plastic is one that can either decompose completely via microbial digestion (into such products as water and carbon dioxide), or at the very least, leave only inert substances behind. Natural Wonders The thing is, this is generally not in the nature (so to speak) of synthetic polymers. The interesting solutions, therefore, are largely to be found in biopolymers, a class of materials that look, feel, and act like the plastics we all know and love, but which, owing to their natural sources, can also serve as food for bacteria. Products made directly from cornstarch, other starches, or cellulose certainly fit that description. And such materials, which are used not only for packing peanuts but for things like fast-food containers, do show a great deal of promise. But if you’re looking for something bacteria might like to eat, how about the food they make themselves? Many different kinds of bacteria (and other organisms, for that matter) create a substance known as polyhydroxybutyrate, or PHB, that they store as an energy source in much the same way humans store fat. PHB, it turns out, is a rather versatile plastic. It can be produced in quantity quite quickly simply by feeding sugar to the right kinds of bacteria in what amounts to a fermentation process; it can also be produced by genetically modified plants (including a type of potato). Because it is, in fact, a bacterial food product, it’s completely biodegradable. Another often-mentioned biopolymer is polylactic acid, or PLA, made from lactic acid—which, in turn, is produced by the fermentation of cornstarch. Surprisingly enough, a few petroleum-based synthetic polymers, such as polycaprolactone, can also decompose by way of microbial action. But the appeal of using plant derivatives as the source of plastics is that they’re renewable: you can “grow” your plastics in a field or “brew” them in a vat—and make more whenever you want. At the moment, biopolymers such as PHB and PLA are relatively expensive to produce, and less flexible than many synthetic plastics. And, of course, conventional plastics are heavily entrenched in many industries. But perhaps in the future, we’ll toss all our bottles and used packing materials into the same bin as our trash—without guilt. Wouldn’t that be amazing? ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/BiodegradablePlasticUtensils.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Plastic.aaebe0fab1a2.mp3"
	},
	{
		"title": "Space Pens",
		"text": "For several years as a child, I was convinced that I would be an astronaut when I grew up. I loved everything having to do with space and rockets; I collected photographs and magazines about space travel; I begged my parents to take me to the National Air and Space Museum in Washington, D.C. when it opened in 1976, and of course I also watched Star Trek reruns religiously. There simply could be no other occupation worth pursuing, and nothing could dissuade me from my passionate desire to go into space. Well, maybe one thing. I was watching the TV coverage of some space launch or another. It followed the astronauts through all the preparations they underwent leading up to the mission. And before they got into the rocket, a doctor gave them shots of some kind. I couldn’t believe my eyes. Injections? Just to go into space? No way. I’d have to find a safer profession. And from that very moment I knew I’d never be an astronaut. Pen-t Up Ambitions Although my dream of traveling into space had met an untimely end, I was still extremely happy to watch other people do it, and I was particularly interested in the paraphernalia of space flight—the spacesuits, the computers, the freeze-dried meals, and so on. One day I was leafing through a catalog and I saw something that made my jaw drop: the Fisher Space Pen. “Just like the astronauts use!” it said. I was already drinking Tang, so that became my next object of desire. This pen, so the catalog said, would write in zero gravity—and, as a bonus, it could also write upside down, underwater, in a vacuum, on glossy paper, in extremely hot or cold environments, or even on greasy surfaces. And it was very shiny and futuristic-looking. Wow. I had to have one. “We have plenty of pens,” my parents said. Which was true. The problem, of course, was that the Fisher Space Pen was quite a bit more expensive than your basic disposable Bic. “But they don’t write in zero gravity!” I complained. My parents, ever pragmatic about such matters, then inquired when I expected to encounter zero gravity. I had to admit that was unlikely. After further discussion, I also conceded that I would probably have no need to autograph greasy, glossy photos while standing on my head underwater. So even the dream of writing with the same pen the astronauts used evaporated. Many years later, having all but forgotten this episode, I received a Space Pen as a gift. I was absolutely giddy with excitement. It didn’t matter that it had cost only US$20. I couldn’t believe I was actually the proud owner of something I’d always believed I could never have. It was, for some time, my Favorite Thing Ever. And yes, it performed flawlessly—just as advertised. I never encountered a surface or angle it couldn’t handle. The Write Stuff A few years ago, I read a story that the Space Pen had cost NASA a fortune to develop. According to the story, when a U.S. astronaut asked a cosmonaut how they’d ever managed without one, the simple reply was, “We use pencils.” Although I can certainly imagine that NASA has, over the years, wasted huge sums of money engineering their way around problems that could have been solved with common sense, this particular story turns out to be false. The Space Pen did cost about $1 million to develop, but that money was invested by the Fisher Pen Company. Prior to the pen’s introduction, astronauts used mechanical pencils, and cosmonauts used grease pencils. But both implements were less than ideal (lead, in particular, caused problems if it broke off and started floating around the cabin), so a new writing tool was certainly needed. Paul C. Fisher ran a successful company whose main product was a “universal” refill for ballpoint pens. At the time, most ballpoint designs were prone to leaking, skipping, and drying out. One night, a completely new design occurred to Fisher in a dream, and he went on to build it. This new pen had two main innovations. The first was a sealed cartridge, pressurized with nitrogen to about 40 psi. Because the cartridge was sealed, it would not dry out; the pressure ensured that the ink would flow regardless of the angle at which the pen was held. However, ordinary ink was too runny; the pressure caused it to leak at the tip. So Fisher developed a gel-like ink that was thixotropic—meaning it was semisolid until agitated (by the motion of the rolling ball), which turned it into a liquid just long enough to flow onto the page. This ink, which has a consistency similar to rubber cement, is also waterproof and resistant to smudging. When Fisher presented the final product to NASA, they tested it for months before certifying it as spaceworthy. From 1968 on, Fisher Space Pens have been used on all NASA missions; they’re also used aboard Russian spacecraft. Interestingly, I’ve read a report by one astronaut saying that “ordinary” ballpoint pens work fine in zero gravity after all. Whether this is true of only some designs and not others, I don’t know—but it does make one wonder whether NASA actually tested conventional ballpoint pens in space before deciding an alternative was needed. Be that as it may, the design certainly works well on Earth—especially at odd angles that frustrate most ballpoints. It is very nice to know that if the need arises, I can write in the rain, on a wall, or what-have-you. But the truth is that my own Fisher Space Pen has been lying unused in a box somewhere for years because of two deficiencies: it has no clip and uses black ink. For reasons chronicled elsewhere, I have adopted the customs of keeping a pen clipped to my collar pretty much all the time and writing exclusively in purple ink. I was thrilled to discover, on a recent visit to the Fisher Space Pen Web site, that the company now offers refills in purple (and nine other colors—including, bafflingly, “invisible”) as well as slide-on clips; I can even pick up a titanium model if I want. How very exciting: perhaps I’ve just discovered the last pen I’ll ever need—whether I make it into space or not. —Joe Kissell UPDATE: I did indeed get a new Space Pen with a clip and purple ink. I’m sorry to say, though, that it has not lived up to my expectations. Writing with the purple Space Pen ink is not nearly as smooth as with the black ink, but more seriously, the purple ink has a strong tendency to bleed when exposed to moisure. That’s right: it can write underwater, but you’d better read quickly, because the purple ink is actually water-soluble! I described this problem in detail (with photos!) in Space Pens with Purple Ink: A Sad Tale. The quest for the perfect pen continues. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/07/Space-Pen-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/07/Space-Pen.bb5f9e32a4dc.mp3"
	},
	{
		"title": "Bakelite. The Plastic Age",
		"text": "In the autumn of 2000 I went on honeymoon to Somerset—a beautiful rural region in the south-west of Britain. Unfortunately, our trip coincided with widespread fuel blockades, and many petrol stations had run dry. We had enough fuel to drive to Somerset, and enough to get back, but very little to spare for travelling around during our stay. This didn’t bother us too much (we were planning to do a lot of walking anyway), but when the weather was bad it presented a bit of a challenge. On one particularly drizzly day, we found a flyer for The Bakelite Museum. I think that the unspoken thought in both of our minds was, “It will probably be a bit boring, but at least it will be dry.” As it turned out, we were utterly wrong about the appeal of Bakelite: it’s fascinating stuff. Great Balls of Fire Around the turn of the 19th century, some plastics were already in use. Early plastics were not wholly synthetic, even though that’s how we think of plastics today. Instead, they were formed from a mixture of synthetic and organic compounds. The realisation that natural materials like ivory, horn, and tortoiseshell were becoming scarce because of over-exploitation prompted chemists to search for a synthetic alternative. Cellulose nitrate (more commonly known as celluloid) was the first commercially successful product, and was developed by the British inventor, Alexander Parkes. Produced by reacting cellulose (the organic part derived from plant cell walls) with nitric acid (the synthetic component), celluloid was a very adaptable material. It was thermoplastic, meaning that it could be moulded into almost any shape with the application of heat and pressure. It could also be coloured with dyes and pigments so that the products did not need to be painted, and had a tough, durable finish. Celluloid was soon being used to replace ivory in objects like billiard balls, but there was one big drawback; celluloid is highly flammable and sometimes explosive. An enthusiastic break in billiards sometimes resulted in exploding balls—something that in my opinion would considerably improve its appeal as a spectator sport today. Early celluloid cinematographic film also had the tendency to burst into flames, burning down cinemas and causing problems even today for the conservation of early films. This also meant that celluloid was useless as an electrical insulator, something that was becoming increasingly sought after as the early electrical industries flourished. The compound used for electrical insulation at the time was shellac. This was a lacquer manufactured from the resin secreted by a small south-east Asian insect, Laccifer lacca. It was a labour-intensive and expensive process, requiring around 300,000 insects to produce 1 kg (about 2.2 lb) of shellac. With the new electrical industries booming, supply was not keeping up with demand. Chemists around the world began to see that anyone who developed a synthetic substitute for shellac would become very rich. Promising Goo Leo Baekeland (1863–1944) was a Belgian inventor who emigrated to the United States in 1889. He had developed (pardon the pun) a photographic paper called Velox which could be exposed using artificial light rather than sunlight, giving photographers much greater control over the process. He sold the full rights to Velox to George Eastman of the Kodak corporation in 1899 for a staggering US$1 million, and used the money to set up a laboratory in Yonkers, New York. There, he worked on the ‘synthetic shellac' problem. He had an idea that the reaction between phenol (derived from coal tar) and formaldehyde might be promising. The German chemist Adolf von Baeyer had already noted that such reactions resulted in a sticky substance that he dismissively called Schmiere (“goo”). Von Baeyer’s interest was in dyes rather than insulators (he won the Nobel Prize for Chemistry in 1905 for his synthesis of indigo), but Baekeland saw the potential of the “goo.” He experimented with different combinations of the raw products subjected to heat and pressure in an iron pressure cooker he invented called a ‘bakelizer,' and finally found the magic combination in 1907. The Magic Plastic Bullet Bakelite turned out to be extraordinarily versatile. It was a thermosetting plastic, which meant that once heat and pressure had been applied to mould the material into a particular form, it could not be reversed. It would not burn or melt (which made it a great insulator), nor could it be readily dissolved with the common solvents or acids of the time. If ‘fillers' like fine sawdust or other fibres were mixed in before the mixture was set, the resulting Bakelite could be as strong as wood or even steel. It could be moulded or carved into almost any shape. Early Bakelite made with phenol tended to be dark brown or black, but a later process combining urea and formaldehyde produced a colourless resin which could be dyed with bright colours. The colourful age of plastics had begun. The Age of Design Bakelite enabled a new era of mass production. The moulding process meant that—while the initial investment in making the mould was very high—each item produced in the mould could be made relatively cheaply. The maximum return on the investment could be gained by producing as many items from the same mould as possible. At the same time, design became an important element in the marketing of products. The products were cheaper and the appearance of an item became as important in convincing customers to part with their money as its function. The Art Deco style of the 1920s and 1930s, with its sweeping curves and bold, geometric designs, was perfect for Bakelite. Almost anything that you can imagine being made of plastic today would have been available in Bakelite, but radios, telephones, clocks, jewellery, kitchen utensils, cameras, combs, and brushes were particularly popular. The new, colourful, glossy materials developed in symbiosis with the Art Deco style to form a confidently modern style, quite different from anything that had been seen before. Bakelite was eventually superseded by newer plastics which were less brittle and cheaper to produce, but you can still find Bakelite items in many places today. Wandering around the Bakelite Museum was like seeing the distilled essence of five decades. The museum was packed with household objects of every kind from Bakelite condiment sets to an extraordinary Bakelite coffin, and I kept recognising things from my grandmother’s house. In particular, a set of fluted egg cups in 1950s pastel colours took me right back to having breakfast at my grandmother’s when I visited for the weekend as a child. All that nostalgia from something that starts off as sticky goo. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/06/Bakelite_radio.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/06/Bakelite.3b8261cb68c6.mp3"
	},
	{
		"title": "The Paperclip",
		"text": "I discovered the importance of paperclips in first grade. One day at lunchtime, my friend Brad gathered a few of us geeky types together on the playground and solemnly handed each of us a small, shiny object. “These,” he said, “are paperclip communicators. You must carry them with you at all times and guard them carefully: these are the only ones of their kind.” He went on to explain that using these special communicators, which merely looked like paperclips, we could talk to each other from a distance. The next morning, a few of us arrived at school early, before Brad got there. We decided to call him on our paperclip communicators. We didn’t hear a reply, but perhaps we just weren’t listening carefully enough. A few minutes later when Brad walked in, we asked if he’d heard us. “Oh yes,” he said, “I heard you on my paperclip communicator when I was riding the bus.” Well, that settled it: there could be no doubt that we were in possession of some powerful technology. I proudly wore my paperclip communicator on my belt. A few weeks later, though, it disappeared. I looked everywhere, but couldn’t find it. In tears, I told my mother what had happened. She didn’t seem upset; she simply reached into a drawer and handed me another paperclip. “No!” I shouted. “It’s not the same thing! That’s just an ordinary paperclip. Brad couldn’t hear me if I talked into that!” For days I was inconsolable at my loss, and deeply frustrated that my mother couldn’t tell the obvious difference between a paperclip communicator and a bent piece of wire. Brad, of course, couldn’t help me: there were no more paperclip communicators to be had. Little Things Mean a Lot About twenty-five years later, I started working for a computer accessories company called Kensington, which is a business unit of ACCO Brands—a major office-products manufacturer. I knew that ACCO made products like paperclips and binders, but what I did not know until I’d worked there for several years was that ACCO was originally short for “American Clip Company.” The humble paperclip was largely responsible for the initial success of what is today a gigantic and extremely profitable business. Where did this simple, cheap, and indispensable invention come from? Appropriately, the story is twisted. As recently as the late 19th century, the most common way to hold papers together was by using a straight pin. This was an inexpensive and functional solution—and, unlike staples, easily removable. It did, however, leave holes in the paper (and occasionally in the finger). But as steel wire became more common, inventors began to notice that it had just the right amount of springiness to be formed into various sorts of effective cliplike devices. In the years just prior to 1900, quite a few paperclip designs emerged—both in the U.S. and in Europe. Some were patented, some not. There was at the time, and still is now, considerable disagreement about who devised which particular type of wire loop when. The Norwegian Clipper The name most frequently associated with the invention of the paperclip is Johan Vaaler, a Norwegian inventor who received patents on several designs—from Germany in 1899 and from the U.S. in 1901. However, Vaaler’s clips were by no means the first, nor are they the same as what we think of today as the paperclip—they did not have an interior loop. The familiar double-U design was devised by Gem Manufacturing Ltd. in England; this clip is therefore sometimes known as the Gem clip. (Incidentally, despite the fact that ACCO made a name for itself with paperclips, the so-called ACCO Fastener is not a paperclip; it’s a two-pronged brass fastener that was invented in 1912. ) Because the Gem clip itself was never patented, we don’t know exactly when it first appeared. Some sources speculate that it may have been as early as 1890; in any case, it was certainly well before Vaaler’s first patent in 1899. In that year, a Connecticut man named William Middlebrook patented a machine for bending Gem-style clips. Such a device would be crucial to the paperclip’s success, as it would enable the clips to be manufactured much more quickly and inexpensively. Clip Will Keep Us Together Despite the fact that Norway holds a rather dubious claim as the birthplace of the paperclip, it played an important historical role there. During World War II, when the German army occupied Norway, they forbade citizens to wear any likeness of the king, or even his initials. So instead, people began to wear paperclips on their lapels—symbolizing both national pride and “sticking together.” When the Nazis realized that paperclips were a sign of solidarity against the occupation, they outlawed the practice. Later, a giant paperclip statue was erected in Oslo to honor Vaaler—even though his design was never actually manufactured. The Gem clip (by whatever name) is, of course, just one of many modern paperclip designs. Some competing clips have little or no tendency to become tangled with each other. But this seeming advantage hasn’t kept the Gem design from becoming synonymous with “paperclip” and holding the top position by far, to this day, in worldwide sales. As for the paperclip communicator…unfortunately, it hasn’t been manufactured since 1973 ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/06/paperclip-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/06/Paperclip.1dedd42c8930.mp3"
	},
	{
		"title": "Optical Telegraphs",
		"text": "Let’s say you’re besieged by a bunch of Orcs and Nazgûl in some fictional city in the realm of Gondor. And let’s say your ancient allies from far away in the land of Rohan are your only faint hope for rescue. How might you call out for help over such a great distance, especially with a bunch of mountains between you and Rohan? You would ignite a large pile of firewood that has been waiting ready at the top of a tower for just such a purpose. And many miles away, on the top of the nearest mountain, a beacon-warden would notice this fire and light one of his own. And then the warden on the next mountain over would do the same thing, and so on, until seven mountains later, your friends saw the fire nearest them and got the message. Tolkien mentioned this event only in passing on the opening page of his book The Return of the King, but Peter Jackson made it into a dramatic scene in his Oscar-winning 2003 film version of the story. It was a moving and visually stunning portrayal of a desperate plea for aid that, given the circumstances and technological resources available, could not have been conveyed in any other way. And if you understand this long-distance visual method of relaying information, you’ve grasped the basics of the optical telegraph, which predated the more commonly known electric telegraph by decades. Better Than Shouting! In the early 1790s, French inventor Claude Chappe and his brother Ignace were trying to develop a reliable means of high-speed, long-distance communication. Their first attempt was clever but misguided. Each station had a large mechanism based on a pendulum clock, but in place of a regular clock face was a dial with 10 sections, corresponding to the 10 numerals. The clocks were carefully synchronized, being set in motion at the same time by way of a prearranged signal. The sender waited until his clock was pointing at a specific numeral and then made a sound; the receiver, whose clock would at that moment be pointing at the same symbol, thus knew what number was being signaled. Sequences of numbers corresponded to letters and words—and so, after a fashion, any message could be transmitted. But it was slow, noisy, and limited by the range of hearing, wind direction, and so on—clearly in need of an upgrade or two. Their next attempt, which continued to rely on the synchronized clock mechanism, replaced the sound with a movable panel painted white on one side and black on the other side. This gave them much greater range (with the help of a telescope) and, of course, quiet operation. But it then dawned on them that they could send much more information in a shorter period of time if they ditched the clock and instead constructed a mechanism capable of displaying a variety of visual signals directly. So they created a large apparatus with five panels; each combination of black and white panels stood for a different character. That worked better, but more innovations were soon to come. Up In Arms After another year or so of experimentation, the Chappe brothers determined that long wooden beams placed at various angles could be seen more clearly over long distances than black and white rectangles. So they created a simple mechanical device that could reposition two large arms (each with two segments—a main bar and a crossbar) into any of nearly 200 configurations; anyone with a code book could translate those signals into words and numbers. They dubbed their invention the “telegraph,” though nowadays all the early visual transmission systems are referred to as optical telegraphs, and this particular version is called a semaphore telegraph. (An aside…At almost exactly the same time the Chappe brothers abandoned their panel-based system, a Swedish inventor named A.N. Edelcrantz, who was working on a remarkably similar project of his own—apparently without any knowledge of what was happening in France—decided against the semaphore arms he had been using and switched to a panel design. Edelcrantz’s system, which used a 3x3 grid of movable panels plus a tenth, larger one on top, could produce a wider range of characters with a single configuration (and thus send more information in less time). However, it never caught on outside Sweden, and as far as I know, was never given a head-to-head comparison with the Chappe telegraph. ) Gimme an A The first major semaphore line, which stretched between Paris and Lille, 120 miles (about 190km) north, near the border of Belgium, began operation in 1794. It consisted of 15 stations, each of which could receive and relay a single character in well under a minute. I can just imagine a guy sitting there in a tower, patiently peering through a telescope, and then, suddenly: “Yo, François, it looks like an A!” And François would go orient the mechanism to display an A to the next station while his buddy watched for the next letter. A single character could be passed all the way down the line in this manner in as little as 9 minutes, and an entire (very brief) message in about a half hour. Before long, optical telegraph lines were installed all over France. When Napoleon came to power in 1799, he immediately began using the semaphore telegraph to relay tactical information to and from his troops. This system remained the primary means of telecommunication in the country for several decades. In fact, around 1840, after Samuel Morse had successfully proven his electric telegraph design, the French government initially declined to replace their semaphore telegraphs with the new technology. Despite its reduced need for human labor and its availability in poor weather or after dark, the electric telegraph was thought to be easily sabotaged—someone could simply cut the wire. The naysayers finally came to their senses and agreed to electric telegraphs in 1846, though some optical telegraphs were still in operation as late as 1881. The use of the word “semaphore” to refer to signals made with hand-held flags, typically for naval communications, came well after (and was inspired by) the semaphore telegraph. Thus, in a manner of speaking, the technology developed by Chappe and Edelcrantz is still in use—at least occasionally. Your wireless internet connection may be faster, but it doesn’t provide nearly as much exercise. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/06/Optical-Telegraph-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/06/Optical-Telegra.165245921b9b.mp3"
	},
	{
		"title": "Fire Pistons",
		"text": "I’ve never been much of a camping enthusiast. It’s not that I don’t appreciate all the great gadgets associated with camping, and I certainly enjoy hiking, fresh air, and getting away from it all. But after toting all our high-tech apparatus into the middle of nowhere, setting up a tent, and rolling out the sleeping bags, I invariably think to myself: this is an awful lot of work for very little comfort. At home I would have had a nice squishy mattress, a flush toilet, clean water, and no mosquitoes. Why am I doing this again? Then it comes time to build a fire and I discover some cruel corollary of Murphy’s Law at work. On those few days I ever have to attempt this task, it’s always windy, damp, or both. Of course, I know that when matches fail, I can always bring out some specially flammable substance designed expressly for the pyrotechnically challenged. But the latest rage in fire-starting equipment is actually centuries old and uses no chemicals, sparks, or even metal components. Meet the fire piston: a deceptively simple tool that uses compressed air to start a blaze in just seconds.\n\nLight Me Up\nA fire piston is a small cylindrical object usually made of wood, bone, or plastic. It consists of two main parts: an outer casing, which is hollow but closed on one end, and the piston itself—a rod or plunger that fits the hole in the casing perfectly and whose tip reaches almost, but not quite, to the stoppered end of the tube. The tip of the piston has a small indentation or hole, and just behind the tip is usually a gasket of some kind to ensure an airtight seal—perhaps a rubber O-ring or simply some waxed string. In other words, very basic parts that require little technological sophistication to create.\n\nTo use a fire piston, you put a tiny piece of tinder in the indentation at the tip of the piston, and perhaps apply a dab of grease to the gasket for lubrication. Then you place the plunger into the tube and smack it down rapidly. This compresses the air inside, which raises its temperature. Within less than a second, the temperature at the tip of the piston can reach more than 800°F (about 425°C)—enough to turn the tinder into a glowing ember. The pressure also, conveniently, works as a spring that forces the piston back out of the casing. Transfer the ember to a larger pile of tinder, blow for a few seconds, and poof! You’ve got fire.\n\nPressure Cooker\nFire pistons work according to a well-known physical principle called Charles’s law. This law says that the ratio of a gas’s temperature to its volume is a constant. So when you decrease the volume of a given quantity of gas by compressing it, you increase its temperature; by increasing the volume, you decrease its temperature. If you have any doubts, pick up the nearest aerosol can—or better yet, a can of compressed air—and spray it for a few seconds. The can will feel colder. (I’ve sometimes seen ice form on compressed air cans after heavy use.) By releasing the pressure you’re increasing the volume of the gas, and thus decreasing its temperature. Or try inflating a tire with a manual tire pump (yet another piston design) and notice that the pump gets hot as you use it. This very principle is what makes diesel engines work: the fuel is ignited by rapidly compressed air, not by a spark as in conventional internal-combustion engines. In fact, some people believe Rudolf Diesel may have gotten the idea for his engine from seeing a fire piston being demonstrated.\n\nNo one knows who invented the first fire piston. Although the device was patented in England in the early 1800s, a similar design (albeit made from different materials) was apparently in use long before that in Indonesia, the Philippines, and several other southeast Asian nations. The prevailing theory is that in the process of hollowing out a long tube to make a blowgun, a hunter inadvertently ignited some sawdust.\n\nIn any case, just as fire pistons were beginning to catch on in Europe, matches hit the scene, and quickly took over as the most popular method of making a flame. And so fire pistons were all but forgotten—at least in the western world—for the better part of two centuries.\n\nBut under certain conditions, matches are still no match for a fire piston. Because fire pistons create a watertight seal, they’re virtually weatherproof. And because you’re working with a glowing ember rather than an open flame, wind can actually work in your favor. You do, of course, have to have dry material to burn, but that’s pretty much a given if you’re going to start a fire by any means.\n\nI first heard about fire pistons in an email from one of the many readers who regularly supplement my list of interesting things to research. After browsing a few Web sites—and, especially, watching some videos of the devices in action—I was simply astonished. I couldn’t believe that something so simple, effective, and useful wasn’t part of every camper’s gear. It might have been, had matches not been invented at just the right (or wrong) time. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/06/Fire-Piston-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/06/Fire-Pistols.c4e5b04c6460.mp3"
	},
	{
		"title": "Rebreathers",
		"text": "If I end up completing all the tasks on my Life’s To Do List, I’ll live to be a very old man indeed. So many places to visit, books to read, foods to try, experiences to have—and the list is perpetually growing. “Learn scuba diving” is on the list, but like “visit Machu Picchu” or “have dinner at La Tour d’Argent,” it’s something that requires a greater investment of time and money than I am able to make at the moment. Still, it’s something I’d like to do if the opportunity ever presents itself. Yes, there’s a lot of fascinating stuff underwater—the marine life, the shipwrecks, and all—but equally appealing is the geek factor. Scuba diving requires lots of cool, specialized equipment, and just think of the entirely new range of dive-enhancing gadgets I could justify buying! Then perhaps one day, if I become sufficiently advanced and still have some money to spare, I’ll invest in the ultimate piece of scuba gear: a rebreather. This fabulous piece of kit could set me back as much as US$20,000, not to mention the extensive additional training and certification I’d need to use it. But a rebreather does for scuba diving something like what a hybrid engine does for a car: it provides much greater fuel efficiency while reducing noise and pollution. These things may not seem like a big deal on the road, but underwater, they can make all the difference in the world. Heavy Breathing In ordinary scuba diving, you have one or more tanks of air—or, depending on what sort of dive you’re undertaking, a mixture of oxygen with nitrogen, helium, or other gases in carefully measured proportions. Regulators deliver just the quantity of air you need, at an appropriate pressure, through a mouthpiece; when you exhale, a valve releases the used air into the water. Each time you take a breath, though, your lungs absorb only about a quarter of the oxygen in the air; the rest is exhaled along with the carbon dioxide you produce. So a lot of the oxygen divers take with them is essentially wasted. The deeper you dive, the more rapidly you use up air, so a dive’s maximum duration is determined by its depth and the number of tanks a diver carries. Even though air tanks don’t feel heavy underwater, there are practical limits to how much a diver can carry—and thus limits on the duration of a dive. Rebreathers change this equation by recirculating the unused oxygen from every exhaled breath. Instead of being expelled into the water, the used air is channeled into a “scrubber,” an assembly that uses a chemical such as a soda-lime mixture (sodium hydroxide and calcium hydroxide) to absorb the carbon dioxide. That leaves a good bit of usable oxygen, which is recirculated into the system and supplemented, as needed, with more oxygen from a tank. In this way, a rebreather can provide dramatically longer dive times with a much smaller and less cumbersome apparatus. In addition, because air isn’t discharged into the water when you exhale, there are no bubbles (or at least very few). As a result, a diver wearing a rebreather can swim almost silently and invisibly—handy if you’re photographing bashful fish or, you know, sneaking up on the enemy spy who’s trying to sabotage your submarine. In the Loop Conventional scuba apparatus is “open-loop” (or “open-circuit”), meaning the air goes out of the system when it’s been used. Rebreathers, by contrast, generally fall into three major categories: * Oxygen rebreathers are the simplest variety. They use a single tank of pure oxygen, but because of the danger of oxygen toxicity (a situation where pressure forces too much oxygen into the blood), they can only be used at shallow depths of about 6 meters (20 feet) or less. * Semi-closed circuit rebreathers replace the oxygen tank with a tank of mixed gases, allowing deeper dives. But their design also requires that a portion of the used air be vented into the water to maintain the proper levels of oxygen and other gases. * Closed-circuit rebreathers are the most complex design. They use two gas tanks: one for air (or at least an oxygen-nitrogen or oxygen-helium mixture) and one for pure oxygen. Oxygen sensors feed data to a microprocessor that regulates the oxygen pressure in such a way that no gas needs to be expelled. Closed-circuit rebreathers also enable the diver to maintain very low levels of nitrogen (or other non-oxygen gases) in the blood, which reduces the need for slow decompression when ascending from deep water. As great as rebreathers are for certain applications, they have some disadvantages compared to conventional scuba gear. For one thing, because rebreathers are so complex, more things can (and do) go wrong. They must be carefully maintained—and even then, they are far more prone to failure than a simple tank-and-regulator setup. (Failure of one’s breathing apparatus deep underwater, of course, is a rather serious problem.) In addition, it’s surprisingly difficult to regulate oxygen pressure precisely so that it falls into the narrow range between too little (which can result in a potentially deadly condition known as hypoxia) and too much (which can result in a potentially deadly condition known as oxygen toxicity). If a rebreather fails to deliver just the right mix of gases, the diver is in trouble. And of course there’s the price, which is not a big deal for the military, but problematic for many recreational divers. Note to self: Put “become fabulously wealthy” higher on Life’s To Do List than “learn to use a rebreather.” ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/06/Rebreather-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/06/Rebreathers.38d3055da18f.mp3"
	},
	{
		"title": "Titanium Art",
		"text": "The colorful process of anodization When Morgen and I got married, most of our wedding guests came up to us and said things like “Congratulations!” or “Enjoy your honeymoon!” One of our friends, however, on seeing our titanium wedding bands, cautioned us gravely, “Avoid electrified salt solutions.” That’s one of the strangest things anyone has ever said to me. Not knowing how else to respond, I assured him that we would—in fact, I think I can safely say that I have made a lifelong practice of avoiding electrified liquids of any kind. But I always wondered about that odd warning. A couple of months ago I ran into this friend again and asked him what the deal was—what terrible fate would have befallen us, or our rings, had we encountered an electrified salt solution? He said it would permanently alter the appearance of the ring, and sent me some links to photos of titanium that people intentionally treated in this way in the name of art. The examples of titanium jewelry, sculptures, and other artwork in the pictures were lovely, with intricate patterns in rich, vibrant colors. Our friend had mentioned that one could obtain a wide range of colors using this process, and sure enough, artists seem to use every color of the rainbow. But what I found most interesting about all this is that all the colors are essentially an optical illusion. Just Add Water (and Electricity) Any metal, given the right conditions, will oxidize, which simply means reacting chemically with oxygen to form a new compound. When iron oxidizes, the result is iron oxide, which we all know as rust. Some metals are less prone to oxidation than others—aluminum and titanium, for example, do not readily oxidize in air. But with a little help, they can form very thin oxidized layers that, unlike rust, actually protect the metals from further damage. One way to cause oxidation is to put a piece of metal in an electrolyte (an electrically conductive solution) and apply electricity—the negative electrode, or cathode, is placed in the liquid and the metal being treated is connected to the positive electrode, or anode. This procedure is therefore known as anodization. Chances are, if you have any aluminum products in your home—cookware, for instance—they have been anodized. The aluminum oxide coating thus created is very hard and prevents the aluminum from reacting with, say, tomato sauce. You can do the same thing with titanium (and several other metals). Titanium oxide is clear, but when light shines through it onto the reflective metal surface and then bounces back, the titanium oxide refracts it. The result is the appearance of color—even though the metal itself is whitish gray and its coating is transparent. So without dyes, paints, enamels, or any other materials besides titanium and oxygen, anodized titanium products can be made to look outrageously colorful. The Anodizing Solution Although some electrolytes are salt solutions, most common salts produce poor results when it comes to anodizing titanium. Better results come from an alkaline solution of something like baking soda or trisodium phosphate (TSP), or an acidic solution (think Coca-Cola). The color obtained is mainly a function of the amount of voltage applied to the metal; the more voltage, the thicker the layer of titanium oxide produced and the more refractive power it has. Some shades require that the titanium be etched with an acid before anodization, and some (like pure black) are impossible with anodization alone. Artists whose medium is anodized titanium have developed numerous clever techniques for controlling the thickness of titanium oxide deposits with great precision. In this way, they can create nearly any imaginable design. I’ve seen framed titanium “prints,” titanium earrings, pendants, and pins, and all sorts of stand-alone titanium sculptures. There are also some anodized titanium rings, but because rings are subject to a lot of abrasion, which can wear off the titanium oxide coating, they tend to dull and lose their color. Of course, if my hand just happened to fall into an electrified salt solution and I managed to survive, it’s comforting to know my ring would eventually return to its original color. Who needs that kind of stress in a marriage? ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/06/titanium-ring.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/06/Titanium_.fed587d8cad5.mp3"
	},
	{
		"title": "Lagniappe",
		"text": "On our last trip to Paris, Morgen and I met some friends for dinner at a restaurant that had gotten some very good reviews. The owner of the restaurant arrived at our table to take our orders, and we told him the prix fixe set menu sounded good. He looked strangely concerned, as though we foreigners couldn’t possibly know what we were getting ourselves into. “You understand,” he asked, “that this meal includes an aperitif, an entree, a main course, a dessert, and coffee…and an unlimited quantity of wine?” We nodded and assured him that we knew the routine. He smiled slyly and said, “Ah bon. There will also be…some surprises.” A few moments later, a small dish of sausages arrived at our table—an amuse bouche, or a sort of pre-appetizer—along with some fresh bread. Then the advertised courses appeared, one by one, until finally, after coffee, the owner returned with a bottle and four small glasses in his hands and a conspiratorial expression on his face. “A little something to conclude your meal,” he offered, and poured us each a glass of marc, a potent digestif distilled from the bits of grape skin left over when wine is made. Splendid. We would have enjoyed the meal thoroughly even without the unadvertised extras, but the unexpected attention to detail left us with an even warmer feeling about the restaurant. Little Things Mean a Lot In New Orleans, the term that would be used to describe “a little something extra” of this sort is lagniappe, pronounced “LAN-yap.” There is an old custom among merchants in New Orleans to add a small, nearly trivial gift to an order—particularly for large purchases or repeat customers. The word “lagniappe” originally comes from the Quechua word yapay (“to give more”), which led to yapa (“gift”), and then to the American Spanish la ñapa (“the gift”). Although the term lagniappe is not used in, say, Paris, the underlying principle appears in many forms in many cultures—including the “baker’s dozen” that was once the norm in North America. There’s a subtle yet powerful psychological principle at work here: the amount or quality of something you actually receive is not as important as how it compares to what you were anticipating. For example, let’s say you see an ad on TV for a salad steamer and think, “Wow, I have to buy this.” When your package arrives in the mail, you discover it contains not just what you ordered, but as a special thank-you gift, a certificate redeemable for a free head of lettuce. Because what you got was more than you thought you paid for, you’re likely to feel happier with your purchase and more favorably disposed toward the merchant. On the other hand, if the merchant had promised “free lettuce with purchase” and you expected a fresh head of lettuce in the box, you might be disappointed and annoyed to find that you have to make an extra trip to the store to get what you paid for. The actual contents of the package may have been the same in both cases, but your reaction was different because of the expectations you had. As Seen on TV This principle can be a very effective marketing tool if used correctly; it can also, of course, be abused. If you have three products that are all cheaply made and collectively worth US$10, how do you sell the set for twice that? Easy: hype up just one of the products and advertise it at the “low, low” price of “only” $20. Then, dramatically, add: “But wait, there’s more!” and mention, as if benevolently bestowing excess riches on a favorite nephew, that you’re going to throw in the other two products “absolutely free!” This strategy works surprisingly well, all because the initial step of setting expectations was executed so cunningly. This is also why some hardware and software developers in the computer industry have adopted a mantra: “Underpromise and overdeliver.” What counts is not so much the feature set and delivery date of a product, but rather how the reality compares to what your customer (or your manager) was expecting. This is not to say, of course, that the notion of lagniappe is always or even usually misapplied; merchants who are generous—or just very savvy—may well give you more than you pay for. For that matter, you don’t even need to be selling something to apply the principle of lagniappe—it is equally effective when giving gifts, inviting friends over for dinner, or even writing a book. But for lagniappe to function most effectively, it should really be unexpected. (This is why I’m perturbed at New Orleans merchants who go out of their way to advertise “We Offer Lagniappe!” on their signs—that seems to me to be missing the point.) When the “little something extra” is a surprise, it can truly delight the recipient. —Joe Kissell A Little Something Extra If you enjoy reading Interesting Thing of the Day, you might also want to check out idea a day. I don’t have anything to do with this site personally, but I’ve enjoyed reading it for quite some time. Every day, a new idea—often for a new product or service, but there’s quite a variety—appears on this site. You can also subscribe to the ideas by email, which I find more convenient. Ideas are contributed by readers and are in the public domain, so anyone who thought the idea was worthwhile could attempt to implement it. Some of the ideas are really brilliant; others border on the absurd. But they’re all free, and well worth a few seconds of your time to glance at every day. You may stumble on a real gem. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/06/gift.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/06/Lagniappe.d47b6ed823ca.mp3"
	},
	{
		"title": "Printing Skin Tissue",
		"text": "An earlier article here covered 3-D printers, which use modified inkjet technology to create solid objects with extremely complex shapes. The printers use a variety of techniques to solidify arbitrary areas on the surface of a powdered substrate, which supports the object as it is built up layer by layer. Designers commonly use 3-D printers for prototyping things like consumer electronic products, ensuring that they will be manufacturable before expensive metal molds are created to enable mass production. I ran into an old acquaintance the day that article ran who had never heard of Interesting Thing of the Day, so I told him about the site. He asked me what that day’s topic was, and I happily described the 3-D printers. He said, “Oh yeah, I know about those. Did you know they’re also using them to ‘print' human tissue?” Um…no, I had no idea. It turns out that the humble inkjet printer has quite a few tricks up its sleeve—including, incredibly, the capability of manufacturing living skin and other organs. Cell Mates Growing individual human cells is not especially difficult. Take a sample of healthy cells, provide them with the right nutrients and environment, and they will grow and multiply. When multiple tissue cells are placed in close proximity to each other, they have a tendency to fuse together. Because of this phenomenon, hospitals can “grow” new skin to be used as grafts for burn patients using the patient’s own skin cells. However, this technique does have significant limitations. In particular, the skin cannot be made very thick because there’s no way to get blood to deeper cells—the process grows a homogeneous sheet of skin without the essential network of blood vessels, not to mention pores and other minute structures. But creating intricate solid structures layer by layer is easy for a 3-D printer. So researchers have adapted old inkjet printers to hold a suspension of human cells in one reservoir and a gel-like substrate in another. Each pass of the print head lays down a pattern of cells held in place by the gel; when the next layer is applied, the adjacent cells begin to fuse to the layer beneath. If, for example, each layer contains a circle of cells in the same location, the result will be a tube—in other words, a structure very much like a blood vessel. A printer could in fact hold different kinds of cells in an array of ink reservoirs (like those used by color printers), theoretically enabling the creation of entire organs. It’s All Beginning to Gel The gel that functions as the substrate for this type of tissue printing is itself quite interesting. As with the powdered material used in rapid prototyping, the gel must be removed after the rest of the structure has solidified. Called thermo-reversible gel, it has the unusual property of being solid above 32°C and turning into a liquid when cooled below 20°C. So after the cells have fused, the tissue is cooled and the liquefied gel simply drains away. Although the most obvious application for such a technology is producing skin grafts that are more robust than what’s currently possible, one day much thicker organs could be printed—making the inkjet printer a veritable tool for manufacturing replacement human parts. But although early laboratory experiments have yielded impressive results, researchers caution that the technology is in its infancy—likely a decade or more away from even initial trials with real patients. One of the hurdles to be overcome is that cells take time to fuse together into tissue, but can only survive for a short period of time without nutrients and oxygen. So the thicker a printed organ is, the more difficult it will be to keep it alive and healthy until the gel can be removed and it can begin getting nourishment from blood (or a reasonable facsimile thereof). Furthermore, remember that the printers don’t actually create the cells; they only arrange them. All the cells must have been grown in advance, a process that can take weeks (and that cannot be done equally well with all types of cells). So don’t expect to show up at the emergency room and get a new pancreas printed while you wait. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/06/Epithelial-cells.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/06/Printing_Skin.6c7a6b017bd5.mp3"
	},
	{
		"title": "Online Lost-and-Found Services",
		"text": "While I was shopping at a travel store, a piece of luggage caught my eye—but not because of its modern styling, heavy-duty ballistic nylon fabric, or retractable handle and wheels. What attracted my attention was a small tag with the words “RETURN FOR REWARD,” along with a toll-free phone number, a URL, and a serial number. This tag was supplied by a service called BoomerangIt, one of several internet-based lost-and-found services that provide a new spin on an old concept. If you go to a coffee shop and leave your glasses, keys, or notebook on the table, chances are some honest citizen will turn them in at the counter, and as long as you know where you left the article, you can return later to claim it. Larger stores, stadiums, concert halls, theme parks and so on typically have central lost-and-found departments that serve the same purpose. But again, you must have at least a general idea of where an item was lost, and you can only hope that whoever found it didn’t decide just to keep it. (Lost-and-found departments are not very likely to have your lost camera, laptop computer, or wallet—at least not with the money still in it.) Wouldn’t it be nice if there were a general, all-purpose lost-and-found service that didn’t require you to know where your valuables went missing? And wouldn’t it be nice if there were an incentive for the finder to return your lost item rather than just pocketing it? These are precisely the ideas behind several online services. The Carrot and the Sticker In general, the programs require you to purchase tags, stickers, or labels of some kind and affix them to the things you want to keep track of. The person who finds your missing item can either call a toll-free number or visit a Web site and enter the ID number on the label. The finder is then informed of the amount of reward you’re offering—which can be any amount you choose. At this point, the details diverge depending on which service you’re using. Some services simply send you a message from the finder—allowing you to make your own arrangements for getting the item back. In other cases, the service arranges for anonymous return of the item (at your expense) and delivery of the reward to the finder. Unfortunately, even the promise of a reward may not result in the return of items that have been stolen rather than simply misplaced. However, if stolen goods are later recovered by the police, the ID tags provide a way for them to get in touch with the rightful owner and arrange for return of the goods. When police confiscate stolen property and can’t determine who owns it, it is often sold at auction. The idea for online lost-and-found services actually came from a very successful program called the National Bike Registry (NBR) that is endorsed by many police departments. Like more general lost-and-found services, NBR provides you with a tamper-resistant ID label for your bike which includes a URL and a toll-free phone number. Since missing bikes are much more likely to have been stolen than lost, though, it is rare for anyone other than law enforcement officials to use the service. Fringe Benefits Though not their main purpose, there is reason to believe ID labels provide a deterrent to theft. Because the labels are tamper-resistant, they cannot be removed cleanly, making resale of stolen goods more difficult. Although these lost-and-found services are still small enough not to have aroused much interest in the insurance industry, the potential certainly exists for reduced premiums for people who use the ID tags, as they decrease the probability that an insurer would have to pay the cost of a missing item. Lost-and-found services offer labels in a wide variety of shapes, sizes, and materials to be used with almost any imaginable product. For example, StuffBak sells skinny labels that can fit unobtrusively on eyeglasses and sunglasses, and wrap-around labels that can be affixed to headphone cables, zippers, and other oddly shaped items. BoomerangIt, meanwhile, offers metal key tags, clip-on luggage tags, and even combination luggage locks. And now that you can buy certain brands of luggage with lost-and-found labels already on them, other products are sure to follow. You may feel a bit self-conscious with a bright yellow label on your cell phone, camera, PDA, wallet, and everything else you carry with you, but along with insurance, the tags are an excellent way of making sure you don’t suffer for forgetting to pick up that umbrella or briefcase when you step off the train or out of the restaurant. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/06/purse.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/06/Lost-and-Found.5e63660211c1.mp3"
	},
	{
		"title": "Straw Bale Houses",
		"text": "Several years ago, the company I worked for had a big Halloween celebration. One of my coworkers decided that a group of us needed to dress up as the Three Little Pigs and the Big Bad Wolf. So she worked for days sewing costumes for all of us, and even brought in plastic pig noses for us to wear. For an authentic touch, she asked that we also decorate our desks with the building materials featured in the story. I got the short straw (so to speak) and ended up making a pathetic mess by scattering straw all around my desk, and the “pig” who used sticks didn’t fare much better. But our colleague with the brick “house” simply printed out a huge brick pattern on a large-format color printer and wrapped it around his desk. In life as in the story, his design was clearly the best. It is difficult to set aside the bias that straw is an inappropriate building material, even knowing that wolves lack the lung capacity to blow down a straw house. And yet people have been building sturdy, comfortable houses out of straw bales for more than a century. This building technique has been, shall we say, a bit slow to catch on—and is not without its limitations. But using straw as a building material turns out to have some interesting merits. If You Can’t Eat ‘Em… Straw is what’s left over when grains like wheat, barley, or rice are harvested—basically the hollow stalks. Unlike hay, which can be used to feed animals, straw is a nearly useless agricultural byproduct. Millions of tons of straw must be burned or otherwise disposed of each year. Inconveniently, it doesn’t even decompose rapidly. Automated baling machines, invented in the 1890s, compact straw into tightly compressed blocks, so that they will at least occupy as little space as possible. Faced with a surplus of straw bales, a lack of trees, and a cold winter approaching, some settler long ago decided to stack up the bales and use them as the walls of a house. This worked surprisingly well, and after years of refinement, straw bale construction is beginning to gain respect as a mainstream technique. Walls made of straw bales are held together and reinforced with rebar (or sometimes, wooden or bamboo stakes). In some designs, walls made entirely of straw bales support a roof; in others, a conventional wooden frame is used as the load-bearing structure while the straw bales form the exterior shell. Straw will rot if exposed to moisture, so to keep it dry, both interior and exterior surfaces are sealed with plaster, stucco, or adobe. The net effect is that walls of a finished straw bale building look just like any other wall, only a bit thicker. The Last Straw One of the strongest arguments for using straw as a building material is that it saves lumber. Even if wood is readily available, straw is invariably much cheaper. It’s a rapidly renewable resource, and one that usually goes to waste. A wall made of straw bales also has dramatically higher insulating properties than a standard wooden wall, making buildings that use them very energy-efficient. Straw bale houses are also easier to build than wooden frames, even by people with little experience. Studies performed by various universities and government organizations have shown that a properly constructed straw bale house, sealed well with plaster, is actually less susceptible to damage by fire than a wooden building. Although you wouldn’t build a high-rise condo out of straw bales, a carefully designed one-story building is also quite safe in an earthquake. Owners must be careful to keep all cracks sealed, though, because once infiltrated by moisture, bugs, or rodents, a straw bale wall will rapidly lose its integrity. Last but not least, straw bale buildings are extremely resistant to damage by wind. So much for the Big Bad Wolf. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/06/straw-bale-home-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/06/Straw.fbd87882a3bb.mp3"
	},
	{
		"title": "Geodesic Domes",
		"text": "Unless you’ve been living in a cave for the past half century, you have probably encountered a geodesic dome at one time or another. They can be found on playgrounds, at amusement parks, and in museums; and any number of homes and public buildings are constructed using some variation of this structure. Depending on your tastes and disposition, you may think geodesic domes look cool, endearingly retro, or woefully unfashionable. But you may not know the story (and the logic) behind this sometimes-controversial design. Bucky-ing Trends R. Buckminster Fuller was one of the most prolific thinkers and inventors of the 20th century. He wrote numerous books, received dozens of patents, and worked tirelessly for decades to solve some of the world’s most vexing problems using the tools of engineering and common sense. For all his innovations, Fuller was a very practical man, and like most engineers he saw a great beauty in elegantly logical solutions—even if they defied tradition, aesthetics, or conventional wisdom. So when a housing crisis arose in the years following World War II, he set out to find the simplest and most effective solution, no matter how unusual it may be. Fuller loved geometry, and he was particularly impressed by the triangle, the most stable geometrical shape. Many of his building designs involve triangles, because they provide the greatest structural integrity. He also knew that the sphere was the most efficient three-dimensional shape, enclosing the largest possible volume with the smallest surface area—meaning a dome (a partial sphere) should be a logical shape for a building. But dome-shaped buildings are notoriously awkward to construct. Fuller’s innovation was a way to create a sphere (or partial sphere) out of triangles, providing the best of both worlds. He called this shape a geodesic dome, because the pattern of triangles forms an interlocking web of geodesics. A geodesic is the shortest path between two points. This is, of course, a line in two-dimensional geometry, but on the surface of a sphere, the shortest distance between two points is an arc defined by a great circle—a circle with the same diameter as the sphere (like the equator). The Miracle Building If all that geometry is too much to wrap your brain around, consider the main advantage Fuller cited in his 1954 patent application for the geodesic dome: this shape, because it is self-reinforcing, requires far less building material than any other design. Conventional buildings, according to Fuller, weigh about 50 pounds (22.7kg) for each square foot (0.09 sq meter) of floor space. A geodesic dome can weigh less than 1 pound (0.5kg) for each square foot of floor space. (One of Fuller’s original geodesic domes was a metal framework lined with a sheet of heavy, flexible plastic.) The upshot of this is that you can create buildings very inexpensively, and with a minimum of equipment and labor. Geodesic domes are also stronger than conventional buildings, highly resistant to earthquakes and wind, and more energy-efficient too. What’s not to like? Well, that’s a circular question. The main problem with a dome-shaped building is that although it encloses a large volume of space, a lot of that space is not easily usable by humans. The slope of the walls means the floor space is effectively limited (more so, the taller you are), and most furniture, having been designed for flat walls and corners, doesn’t fit well. There’s also the fact that you need a fairly large lot for a dome of any reasonable height; in urban areas, such real estate may be hard to come by. And banks are generally hesitant to provide home loans for dome builders; they’re seen as a risky investment, because there’s no way to gauge their resale value. All these issues in no way diminish my enthusiasm for Fuller’s design, because, as he did, I feel that logic and elegance count for a lot. Plus—let’s not beat around the sphere—I think geodesic domes look very impressive, and I imagine it would be interesting to live in a space without right angles. If fortune ever smiles upon me broadly enough that I can afford to build my own home, you can be certain a dome will find its way into the design somewhere. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/06/geodesic-domes.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/06/Geodesic.8094b1904b3d.mp3"
	},
	{
		"title": "Ice Hotels",
		"text": "When I first heard about an “ice hotel,” I thought it must be a joke. I’ve heard of igloos, of course, but that’s not really the image that comes to mind when I think hotel. Sure, there was the Bad Guy’s ice lair in the James Bond film “Die Another Day,” but that’s just fantasy, right? The thought that someone might really construct an entire hotel out of ice, rent rooms, and then repeat the process each year was almost too wacky to believe. Believe it—not only does it happen, it has now become the trendiest way to spend a winter vacation. They’ve Got It Down Cold The first ice hotel was built in 1989 in a village called Jukkasjärvi in northern Lapland, Sweden. That first year it was a modest, 60-square-meter igloo; this year, the structure measures over 4,000 square meters and has 85 rooms. Construction begins each year in October, and the hotel is open for guests from December through April (weather permitting). By summer the hotel has melted, but plans are already underway for next year’s bigger, better ice structure. Ice hotels are built, naturally, entirely out of frozen water in the form of ice blocks and hard-packed snow. In some cases, blocks of ice are sawed from a river; for other parts of the building snow is compressed into wooden forms to create building blocks. The guest rooms contain beds made of a block of ice and topped with a foam mattress. You sleep in high-tech mummy-style sleeping bags covered with animal pelts; although the air temperature in the room is below freezing, your body remains toasty warm. If nature calls in the middle of the night, you can head to an adjoining heated building with conventional facilities. Outhouses would not be much fun, as the exterior temperature frequently reaches –40°. Put It on Ice But a classy hotel is much more than a place to sleep, and at the prices of these rooms, you’d better get much more than a sleeping bag. Although the design changes from year to year, Sweden’s Icehotel invariably includes an ice bar for vodka-based drinks (beer would freeze); even the glasses and plates are made of ice. There’s also an ice chapel for “white” weddings, an ice cinema, an ice sauna (I have yet to figure that one out), ice art galleries, and even—I am not making this up—a replica of Shakespeare’s Globe Theatre built of ice. Most guests stay only one night in an ice room; ordinary heated hotel rooms are available nearby for longer stays. Even so, the hotel has a waiting list several years long. Sweden’s Icehotel was the first, but imitators are appearing all across the Arctic Circle. In Kangerlussuaq, Greenland you can find the more modest Hotel Igloo Village, with six adjoining igloos (four of which serve as guest rooms). If you want the igloo experience in Greenland during the summer, you can also stay at the Hotel Arctic in the town of Ilulissat, where guests enjoy all the comforts of home in melt-proof aluminum igloos. For the past five years, Québec has had its own Ice Hotel, modeled on the original Swedish Icehotel and rivaling it in size and luxury. In 2004, the United States saw its first ice hotel—the Aurora Ice Hotel at the Chena Hot Springs Resort in Fairbanks, Alaska. During its construction, state officials cited the hotel’s owner for fire code violations and did not permit the building to open until smoke detectors and fire extinguishers had been installed in each room. (I’m not kidding. Only in America.) Although the initial structure melted in the spring of 2004, it was rebuilt for the 2005 season, this time inside a larger, refrigerated structure—with the goal of keeping it frozen and habitable year-round. As far as I know, I’m not personally acquainted with anyone who has stayed at an ice hotel. I rather suspect—marketing hype and high prices notwithstanding—that it would be a decidedly uncomfortable experience. But then, many uncomfortable experiences are worth having, and it’s not every night you get to drink vodka out of an ice glass while watching the Northern Lights, and then sleep on a slab of ice. Sign me up! ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/06/ice-hotel.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/06/Ice_Hotels.a2aa1edeff18.mp3"
	},
	{
		"title": "Urban Monorail Systems",
		"text": "I`ve never reg retted the decision I made a few years ago to live without a car. After all, if I walk down the hill a few blocks from my home, I can catch a subway, streetcar, or bus to take me nearly a nywhere in San Francisco I may want to go. But every now and then, that “nearly” part causes me grief.[:] There are certain spots in the city I can reach via public transit only by taking a subway, a streetcar, and two buses—and then walking for 20 minutes. The prosp ect of all that waiting and transferring, especially on weekends or when buses are running late, tempts me to take a taxi (which gets quite expensive) or rent a car (forcing me to worry about parking and traffic).[:] Even in a compact city such as this one, getting from place to place quickly, inexpensively, and safely can be difficult. Owning a car can help in some ways, but for many of us, it would be more trouble and expense t han it's worth. It's a Bird, It's a Train, It's a…Taxi? Several articles here on Interesting Thing of the Day have mentioned wa ys of addressing the urban transportation problem: car sharing programs, carfree cities (including Arcosanti), and personal flying machines, for example. A while back, a reader suggested I check out an innovative urban transportation system called SkyTran. Later, another reader wrote to tell me about a different urban m ass-transit solution called the RUF (Rapid Urban Flexible) system. /span> Although the two differ significantly, they are both monorail transit systems designed for cit ies. As I began reading about these, I discovered that they are just two amon g many similar proposed designs. Clear ly, this was a meme worth investigating. The beauty of elevated monorail-based systems is the relative ease with which the y can be retrofitted into an existing urban environment.[:] Unlike subways, they require an absolute minimum of disruptive street closures (and no digging). Unlike street cars, monorails don't have to compete with cars and pedestrians for space on th e roads. And unlike conventional elevated light-rail train tracks, monorails can be constructed quickly and inexpensively. :] Seattle already has a (very short) monorail line, as do some other cities. But some proposals currently being advanced call for much more elaborate and pervasive systems—with some interesting innovations that could make them much more efficient than buses or trains. These systems are known generically as Personal Rapid Transit (PRT). Unlike conventio nal mass transit, PRT replaces large vehicles with small cars that hold only two to six people—and therefore use very small and inexpensive tracks as well.[:]\nPacket-Switching Meets Mass Transit The SkyTran is one such PRT system. span> Its designer proposes to install a network of tracks that can take riders within a few blocks of any location in a city, using a flexible point-to-point scheme rather than a fixed route.[:] The cars can travel much more rapidly than a train or bus, and a sophisticated computer system prevents collisions and congestion.[:] In theory, there would always be at least one car available at each stop; after you board, the car zips from the station's bypass track onto the main track, where it picks up speed and takes you directly, without stopping, to your destination. This seems to combine all the advantages of a taxi with the advantages of a subway—and then some. Similar designs include the SkyWay Express, the ATN (Automated Transportation Network), and the ULTra (Urban Light Transport) system, which is being developed in the U.K. If you want to avoid any walking—or be able to travel outside the immediate area served by the transit system—you might prefer another variant of PRT. The RUF (Rapid Urban Flexible) system being developed in Denmark is an example of a hybrid that uses specially modified electric cars that can operate automatically when riding on the tracks or man ually on the road. Use your car around town as usual, but when you want to travel farther or faster, drive into a station where your car is guided onto a special monorail track. From there, allow the computer to drive you to your destination stop, where you drive off the track and resume manual control. RUF requires much less track than SkyTran and provides passengers with greater independence; on the other hand, the cars themselves are much more complex and expensive. Proponents of PRT systems invariably point out that the cost of installing a citywide monorail system of this sort would be comparable to the cost of installing a traditional light-rail line; the additional efficiency should make it so cost-effective that it's a no-brainer. Municipal governments are understandably hesitant to sink tens or hundreds of millions of dollars into unproven technology—but this is a chicken-and-egg problem; until one of these designs is actually put into large-scale use somewhere, there's no telling how well it will live up to its promises. There's another source of hesitation too: however flawlessly such a system may work, the question remains whether the teeming masses will like it and trust it enough to give up their cars. But as more urban dwellers go carless anyway (out of choice or necessity), PRT systems look increasingly appealing. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/05/monorail.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/05/Monorail.639080325fe8.mp3"
	},
	{
		"title": "Carbon Sequestration",
		"text": "As everyone knows, a lot of scientists are extremely concerned about global warming. Evidence suggests that the high levels of so-called greenhouse gases produced over the past half-century or so will result in higher temperatures worldwide over the coming decades. The additional heat could melt polar ice and raise the level of the ocean, causing flooding and eroding coastlines; it could also lead to more severe climate change with potentially devastating effects. Other scientists say that worries about global warming are overblown—that the temperature will not rise significantly (at least, not due to human activity), and that in any case, the results of a slightly increased average temperature would be mild rather than disastrous. But no one disputes that the air has become quite polluted—you can verify this easily by looking out your window. One major component of air pollution is carbon dioxide (CO2), which is produced as a waste product when fossil fuels are burned. The level of carbon dioxide in the atmosphere has risen markedly since the beginning of the industrial age, and even if that change is not completely attributable to human progress, it’s not a good thing. Whether or not human-generated CO2 contributes to global warming, it clearly causes other problems. Convincing the people and governments of the world to reduce the use of fossil fuels is essentially a lost cause, so the latest trendy approach to dealing with all that excess CO2 is capturing it as soon as it’s created and then disposing of it somewhere. Equipment installed at power plants and other major industries can separate the carbon dioxide from other waste products and liquefy it for temporary storage; finding a long-term home for massive amounts of the gas is the real problem. The process of storing carbon dioxide permanently in such a way that it cannot escape back into the atmosphere is known as carbon sequestration (or, sometimes, carbon dioxide sequestration). Broadly speaking, there are two places one might put large quantities of unwanted carbon dioxide—in the oceans or underground. Techniques for getting the CO2 to its putative final resting place (and keeping it there) are in varying stages of experimental development. Ocean Storage The world’s oceans already absorb unfathomable amounts of CO2; some researchers believe they could hold a great deal more with a little help. The upper part of the ocean typically has a fairly high concentration of CO2 (absorbed directly from the atmosphere), but at greater depths, the concentration is much lower. So one way to dispose of CO2 is to inject it into deep ocean water. At depths over 3,000 meters or so, liquid or solid CO2 is denser than the surrounding water, meaning that it could sink all the way to the ocean floor. Closer to the surface, it will dissolve into the water. Dissolved CO2 makes the water acidic, with unknown (but likely detrimental) effects on marine life. Liquid CO2 on the ocean floor may react with minerals there and form solid precipitates—or it may simply kill off organisms already living there. Geological Storage Merely burying CO2 is not good enough; in order for it to stay put, it has to be stored very deep in the ground, and somewhere that the gas cannot escape into the atmosphere. Some possibilities include: * Saline Aquifers: An aquifer is a porous layer of rock that holds a large quantity of water—often saltwater. Inject CO2 deeply enough into an aquifer, and the surrounding pressure keeps it in liquid form. Meanwhile, an impermeable layer of solid rock above prevents the gas from being released back into the atmosphere. Although aquifer storage is expensive, it is likely to have less impact on the environment than ocean storage—and the CO2 can remain safely underground, theoretically, forever. * Oil and Gas Reservoirs: If you can put carbon dioxide into an aquifer, you can also put it into a depleted gas or oil well. In fact, the technology to deliver CO2 into such wells has been in use for decades; pump CO2 into an oil well, for instance, and you can push out extra oil that would otherwise be unreachable. As long as the CO2 is stored deep enough, it will remain as a liquid. * Coal Seams: Most of the world’s coal deposits are located too deep in the ground for mining to be practical. When CO2 is injected into coal seams, the coal absorbs the gas. Meanwhile, in a manner similar to enhanced oil recovery, the process also pushes out methane gas, which can be used as a fuel. And then, of course, there’s a natural CO2 storage apparatus: forests. Trees are incredibly effective at absorbing carbon dioxide and creating oxygen, so planting (or replanting) millions of acres of forest could go a long way toward solving the CO2 problem—no drilling or high-tech research required. This is not technically sequestration, as you wouldn’t manually inject previously collected carbon dioxide into a tree—but it does have essentially the same net effect. Politicians hope carbon sequestration—of one kind or another—turns out to be a magic bullet that can appease consumers, energy companies, and environmentalists alike. Although all the potential terrestrial CO2 storage spots show some promise, the safety, capacity, and long-term effectiveness of carbon sequestration is ultimately unknown. At best, it will address only a small portion of the world’s pollution problem; at worst, we may find that something we thought we buried comes back to haunt us. On the other hand, we certainly take a lot of carbon out of the ground. Putting some back in just may balance the scales a bit. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/05/Eight_Allotropes_of_Carbon.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/05/Sequestration.f18c744d3f8e.mp3"
	},
	{
		"title": "3-D Printers",
		"text": "I remember the days when a laser printer was a fabulously expensive luxury item that only large businesses could afford; now anyone can buy one for a few hundred dollars. I also remember when a photo-quality color printer was far beyond the reach of the average consumer; now they’re so inexpensive that they’re often bundled with new computers at no extra cost. What’s the next generation in printing? If you have enough money—let’s say, US$25,000 and up—you can purchase a 3-D printer that will sit on your desktop and create solid plastic models of just about any shape you can throw at it. For a few thousand dollars more, you can even make full-color 3-D objects. Perhaps in a few years, these printers, too, will drop into a more interesting price range. But even now, for a certain type of user, they represent an extraordinarily quick and cost-effective alternative to older methods of generating accurate, tangible copies of three-dimensional objects. Modeling Mice When I was working for Kensington Technology Group, a major computer peripherals manufacturer, my job was to manage software development. But I shared an office with several people whose job was to design the hardware for new products—specifically, keyboards, mice, and trackballs. Because we needed to create products whose hardware and software features were tightly integrated, we worked as a team. I got to participate in the hardware development process, and my coworkers were also involved in shaping the features of our software. The process of designing a new mouse, say, is a lot more complicated than one might imagine. Over a period of months, we’d hold brainstorming sessions and focus groups, conduct surveys, hire artists to create concept drawings, and finally—many meetings later—decide on approximately what the mouse would look like and what its features would be. Next, we had to get the shape just right. Usually we’d start by having a model shop create rough carvings out of a firm foam material. We’d all hold the models and choose which shape came closest to what we were looking for. Then we’d go back to the model shop and ask for modifications; sometimes, the next step would be to carve a near-final version of the shape out of wood and paint it so that it looked much like the final product. Such models were essential for ascertaining usability, designing boxes, and helping the company’s executives to understand exactly what they were investing so much money in. Once we had the overall shape worked out, it was time to do heavy-duty 3-D modeling on a computer. Not just the overall form, but every individual plastic or metal part—all the buttons, wheels, battery doors, and so on—had to be painstakingly designed. But before we could feel confident about having expensive molds made to produce the final product, we had to be able to see, feel, and work with a plastic representation of the device—to make sure everything fit together properly (including the electronics inside) and was easy to assemble. When we got to this stage, someone would say, “I’ll send the files out to have an SLA model made.” And a few days later, a box arrived with all the plastic pieces that had appeared on the computer screen, ready to be assembled. The SLA models were made of a translucent plastic, with a somewhat odd texture—curves and angles generally had a subtle “stair step” effect. When people asked, as they frequently did, what “SLA” meant, a designer invariably replied, matter-of-factly, “stereolithography apparatus,” as though that explained everything and further probing would be inappropriate. When I left the company years later, I still had no idea how that process actually worked. Laying It On Thin Recently I attended a technology exposition where I saw a 3-D printer being demonstrated. Designed to produce rapid prototypes similar to those I’d seen at Kensington, it was truly fascinating to watch. Seeing this machine made me wonder once again about stereolithography and other automated methods of creating three-dimensional physical models from computer-based designs. A brief investigation turned up dozens of different 3-D printing techniques. Although they differ tremendously in the details of the technology they use, they all employ certain general principles, and are evolving rapidly to become smaller, faster, more versatile, and less expensive. A sculpture begins with a solid block of material from which bits are carved or chiseled away to reveal a 3-D shape. And to be sure, there are any number of clever devices that can create carvings using lasers or robotic grinding tools. But the problem with such an approach is that you can only affect the outside surface of an object; hollow or deeply concave areas, or oddly shaped interior cavities are difficult or impossible to achieve. So instead, 3-D printers build up an object in layers. Special software splits a 3-D computer model of an object into a succession of very thin layers. The printer then deposits a layer of material that represents a cross-section of the very lowest (or highest) point on the object, and keeps building on that with additional layers until it reaches the other end. Stereolithography is one of the oldest and best-known rapid-prototyping (RP) methods for small objects. You start with a platform suspended just below the surface of a vat of a special liquid polymer that hardens (or “cures”) when exposed to ultraviolet light. Using an ultraviolet laser, the machine “draws” the first layer of the object on the polymer-covered platform. When it hardens, the platform moves down slightly, allowing a fresh layer of the substance to ooze over it. Then the machine draws the second layer, which not only hardens but fuses to the first. The process repeats until, many hours later, the entire object is finished. Drain off the excess goo, and you have yourself a model. Beyond Stereolithography As cool as stereolithography is, it’s not appropriate for some kinds of objects. For one thing, you’re limited by the properties of the hardened polymer (strength, flexibility, and so on). For another, overhanging structures are a problem, because if the laser draws a pattern onto an area of the polymer without a solid surface beneath it, the resulting patch, when hardened, will either float away or sink. But other 3-D printing techniques can solve both of these problems and more. Selective Laser Sintering (SLS) replaces the liquid polymer of SLA with a powder. When the layer heats the powder in a certain spot, it melts, fuses to the layer beneath, and hardens as it cools. As with stereolithography, the platform on which the model is sitting drops slightly after each pass, and a new layer of powder is spread on top. But because every layer is supported by the unused powder beneath, overhanging or even completely independent structures can be created. There’s also a relatively new printer type that “prints” onto powder (as SLS does) but replaces the laser with a moving print head containing a number of nozzles just like those in an inkjet printer. Instead of using ink, the nozzles squirt out tiny amounts of a binding agent that causes the powder to harden almost instantly. Furthermore, different types of powder and binding agents can produce products with a variety of characteristics—and by adding dyes to the binding agents, these machines can even produce solid objects in full color. Yet another variation on this theme is called Multi-Jet Modeling; it uses an apparatus similar to an inkjet head that deposits layers of a special polymer with a very low melting point; it hardens as soon as it leaves the nozzle. There are also nozzle-based systems that deposit liquid polymer that is then cured, layer by layer, using an ultraviolet light. These are just a few of the current 3-D printing techniques, with new variations appearing all the time. Some 3-D printers are restricted to creating plastic objects, but these basic principles have also been adapted to many other materials, including ceramics, wax…even stainless steel, titanium, and other metals. The U.S. Department of Defense is funding development of a metal inkjet process that could be used to create replacement parts for submarines. Some high-resolution 3-D printers are being used to test jewelry designs, while others are being designed to create dense, multi-layer electronic circuits on an extremely small scale. But if manufacturers are smart, they’ll begin thinking not just about industrial and military customers, but about consumers. Imagine receiving a birthday present as a file enclosed in an email message. Send it to your desktop 3-D multi-printer, and out comes a framed photograph…or a statuette of your parents. It’s a fantasy today (except, perhaps, for the obscenely wealthy)—but tomorrow, who knows? ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/05/3D-printing-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/05/3-D_Printers.25780006fc73.mp3"
	},
	{
		"title": "Wikis",
		"text": "Have you ever visited a Web page—perhaps even this very one—and thought to yourself, “I would have written that differently”? Maybe you’ve noticed a typo, an inaccurate statement, or important missing information. Maybe you just dislike the style of the writing, or feel that more needs to be said. Wouldn’t it be nice if you could just click a button and make your own changes to the page? On some Web sites you can, thanks to an increasingly popular method of online collaboration called a wiki, which is short for Wiki Wiki Web (another WWW). Double Quick The term wiki is a Hawaiian word meaning “quick”; wiki wiki means “really quick.” (Linguistic side-note: Other languages in the Malayo-Polynesian family also employ reduplication, or doubling, as a means of intensification. In Indonesian, you pluralize a noun by doubling it—anak is “child”; anak-anak is “children.” But reduplication can also apply a meaning of “even more so”—pagi is “morning,” but pagi-pagi is “really early in the morning.” I could tell you were wondering about that.) The first usage of the term wiki to refer to a Web editing mechanism came in 1994, when Ward Cunningham wrote a simple script in the Perl programming language that enabled anyone to edit pages on his site freely. His original Wiki Wiki Web is still going strong, and has sparked innumerable imitators, derivatives, and clones of every description. The exact definition of wiki in its Web sense is a bit nebulous, but fundamentally it refers to any Web site built around tools that allow collaborative modification of the pages. Wiki pages come in many different styles, with the only consistent element being that they focus primarily on text, as opposed to graphics, multimedia, and complex layouts. The content of a wiki—not its style—is of primary importance. So a wiki is a good tool for collecting ideas, brainstorming, building a historical record, organizing a team project, or any other activity that requires input from lots of different people. Sometimes people use wikis as discussion boards, asking questions and posting answers (with or without leaving their names); in other cases there’s no effort to maintain a running conversation, with the goal instead being to continually improve upon some body of text. Editing Made Easy How does a wiki work? The easiest way to understand this is to try one for yourself (see below), but I’ll give you a quick overview. When you visit a wiki site, each page usually has a link at the bottom or on the side that says “Edit Page” (or words to that effect). Click that and you’re presented with a version of the page with its text in an editable field. Make whatever changes you want, click Submit—you’re done. Nothing could be simpler. Each wiki system is slightly different, but in general, a help page or info box somewhere explains how to make text bold or italic, create bulleted lists, add hyperlinks, and so on. You don’t need to know any HTML; you simply use punctuation marks such as asterisks for bullets and exclamation points for italics, and the wiki software converts them to the proper tags behind the scenes. It really is easy enough that anyone can learn to do it in minutes. Given that description, the first question most people have is, “Isn’t that asking for trouble?” If you make Web pages editable by anyone in the world—no passwords, no logging in, no control—won’t people just write junk, vandalize the site, or cause other problems? What’s keeping someone from misusing those tools? These concerns are addressed by a combination of technology and culture. On the technology side, every time someone edits a page, the previous version is saved, so that you (or anyone) can always undo damage by going back to an earlier revision. (Usually, the revision system allows you to see every change a document underwent since it was created.) But it’s the cultural aspect of wikis that I find most interesting. The people who contribute to any given wiki tend to adopt a proprietorial attitude toward it, meaning they monitor it for inappropriate content and quickly revert it to an acceptable version if necessary. Because of this informal policing—not to mention stronger controls an administrator can exert, such as banning certain IP addresses from modifying a file—wiki abuse is relatively infrequent; it’s not worth the time and effort to damage something that can be repaired so easily. Power to the People That said, wikis are by nature anarchic. Some wikis are freely editable only by a select group of people with password privileges (such as a small group of coworkers), but whether or not the group is restricted, there is no formal mechanism to force a wiki page to conform to any particular style, to stay on topic, or to maintain a high signal-to-noise ratio. And yet, amazingly, most wikis evolve to have these characteristics automatically. Again, this is due to the wiki culture—a way of thinking about editing shared documents that seems to arise spontaneously whenever a group of people becomes attached to a wiki. Curiously, the open nature of wikis sometimes backfires in an unexpected way: many people are reluctant to modify a page that isn’t “theirs.” I’ve had this experience myself; while browsing a wiki site I’ll think, “Sure, I could modify this page, but who am I to mess with it?” The answer, of course, is that I’m a person with Web access, exactly the credentials of every other person who has edited that page. As long as I have something useful to add or change, there’s no reason I shouldn’t do so. Thus, some advice to wiki wannabes: if you feel weird about modifying a wiki page, try just rewording a sentence, fixing some punctuation, or doing something similarly innocuous. If other users don’t like what you’ve done, they can undo it easily. But jump in and try it—it can become addictive very quickly. Oh, Wiki, You’re So Fine One of the most surprising things about wikis is that the underlying software is incredibly simple. It can be written in any language; Perl, PHP, Python, Ruby, and Smalltalk are popular choices. While wiki developers can (and sometimes do) write very complex code based on relational databases, there has been an ongoing competition on one wiki site to write the shortest possible wiki program that still has all the necessary features. The current leader is a 4-line, 222-character script. Content management systems don’t get much simpler than that. The largest and best-known wiki project is called Wikipedia. As the name suggests, it’s an online encyclopedia, compiled and written by…everybody! It’s not yet as large as a conventional encyclopedia, but it’s growing quickly. The quality of information is, for the most part, excellent, and it also has the advantage of being copyright-free. I have been finding with increasing frequency that topics I’m researching for this site are covered admirably in the Wikipedia, and it’s becoming one of the first places I look for information. To be sure, not every site is a good candidate for wikification. News, corporate Web sites, product specifications, copyrighted literature, and many other types of Web content demand stricter control than a wiki can provide. But the success of the Wikipedia and a great many other large wiki sites shows that anonymous, collaborative Web editing has tremendous potential. ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/05/Wikis.3e490dc77fb.mp3"
	},
	{
		"title": "Bookcrossing",
		"text": "Every few years or so, I like to look through my books and weed out the ones that have outlived their usefulness to me. Maybe I've read them and enjoyed them, but don't expect to re-read them any time soon. Or maybe they're books I picked up used long ago and simply never got around to reading. After a certain period of time passes—a decade, perhaps—I have to admit that I probably never will read them. So with a great deal of nostalgia and a bit of remorse, I pack up a few boxes and cart them off, sometimes selling them at a used book store, sometimes donating them to a library. This pruning process, which I've repeated countless times, is crucial because there's simply no more room to put bookshelves. No matter how hard I try, I always accumulate books much faster than I can read or even make space for them. I'm always on the lookout for interesting books, and only my budget keeps my habit from becoming truly intractable. Well, it's about time for another round of debookifying (followed, of course, by a small, ritual replenishment at my favorite bookstore), and this time, I'll include the latest couple of books I've written, since I got more free copies from the publisher than I know what to do with. But instead of selling them all for a pittance and then weeping over how much money I've lost, I'm going to “set them free.” That's the lingo used by members of a rapidly growing movement known as bookcrossing, which aims to turn the entire world into a library. Take My Book, Please Bookcrossing is the brainchild of Ron Hornbaker, an entrepreneur and book lover who was running a software company when the idea came to him in 2001. After learning about Web sites that enable people to track the movements of other objects around the world, including banknotes and disposable cameras, Hornbaker imagined using a similar process for books. After less than a month of work, he and his wife turned the idea into a unique Web site called BookCrossing.com. The idea is simple: someone registers a book on this Web site, and in so doing gets a unique ID number that can be jotted down inside the front cover, along with the site's URL. The owner then hands the book to a friend or leaves it in a public place, perhaps with a sticky note that says “I'm Free!” Whoever picks up the book next is encouraged to record the find, along with comments on the book, on the Web site, and then pass it along to another reader. Books that have been left for someone else to find and read are said to be “released into the wild”; someone who picks up a book and writes a journal entry on the Web site is said to have “caught” it. Although bookcrossing got off to a slow start, the movement now has hundreds of thousands of members, and is growing at an astonishing rate—with well over a million and a half books released so far. Some books have already been through dozens of hands and have traveled thousands of miles. Although the United States has the largest number of registered books in the wild, bookcrossing participants have released books in at least 90 different countries worldwide. If You Love It, Set It Free Tracking the progress of a book and other readers' comments is one of the most satisfying parts of the bookcrossing experience. Less than 25% of the books released so far have been caught, but participants don't seem to mind if a book they release vanishes into the ether; they feel they're doing a public service by making the books available without cost to random people. In fact, the sheer randomness of the entire system is what attracts many people to participate. Although a book you've read may disappear, it may also fall into the hands of a celebrity, change someone's life, or have any number of other unexpected effects. The BookCrossing Web site enables you to search for books in a wide variety of ways, read journal entries, and register your own books—all free, and with a tasteful minimum of advertising (for books and other relevant products, of course! ). And yet, it has become such a success that Hornbaker sold off his company's software business to concentrate on bookcrossing full-time. The site earns money primarily by selling labels, stamps, bookplates, and other supplies that make it easier to release books, and more likely that finders will catch them. The whole operation is so refreshingly low-key and straightforward that it easily sucks in anyone who likes books and has even a shred of generosity. Some authors and publishers have expressed concern that if the bookcrossing phenomenon becomes too large, it could damage sales. But so far, just the opposite appears to be true. Participants frequently buy extra copies of their favorite books just to give away, and people who get excited about a book by reading glowing journal entries are much more likely to purchase it themselves than to go looking for it in the wild. All in all, it's a fabulously clever and effective recycling program that never runs out of raw materials. Coming soon to a coffee shop near you: the world's largest library! ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/05/books-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/05/Bookcrossing_.c349ed847895.mp3"
	},
	{
		"title": "Rent-a-Dog",
		"text": "Canine company by the hour On my last trip to Costa Rica, I was walking along the beach in a small town on the Atlantic coast that’s best known as a hot spot for surfing. There were a number of dogs playing on the beach—catching sticks and Frisbees, sniffing the tourists, and generally having a good time. The dogs may have been strays, or they may have belonged to local residents—the people playing with them did not appear to be their owners. But in any case, the dogs were apparently healthy, friendly, and well-cared-for. I’ve always liked dogs, though for a variety of reasons I can’t see myself owning one. Still, that afternoon on the beach, I was thinking that it would be great to have a dog to play with for just a few hours, and that some enterprising person ought to set up a little dog-rental business there to cater to people such as myself who could not bring their own dogs to this remote location. I filed this idea away in the back of my head along with all the other goofy and implausible notions I’ve come up with over the years. And then, last month, I read an article in a local newspaper about a growing trend at luxury hotels and resorts around the world: free (or inexpensive) loaner dogs for the guests. Maybe my idea wasn’t so goofy after all. A few Web searches turned up many businesses that loan or rent dogs for short periods of time—often, though not always, as a way for tourists to have canine companionship away from home. This idea seems to be catching on so rapidly that I thought it merited a bit more research. BYOD Although it seems a bit crude to compare rental dogs with rental cars, the concepts are similar at least in the sense that someone else is responsible for major care and maintenance. I’d never expect to rent a car for a weekend and then be asked to take it in for an oil change or a tune-up; and when borrowing or renting a dog, you don’t worry about grooming, bathing, or veterinary care. But these factors are rarely the major attraction to potential renters. Some people like having a dog with them as a way of breaking the ice when meeting other humans (a role dogs perform nearly as well as babies). In other cases, it’s simply a matter of wanting company, a hiking companion, or a playmate. Either way, the availability of loaner dogs is increasingly becoming a competitive advantage for hotels in areas where guests like to spend a lot of time outdoors. Dog lovers on vacation may be the most visible niche market for rent-a-dog services, but there are numerous other examples. Specially trained guard dogs and hunting dogs are available in some areas for people who are unable to care for such animals year-round but need their special services on occasion. And in some Asian cities, such as Tokyo and Hong Kong, where it’s virtually impossible to find dog-friendly housing, rental services enable people to spend quality time with dogs. Increasingly, animal shelters and pet stores are using dog rental as a way of encouraging adoptions: people borrow pets for a few days, become attached to them, and decide to keep them. Conversely, many people who rent dogs do so in order to make sure the animals will fit into their households and lifestyles before making a permanent commitment. If you’ve lived with a dog for a week and find that it doesn’t get along with your other pets, bothers the neighbors with its barking, or causes a severe allergic reaction, it’s nice to know that you can return the dog with no leash attached, so to speak. Barking Mad Many people, not surprisingly, think rent-a-dog programs are an atrociously bad idea. I’ve frequently read complaints to the effect that a dog is a living being, not an inanimate object like a car or a library book that can be passed from owner to owner without any ethical difficulty. Critics of dog-rental services worry that renters may not be trustworthy, that being handled by many different people can create stress and confusion for the dogs, and that dogs who are frequently rented out may have difficulty bonding with their owners. Some people go so far as to say that if you’re not willing to undertake the responsibility of full-time dog ownership, you have no business becoming a short-term steward either. I certainly agree that dogs should not be loaned or rented out haphazardly; owners have an obligation to ensure that potential borrowers or renters can safely and responsibly care for the dog. But many owners hire dog walkers or dog sitters, or place their dogs in kennels when they’re out of town, so I think there’s a reasonable precedent for giving someone else temporary control of a dog—though, of course, some dogs are more amenable to this sort of lifestyle than others. Arguably, dogs may benefit from increased exercise and socialization with humans, as long as the rental periods are not too long or too frequent. I have not yet found any programs that rent pets other than dogs. As a cat owner, I think cats would tend to be temperamentally ill-suited to such drastic changes. On the other hand, I certainly enjoy visiting bookstores where cats are available to sit on the laps of browsers. So here’s my idea: an internet café where you can rent a computer with a mouse for $10 an hour, or a computer with a cat for $15. I’ll call it the CyberCatfé. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/05/Bulldog-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/05/Rent-a-Dog.babd2f68f074.mp3"
	},
	{
		"title": "Micropayment Systems",
		"text": "In 1994, when the Web was still young, I attended an internet technology conference. A well-known programmer who had written some internet software for the Macintosh was discussing the commercial potential of the internet, and as an illustration, he told the following story (which I’m reconstructing from memory as best I can, as I’ve never been able to find independent confirmation of the details). Back then, there was a relatively new internet payment service called First Virtual, which employed a clever mechanism whereby one person could send money to another over the internet—even in an email message. A man signed up for the service but was skeptical of how well it would work, so he did an experiment. He posted a message on a newsgroup asking for help testing the service. Everyone who sent him US$1 through First Virtual would receive, for an entire year, a new limerick each day by email. Within three months, over 60,000 people had signed up. This was a mixed blessing—the experiment worked, but he encountered major technological problems in sending all those email messages, and soon discontinued the offer. Enter Credit Card Information Here First Virtual went out of business years ago, largely because of the proliferation of banks and services that allow merchants to accept credit cards over the Web. By comparison, First Virtual was awkward and low-tech. And certainly for most purchases one might want to make online, credit cards are a convenient way to do so. But there are a few major difficulties with online credit card purchases. First, they’re fine for paying a merchant, but what if you want to send money to a friend or family member? If the recipient doesn’t have a merchant account, you’re out of luck. Second, lots of people don’t have credit cards, or don’t feel safe using them over the Web. And third, credit cards don’t make sense for very small payments of less than a few dollars or so. The reason for this is that banks charge merchants a fee for every credit card transaction that consists of a fixed amount plus a percentage of the transaction. Because of the way the fees are calculated, a merchant could end up paying only $0.60 for a $10 transaction, but $0.33 for a $1 transaction. That means the $1 purchase is not very profitable, and a purchase of less than $0.33 would actually cause the merchant to lose money. The term “micropayment” was coined to describe these very small purchases. And there are many good reasons you might want to make a purchase of just a few cents. For example, suppose—hypothetically, of course—that a Web site called “Interesting Thing of the Day” wanted to offer a subscription of some sort for just $1 per year (rather than, say, $10). Using credit cards, this would be a losing proposition. And yet, charging higher prices to offset the merchant fees makes the content less attractive to buyers. Other common examples of micropayments are music downloads, news stories, and Web-based services such as translations and image processing—to say nothing of real-world purchases such as feeding parking meters or buying a cup of coffee. A Small Problem In the past several years, numerous systems have been proposed to solve the micropayment problem. They vary tremendously in their details and implementations, some being more promising than others. Unlike credit card transactions, which anyone with a card can make instantly, almost every micropayment system requires users to take some preliminary steps to set up an account or enter billing information. In some cases these steps add just a few minutes to the initial transaction; in others, setting up an account can take a week or more. Of course, no one expects to be able to drop a coin into their computer and have it drop out of someone else’s; a bit of effort is reasonable. But the convenience of a system, coupled with its fee structure, are the main factors in determining a system’s success. I could not hope to do justice to the wide variety of micropayment systems here, but I’d like to describe a representative sampling. One key concept in micropayment processing is aggregation, which simply means grouping several smaller purchases together and billing the buyer once (perhaps monthly) for the total amount. This takes the edge off the transaction fees for merchants, and it gives consumers the ability to make very small individual purchases—such as those 99¢ tracks at Apple’s iTunes Music Store. Of course, you still need a credit card, and bank transaction fees still frustrate merchants, especially when an individual customer makes very few purchases. If a business doesn’t do enough volume to aggregate its own sales, it can make use of a third-party credit card aggregator, which then also takes a cut of each payment. Another approach to aggregation, used by payment processor BitPass among others, is to sell prepaid cards that can be used to make small purchases at participating vendors. In this case, the aggregation happens up front, requiring less effort for the vendor and the payment processor, but more for the customer. Good as Gold A very different approach is taken by several companies that use gold (or other precious metals) as the basis of electronic transactions. Under this system, a company maintains a stash of gold securely in a bank vault somewhere. As a subscriber to the service, you can buy some of this gold, which (for a very tiny fee) the company will store for you. In other words, the gold itself doesn’t move—only the ownership of a portion of it changes. You can purchase gold using cash, checks, credit cards, or whatever form of payment you want. Then at any time, you can log into your account and transfer any portion of your gold to another subscriber. (This can be designated according to value, like $0.02, or mass, like 0.02g.) Because it costs virtually nothing for the company to transfer ownership of gold from one account to another, transaction fees are negligible. And as the owner of any amount of gold, you can request payment from your account at any time, in the currency of your choice. Gold-based electronic transactions have a number of advantages over aggregation. For one thing, they cost less for the recipient. For another, they can be used to transfer money between individuals, even if neither one is a merchant. And they do not require either party to have a credit card. Gold is even more appealing for international transactions. Most banks charge hefty fees to transfer money from one country to another—US$10 or $20 is not uncommon—making it unreasonable to use a check or credit card for small international payments. But transferring gold ownership internationally involves no currency conversion, so it’s no more expensive than making a domestic transfer. There is a catch, however: you can only transfer gold to someone after you’ve purchased it yourself. So unless you’re willing to maintain a balance of gold in your account, each transaction ends up being a two-step process: first put gold into your account, then transfer it to the other person. And, of course, you can only pay for a purchase with electronic gold if the merchant is set up to accept gold payments. Saved by Mathematics? A relatively new idea for micropayments, called Peppercoin, promises to solve many of the problems of aggregation while maintaining credit cards as the means of payment (and thus avoiding any need for account setup on the customer’s part). Under Peppercoin’s patented system, which they call “Intelligent Aggregation,” customers are charged for each transaction, but merchants don’t get paid for each one individually. Instead, a complex mathematical algorithm uses statistics to randomize payments, resulting in a far smaller number of total transactions (and resulting fees). For example, if I as a merchant sold 100 items at $0.10 each, I may receive 100 tokens—each with a value of $10.00, but only a 1 in 100 chance of being “live.” So, on average, I’m still getting paid for the value of goods I delivered, but instead of having to deal with massive numbers of tiny transactions, I only deal with a few. The math on which Peppercoin’s system is based seems to be valid, but it makes the most sense when very large numbers of transactions are involved; if you only expect to sell a few items per month, the logic sort of breaks down. Unfortunately, for small person-to-person transactions, there’s still no magic bullet. Services like PayPal and Western Union do enable an individual to send money to someone else electronically, but the transaction fees still make it impractical for amounts less than $1. Although many attempts have been made, no one has yet devised an electronic equivalent to putting cash in an envelope. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/05/Penny.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/05/Micropayment.f5f141ac0f34.mp3"
	},
	{
		"title": "Donate-a-Click Programs",
		"text": "When I began using the internet back in the early 1990s, it was still the province of universities, governments, and large corporations. It was actually quite difficult to find a commercial internet provider, and when you did manage to get access, the experience was one of obscure command-line programs. The World Wide Web hadn’t been invented yet; the internet was a world of text, not of graphics, animation, and sound. And companies that contemplated advertising on the internet worried that they’d get in trouble because commercial use of the network was contrary to the government rules in existence at the time. (Ah, the good old days…) The commercialization of the internet over the past decade or so has been one of the most important and far-reaching cultural developments in modern history. Of course, all the wonders and convenience of the internet have been tempered by the modern demons that invade our computer screens constantly: spam, pop-up ads, and Web sites with so many annoying, flashing graphics that you can’t see the content for the advertising. Ad It Up The most time-tested form of internet advertising is the banner ad—a graphic, usually rectangular and at the top of a Web page, that encourages you to click it for more information on whatever product or service it’s advertising. Advertisers pay to have their ads placed on other sites; sometimes they pay by the “impression” (the number of times the ad was displayed to a visitor), and sometimes they pay by the click (the number of times a visitor actually followed the link back to the advertiser’s site). But studies have shown that only a small percentage of people even look at most ads, and of those that do, only a very few bother to click on them. As the novelty of banner ads has worn off, their usefulness to advertisers has decreased, and their value as a revenue source for sponsored sites has diminished in turn. And yet, strangely enough, banner ads continue to proliferate at an amazing rate. The public has come to realize that they’re like weeds—an annoyance we can never truly conquer and must learn to live with. However, a number of organizations have put banner advertising to a very worthwhile use. In a nutshell, by clicking on one of these special ads you can make a donation to a charity—without actually spending any money. The click itself is magically transmogrified into cash. This “donate-a-click” mechanism sounds wacky, but in fact it’s legitimate and quite clever. Here’s how it works. Every time you click one of the special “donate” links, you’re taken to a page that shows a sponsor’s ad. The sponsor pays the charity a fixed amount of money for each person who looks at the ad; the charity, meanwhile, employs a sophisticated checking mechanism to prevent abuse, by restricting any individual’s “contribution” to one click per day. Takes a Clicking and Keeps on Giving In other words, donate-a-click programs are not much different from conventional pay-per-click banner ads, except that the money paid by the advertisers goes mostly to charity, and anyone can influence how much money the charity gets simply by clicking the ad once a day and agreeing to look at another ad. The charity gets paid even if the person who clicked the link doesn’t buy anything from the sponsor, but advertisers figure a certain percentage will; and even if they don’t make much money, they’re generating goodwill by showing off their social or environmental consciousness. The amount of money an advertiser pays the charity per click varies from just a few cents to US$1 or more. Depending on the cause in question, the charity may frame the clicks as representing something more tangible—so many children fed, square feet of rain forest saved, or trees planted, for example. Donate-a-click programs make sense because everyone involved can benefit. Web surfers who volunteer a few seconds of their time to click the link can feel they’ve done something useful to help a charity without actually having to spend any money. Advertisers get exposure for their products or services, generate respect by supporting a cause, and—not insignificantly—receive a handy tax write-off for their charitable contributions. And the charities get support for their good work, whether curing disease, protecting the environment, or stopping hunger. ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/05/Donate-a-Click.4b8d05499206.mp3"
	},
	{
		"title": "Carfree Cities",
		"text": "I’m sure that without too much effort, I could write a book of stories about all the misadventures I’ve had with cars in my lifetime. Cars that have broken down at inconvenient times and places. That used-car salesman who swindled me. Mechanics who couldn’t diagnose a simple problem after weeks of trying and many hundreds of dollars spent. Accidents. Wrong turns. Break-ins. Traffic jams. Leaky roofs. Road rage. Running out of gas. Parking tickets. Getting towed. Car payments and insurance so high I could barely pay my rent. The time, a few years ago, when I got hit by a car while walking across a city street—because a driver was playing with his cell phone instead of watching the traffic light. Or the time, when I was living in Texas, that I urgently needed to conduct a transaction at the bank after the main lobby had closed. The drive-through teller window was open late, but I didn’t have a car at the time. I walked up to the window and the teller yelled at me, insisting that it would be an egregious violation of bank policy to serve a pedestrian. I think just about everyone who has driven a car for more than a couple of years has plenty of stories like these—stories about cars that get our blood boiling. Stories that almost make us say, “Forget it, I’m getting rid of my car.” Almost. But despite the fact that the costs of cars, gasoline, insurance, and maintenance are on the rise, despite decreasing gas mileage and increased pollution, despite every frustration they’ve ever caused, the vast majority of us would no sooner part with our cars than quit our jobs. We hate them and yet we love them, because we need them. Losing My Drive And yet…some of us don’t. I, for one, reached the breaking point about three years ago, sold my car, and never looked back. (But, of course, I also live in a compact city where public transit is good; I work from home; and I belong to a cooperative that lets me rent a car at a moment’s notice for short trips. Needless to say, this sort of lifestyle wouldn’t work for everyone.) Then there are people who live in cities that are mostly or entirely car-free. Venice is usually the first example mentioned—a place where there is simply nowhere to put roads. Although such cities are few and far between, wherever historical, architectural, or topographical considerations make it impossible for a city to accommodate cars, the residents always seem to adapt, to find other ways to get where they need to go—or to bring the things they need closer to them. According to J. H. Crawford, author of the book Carfree Cities, a well-planned urban environment that’s carefully engineered to avoid the need for cars has many advantages besides saving its residents money. It’s quieter, cleaner, safer, more conducive to exercise and human interaction, and for a long list of other reasons, a happier and more peaceful place to live. Citing numerous examples of car-free areas, particularly in Europe, Crawford makes a persuasive case that as long as folks can get where they need to go, when they need to get there, the seemingly retro life of a pedestrian is an idyllic possible future for many urban dwellers. In a city designed according to Crawford’s plan, every resident’s basic needs would be available within a five-minute walk, and any point in a city—even one with a million people—would be reachable from any other point by public transit within 35 minutes. Putting the Brakes On As a proud ex-car owner, and as someone who has greatly enjoyed visiting several car-free towns, I think the notion of building an entirely car-free city is splendid. But maybe I’m just a sucker for lost causes. The barriers to accomplishing such a thing are considerable, to say the least. For one thing, an ideal implementation of Crawford’s design would require a new city to be built from scratch; retrofitting an existing city with the necessary infrastructure to avoid the need for cars is a shockingly difficult proposition—not only because of the sheer amount of work required, but because it would be tough to convince existing car owners to part with their vehicles, no matter how convenient life could be made without them. For another thing, residents would have to trust all their transportation needs to the city government or designated private enterprises. What if the bureaucracy running the city’s transportation system becomes corrupt? What if transit workers go on strike? What if a massive power failure, terrorist attack, or civil uprising makes it impossible to get around? These and many other “what ifs” would require some pretty convincing answers if hundreds of thousands of people were to accept the idea as reasonable. On the other hand, it’s not as though Crawford is a lone voice in the urban wilderness. There’s a large and growing international carfree movement, which, in addition to promoting the notion of car-free cities, encourages the use of bicycles and improved public transport, and helps to organize World Carfree Day each September in dozens of cities around the world. Although this celebration does not mean a city outlaws cars for a day, it does encourage people to go without using their cars for one day each year in order to raise awareness of the possibilities of car-free existence. I know from personal experience that with careful planning, even a Californian can lead a blissfully car-free life. All it takes is enough willpower—or enough frustration. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/05/Toyota-Corolla-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/05/Carfree.65d9c11aaef7.mp3"
	},
	{
		"title": "Pedometers",
		"text": "Your mileage may vary Thomas Jefferson was born in 1743 and served as the third president of the United States from 1801 to 1809. He drafted the Declaration of Independence, founded the University of Virginia, and built a famous home called Monticello. These accomplishments are all quite impressive, and every schoolchild in the United States learns them (and then promptly forgets them after their exams). What I did not know until recently, however, was that Thomas Jefferson invented macaroni and cheese. That’s right: I owe yesterday’s dinner (and my favorite dish as a kid) to Mr. Jefferson. Were he alive today, I’d vote for him on that basis alone. But that’s not all Jefferson invented. He is also responsible for the swivel chair (a descendant of which I’m now sitting on), an improved version of the dumbwaiter, the hideaway bed, and even the machine used to make macaroni. For all his innovations, he never applied for a patent, believing that his inventions should benefit all of society and not just the inventor. (He’d fit right into the open-source movement today.) But few people realize Jefferson also invented the pedometer, the little gadget you wear on your belt to tell you how far you walked today. Stepping Into the Future I saw my first pedometer when I was about 10 years old, and I thought it was absolutely magical. How could this little wind-up mechanical box tell how far you walked? A few years ago I got a modern digital pedometer that tells me not only the number of steps, miles, or kilometers I’ve walked but even how many calories I burned. All this from a plastic box that can be had for less than US$10 and doesn’t even require satellite transmissions. Amazing. Pedometers don’t truly measure the distance you walk; they simply count the number of steps you take and do a simple multiplication based on the average length of your stride. For this reason, they’re not exceptionally accurate; if your stride length varies (which is more likely if you’re running or navigating uneven terrain), a pedometer may have a margin of error greater than 10%. Still, the measurements pedometers provide are accurate enough for most people, and those who need to measure distances on foot with greater accuracy can always use a GPS receiver. A Bounce in Your Step I have always understood that there is some sort of swinging or bouncing mechanism in a pedometer that jiggles each time you take a step, thus causing a ratchet to move (in mechanical models) or incrementing a counter (in electronic ones). But I still wondered exactly how the mechanism works, so I decided to take my pedometer apart and just see for myself. Although other designs may vary, my pedometer has a horizontal arm with a hinge on one end and a magnet on the other. The arm is weighted (to give it some inertia) and held in place with a tiny spring that’s just strong enough to keep the arm centered when it’s not in motion. Move the pedometer up or down and the arm bounces the opposite direction. When it does, the magnet swings by a tiny reed switch. The magnet briefly pulls one of the two slender pieces of metal in the switch out of contact with the other, breaking the circuit, and these breaks are what the counter counts. OK, it’s not rocket science, but I feel smarter for having understood that little piece of engineering. I still don’t know how macaroni works. I’ll tell you as soon as I figure out how to take it apart. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/05/Pedometer-2.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/05/Pedometers.3e5b1fc62972.mp3"
	},
	{
		"title": "The Steadicam",
		"text": "Despite my lifelong interests in photography, gadgets, and movies, I have never owned a camcorder. If I had one, I could plug it into my computer, download the video I shoot, make impressive-looking movies, and save them onto DVDs. In the abstract, that sounds like a lot of fun, but whenever I try to think through the purchase and use of a camcorder logically, I always get stuck. What if the model I buy is outdated six months later (a virtual certainty given the rapid pace of development in this area)? Would I become one of those obnoxious tourists who see the places they visit only through a viewfinder, less concerned about experiencing new places than about recording them? And worst of all, would I make my family and friends sit through hours of boring vacation footage? I fear that all these things would be true, that they are somehow maxims of camcorder ownership. And so, against all odds, I remain, for now, camcorderless. Having watched my fair share of video shot by other people, it has become painfully obvious to me that a fancy tool is no substitute for actual skill in videography. Composition, lighting, audio recording, judicious use of camera angles, panning, zooming, and so on all require practice and a certain degree of artistic sensibility; these do not come in the box with your camcorder. And although virtually every modern camcorder has a built-in device to compensate for the jitter caused by small hand movements, long handheld shots—especially those taken while walking, as is natural for camcorder users—typically include a fair amount of bounce and sway, making them look amateurish regardless of any other merits the recording may have. You almost never see such bumpy images on TV or in movies, unless a shot was made that way intentionally to achieve a certain effect. Professional videographers and cinematographers supplement their skill with a great piece of technology called a steadicam to smooth out the trickiest of handheld shots. Steady as You Go You can think of the steadicam as an extremely sophisticated shock absorber for a camera. Just as the shock absorbers on your car keep the ride smooth even when the road is not, so a steadicam keeps a camera steady despite bumps underneath. But unlike automotive shock absorbers, a steadicam must also compensate for pan (horizontal rotation), tilt (rotation up or down), and roll (rotation about the axis of the lens)—but only when these changes are not explicitly implemented by the operator. After all, a handheld shot that could only ever point in one direction would not be terribly interesting. To do all this, a steadicam starts with a large, rigid harness or vest worn by the operator. Because the entire apparatus, including the camera, is typically quite heavy—sometimes as much as 90 lb. (about 40kg)—the vest spreads out the weight as much as possible. This not only minimizes fatigue, it gives the camera a much more solid attachment point than the operator’s arms would provide. Protruding from this vest is a heavy-duty mechanical arm, somewhat reminiscent of the ones used in certain adjustable desk lamps. The arm has two rigid segments (called “bones”), connected by spring-loaded joints. The mechanism is designed in such a way that the bones always remain parallel to each other, but can move up, down, left, and right with the application of a small force from the operator. The camera itself (whether film or video) sits atop a postlike mounting assembly called a “sled,” which is attached to the end of the arm by a free-floating rotating joint known as a gimbal. The weight of the camera is counterbalanced partly by the tension of the springs and partly by other components mounted at the bottom of the sled such as batteries and a video screen that enables the operator to see what is being filmed while watching his step. All these joints, springs, and weights shift the center of gravity away from the camera itself while providing multiple points where vibration and other unwanted movement can be isolated from the camera. The net effect is that the operator can walk, climb stairs, step over obstacles, or even jog while keeping the “floating” camera perfectly smooth. This makes possible shots that could never be achieved with a tripod or dolly, enabling the camera operator to walk among the actors freely while keeping all equipment out of the shot. Gonna Film Now The steadicam was invented in 1973 by cinematographer Garrett Brown, with its mainstream debut in the 1976 film Rocky. Since then, it has become ubiquitous in both film and TV. The most impressive use of the steadicam I’ve seen is the 2002 film Russian Ark, shot in the Hermitage, a former palace in St. Petersburg that’s now a museum. The entire 90-minute film was done as a single, continuous steadicam shot that followed the main character as he walked from one room to the next. Garrett Brown himself also famously used a steadicam to capture footage of California’s Redwood National Park in slow motion as he walked through it; when the footage was played at regular speed, it produced the backdrop for the speeder bike sequence in Return of the Jedi (1983). And steadicams are used to film a significant number of scenes in the popular TV series ER, bringing the viewer directly into the action. As sophisticated as steadicams are, they are useless without a highly trained operator. It requires a great deal of practice, not to mention stamina, to become proficient filming scenes with a 90-pound weight hanging from your chest. Steadicam operators, who generally work as freelancers and provide their own equipment, are both highly paid and well respected. Professional steadicam equipment is, not surprisingly, quite expensive—though scaled-down versions for use with consumer camcorders can be had for well under US$1,000. That money won’t make your vacation videos less boring, but your camcorder’s “off” switch was designed for just such a purpose. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/05/camcorder-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/05/Steadicam.235069c54e2.mp3"
	},
	{
		"title": "Freeze Drying",
		"text": "I remember where I was when I heard the news that Elvis died. On August 16, 1977, I was in Washington, D.C. on vacation with my parents. We were watching TV in our hotel room while getting dressed for our day of sightseeing when the news was announced. Although they would not have said so, I suspected my parents were secretly relieved that the world was rid of a corrupting influence. As for me, I was only vaguely aware of Elvis from commercials pitching his records, and from the fact that he and my father had the same birthday. I was much more concerned that we have time to visit the National Air and Space Museum, which had just opened the previous summer, and which was to be—for me, at least—the highlight of this trip. The promise of getting to see a real spaceship, real moon rocks, and so on was, for this ten-year-old kid, incredibly exciting. The museum was everything I had hoped it would be—and more. The last attraction we saw was, naturally, the gift shop, and I tried to get my parents to buy me as many of those amazing goodies as possible. One particular item near the checkout caught my attention: freeze-dried ice cream (“like the astronauts eat!”). At that time, Astronaut Ice Cream was not available just anywhere, and this curious novelty was too good for my mom, a confirmed ice cream junkie, to pass up. We bought a packet and marveled at how this warm, dry stuff nevertheless tasted exactly like ice cream. I had previously thought that the coolest thing about astronauts was that they got to go into space. My experience with freeze-dried foods had, to that point, been limited to a jar of instant coffee that we kept in our cupboard for when my grandparents visited. That was the only time anyone in the house ever drank coffee (another corrupting influence, natch), and I think that one small jar must have lasted well over a decade. In later years I would come to believe that instant coffee (freeze-dried or otherwise) was an abomination, but then, as a ten-year-old I still thought digital watches were a pretty neat idea too. Dry Ice? Nevertheless, the idea of freeze-dried foods has always seemed somewhat incredible to me, and not just because that’s what astronauts eat. I’ve frozen lots of things and never had anything come out of the freezer completely dry and reconstitutable into its original form. And I guess I sort of carried that sense of wonder with me all these years, feeling that freeze drying was some mysterious black art that was always intended to be beyond the comprehension of mere mortals. It actually never occurred to me until yesterday that I could discover how exactly it was done, so I did. I was a bit surprised at the answer—and also surprised at some of the other uses to which this process is put. Freeze drying, (also known as lyophilization) starts, logically enough, with freezing. The mundane process of converting the water molecules in a substance to their solid state is in fact much more of an art than I’d suspected. Depending on what you’re freezing and what its intended use is, you may wish to freeze it very quickly (so that small ice crystals form), very slowly (so that large ice crystals form), by immersion in a cold liquid such as liquid nitrogen, or simply by exposure to cold air. After freezing, though, the substance is subjected to a vacuum before being very gently heated. A precise combination of pressure and temperature causes sublimation, in which the ice crystals turn directly into water vapor without passing through a liquid phase. This vapor is then condensed and drained away, and the temperature and pressure returned to normal. Although this description is somewhat of an oversimplification, the result is a substance that is almost completely devoid of moisture, and yet not damaged in any other way. Time Capsule There are, of course, other ways to dry foods, such as setting them out in the sun for a few days or using a convection drying apparatus. But such conventional dehydration processes present some problems. For one thing, they can take a long time, during which bacteria and naturally occurring enzymes begin to degrade the quality of the food, or even cause it to spoil. For another, the heat can partially cook the food—perhaps not the desired result. And conventional dehydration is rarely complete, leaving some liquid water molecules still present in the food. Freeze drying, on the other hand, removes virtually all the water, which in turn prevents bacterial or enzymatic activity—locking the food into a state of suspended animation for as long as ten years. Add water, and the food assumes more or less its original taste, texture, and nutritional qualities—though some foods, such as lettuce, rehydrate poorly because they have such a high water content in the first place. Interestingly, freeze drying so carefully preserves the cellular structure of animal and plant matter that any bacteria that were present before the food was dried may reanimate when water is added, restarting the spoilage process that freeze drying put on hold. Although food—whether coffee, ice cream, or complete meals (for astronauts or campers)—is the best-known application of freeze-drying, other substances that can degrade too rapidly when moist are also candidates for the process. This includes pharmaceuticals, blood plasma, and even roses. The latest fad, though, is using the freeze-drying process on somewhat larger items: pets. You can’t freeze-dry Spot and bring him back to life later by tossing him in the shower, but if your pet has already died, some companies will preserve it using a taxidermy process that includes freeze-drying. From there, the inevitable next step was to human corpses, and sure enough, a Swedish company recently announced plans to offer just such a service, which they claim is much more environmentally friendly than either embalming or cremation. They’ll immerse your corpse in liquid nitrogen, shatter it into tiny pieces with ultrasonic waves, dry these particles, and then bury the final, compostable product in a coffin in a shallow grave—so that you can be directly reincarnated as, say, a tree. Just think: If they’d done that with the King, he really could still be alive today. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/02/FREEZE-DRIED-ice-cream.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/02/Freeze-dry.b6cdcf2beb49.mp3"
	},
	{
		"title": "___-of-the-Month Clubs",
		"text": "When I am unable to visit my parents at Christmas, which is more often than not, we generally exchange gifts through the mail. Or at least we did for a number of years. Then, as the internet evolved, my parents and I started sending each other boxes of wrapped gifts from Amazon.com. One-click shopping beats mall crowds and lines at the post office any day. A couple of years ago, though, in place of books or DVDs, my wife and I got a letter in the mail saying that we were about to begin receiving our Christmas gift from my parents in monthly installments. The gift that kept on giving was a subscription to the Fruit of the Month Club. Once each month, Airborne Express arrived at our door with a box of fresh fruit. The selection changed each month. In December, for example, it was Mandarin oranges; in April it was kiwi and pineapple. The fruit was always of good quality, and the shipments were just infrequent enough that I was always slightly surprised when each package arrived. Although the shipments were fairly small, they were always a welcome treat that didn’t require a trip to the market—and the subscription is something I never would have thought to purchase for myself. Last year, instead of fruit, we got a subscription to a monthly box of chocolates, enabling us to continue our ritual holiday overeating throughout the year. They Deliver for Me Before my fruit started arriving, I had heard of the Book-of-the-Month Club but had only a vague notion that other kinds of things were available on a monthly subscription plan. Now, however, I seem to find ___-of-the-month clubs every time I turn around. The company that provided our monthly fruit and chocolate selections, for example, also offers monthly subscriptions to beer, wine, flowers, gourmet pizza, cigars, and coffee. In each instance, the general idea is the same: for a fixed fee, you get a six- or twelve-month subscription, with a different selection of your chosen product arriving each month. This can be an easy way to experience new tastes or just make sure you never run out of important foods. In our household, the number one staple food, ahead of milk, butter, and flour, is coffee—our favorite brand being Illy, which produces especially good results in our superautomatic coffee machine. Morgen discovered that Illy offers their own subscription programs, ranging from two cans per month (about the rate we consume it) to a full case every month (perhaps appropriate for a large family of people who never sleep). So we signed up, and have never run out of fresh coffee since. This stuff is not inexpensive—in fact, it’s almost the same price as buying it at the local market. But you’re buying convenience, which is certainly worth something. What other sorts of ___-of-the-month clubs are there? A quick Google search turned up hundreds, ranging from the delightful to the bizarre. Things you can receive by monthly subscription include: gourmet cheese, minerals (for rock collectors), potato chips, sock-knitting kits, trout flies, tea, jam, pasta, pastries, magic tricks, oysters, candles, condoms, quilt blocks, nesting dolls, software, cookies, compact discs…well, I could go on, but you get the idea. I haven’t seen armchair-of-the-month or vaccine-of-the-month clubs, but with very few exceptions, it appears one can now receive virtually every item needed for survival or leisure by subscription. Reader’s Dozen And then, of course, there are books, the item-of-the-month that started it all. The original Book-of-the-Month Club was founded in 1926, designed as a way to get new books into the hands of people living in rural areas without easy access to bookstores or libraries. A panel of judges selected a new volume each month, sent at a respectable discount to subscribers. The following year, The Literary Guild—another variation on the same theme—started business. Decades later, after a series of mergers and acquisitions, both clubs still exist, but under the same joint ownership. If you enjoy reading the types of books the book-of-the-month club offers, it can be a convenient way to stay on top of the latest bestsellers and keep your library well-stocked at a reasonable price. As for me, I already accumulate books far faster than I can read them, so I’m more likely to subscribe to consumable products. Notwithstanding the fact that I write a ___-of-the-day column, I find the notion of monthly subscription clubs strangely appealing—in an endearingly retro sort of way. Since it’s easy to purchase almost anything instantly on the Web these days, the subscription program is a bit of an anachronism. My suspicion is that clubs like these continue to thrive not so much for the convenience they provide but because people like novelty…and they like getting packages. If you can justify a subscription by convincing yourself that you’re saving money, all the better—but when you get right down to it, there’s just nothing like opening a box of goodies. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/02/gift-box-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/02/Clubs.836b57361686.mp3"
	},
	{
		"title": "Flywheel Batteries",
		"text": "A friend of mine recently installed solar panels on his roof to generate electricity. They were quite expensive, but my friend considers it an investment that will pay for itself in lower electricity bills over a period of decades. Of course, the panels generate electricity only when the sun is shining. The house is still connected to the electrical grid just like every other house in the neighborhood, but in such a way that it uses electricity from the grid only when the demand is greater than the output from the solar panels. When the panels are producing more electricity than is being used, the electric meter spins backward, and the electric company effectively buys the excess power. So if there were a power outage, the house would have electricity only during the day. Homes that are “off the grid” and use solar panels or windmills to produce electricity must store the excess for times when insufficient power is being produced. The usual way to do this is to install a large bank of lead-acid batteries, similar to the ones used in cars. When electricity is being generated, it’s stored in the batteries, and when it’s needed, it’s drained from the batteries. The very same principle is used in hybrid gasoline-electric cars, on the International Space Station and in a number of satellites and spacecraft. It’s also fundamental to an uninterruptible power supply (UPS), which you can purchase to keep your computer going for a while or provide emergency lighting in the event of a power outage. Battery Up But there’s a problem with using batteries for storing electricity: they wear out. Even the most sophisticated modern batteries used in cell phones and laptops can only be discharged and recharged a finite number of times; sooner or later, they refuse to hold a charge. Depending on the type of battery and how it’s used, the lifespan can be as little as three to five years. Now, buying a new laptop battery every few years for $50 is one thing, but buying enough batteries to power a whole house is going to be enormously expensive. Meanwhile, those old batteries will need to be disposed of very carefully, because they contain toxic elements. And let’s not forget that such high-capacity batteries are both heavy and bulky. If you’re using them to power a space station, you’re going to face considerable inconvenience in replacing them. Although chemical batteries are likely to be around for a very long time, those with a need for high-capacity, long-term electricity storage are eagerly looking for alternatives. One such alternative is based on a very old and simple device: the flywheel. A flywheel is simply a heavy spinning wheel that stores kinetic energy and then releases it as needed. Flywheels are common in mechanical devices from potters' wheels to automobiles to clocks as a means of regulating or smoothing motion that comes in spurts. Because a flywheel can build up a good bit of inertia, it can keep a mechanism moving during lulls in energy input. Now people are turning flywheels into batteries. Conceptually, a flywheel battery is very simple. Hook up a motor to a flywheel to spin it when electricity is supplied (storing the energy as kinetic energy). When you want to retrieve energy from the flywheel, hook it up to a generator. (In fact, the motor and the generator can be one and the same.) So you put electricity in and get electricity out, and in the meantime it’s “stored” as the motion of a spinning wheel. Putting a New Spin on It As you might expect, however, it’s not quite that simple. Because of the forces of gravity and friction, any flywheel will eventually dissipate all its energy and spin down. So for long-term storage, you want a design with as little friction as possible—which can be accomplished using magnetic bearings to make the wheel “float” and enclosing it in a vacuum to eliminate air resistance. Capacity is another issue. The greater the mass of the wheel and the faster it spins, the more energy it holds—though you improve efficiency more by increasing the speed than you do by increasing the mass. However, the faster you spin a flywheel, the more centrifugal force will build up, potentially causing it to shatter. So materials must be chosen (or created) very carefully, and the entire assembly must also be well shielded, in case the wheel shatters due to a defect or other problem. In the last decade or so, technological solutions to these problems have begun to present themselves, and modern flywheel batteries, which put out about ten times the power for their weight as lead-acid batteries, are beginning to appear with life expectancy ratings of 20 years or more. Two problems that have not yet been solved are cost and scalability. Although it’s possible to purchase a flywheel battery to act as a backup power supply for your home or business, it will set you back many thousands of dollars—enough to pay for quite a few years' worth of batteries. And you won’t see a flywheel battery small enough to power handheld devices or large enough to power a city block. Still, in an era that values devices with no moving parts as a design triumph, it’s fascinating to watch a good old-fashioned spinning wheel emerge as the battery of the future. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/02/wind-power-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/02/Flywheel.9c86c26e0cd9.mp3"
	},
	{
		"title": "Car Sharing Programs",
		"text": "For all the benefits automobiles provide, their impact on air quality has been quite harsh. I’m as concerned about the environment as the next person, and as I look out over the smog-filled skies of California, I can’t help but be annoyed at the millions of cars spewing pollutants into the air. I’m driving one of those cars, of course: modern life being what it is, the need to get from place to place seems to take precedence over the need to breathe. Still, my conscience is clearer than the air because the car I’m driving is owned by a nonprofit organization that aims to reduce the number of cars on the road. In this city, as in a growing number of places around the world, modern technology has joined forces with ages-old ideas of community ownership to produce a brilliant new system of car sharing. I have been aware of the concept of car sharing for years, but I must confess that it took a while for me to warm to the idea of participating personally. I had owned a car almost since I was old enough to drive, and the notion of not having my own car—and the freedom it provided—was hard to accept. I imagined it to be like carpooling: an idea I agreed with in theory, but could never see myself putting into practice. I didn’t want to be rigidly tied to someone else’s schedule, without control over where I drive and when. It took a good strong dose of city driving to enable me to see the light. Driving Me Mad Although there are many things to love about San Francisco, it is not a great place for drivers. Parking spots are notoriously hard to find, and many residents pay dearly for a permanent off-street parking spot. Car ownership is expensive in other ways too. The costs of car insurance, gasoline, and maintenance are high; theft, vandalism, and accidents are common. More importantly for me, dealing with traffic congestion and road rage during my daily commute began taking its toll on my mental health. I liked my car—it worked perfectly well and was fully paid for. I even had a parking spot. But the headaches of car ownership had begun to outweigh the benefits. At the end of 2001, after much contemplation I made a strategic decision: I was going to become a non-car owner. I sold my car, and put my fate in the hands of mass transit. San Francisco has a generally excellent public transportation system, including buses, subways, light-rail trains, and cable cars. There’s also a commuter train that extends down the peninsula from San Francisco to San Jose, airport shuttle vans, and of course plentiful taxis. I figured that if I made maximum use of these resources (along with my legs and occasionally my bicycle), I could get pretty much anywhere I needed to go. I had deliberately chosen to live in a neighborhood served by several different transit lines, just to keep my options open. Man Cannot Buy Bread Alone There were a few instances I needed to consider in which simply getting from place to place was not enough. Take grocery shopping, for example. A local market is fine if all you’re buying is milk and bread, but I was used to filling up my trunk with a dozen or more bags of food every few weeks. Luckily, two major supermarket chains (Safeway and Albertsons) offer online ordering and inexpensive home delivery in the city, so that problem went away. For an occasional weekend trip out of town, car rental agencies provided a reasonable—if somewhat pricey—solution. Other transportation needs were met by borrowing a car, riding with a friend, or taking a cab. For a full year I lived this way, commuting to work on the train, taking a bus to the movies, and blissfully enjoying freedom from car ownership. My monthly bills were lower than ever, and my stress level had decreased dramatically too. Then, when my job changed, I moved to a new neighborhood and started to experience some frustration. Public transit was still good, but now I needed to get across the bay to shop at IKEA, go to a doctor’s appointment across town, or run a quick errand to an outlying city that would take me half a day on the train. These sorts of trips came up with increasing frequency, and renting a car or van to take care of them was both expensive and inconvenient. That’s when I signed up for City CarShare. Drive, He Said Unlike carpooling, car sharing gives me the independence to drive wherever and whenever I want, at a tiny fraction of the cost of owning a car. The concept is basically very simple: A co-op owns a fleet of cars—many of them brand-new green Volkswagen Beetles, but also station wagons, pickups, and other vehicles—and members can use a car whenever it’s not already spoken for. Because there are plenty of vehicles in the fleet, chances are excellent that when I need a car, one will be available. The cars are kept at lots all over the city, and in about 30 seconds I can use a Web site or automated phone system to make a reservation for a few hours or even a few days. If a car is available, I don’t even need advance notice: I can call on my cell phone from the parking lot, and then hop in and drive away. Each member has an electronic key fob that opens the doors, and the car has a radio link to headquarters that allows the company to enable or block access for individual fobs. After an initial application fee and deposit, members pay just US$10 per month, plus very reasonable fees for the time and distance they actually drive. For local trips, this invariably ends up being way less expensive than a conventional car rental. But the real beauty of the system is that the organization takes care of maintenance and insurance, washes the cars, and even pays for gas. It’s as nearly hassle-free as car ownership can be. In exchange for the tiny added step of having to schedule your car use, you eliminate most of the worries of owning a car—and save lots of money too. First Watches and Knives, Now This City CarShare is modeled after highly successful programs in Europe. The first modern car sharing program began in Switzerland in 1987. Over the years, smaller organizations have banded together under a larger group called Mobility, which now has more than 56,000 subscribers. Mobility, in turn, is part of the European Car Sharing consortium, whose members enjoy car sharing benefits in Denmark, Norway, Germany, and Italy as well. This extensive membership has made it possible to integrate shared cars into larger regional transit programs. In Zürich, for example, you can buy a single transit pass that can be used for trams, buses, trains, and ships in addition to cars. Some cities have programs affiliated with the rail system so that you can pick up your car at the train station—handy for day trips and shopping excursions. Car sharing has gradually been catching on all over the United States and Canada. From Boston to Seattle, Montréal to Vancouver, programs of varying sizes have sprung up, with more in the planning stages. Anywhere crowded streets, limited parking, and high car ownership costs converge, someone gets the idea that there must be a better way, and car sharing certainly represents one effective solution. It may be good for the environment, but as far as I’m concerned, the best reason to share a car is reducing stress. My own mental health has improved by over 12% since I gave up owning a car, and the money I’ve saved has paid for a lot of Swedish furniture. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/02/car-120.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/02/Car_Sharing.6bbd239d0a16.mp3"
	},
	{
		"title": "Automatic Transmissions for Bicycles",
		"text": "Reinventing the two-wheeler When I first learned to drive, I learned on a car with a manual transmission. It never seemed especially difficult because that was what I got used to. In fact, the first time I had to drive an automatic, I remember being very confused. What was I supposed to do with my left foot? Do I not have to shift at all? And if it’s automatic, then what’s with all these different choices on the gearshift lever? I quickly got the idea, of course, but still preferred the increased control and responsiveness I got from making my own decisions about when to shift. It would therefore seem that I should have the same attitude about bicycles, which not only require manual shifting but typically have many more than four or five gears. But manual bicycle transmissions have always given me trouble, and I’ve frequently wished I could have the convenience of an automatic transmission on a multi-speed bike. Yanking My Chain For the record, I am not what you’d call an avid cyclist. I own a bike—actually a fairly nice one—that over the past few years I’ve ridden, on average, once or twice a year. Not that I feel I need to make excuses, but I live in a part of San Francisco that isn’t especially bike-friendly (on a hill, no less), and the vast majority of places I need to go are much easier to reach by train or by bus. Nevertheless, I can’t imagine not owning a bike, and I like the idea of bike ownership very much—good exercise, good for the environment, and so on. But even when my bike was my sole form of transportation a number of years ago, I never fully grasped the way bicycle gears worked. That is to say, I understood the mechanics, but actually using them was another story—the logic of how one must manipulate those levers to reach the desired balance between torque and speed always seemed a bit like a black art. It was not a simple linear progression of lower to higher as on a car, but a function of the ratio of the front gear size to the rear gear size, both of which are variable. My usual practice was just to fiddle with the controls until pedaling felt about right, then leave them where they were until I couldn’t stand it any longer. Another problem with shifting gears on bicycles is that the derailleur—the mechanism that moves the chain between gears of different sizes—is by nature imprecise. Although some designs are better than others, over- or undershooting your desired gear is common, and if you’re pedaling too fast or under too heavy a load, the chain can easily slip off the gears entirely, requiring a greasy manual adjustment. Wouldn’t it be nice if bikes could figure out how to change their own gears as painlessly and accurately as cars with automatic transmissions? Gearing Up for a Change Sure enough, automatic bicycle transmissions have been in development for almost 30 years, though only recently have they become commercially available. Mechanically, the main thing needed for an automatic bike transmission is a motor or piston that moves the chain between gears in place of the standard lever-operated cable. This is a relatively straightforward engineering problem, but the difficult thing is working out how and when to tell the gears to shift. That computation currently requires the use of a tiny, battery-operated computer along with sensors that determine the current gear and the speeds at which wheels, pedals, and sprockets are moving. The computer constantly recalculates the optimal combination of front and rear gears to keep the rider at a consistent pedaling cadence, automatically signaling the gears to shift lower when going uphill or higher when going downhill. Using a controller on the handlebars, riders can, if they wish, adjust the gearing to provide a more intense workout or a gentler ride; they can also override the automatic shifting entirely and use it as a power-assisted manual transmission. The first automatic bicycle transmission was designed by the Browning family, whose main claim to fame had been gun design. Now an independent company based near Seattle, Browning Components, Inc. focuses solely on bicycles and bike transmissions. Their most interesting innovation is a special gear with a hinged section (somewhat like a pizza slice) that swings in and out to guide the chain from one gear to the next. What’s great about the Browning mechanism is that the chain remains engaged in sprockets at all times, rather than simply dropping onto the next gear. This virtually eliminates the possibility of the chain slipping, and also makes it possible to shift smoothly and almost silently regardless of speed or load. Browning manufactures their own bikes (whose frames must be custom designed to accept the special transmission) and also supplies the transmission mechanism to other bike manufacturers. Shifting More Than Gears Shimano, the largest manufacturer of bicycle components such as brakes and shifters, has also begun selling automatic transmissions. One design uses a seven-speed, internally geared hub; another, which is not yet available in North America, uses a power-assisted derailleur system, but adds an automatic, powered suspension to adjust the comfort of the ride to fit current conditions. Bikes with the Shimano mechanism are significantly heavier and more expensive than their manual counterparts and are designed more for leisure riding than racing or mountain biking. The Browning mechanism, on the other hand, was first employed on bikes used for BMX racing, and adds somewhat less to the cost and weight of a bike. Adding an automatic transmission to a bicycle seems—in the abstract at least—like a wonderful step forward in user interface. It replaces something awkward with something invisible, which is the way good technology should be. Whether or not the reality lives up to the hype (or will in the future), I don’t know. And something tells me it ought to be possible to create a purely mechanical automatic bike transmission. I’m not sure what happens to an electronic one when the batteries inevitably die; presumably it just stays in whatever gear it was last set to. At this point, automatic bike transmissions are not taken very seriously among cycling enthusiasts. Some are put off by the extra weight; some feel it’s not worth the money just to avoid having to move a lever; and some just think automatic transmissions are for wimps. Having never used one of these bikes myself, I can’t say whether the performance would be improved enough to make me want to ride my bike more often, but at least I would no longer view gear shifting as the annoyance I do now. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/02/bike-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/02/Transmissions.68ba27dc8697.mp3"
	},
	{
		"title": "NextBus",
		"text": "One evening Morgen and I were at a dreams group meeting way across town. The most direct route home was by way of San Francisco’s MUNI light rail line, but as we approached our stop, we saw that we had just missed a train. Knowing how infrequently trains tend to run late at night, a friend who was waiting with us wondered out loud how long we might have to wait for the next one, and whether we should consider finding an alternate route. I pulled my cell phone out of my pocket, and after a few clicks on the keypad, I announced: “Looks like 11 minutes.” We decided to wait. Sure enough, exactly 11 minutes later, the train arrived. This little trick came courtesy of a high-tech service called NextBus. Location, Location, Location The idea behind NextBus is sophisticated yet elegant. Every vehicle on a transit line is equipped with a rooftop device that contains a Global Positioning System (GPS) receiver and a radio transmitter. The GPS receiver constantly tracks the vehicle’s exact location by satellite. This information is transmitted to a central computer, which calculates the amount of time it should take that vehicle to reach its next several stops, based on its current speed, typical travel time, and other variables. These predictions are continuously recalculated, so that even with delays, traffic, or detours, the estimates remain highly reliable. The information is available in real time via the Web and can be viewed using the built-in browsers on most cell phones and PDAs. In addition to time estimates for particular stops, you can even see a live map showing the locations of all the vehicles being tracked. Digital displays are also posted at some bus stops and shelters for added convenience. Municipal governments and transit agencies subsidize the NextBus service—which is free to users—as a way to reduce frustration among riders. Knowing when the next bus is going to arrive can help you plan your schedule, avoid spending unnecessary time in the rain, and travel more efficiently. NextBus is also extremely useful for route planning. For example, there are usually several ways to get from place to place in San Francisco. If I know that a train won’t be coming for a while, I can opt for a subway or bus instead—perhaps more walking, but a shorter overall travel time. Can You Track Me Now? Of course, NextBus is far from perfect. I’ve seen the system predict the arrivals of trains that never came, and I’ve also been told the next train was 45 minutes away only to have one roll up the next minute. One of the reasons for the inaccuracies is that transit systems sometimes switch trains between lines for one reason or another. If a train from line A happens to be on track B, the system doesn’t know what to do with it, because it can’t tell what route it’s ultimately going to take. The tracking devices are also subject to electronic failure, and can sometimes get out of sync when going through tunnels. Then there’s the fact that the computer needs a certain amount of history in order to perform a calculation. I live near the beginning of a certain transit line; the first stop is only three minutes away. So when I ask NextBus when the next train is coming, it often gives a wildly inaccurate prediction 20 minutes or so in the future, based on the average departure times of the trains. A few seconds later, though, the prediction may become “3 minutes.” The NextBus service is currently deployed in dozens of different transit agencies across the United States and England, and is expanding into Canada. However, some agencies still have only limited coverage. In San Francisco, for example, where all the light rail trains have tracking devices, only a tiny percentage of the buses do—even though the service has been in place since 1999. And in some other cities, the service is still in a pilot or demonstration stage, awaiting approval or funding for a full roll-out. Still, NextBus is a textbook example of technology as it should be—useful, accessible, and simple. Unlike regular trains, the buses and rail lines that use city streets have no hope of running on a strict and reliable schedule. Although NextBus won’t make them arrive sooner, it keeps riders happier while they wait ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/02/gps.jpeg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/02/NextBus.3b40ef8c2e9d.mp3"
	},
	{
		"title": "Ventless Clothes Dryers",
		"text": "Laundry without the hot air Nearly two years ago, my wife and I decided to move out of our trendy loft apartment and find a quieter, friendlier, and less expensive place to live. One of the criteria on our list was laundry facilities. Here in San Francisco, this is not a trivial issue. There may be plenty of beautiful Victorian and Edwardian buildings, but it’s relatively rare to find an apartment with a washer and dryer in the unit, and even shared laundry facilities in the basement or garage are not the norm. Although many thousands of people make their way to the neighborhood laundromat each week with a basket of clothes and a roll of quarters, that’s something we hoped to avoid. Years of experience have shown us that there is a positive correlation between convenience of laundry facilities and marital bliss. So we were most drawn to homes that had their own washer and dryer. At a certain point in our search, we came across an otherwise suitable apartment that included a small extra room with hookups for a washing machine, but no space for a dryer—nor any way to vent one. That sounded to me like a problem that ought to have a technological solution, so I began searching the Web. Sure enough, I found a class of machines that used a single chamber for both washing and drying—put clothes in dirty, push a button, wait an hour or two, and take them out clean and dry. That by itself was interesting, but what really got my attention was the fact that these devices could dry clothes without any sort of vent. I had always assumed that hot, moist, linty air has to come out of a clothes dryer one way or another—it seemed like one of those cosmic truths you just couldn’t get around. But you can get around it, and surprisingly enough, one way to do so is to use water to dry your clothes. Small Change We eventually found a home with a conventional washer and dryer, and I forgot all about the combination devices until I went over to a friend’s apartment and saw one of the combo washer/dryer machines in the corner humming merrily along. After it washed his clothes, a different light came on and it started drying them. It didn’t give off any heat, which was actually slightly disappointing because that room was a bit chilly. He said it worked extremely well, the only minor drawback being that it had a relatively small capacity. According to the sticker on top of the machine, it was expected to consume about US$12 worth of electricity in a year—or about as much as a typical San Franciscan spends on coin-operated washers and dryers in a month. But it wasn’t the compactness or energy efficiency of this machine that intrigued me, it was the way it got the clothes dry. Ordinary dryers suck in cool, dry air from the room, heat it, blow it through the clothes, and then discharge the damp, hot air outside through a vent. This dryer, on the other hand, runs the exhaust through a heat-exchange system to cool it. Cold water flows through the heat exchanger, absorbing heat from the air. As the air cools, the moisture in it condenses and runs down the drain (along with the used cooling water); the dry air is then heated again, sent back through the clothes, and the cycle continues. The upshot of this is that drying your clothes with a ventless dryer requires a few extra gallons of water, but eliminates the need for a vent and keeps your laundry room from overheating. Air Apparent Not all ventless dryers (or condenser dryers, as they are sometimes called) have built-in washing machines, and not all of them use water to condense the moisture from the air. Another design—frequently seen in Europe but hard to find in North America—has heat exchangers that use cool air from the room to absorb the heat. This means that hot (but dry) air is discharged into the room; the condensed water drains away just as it does in the combination units. Now that you can wash and dry your clothes with the push of a single button—while keeping your apartment cool and dry—it’s time for the world’s engineers to tackle the final frontier of laundry automation: folding. I remember an old “Lost in Space” episode in which Mrs. Robinson put the family’s dirty clothes into a box, pressed a button, and then pulled out clean, dry, folded, and plastic-wrapped garments a few seconds later. That’s what I want. Then my wife will be happy to do the laundry while I replicate dinner. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/02/washer-dryer-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/02/Ventless.7c88370df8b.mp3"
	},
	{
		"title": "Heat-Resistant Chocolate",
		"text": "Defying the laws of confectionary I once heard a rumor that almost provoked a deep moral crisis. I have always had a profound, passionate, and unshakable devotion to chocolate. Equally strong is my contempt for mosquitoes (and I’d say that even if I hadn’t contracted malaria during a summer in Indonesia when I was in college). The rumor, which turned out to be unsubstantiated, was that mosquitoes pollinate the cacao trees from which cocoa is produced. I had been worried, because I didn’t know how I could maintain my belief that mosquitoes were pure evil if they were necessary for the creation of pure good. Luckily, I did not have to grapple with this serious philosophical issue and I could go on loving chocolate and hating mosquitoes without feeling any inconsistency. The only real shortcoming of chocolate is that it has an unfortunate tendency to melt when you don’t want it to. Hot chocolate, hot fudge, and chocolate syrup are all fine if that’s what you’re expecting, but if you open a chocolate bar that’s been in a hot car, let’s say, and find that it has liquefied, you’re not going to get the experience you want. Then, of course, there’s the perennial problem of chocolate melting in your hands even when the ambient temperature is low enough to keep it solid. This is, so the ads would have us believe, the entire reason for the existence of M&Ms—a brilliant technological solution that doesn’t actually keep the chocolate from melting but at least keeps it from making a mess. Military Solutions A friend of mine who serves in the Swiss army told me that soldiers are supplied with a special chocolate bar that doesn’t melt, even in a pocket on a hot day—part of their standard rations. This sounded like a remarkable invention. I sampled some, and it was OK, though it had none of the soft creaminess for which Swiss chocolates are so famous. My friend considered it barely edible, but better than nothing (and much better than a pocket full of goo). Members of the American military were issued nonmelting chocolate as early as the 1940s, when Hershey created its Field Ration “D,” but that bar, with its oat flour base, could hardly be considered a true chocolate bar. Chocolate technology has come a long way since then. In the first Gulf War, Hershey and Mars fought bitterly for a military contract to supply new and improved chocolate bars that would remain solid at temperatures up to 140°F (60°C). So how exactly does one go about making a chocolate bar that won’t melt? There are several techniques. Milk chocolate is generally composed of cocoa (or chocolate liquor), cocoa butter, milk, and sugar. It’s primarily the cocoa butter—a type of fat derived from cocoa beans—that determines the chocolate’s melting point. So one technique is simply to play with the proportions of ingredients, starting with a reduction in cocoa butter, until you get something that tastes reasonably good but still resists heat. You can also add solid fillers (as Hershey did originally) to soak up some of the fat, or use other stabilizing agents to keep the keep the bar rigid. (Hershey claims they added egg whites to milk chocolate for their more recent Desert Bar). Breaking the Mold But there’s a much simpler approach too. On a visit to a botanical garden in Costa Rica last year, we were given a sample of some homemade chocolate that, despite my best efforts, I couldn’t melt. Our guide told us that they harvested the cocoa beans by hand, roasted them, shelled them, and then ground the resulting cocoa nibs together with pure cane sugar (also produced locally). The mixture was pressed into molds and allowed to harden. This simple two-ingredient treat is a bit dry and grainy, but still delicious—and utterly heat-proof. Local markets sell the candy (with a variety of additional ingredients, such as nuts and ginger) alongside commercial chocolate bars. One would think there would be a significant market for chocolate that won’t melt easily, especially in hot climates. But with few exceptions, heat-resistant chocolate has not become commercialized, and it’s extremely difficult for ordinary consumers to get their hands on it. However, if you’re not particular about your hands being what comes in contact with the chocolate, there’s hope. Austrian designer Reinlinde Trummer sells elaborate, custom-made chocolate bras for about US$60 (£100). The bras, which take nearly two weeks to harden, are made from a special variety of heat-resistant chocolate, and Trummer can’t keep up with the demand. They’re the perfect gift for someone who likes milk chocolate. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/02/chocolate.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/02/Chocolate.dd3b8cb6b44c.mp3"
	},
	{
		"title": "Powder Coating. Paint’s shocking competitor",
		"text": "During the three years I lived in Vancouver, Canada, I worked at an office in the back of a large building in an industrial park. Our company didn’t own the building, and as the smallest of several tenants, we didn’t merit a sign on the front. The company that occupied the largest portion of the building, and therefore had its sign in large letters facing the street, was Hudson Powder Coating. I had to explain this to visitors when giving directions, and they were always confused. “What is powder coating anyway?” they usually asked. I had no idea. All I knew was that as I drove through the parking lot, I saw a lot of miscellaneous metal objects sitting in front of the company’s loading area—things like bike racks, lamp stands, car parts, and folding chairs. In the morning, these items were unfinished, and in the evening when I drove by again, they were brightly colored. I inferred from this that “powder coating” must be something like painting, though I didn’t quite see where the powder part came in. For reasons I cannot fathom, I never actually bothered to find out what powder coating was at any time during the three years I worked in the building with the powder coating company. When I finally managed to look it up, it turned out to be much more interesting than I had imagined. Like most men and relatively few women, I have the Hardware gene. I love tools, building materials, and especially hardware stores—those magical places filled with sacred Things Used To Create Other Things. In particular, I always find myself lingering in the adhesive section, eagerly reading the label of every new epoxy or sealant. I feel the same way about tape. The whole notion of one thing sticking to another has always fascinated me, and that is equally true when it comes to magnets or static electricity. For someone who likes hardware and things that stick, there could hardly be a more exciting topic than powder coating. The Drip-Free Paint If you look around at the metal objects in your home or office—filing cabinets, toasters, computer stands, chairs, garbage cans, and whatnot—you’ll probably notice that most of them are painted. Metal things are painted not only to make them prettier, but for the utilitarian reason of protecting them from rust, corrosion, and general dinginess. What may surprise you, however, is that many of those seemingly painted objects have never seen a drop of paint in their lives. More likely than not, the paint-like surface was applied by the wondrous process known as powder coating. Powder coating starts with, as you might guess, a powder. This powder is somewhat like a finely ground, dried paint—a mixture of resin and pigment. You can also think of it as a powdered plastic. The general idea is to cover an object with this powder, and then heat it briefly in an oven so that the powder melts and flows together, forming a smooth, solid layer. The tricky part, though, is getting the powder to stick, preferably in an extremely even coat. This is done using electrostatic charges—the same phenomenon that makes your hair stick to your comb or dust stick to your computer screen. The powder is applied to the object using a special spray gun that gives the particles a negative electrical charge. Meanwhile, the object being coated is grounded (or, in some cases, given a positive charge). The difference in charge between the particles and the object causes a strong attraction, and presto! The powder sticks to the surface. The object and powder can maintain their attraction for hours, which is much more time than is needed to apply the heat that bakes on the finish. A Strong Finish Powder-coated finishes are durable and highly resistant to peeling, chipping, and fading. They can be made in almost any color, and with varying degrees of shininess ranging from a high gloss to a dull, flat finish. The process is quick, efficient, and environmentally friendly, producing no pollution or dangerous waste products. There’s also no waiting for paint to dry: as soon as a coated piece comes out of the oven and cools to the touch, it’s ready to be used. For the most part, powder coating is used for metal objects—appliances, garden tools, engine parts, and so on. But any object that can be given an electrostatic charge is a potential candidate for powder coating. This includes glass, wood, and many kinds of plastic (think of your charged comb). The only problem comes in the curing process—plastic melts at fairly low temperatures, and wood can burn. So special types of resin powder have been created that melt at much lower temperatures; still others can be cured using infrared radiation, with curing times as short as a fraction of a minute. A Powder Room in Your Home While the equipment needed for powder coating is considerably more elaborate than a spray can, several companies are now offering kits that make it possible to do this at home. You can buy the special electrostatic spray gun apparatus for as little as US$100. In addition, you’ll need, at minimum, an air compressor and a spare electric oven—spare because you really don’t want fumes from melting plastic mixing with your food, and electric because the vapors can ignite in a gas oven. Depending on what kinds of parts you’re coating, you may also need equipment to prepare the surface, such as sandblasting apparatus. Still, a home powder coating workshop is well within the means of many hobbyists, and provides a very professional, high-quality finish that paint often can’t match. Powder coating is very similar in concept to the way a photocopier or laser printer works, only in three dimensions. Charge up particles of stuff, make them stick to something else, and apply heat to make the bond permanent. It’s a brilliantly simple idea, yet extremely effective and versatile. And to think, all that magic was going on right around the corner from my office for three years. Sometimes the most interesting things are the ones right under your nose. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/02/dry-coating-equipment.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/02/Powder-coating.4156214bc3d4.mp3"
	},
	{
		"title": "Giving Away the Razor, Selling the Blades",
		"text": "The curious strategy of loss-leader marketing One day I opened up my mailbox, and there inside was a box from Gillette containing a brand-new Mach3 razor. It turned out that the box was addressed to my neighbor, which is just as well: the idea of shaving with a triple-blade razor seemed a bit—excuse me—over the edge. That was just a few years ago, and since then, the Mach3 has been superseded by models with four and five blades, with or without a vibrating feature—the mind boggles. But the twin-blade Gillette SensorExcel razor I used for many years also came in the mail for free, and also, coincidentally, wasn’t addressed to me—I got it from a friend who didn’t want it. Still, exactly as Gillette hoped, I spent many, many dollars over the years on their obscenely overpriced blades before breaking down and buying an electric razor. Like countless other people, I was sucked in by the “give-away-the-razor-sell-the-blades” concept. Old-fashioned and counterintuitive, this marketing gimmick is still going strong. Razor-Thin Profit Margins Around 1900, a salesman named King Camp Gillette dreamed up the idea of disposable razor blades. Before that time, razor blades were thicker and were simply sharpened when dull—a time-consuming and imprecise (not to mention dangerous) process that no one enjoyed. Gillette’s innovation was to make the blades thin enough and inexpensive enough that they could simply be thrown away when they dulled. At first, he couldn’t sell the blades for as much money as it cost to make them, but then he had a wacky idea: he would give away the razor handles. People who got them perceived them as being valuable—but only when fitted with one of Gillette’s blades. So there was a subtle yet forceful psychological pressure to maintain that value by continually buying the blades. After a few months of blade sales, the cost of the handle was recovered and Gillette began to make a profit. Within a decade, Gillette’s company dominated the razor market and made its inventor extremely wealthy. Nowadays, Gillette’s strategy has been—excuse me again—honed to a new level of sophistication. Each new model of razor has a unique design such that only blade refills made to those exact specifications will fit. When possible, the designs are patented so that third parties are prevented from selling their own refills; Gillette, meanwhile, charges a small fortune for their blades, and customers dutifully buy them. Predictably, when a patent expires, opening the market for generic competitors, Gillette releases a new design, along with a new marketing campaign geared toward making people with last year’s model feel like they’re no longer—sorry—on the cutting edge. The Leading Edge This strategy is technically a form of what’s called “loss-leader” marketing. In general terms, a loss leader is a product sold at a loss in order to generate secondary sales later on. In some cases, a loss-leader product doesn’t produce dependencies that lead to other sales directly, but rather builds brand image and goodwill among customers, in hopes that this will indirectly produce sales later on. In other cases, products are sold at a loss strictly to gain market share or monopolize shelf space; profits come from upgrades, add-ons, or other secondary sales. One of the most common implementations of loss-leader marketing is cell phones. Almost every day I see an ad in a newspaper or magazine advertising a cell phone for free (or some trivially small amount of money), even though I know they cost quite a bit to manufacture. In this case, the “blades” are the monthly service fees. The cell phone company expects to recoup the cost of the phone—and then some—by selling you air time. Distributors guarantee they won’t lose money by building a clause into the contract stipulating that you must pay a “cancellation fee”—in other words, the cost of the phone—if you discontinue service before your contract expires. Give Away This, Sell That Any product that requires a service plan, periodic upgrades, or consumable refills is ripe for this type of marketing approach. Satellite TV providers will sometimes install an antenna on your roof and a receiver in your living room for free, as long as you make a one-year commitment to pay for monthly service. Another example is color inkjet printers, which used to be fairly expensive but now routinely sell for well under US$100. Replacement ink cartridges, however, often cost an arm and a leg, in some cases making your total cost per page higher over the long run than if you’d purchased a more expensive laser printer. But my favorite new implementation of “give-away-the-razor-sell-the-blades” comes from the Italian coffee company Illy. Illy offers a subscription program whereby you can receive two to six cans of gourmet coffee in the mail every month. But they also offer a special twist: you can buy a high-end espresso machine at a savings of about US$450 if you commit to a one-year membership. If I didn’t already have an even fancier espresso machine, I’d be all over that program. It’s not just physical products that work with this sort of scheme either. Countless software developers, Web sites, and internet services follow the same model. If a company is giving away a product for free—whether it’s a Web browser, a news service, music, or whatever—it’s a fairly safe bet that there’s some moneymaking plan behind it, which may very well be a loss-leader strategy. Hmmmm, come to think of it, my company gives away digital products for free—including the very article you’re now reading—in order to produce advertising revenue and promote sales of subscriptions, audio recordings, merchandise, and so on. Has it worked? You’d better believe it. This strategy brings in enough money every month to buy inkjet refills and pay for my coffee subscription. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/01/gillet.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/01/Razor.35e138a9c96c.mp3"
	},
	{
		"title": "Public Enrichment Project",
		"text": "Fun and common sense for a better world When I began working on Interesting Thing of the Day, it was not with the idea that it would make tons of money. I was, and still am, optimistic that eventually the revenue generated by this project will be enough to make it worth the time spent working on it. But when you get right down to it, I do this because I feel it needs to be done. I like to learn, teach, and have fun, and Interesting Thing of the Day accomplishes those things for me. So when I heard about a very unusual nonprofit organization that appears to have the very same goals, I felt an immediate sense of kinship. The organization is called Public Enrichment Project (or PEP for short). A friend of mine handed me a very sober-looking two-page newsletter from the organization that looked exactly like the newsletters from every other small nonprofit. It didn’t try to be cute or flashy, it simply recounted the group’s recent activities. But the activities were unlike anything I’d ever heard of—weird, inventive, and compellingly sane. The organization’s Web site says, “PEP’s mission is to assist individuals with projects that are extraordinarily creative, publicly enriching and also run the risk of going unnoticed.” That’s it? What’s the catch? Where’s the ulterior motive, the grand idea they can pitch to potential donors, the touching story of a need they’re trying to meet? There isn’t one. PEP Rally To give you the flavor of what PEP is about, consider their major event of 2003, the PePathlon. This day-long competition consisted of four distinct activities: trash collection, bicycling, creative presentations, and—this was the part that won me over—taking the Graduate Record Examination (GRE). Contestants were scored in each of the activities except bicycling, to prevent superathletes from having an unfair advantage. On the other hand, bonus points were awarded during the trash collection activity for bagging “Special Consideration Items” such as tires and large pieces of lumber and “Extra Special Consideration Items” such as roadkill. PePathletes raised money for the charities of their choice, and the winner walked away with a large trophy and an additional contribution to his charity from the organization. Among the skills displayed in the “creative presentations” activity were speeches, massage, palmistry, poetry, and throat singing. Another annual event is the People Tournament, a bizarre name game played by proxy on behalf of thousands of people and fictional entities. Players compete head-to-head in a series of bracketed rounds; the winner of a roll of dice in each round moves on to the next round. The very first contest this year was between the ancient Canaanite god Baal and E.H. Shepherd, illustrator of Winnie the Pooh. (Shepherd won, but he still has a long way to go before claiming the final victory. Interestingly, Tigger won the overall tournament in 1995. ) One of PEP’s ongoing services is the Court of Common Sense, a dispute-resolution forum in which a panel of nine judges bases their decision not on obscure legal precedent but on common sense and logic. The PEP Web site contains complete records of the cases the Court has tried and the decisions they reached; it’s entertaining reading. PEP also offers a service called Habit Makers and Breakers that’s designed to encourage people to stick with whatever resolutions they’ve made. It works like this: you pay PEP a sum of money and sign a contract stating what activity you intend to do (or refrain from doing). PEP monitors your progress and repays the money to you incrementally only to the extent you succeed; the rest is kept as a donation. In addition to these services, PEP provides financial and logistical support to worthwhile creative projects undertaken by other people or groups. Holy Fun PEP is not an overtly religious organization, although most of its board members and staff attended Mennonite colleges and have careers that exemplify traditional Anabaptist values. What I find delightfully interesting is that with all the activities in which they could have chosen to invest their time, PEP’s founders did not create an organization with pretenses of saving the world. PEP is not trying to stop violence, feed the poor, or spread the gospel. I am not aware of any biblical injunction to “go forth and have fun,” but that is essentially their mandate, and if I may say so, it’s a darn good one. I do wish their Web site and newsletter were a little less matter-of-fact and businesslike—I think people would catch on to the group’s ideas more quickly if their public materials had a catchier look and feel that better reflected the character of the organization. Still, PEP is, in its own small way, spreading good vibes and helping people to take life a little less seriously. If more organizations caught on to that idea, there could be hope for saving the world after all. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/01/Joe-Kissel.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/01/PEP.733027407d2d.mp3"
	},
	{
		"title": "Measuring the Speed of Light",
		"text": "Fun with mirrors and math Last spring when I was in Paris, I marveled at all the technological wonders displayed in the Musée des Arts et Métiers. What impressed me the most was some of the very old laboratory apparatus that enabled scientists of centuries past to figure out some very difficult puzzles without the benefit of modern gadgets such as lasers and high-speed digital computers. In particular, I spent a long time studying the equipment Jean Bernard Léon Foucault used to measure the speed of light in the mid-1800s. Foucault worked in a variety of scientific fields, with his greatest claim to fame being a simple mechanical method for proving the rotation of the Earth—what came to be known as Foucault’s Pendulum. I was even more astounded, though, to see how he solved the extremely vexing problem of making an accurate measurement of the speed of light without so much as an electric motor or a quartz crystal. The display of his lab bench in the museum had not only a printed description but even an animated video presentation. Unfortunately, my French wasn’t good enough for me to comprehend exactly how it worked; I could only tell that it had something to do with a rotating mirror, measuring angles, and (most puzzling of all) a tuning fork. Later, reading about the equipment in English, I finally understood, and I’ll describe his method in a moment. But first, a bit of history. Early Estimates From ancient times, astronomers and other thinkers wondered how fast light moved; for a long while, conventional wisdom held (reasonably enough) that it traveled instantaneously. Galileo described (and possibly performed) an experiment in which two subjects stood about a mile apart, with a third person observing them both from a distance. The first person uncovered a lantern, and as soon as his partner a mile away saw the lantern’s light, he uncovered his lantern. The third person’s job was to measure the time between when he saw the first light and the second light; Galileo then intended to use that amount of time, along with the distances between the participants, to calculate the speed of light. Unfortunately, the test was inconclusive, because the delay was too short to be measured accurately. Even Galileo admitted it was more a test of response time than a measurement of the speed of light. All he could conclude from the experiment was that light traveled at least 10 times faster than sound. Over the following centuries, several astronomers made inferential estimates of the speed of light based on observations of the movements of planets and stars. Some of these estimates were quite shrewd, sophisticated, and (it would later turn out) fairly accurate, but they were unsatisfying because they required educated guesses about astronomical speeds and distances and could not be reproduced in a laboratory. So in the middle of the 19th century, two French scientists started investigating the problem independently, each arriving at a novel way to make the measurement with readily available equipment. Wheels and Mirrors In 1849, Armand Fizeau sent a beam of light through a rotating wheel with a large number of teeth around the outside. A mirror on the other side reflected the beam each time a gap appeared in the path of the light. Fizeau realized that if the wheel rotated fast enough, the return beam would be blocked by the next tooth as it came around. So he varied the speed of the wheel until the reflected beam disappeared, performed a bit of math, and got a result of 315,000 km/second (195,732 miles/second)—certainly in the ballpark. Meanwhile, Foucault was working on a different but equally clever technique, which he demonstrated the following year. Foucault’s method was to shine a sharply focused beam of light onto a rotating mirror, and from there onto a fixed mirror. Once the light hit the fixed mirror, it bounced back onto the rotating mirror and then back toward the source. But because the mirror was rotating, the angle at which it was positioned had changed slightly by the time the beam made its return trip. Consequently, the reflected beam did not line up precisely with the original. Foucault could easily measure the angle between the original light source and the reflected beam, and along with known constants (the distances between the various surfaces and the speed of the mirror’s rotation), it was a matter of a few straightforward calculations to convert that small angle into a representation of speed. Using this technique, Foucault produced a measurement of 298,000 km/second (185,167 miles/second), which is shockingly close to the modern measurement of 299,792 km/second (186,282 miles/second), keeping in mind that the latter figure applies only in a vacuum; light travels more slowly in air. As for the tuning fork…Foucault used this to regulate the speed of the rotating mirror. The apparatus that turned the mirror made a sound that varied with its speed; when the sound exactly matched that of the tuning fork, Foucault knew precisely how many revolutions per second it was making. Interestingly, in 1926 scientist Albert Michelson made a more refined version of Foucault’s apparatus. Using the best equipment available in his day, Michelson measured the speed of light at 299,796 km/second (186,285 miles/second), amazingly impressive for a mechanical measurement. Many other methods for measuring the speed of light followed, and thanks to improved optics, precision measuring devices, lasers, and digital timing equipment, scientists have arrived at a more accurate figure. But not that much more accurate, after all; Foucault did his profession proud. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/01/Foucault.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/01/Light_Speed.40ac6b5b7c05.mp3"
	},
	{
		"title": "Monolithic Concrete Domes. Creating buildings out of thin ",
		"text": "Like many people, I fantasize about one day owning my dream house. Perhaps I have hobbit blood; for me, the idea of a cozy and inviting dwelling is one without many right angles, giving it an organic, somewhat cavelike feel. Although I have always lived in buildings with conventional vertical walls, I picture a home in which each room is a different shape, with rounded corners, curved ceilings, and angled doors. In a concession to gravity, I’ll leave the floor flat and level for the most part. Without a doubt, at least one room must be completely circular—no matter how hard it is to buy furniture or hang artwork. And of course, my ideal home would be sturdy, secure, economical to build, and highly energy-efficient. All these tastes would seem to make me an excellent candidate to own a monolithic concrete dome house. Like geodesic domes, this type of building encloses a large amount of area with a minimum of material and offers a distinctive, unconventional shape. Despite these similarities, the two types of dome building are very, very different when it comes to construction materials and techniques, not to mention some of the characteristics of the finished product. A Dome Idea The word “monolithic” in this sense simply means “in one piece”—not necessarily massive. As compared to geodesic domes constructed out of hundreds of triangular pieces of wood or metal, a monolithic concrete dome is a single, contiguous surface of (reinforced) concrete. What makes these domes particularly noteworthy is the modern method of building them. In decades past, building a concrete dome meant creating a pile of dirt in the desired size and shape, pouring concrete over it, and then digging out the inside after the concrete had set. This was a long and labor-intensive process—and it required you to have a sufficient quantity of earth at your disposal as well as the means of moving (and removing) it. Thanks to a patented process invented in the late 1970s, monolithic concrete domes can be built in a matter of days without any heavy equipment at all. The secret is to build it from the outside in. Inflated Benefits The process begins with a fairly ordinary concrete foundation—typically in the shape of a ring. A heavy-duty, dome-shaped “balloon” known as an airform is affixed to the foundation and inflated by special fans. Using a spray pump, the builder applies a thick layer of polyurethane foam to the inside of this balloon; the foam provides insulation as well as a bit of structural support for the remainder of the building process. Next, the builder attaches a steel rebar framework to the inside of the foam, and finally applies a sprayable concrete mixture known as shotcrete. The shotcrete reaches a thickness of about 3 inches (8cm), embedding the rebar and forming a reinforced concrete shell. Then the fan is turned off and the interior and exterior of the dome are finished using conventional materials (such as stucco). The airform, by the way, remains permanently in place, serving as an extra moisture barrier on the outside of the dome. Concrete domes are strong—highly resistant to damage by earthquake, hurricane, or wind (even tornadoes). Because concrete is not flammable, the shell itself is fireproof, and also invulnerable to termites and other pests. And since concrete is a good insulator, monolithic concrete domes are extremely energy-efficient. Although the materials used to build a concrete dome are expensive, you need relatively little of them, so the cost of a monolithic concrete dome is comparable to that of a wood frame building of similar size. Because the cost savings increase with the size of the building, concrete domes are becoming an increasingly popular choice for churches, gymnasiums, arenas, storage facilities, and even airplane hangars. Concrete Examples For all their benefits, though, concrete domes are by no means perfect. For instance, they tend to trap moisture inside, making a dehumidifier or air conditioner mandatory except in very dry climates. And of course they have the same problems all dome houses have. Their geometry does not work well in narrow urban lots. Furnishing, decorating, and cleaning a dome home can be challenging. You may have difficulty obtaining financing or insurance for such a nonstandard design. And you may have to contend with neighbors who are concerned about their own homes' resale value with that alien spacecraft parked next door. But a “dome” need not look that unusual after all. The airforms used to create monolithic concrete domes can be made in nearly any shape. Although you probably wouldn’t use them to make a cube, there’s no reason a building made in this fashion has to be a perfect dome either. A single custom-made airform can also be used to make a series of interconnected domes, and can include extensions, insets, cutouts, and augmentations—making it possible to integrate doorways, window frames, carports, or anything else you’d like into the shell of your building. On that hypothetical future day when I can afford to build the home of my dreams, I may or may not choose a monolithic concrete dome. Pyramids have a lot going for them too, and then there’s always the classic elegance of a castle. I’ll cross that drawbridge when I get to it. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/01/house.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/01/Monolithic.bec70c42edd7.mp3"
	},
	{
		"title": "Pie Funnels. A piecrust’s best friend",
		"text": "Cherry pie has always been one of my favorite desserts, and this preference was only reinforced by my repeated viewings of the TV series Twin Peaks. A few years ago I had the pleasure of meeting Pat Cokewell, erstwhile owner of the Mar T Cafe (now called Twede’s) in North Bend, Washington. The Mar T achieved fame as the “RR Diner” on Twin Peaks, and it was Pat’s cherry pies that inspired director David Lynch to make the diner (and the pies) a central feature of the show. The cherry pies Pat bakes are indeed unimpeachable (and I’m sure even her peach pies are excellent). After sampling them I decided to teach myself how to bake cherry pies, and while I can’t yet claim to match Pat’s expertise, I’ve done OK. The Crust of the Matter The crust, of course, is the trickiest part of the pie to master, and I’ve messed up more than a few. In the course of my pie experiments, I’ve accumulated a pretty thorough collection of pie paraphernalia—a variety of pie pans, weights that are used to hold down a crust when baking it “blind” (without a filling), the special metal guards you put over the edges to keep them from burning, and so on. I considered myself quite well versed in the apparatus of pie-making until my wife came back from a trip to a large kitchen store with a shocking discovery: there was a Pie Thing I didn’t yet have, and indeed had never even heard of. It’s called a pie funnel. My first thought upon hearing the term “pie funnel” was confusion at why someone would want to pour a pie into a bottle. Then I discovered that pie funnels are in fact devices designed to improve the top crust of a pie as it bakes. When you put a crust on top of your pie filling, you’re creating a sealed vessel containing a lot of moisture. As the pie bakes, some of that moisture turns to steam—and if the crust is completely sealed, the steam pressure can blow a hole through it, covering the inside of your oven. This is why lattice piecrusts were invented: not only do they look impressive, they leave plenty of holes for the steam to escape. But there’s more than one way to skin a pie. Four and Twenty Ceramic Birds Baked in a Pie A pie funnel is a hollow ceramic doohickey (to use a highly technical pie term) that stands a few inches high, with one or more openings near the bottom and a vent at the top—thus approximating the design of an upside-down funnel. In fact, the exact shape of a pie funnel is irrelevant; they are often made in the shape of birds (and called “pie birds”), but you can also find gnomes, chess pieces, and a variety of other designs that serve the same purpose. To use a pie funnel, you cover the bottom of the pie pan with dough as usual, place the funnel in the middle, and pour the filling around it. Then you lay on the top crust, with the pie funnel poking through and its top vent exposed; for best results, pinch the crust around the outside of the pie funnel to seal it. As the pie bakes, the pie funnel vents steam from inside the pie, which helps to keep the crust from splitting, prevents the filling from boiling over, and serves to reduce and concentrate the juices. It also supports the top pie crust, keeping it from sagging into the filling and getting soggy. Depending on the shape of the pie funnel, you may or may not be able to remove it before slicing the pie. Either way, your pie will be a little goofy-looking, but that’s a small price to pay for an otherwise perfect crust. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/01/pie-funnel.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/01/Pie-funnel.343e4c329b99.mp3"
	},
	{
		"title": "Grass Photographs. Photosynthetic art",
		"text": "When I was about 12 (give or take a couple of years), I had what I thought was a fantastic idea. I was going to build myself a volcano. I’m not talking about a little model made out of clay with vinegar and baking soda for the special effects. I wanted to construct a dirt cone in the backyard that was hollow inside and large enough to use as a clubhouse. I was a bit sketchy on the actual structural details, but I figured I’d start by digging a nice big pit, then add some sort of frame and cover it over with the dirt I’d removed previously. So I got an old piece of garden hose and formed it into a circle about 15 feet (5m) in diameter on the lawn to mark the perimeter of the volcano. The actual digging turned out to be a lot harder than I’d imagined—so hard, in fact, that after shoveling about two scoops of dirt I decided I’d better take a break. Weeks later, when I still hadn’t resumed my project, my mother told me to get that hose out of the middle of the yard, and while I was at it, mow the lawn. Reluctantly, I put the hose away, only to find it had left an unsightly yellow ring on the grass. It looked as though a flying saucer had landed, and the ring didn’t fade until the following spring. I was embarrassed at both my inability to build my volcano and the condition of our lawn. It never occurred to me that with a bit more effort, I could have turned my blunder into a huge piece of art—say, a smiley face or a basketball. Just as well; I think my parents would have frowned on that. But nowadays, grass art—based on the very same principle I unwittingly discovered—has reached an exceptional level of sophistication, as artists create giant, stunningly detailed photographs on living grass. The Grass Is Always Greener When grass gets plenty of sunlight, it produces chlorophyll and therefore turns green—but the less light it receives, the more yellow the color is. British artists Heather Ackroyd and Dan Harvey discovered that by projecting a bright black-and-white negative image onto a patch of grass as it grows (in an otherwise dark room), they can use the natural photosensitive properties of the grass to reproduce photographs. When I saw one of these grass photos on display at a museum, I was utterly captivated. From a distance it looks like any other monochrome photograph (albeit with a slightly unusual tint); up close, it looks like perfectly ordinary grass. But even individual blades sometimes have a range of hues, as any given cell can respond to the amount of light it receives. Ackroyd and Harvey stumbled onto this technique after producing an installation that involved covering an indoor wall with living grass. A ladder was leaning against the wall, and the artists noticed that even after it was removed, a faint outline of the ladder remained on the grass. They set about experimenting with ways of enhancing this effect, and soon they were using a slide projector as an artificial light source for growing their unique photographs. A typical exposure time is just over a week, with the image projected for 12 hours a day. It’s an Art and a Science At first, the grass photos faded within several days, as the grass adapted to the light conditions in the place where it was exhibited. Ackroyd and Harvey began looking for ways of increasing the longevity of their images, and they found a genetically modified strain of grass called stay-green. Engineered by researchers at the Institute of Grassland and Environmental Research (IGER) in Wales, stay-green grass cannot break down chlorophyll easily and thus retains most of its green color—even after it’s dead. When using stay-green grass as their medium, Ackroyd and Harvey dry out their grass images rapidly as soon as they’ve matured. Although this kills the grass, the images remain visible for years, rather than days. The IGER scientists working on stay-green grass were impressed with the artwork to which their product had contributed. And while looking at some digital images of the grass artwork, they came up with yet another innovation—a noninvasive way to study the chemical changes in the pigments of leaf cells as they age. Their technique, called hyperspectral imaging, relies on a computer to analyze colors that are too similar to be distinguished by the human eye. So science contributed to art, which in turn contributed to science—and sure enough, this additional research has inspired the artists to explore new creative directions. Ackroyd and Harvey have done grass art installations all over the world. They are especially proud of the fact that although their medium is by nature temporary, the images can be regrown at any time. Some of their most famous pieces have been recreated several times already. If I ever have enough money to commission a work of art, I’m going to ask them to grow me a photograph of a volcano. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/01/grass.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/01/Grass.723d29719191.mp3"
	},
	{
		"title": "The Holographic Paradigm",
		"text": "I’ve always fancied myself an amateur theoretical physicist, so I’m a sucker for any book that claims to explain the mysteries of the universe in laymen’s terms. Such was the case with a book I read in the early 1990s called The Holographic Universe, which promised “a remarkable new theory of reality.” The book was not written by a scientist and therefore turned out to be a bit light on scientific detail. But it was to be the first of several books I’d read about an intriguing theory known as the “holographic paradigm.” The New Physics To set the stage, let’s turn back the calendar to the mid-1970s. In science, quantum physics was the hot area of research. Eastern religions, meanwhile, were moving into the mainstream in North America, and the New Age movement was in full swing. It was only a matter of time before science and mysticism converged. Books such as The Tao of Physics by Fritjof Capra in 1975 and Gary Zukav’s The Dancing Wu Li Masters in 1979 pointed out startling parallels between recent discoveries in quantum physics and ancient beliefs of Taoism, Buddhism, and Hinduism. Serious scientists were beginning to sound like mystics, and mystics were starting to talk about subatomic particles. The “new physics” seemed poised to bridge the world of faith with the world of science, through a common belief in a fundamentally interconnected universe. One of the most interesting notions to emerge from this shiny happy alliance was a particular model of the universe that seemed to explain not only puzzling scientific phenomena but psychic experiences as well. The holographic paradigm was so named because its central metaphor is that of the hologram—or, to be more specific, a certain very unusual feature of holograms. The Magic of Holograms The basic process for creating a hologram involves the use of a laser and a beam splitter, an optical device that sends half the light in each of two directions. One of the beams illuminates the object you’re recording, and the light reflected from the object collides with the second beam. When these two beams meet, the effect is much like what you’d see if you tossed a pebble into a pond and then, as the ripples were still spreading, tossed in another pebble. The pattern formed where the two sets of waves meet is called an interference pattern, and that is what is recorded on film when a hologram is made. Today it’s common to see reflective holograms that can be viewed under ordinary light. Originally, however, holograms could be viewed only by exposing the film to the same type of laser light used to create it. If you were to look at the film with the naked eye, all you’d see would be patterns of ripples; shine the right kind of light onto it, though, and the image emerges in all its three-dimensional glory. This type of hologram has another very curious property. If you cut the film in half and then expose just one piece to the laser light, you’ll still see the entire image. In fact, you can keep making smaller and smaller pieces, and each one will still display the whole image rather than just part of the image—though the clarity degrades as the pieces get smaller. This “whole-in-each-of-the-parts” quality of holograms provided the crucial insight for Karl Pribram, a neurophysicist at Stanford University, and David Bohm, a physicist at the University of London. Each was trying to solve a different type of problem, and the hologram suggested just the answer they were looking for. Building the Holographic Paradigm Pribram was studying the way memories are stored in the brain. Until the second half of the 20th century, conventional wisdom held that memories were localized—stored in a specific group of neurons. But experimental research showed otherwise. Rats were taught to run a maze, then had portions of their brains surgically removed. No matter which part of the brain was removed, the rats still remembered how to run the maze. Likewise, humans with brain injuries or who had portions of their brain removed for medical reasons never lost memories selectively (as in forgetting half of a story)—though overall memory sometimes became hazier. This reminded Pribram of the way holograms work, and he began to suspect that the brain stores memories in a way analogous to holography: by recording diffuse patterns of electrical waves. Meanwhile, David Bohm, who was famous for his work in quantum physics, was taking the metaphor of the hologram in a different direction. He was trying to make sense of the behavior of subatomic particles, which have annoying tendencies to appear and disappear spontaneously, to resist measurement, and to manifest sometimes as particles, sometimes as waves. His idea—arrived at after many years of thought and research—was that the universe itself is something like a hologram. What we perceive as reality is essentially an illusion, like the three-dimensional image of a hologram. “Real” reality, meanwhile, is analogous to the film—a vast pattern of intersecting vibrations in which each part in some way contains the whole. Bohm called the world of sensory experience the “explicate order” and its underlying reality the “implicate order.” According to his theory, the universe is a dynamic series of movements—folding into, and unfolding out of, the implicate order. Bohm coined the term “holomovement” to describe the universe in this way, as “hologram” implies a static image. When Pribram found out about Bohm’s work he was very excited, and these new insights led him to generalize his theory even further. If the whole universe were a holomovement, with every part containing the whole, perhaps our brains actually construct reality as we go along. To put it differently, maybe everything we perceive as real may be nothing more or less than an unfolding of an underlying essence in the implicate order. It is as though only the patterns of vibrations are ultimately real, with all of time and space equally present everywhere in the fabric of the universe. Implications of the Implicate Psychics and New Age types were quick to latch onto this notion. The holographic model, taken to its logical conclusion, could explain a wide range of phenomena such as precognition, telepathy, poltergeists, lucid dreaming, and near death experiences, to say nothing of religious and mystical experiences. The theory is that our brains habitually unfold the implicate order in predictable ways, but as we can change the frequency or angle of a laser beam, perhaps we can experience other places, times, and knowledge—all equally present everywhere in the holomovement—given the right circumstances. This was the major thrust of The Holographic Universe. Author Michael Talbot took the holographic model well beyond what Pribram and Bohm outlined to explain a vast array of paranormal phenomena. Renowned philosopher Ken Wilber, who edited the book The Holographic Paradigm, takes a contrarian view of the model’s viability. He thinks it’s worthwhile in a limited sense, but considers it a grave mistake to apply the model too broadly, or to read too much into it. He resists, for example, attempts to equate the implicate order with God or Brahman. And he worries about trying to understand something transcendent (or transmental) in mental terms. If you want to have a transcendent experience, he says, that requires the long, hard work of spiritual transformation—not simply learning to picture the world differently. The holographic paradigm—and, for that matter, the entire movement to integrate physics and mysticism—has lost a lot of steam over the last decade or so. Karl Pribram’s theories never found widespread acceptance; David Bohm died in 1992 without convincing many physicists of his views; and most of the prominent advocates of the model have moved on to other interests. It’s not that the theory is any less interesting or plausible than it ever was, but there’s just not a whole lot one can do with the notion. Supposing the universe really were something like a hologram, what would that mean in a practical sense? And how could it ever be proved or disproved? It is certainly fascinating to ponder a unified theory that explains the mysteries of physics, time, space, consciousness, and mysticism. But just as you can’t build muscles by studying exercise, you probably won’t master the workings of the implicate order by reading about it. ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/01/Holographic.f09aae43a828.mp3"
	},
	{
		"title": "Global Energy Network",
		"text": "R. Buckminster Fuller, a brilliant engineer, designer, and philosopher who lived from 1895–1983, is best known as the inventor of the geodesic dome. More recently, a spherical carbon isotope whose molecules resemble the dome was named Buckminsterfullerene, or “Bucky ball” for short. The dome was certainly an important invention, illustrating Fuller's intensely logical mode of inquiry: How can basic geometric principles be employed to enclose the maximum amount of space with the minimum amount of weight and materials? His solution, a clever arrangement of interlocking triangles, was elegant and beautiful. And yet, it's unfortunate that many consider this Fuller's claim to fame. Geodesic domes—once thought to be a trendy and futuristic design for homes and public buildings—are now seen as rather passé, a quaint artifact of outdated aesthetic sensibilities, like tail fins on cars and beehive hairdos. By inference, their inventor is sometimes regarded as a wacky innovator who was perhaps out of touch with reality. But Fuller's career involved a great deal more than domes. It is quite true that some of the ideas he investigated were wacky and out of touch with reality—but only because they were based on logic and common sense, which have always been unstylish. Fuller's work included a great many inventions and architectural innovations, a distortion-free map of the world called the Fuller Projection, dozens of books, and tireless efforts to solve basic human problems such as shelter, transportation, and food distribution. His proposed solutions to many serious problems can be shown mathematically or statistically to be workable, but very few of them have made their way into actual use. Fuller assumed that humans would always choose the most efficient and economical solution to a problem if they were shown logically what it is; he did not, however, count on the reality that hard facts are seldom a motivating factor—especially at the level of national and international politics. Such has been the case with one of Fuller's most ambitious ideas, that of interconnecting the world's electrical energy grids. The World Game In order to explain what a global energy network means and why it is such a good idea, I should take a step back and describe the World Game. Buckminster Fuller devised the World Game as a thought experiment intended to be carried out by a group of people. Before the game begins, information about all the world's resources—both physical and metaphysical (by which he meant knowledge and skills)—is entered into a computer, along with data on human survival needs. Teams then work together, using this information to create a simulation of how the resources could be manipulated in such a way as to “make the world work for 100% of humanity, in the shortest possible time, through spontaneous cooperation, and without ecological offense or the disadvantage of anyone.” In other words, participants are supposed to find a way for all the world's people to have food, shelter, safety, and even happiness, with only the resources actually available and with no harm to the environment or other people. As a learning exercise, the World Game is both effective and entertaining, and has been used countless times over the last several decades by universities, corporations, and informal groups. It teaches principles of economics, management, and even sociology. But what's most striking about this simulation of the world is the result it consistently produces. Based on the findings of the World Game, Fuller determined that the world's resources are sufficiently vast that every single person on Earth can live comfortably—with adequate amounts of food, personal space, and leisure. The catch, of course, is that the resources would need to be distributed and managed in a way that is at odds with reality. As long as small numbers of wealthy, powerful people insist on remaining disproportionately wealthy and powerful at everyone else's expense, the idealized solutions of the World Game will be difficult to achieve. More Power To You Be that as it may, one of the specific insights of the World Game involves electricity. Most people would probably say that food, water, medical care, and shelter are far more urgent human needs than electricity. But Fuller believed that the universal availability of affordable electricity was the main thing separating the western world from so-called developing nations. He reasoned that electricity can make the production of food and safe water much easier, and facilitate health care, transportation, and communication. In addition, electricity makes possible a level of economic development that can address these basic issues indirectly. Even though two billion people currently do not have access to electricity, the world's power plants have more than enough capacity to supply the entire planet's needs. The problem, according to Fuller, is that they're just not used efficiently. A given generator will produce a relatively constant amount of electricity, whether that power is used or not. If demand dips, the extra power goes to waste—and the power company loses potential profits. This effect is especially apparent at different times of the day—when it's daytime in one area and electrical demand is high, it's night somewhere else and demand is low. The solution to this imbalance is well known and has been used successfully for decades: interconnecting power grids from different areas. Thanks to technology that allows electricity to be transmitted over distances as far as 4,300 miles (7,000km), electricity can be shared across time zones or even seasons. So all across North America and Europe, local and regional suppliers have made arrangements with each other to balance the load. This results in more consistent availability of power, lower and more uniform costs, and a reduction in the number of generating plants needed. (It has also famously resulted in some widespread blackouts, but these could have been prevented with updated equipment and better monitoring procedures. ) Getting Their Wires Crossed Unfortunately, the parts of the world that would benefit most from sharing electricity can't do so. If rural northern Africa, say, could share power with western Europe, electricity would become more pervasive in Africa and less expensive on both continents. Taken to its logical conclusion, a completely interconnected global electrical grid would improve the quality of life for nearly everyone, while providing essential development infrastructure (and an additional source of revenue) for the places that need it most. It would also benefit the environment, reduce hunger, and foster international cooperation and goodwill. That may sound idealistic, and it is. But the barriers to such a system are not technological, merely political and ideological. In order for any two nations to agree to interconnect their power grids, they need the political will to invest money in the infrastructure, which can be hard to come by when limited budgets are strained to meet needs that seem more pressing. But it also requires a degree of mutual trust. If one nation relies on another's electricity—even if only a portion of the time—they need to feel comfortable that it won't suddenly disappear due to hostilities or political disagreements. In addition, nations whose governments tightly control utilities would effectively lose some of that control. Even a significant cost savings is a weak motivator when political power is at risk. GENI and the Magic Lamp Even so, numerous people are working earnestly to make the vision of a universal energy grid a reality. Global Energy Network Institute, or GENI, is a nonprofit organization based in San Diego. Their mission is to educate the public about the idea of a global energy grid and work with governments, utilities, and international organizations to encourage its adoption. The work is slow, unglamorous, and often thankless. But the lesson of the World Game—that science and common sense can ultimately make the world a better place—is hard to ignore. Even if the global energy network became a reality, that would be only a small step toward winning the game, but it's an important one. In a time when it's fashionable to talk about a wired world as being one where everyone has a cell phone or internet access, it's worth remembering that the electrons that power those gadgets all need to come from somewhere. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/01/Bucky-ball.JPG",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/01/Global.2c1732638934.mp3"
	},
	{
		"title": "The Girolle. One small step for cheese engineering",
		"text": "Switzerland is a country known for, among other things, cheese and engineering. These are two concepts that, while important individually, generally do not go together. (In fact, I have been wary of cheese engineering ever since I read The Absurdly Silly Encyclopedia and Fly Swatter by Jovial Bob Stine in 1978. It cautioned the young reader not to build a raft out of cheese, because cheese does not float.) Nevertheless, the great minds of Switzerland have produced a fascinating, interdependent pairing of cheese and machine, neither of which is complete without the other. As both a cheese lover and a gadget lover, I was delighted to discover a unique device called a Girolle. It’s the world’s most clever cheese slicer, and it’s designed to work with just one very special kind of cheese. Not Your Father’s Cheese Growing up in the United States, I was conditioned to think of cheese as an ingredient or a topping, not as an independent food. Macaroni and cheese, cheeseburgers, cheese pizza, cheese puffs, and Parmesan sprinkled on spaghetti—these were cheese to me. I turned up my nose at sliced cheese served on a cracker, which seemed unnatural. Everyone knew that the cheese on your cracker was supposed to have been squirted out of a can. Europeans, however, take cheese much more seriously. A proper French meal, for example, always includes a cheese course, and in many parts of the continent it is customary to have several cheeses at breakfast. Now that my culinary sensibilities have evolved considerably, I have developed quite a fondness for cheese, and my refrigerator usually has quite a few choices, ranging from soft to hard, mild to smelly. In fact, when my wife and I were looking for the apartment where we now live, the presence of a good local cheese shop was a strong selling point for the neighborhood we chose. A few years ago on a trip to Switzerland’s capital city of Bern, some friends introduced me to a type of Swiss cheese I had never encountered before. It’s called Tête de Moine, or Monk’s Head cheese. Superficially, it’s a firm, whitish cheese with a brown rind. It would be easy to overlook if you found it in a store. What makes this cheese special is the way it is served. According to tradition, this cheese must never be cut. Instead, you must first slice off the top rind of a whole cheese, then for each serving, scrape a thin layer from the top of the round, working at an angle so as to make the edges crinkle. This forms the cheese shaving into a small flower shape called a rosette. Besides giving your cheese an ornamental appearance, this technique is said to bring out the flavor and aroma in a way that ordinary slicing would not. Although labor-intensive, this method of serving Tête de Moine goes back centuries. They Call It “Head” Cheese Near the town of Bellelay in the lush mountains of Switzerland’s Jura region, Tête de Moine cheese was invented over 800 years ago by the monks of the Bellelay Abbey. Eventually, the monks began to teach the local farmers how to make the cheese, which was at first simply known as Bellelay. After the French Revolution, the name of the cheese was changed to Tête de Moine. There are two competing theories as to the origin of this name. According to one story, the monks charged the farmers what we would today call a license fee: in return for permission to make the monks' special cheese, the farmers had to give the abbey one cheese each year per monk; hence, “Monk’s Head.” A more colorful theory—and what I had always assumed to be the case—was that the cheese was called “Monk’s Head” because that’s what it looks like. The traditional monastic haircut, called a tonsure, is a shaved crown (leaving a ring of hair around the outside). Because Tête de Moine cheese always has a round white top surrounded by a ring of brown, the association is easy to see. The Perfect Shave Although Tête de Moine and its preferred serving method have been around for a long time, it was not until 1982 that cheese shaving met modern engineering and Bellelay’s cheese industry really took off. Nicolas Croiviser, a craftsman from the nearby town of Lajoux, had a large family of cheese lovers, and wanted to find a more efficient way of shaving large quantities of Tête de Moine. His first idea was to mount a blade on a rotating handle suspended above the round of cheese. This worked, but still somewhat awkwardly. Then Croiviser had the insight to flip the axis upside down, turning it into a spindle. Pop the cheese right onto the spindle, slide on the handle, and you can crank out cheese flowers to your heart’s content. Thus the Girolle was born. Ever since, the patented Girolle has been distributed by a local mechanical products manufacturer called Métafil-laGirolle. At first, the company thought they may sell a few thousand; according to their Web site, more than two million have been sold to date. This is all the more remarkable when you consider that a Girolle, consisting of just a few simple pieces of wood and metal, typically sells for upwards of US$75. Given the modest cost of goods, this simple device has made its inventor an enormous amount of money, not to mention boosting the popularity of Tête de Moine cheese. You Can Even Eat It With all the fuss over the appearance and preparation of Tête de Moine, you may wonder if it actually tastes any good. It does indeed. It has quite a strong, sharp flavor and aroma that has been described variously as “spicy,” “nutty” (or “almond-like”), “fruity,” and even “beefy.” (It seems somehow incestuous to refer to a milk product as “beefy,” but maybe that’s just me.) In any case, it is generally regarded as the strongest Swiss cheese, and it contrasts nicely with milder varieties like Emmenthal and Gruyère. Tête de Moine is often served with fruit or fresh French bread, or simply as a decorative yet edible garnish for a cheese platter. Today, Tête de Moine cheese is still produced by small local dairies near Bellelay. (The Bellelay Show Dairy even has a Tête de Moine museum, with cheese-making demonstrations each Wednesday and Saturday afternoon.) The cheese is made as it has been for centuries from raw, unpasteurized cow’s milk curded by the addition of natural rennet. It is then formed into a roughly one-kilogram cylinder and aged for three to six months, with periodic brine rinses to enhance the curing process. If you don’t happen to live in Switzerland, never fear: Tête de Moine cheese is exported all over the world. Any good local cheese shop should have it, or at least know where to get it. Failing that, many online retailers sell both the cheese and the Girolle (sometimes even as a set). One suggestion, however: if possible, smell before you buy. I have occasionally purchased Tête de Moine cheese and found it to have an overpowering odor of ammonia. This is a bad sign; it most likely means the cheese was stored improperly. Just as important, if you plan to serve your cheese using a Girolle (as you should), be sure to get either a full cheese or a round sliced latitudinally. A wedge—excuse me—just won’t cut it. Tête de Moine cheese needs a Girolle, and a Girolle needs Tête de Moine—no other cheese has just the right characteristics to make this sort of cheese flower. This perfect combination of food and machine truly warms my heart. The science of cheese engineering is clearly off to a good start ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/11/01/Girolle.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/11/01/girolle-2.d02513110bac.mp3"
	},
	{
		"title": "Piñatas. History of a breakthrough",
		"text": "I can’t remember when I first learned of the existence of piñatas, but it must have been at a very early age. Perhaps a kindergarten teacher was demonstrating papier-mâché and told us that people sometimes use it to make colorful candy jars that you can break open with a stick at a birthday party. There’s nothing about this concept that any kid wouldn’t appreciate. Candy: good. Party games: good. Wanton destruction of decorative objects with full parental consent: good. All in all, a great concept, and I always wondered why I didn’t get to have one at my birthday parties. Then one day, I went to a friend’s birthday party and had my first and only hands-on experience with a piñata. In fact, “hands-on” is an exaggeration. Like each of the other children, I was blindfolded, spun around, and allowed three swings with a long stick in what I could only guess was the right direction. I didn’t break the piñata; I don’t think I even hit it—the adult who was tugging at the rope from which the piñata was suspended to “make the game more challenging” saw to that. Then it was the next kid’s turn, and he had essentially the same experience. Finally, the birthday boy had his turn, and in what can only be described as an incredible coincidence, he managed to beat the stuffing out of the thing. Did I then at least get my fair share of the spoils? I did not. Being the deferential type, I did not push and shove to gather up the candy, and by the time I got to it, all the good stuff was gone. By the end of the party I had completely revised my opinion of piñatas as being a really bad idea. As Italian as Pasta By the time I visited Venice a few years ago, I had completely suppressed this unhappy memory. I saw the house reputed to have been Marco Polo’s, and thought that was pretty cool. I never guessed that this legendary explorer may have been to blame for yet another of my childhood traumas. In North America, most people think of the piñata as a Mexican phenomenon (albeit one that has become ubiquitous among other cultures as well). And so it is, but it took a rather circuitous path to get there—from, of all places, China. Probably. While researching the origin of the piñata, I found a number of conflicting claims. Although pretty much everyone agreed that the piñata was brought to Mexico by the Spanish, some sources traced its ancestry from Spain back to Italy. Others said piñatas came from Italy, yes, but not originally—that Marco Polo discovered them in China and brought them to Italy on one of his excursions. Still others claimed that the piñata can be traced to rituals performed in parts of Africa well before it appeared in China. As near as I can determine—and bear in mind, I’ve performed just a few hours of fairly casual research on the subject—the history of the piñata as we know it today did indeed begin in China (at least as far back as the 12th century). A figure in the shape of an animal such as an ox or buffalo was filled with seeds and broken to celebrate the coming of spring. During the Renaissance, a variation on this custom appeared in Italy—though whether Marco Polo was truly responsible for its importation is a matter of some dispute. One way or another, the Italian pignatta came to be a clay pot—often in the shape of a pineapple, not an animal—filled with trinkets rather than seeds. It was ceremonially broken on the first Sunday of Lent, so rather than having a merely seasonal symbolism it came to have religious significance as well. From Italy the pignatta spread to Spain, where it took on a more ordinary shape, and apparently underwent a linguistic change as well. The term piñata came to be used not for the pot itself (called la olla), but for the game or ritual of breaking it. And the contents tended to be sweets, though the Spanish retained the pignatta’s association with Lent. Eventually, the clay pots started to be covered with colored paper and other decorations, approximating their modern appearance. Jars of Clay Spanish missionaries brought the piñata to Mexico as, of all things, an evangelistic tool. Apparently a similar ritual had evolved independently among both the Maya and the Aztecs. In the native Mexican tradition, a clay pot filled with trinkets was set on a high pole and broken in mid-December as part of a ritual honoring the birthday of Huitzilopochtli, the Aztec god of war. The Spanish co-opted this concept as part of their Christmas celebration, assigning Christian meanings to the ritual. The pot came to represent the devil, and striking it was symbolic of overcoming evil. At some point, the standard Mexican piñata design came to be a sphere with seven conical points—a shape that, depending on who you ask, was meant to represent the Star of Bethlehem (as appropriate to the Christmas story) or the seven deadly sins (as appropriate to the defeat of evil). The tradition of designing piñatas to look like cartoon characters and other distinctly nonreligious forms is a relatively recent occurrence, dating back only to the early 20th century as far as I can tell. The switch from paper-covered clay pots to papier-mâché is even more recent, and may have occurred to satisfy the growing demands of American tourists wanting cheap souvenirs from Mexico. Meanwhile, the religious significance has all but disappeared, and though the piñata is still frequently associated with Christmas in Mexico, it’s equally common at birthday parties and other celebrations throughout the year. Of course, you’ll never see a piñata at my parties, because after much soul-searching, I’ve decided I’m opposed to violence against hollow paper containers. But more importantly, think of all that innocent candy inside. The risk of collateral damage is just too great. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/10/31/pinata.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/10/31/Pinatas.b4e946f69f07.mp3"
	},
	{
		"title": "English Spelling Reform",
		"text": "The difficult path to simpler spelling Allow me to open a very large can of worms. English spelling, as virtually everyone will admit, is absurdly complicated—and much more so than that of most other modern languages. While this situation may be good for editors and those who make dictionaries and spelling checkers, it's bad for nearly everyone else. People learning English—whether as a first language or later in life—struggle to memorize innumerable exceptions to an already long list of spelling rules. But those of us who have known the language all our lives also struggle constantly to write it correctly, lest we embarrass ourselves or betray a lack of attention to detail. Why do we all endure such pain? It seems pointless. And so, as many language authorities have proposed over a period of more than 200 years, why not simply fix it? Why not simplify English spelling so that it looks the way it sounds, and make the entire problem go away? Spelling reform has occurred in other languages, with dramatic results in improved literacy rates and easier communication for everyone. Isn't it about time we did the same thing for English? At first blush, this seems like a no-brainer, a long-overdue exercise—one that we might as well get out of the way now, because it will only be harder later on. And yet, beneath the surface of this noble idea lurk extraordinarily pesky issues. As annoyed as I get when I read misspelled words, and as sympathetic as I am to the plight of those trying to learn the language, I find myself very torn over whether I could actually support an official reform of English spelling. Wutz Rong With This Pikcher? The problems with English spelling, of course, are obvious with a moment's reflection. We have words with silent letters that serve no apparent purpose—such as the second l at the end of “pill” or the gh in the word “eight.” We have letters or groups of letters that are pronounced many different ways (or sometimes not at all). A good example is the letters “ough,” which are pronounced “oo” in “through,” “ou” in “bough,” “oh” in “though,” “uf” in “enough,” and so on. We have words with different meanings that are pronounced the same but spelled differently—think “there,” “their,” and “they're,” for example. And there are countless other examples. Such peculiarities in spelling, for the most part, serve no useful function, and simply add to the amount of work we all need to do in learning and using the language. A reformed, simplified spelling system would resolve all these annoyances and many others. Indeed, a certain amount of reform has happened all by itself over the years, as previously alternative spellings have worked their way into the dictionary as standard forms. Think of the word “catalog,” which was formerly spelled “catalogue,” or “draft,” formerly spelled “draught.” On a relatively small scale, sensible spellings do sometimes replace less sensible ones. However, this process has been hit-and-miss, with more misses than hits. The proposal, then, is that we systematically and definitively wipe out all the anomalous spellings in English so that anyone looking at a word in print will immediately know how to pronounce it—and, conversely, anyone attempting to write English will be able to get every single spelling right the first time. In other words, proponents of English spelling reform want us to adopt a (mostly) phonetic orthography, perhaps along the lines of what one finds in Spanish or Indonesian. Needless to say, though, it's not quite that simple. Fasing Douts The first question that arises is how far such a reform would go. For instance, we could make a good start by simply removing letters that are never pronounced. “Though” could become “tho,” “guard” could become “gard,” “foreign” could become “forin,” “doubt” could become “dout,” and so on. We could also, perhaps, reduce the number of ways to write any particular sound—so the “ee” sound in “street,” for example, might always be written “ee,” never “ea,” “ie,” “ei,” “i,” “e,” or whatever. Although these changes would help, however, they would solve only a subset of the problems—and the more extensive the changes are, the more difficult they would be for the public to accept. Consider the question of words that are pronounced differently in different situations. You don't even have to get into dialectal differences here—think of a word as common as “the.” If we're spelling it phonetically, which vowel do we put on the end? Or do we have two separate spellings—one for when it's pronounced “thuh” and another for when it's pronounced “thee”? In such cases, some reformers propose adopting a neutral spelling that, while perhaps not perfectly phonetic, can adapt itself to either pronunciation. Other reformers say that this is exactly the kind of problem we're trying to solve in the first place. Then there are those who point out that a word's spelling gives important clues to its etymology, meaning, and relationship to other words. So even though the “a” in the word “real” is not pronounced, it serves the important function of showing the word's connection to the word “reality,” in which the “a” is pronounced. Lose that letter, and the words no longer appear to have anything to do with each other. Thus, at least some of the peculiarities of English spelling exist for entirely legitimate, and still useful, historical reasons. Critics of this argument point out that English also has plenty of words whose spellings were entirely arbitrary—the word “receive” might just as easily have settled into the lexicon with an “ie” rather than an “ei,” and we can't blame such oddities on the words' derivations from other languages. Perhaps the most persuasive argument against spelling reform is that simplified spellings would be—at least initially—much harder for all the hundreds of millions of English readers to read, since we've already programmed our brains to work under the current, flawed system. There's also that little matter of what to do with the billions of books, magazines, Web sites, and other documents that already use the “old” spelling. The task of retooling them in a new spelling system is unthinkably huge, but if they remain in their current state and are expected to be readable, most people will have to be able to understand how to read both systems—an even larger cognitive burden than what we already have. Supporters of spelling reform admit that the transition process is bound to be difficult, but that in a few hundred years, our descendants will thank us and the world will be a happier place. I have no doubt that this is true. But if English were spelled the way it sounds, I'd no longer be able to make snap judgments about people's intelligence by observing their spelling skills. That may be too high a price to pay. ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/10/31/English.dc0b014f8243.mp3"
	},
	{
		"title": "English Female Social Titles",
		"text": "Miss-ing the point My wife kept her name when we got married. This being the 21st century, I wouldn’t have thought that would be in any way surprising or problematic. But in the modern English-speaking world, linguistic habits haven’t quite caught up with changing social conventions—many people (and computers) still assume that when a man and woman get married, the woman will take on the man’s surname. As a result, we get mail addressed to “Mrs. Morgen Kissell” and even, bafflingly, “Mrs. Liz Kissell”—Morgen’s given first name is Elizabeth, but she has gone by her middle name since birth, and has never, ever been called Liz. At least no one, to my knowledge, has called her “Mrs. Joseph Kissell,” which I think both of us would find rather offensive. As annoying as such mistakes can be, I do sympathize with folks who no longer feel they have a proper, respectful, and appropriate title to use when addressing women. The title “Miss,” which used to refer to an unmarried woman of any age, has fallen into disfavor, except for young girls. And “Mrs.” is supposed to refer to a married woman, but only when using her husband’s last name. (Morgen certainly is neither “Miss Jahnke” nor “Mrs. Kissell,” but she can’t be “Mrs. Jahnke” either, because that would imply my last name is Jahnke.) So that leaves “Ms.,” which virtually every style guide now proclaims as the only reasonable choice, but which many people hesitate to use because it feels like an odd, newfangled, non-word. Stress and Mistress The basic distinction between “Miss” and “Mrs.” harks back to earlier times when a woman’s marital status was an important indicator of her position—and when, more to the point, a woman was considered a subservient entity with respect to her husband. Interestingly, though, both “Miss” and “Mrs.” were originally shortened forms of the word “mistress.” The modern sense of “mistress” implies an illicit relationship, but before about 1600, a mistress was simply a female head of a household—married or unmarried. As a result, the abbreviation “Mrs.” would originally have been pronounced “mistress,” and would not have been used exclusively to refer to someone’s wife. The pronunciation “misses” was simply a contracted form of “mistress.” Meanwhile, when “miss” was first used as an abbreviation for “mistress” in the mid-1600s, it referred to a concubine or someone in a role more like what we would today consider a mistress. In other words, a few centuries ago, the meanings of “Miss” and “Mrs.” were, at least in some cases, roughly the opposite of what they are today! Only in the 19th century did “Mrs.” (with the pronunciation “misses” firmly established) come to refer exclusively to a married woman. There is also, of course, the title “Ma’am,” which was short for “madam.” Although few people refer to a woman as either “ma’am” or “madam” these days, the situation is parallel to “Mrs./mistress” in that the shortened form is considered respectful whereas the longer form sometimes denotes a woman of questionable character. The Long and the Short of It One of the things about “Mrs.” that has always bothered me is that it can really only ever be used in its abbreviated form. No one would spell it out as “mistress” anymore, and yet there is also no agreed spelling for the full word as it is pronounced; “misses,” “missus,” “missis,” and “missez” all seem wrong. The title “Ms.,” which came into use in the middle of the 20th century, has an even worse problem—it appears to be an abbreviation, but it isn’t short for anything. As with “Mrs.,” no one would know how to spell it out. “Mizz”? And yet, despite the fact that “Ms.” is clearly a modern, artificial conflation of “Miss” and “Mrs.,” it now serves the useful purpose “Mrs.” once did: it provides a respectful title that does not require the speaker to have any knowledge of the woman’s marital status or age. This is a good thing, because such distinctions, even if known, serve only to perpetuate the long-outmoded belief that adult women who are married are somehow socially superior to those who are not. In this respect, “Ms.” is actually a better title than “Mr.,” which says nothing about marital status but does presume the addressee to be an adult. A young girl could be a “Ms.,” but a young boy would not normally be called “Mr.” But then, perhaps such social titles have outlived their usefulness altogether. On Christmas cards, for example, since we can’t be “Mr. and Mrs. Kissell,” and since “Ms. Jahnke and Mr. Kissell” sounds awkward, most people simply use our first and last names and leave it at that. This, I think, is the best solution of all—personal, yet respectful. It’s a hit among Mrs./misses/miss-es. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/10/31/jmanfield.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/10/31/english-female-.d92c517aad66.mp3"
	},
	{
		"title": "Hypercorrection. Taking the rules of language too far",
		"text": "Taking the rules of language too far For all its shortcomings, I’m quite fond of the English language and have always been a bit bothered when people misuse it. That’s not to say I never misuse it myself, or that I even believe in such a thing as perfect English. But whenever I hear or read a glaring grammatical mistake—especially one of the common ones that we were all warned against in school—I shake my head and sigh. It’s not that I won’t understand you if you say, “I ain’t got none,” but it’s awkward and inelegant, like using a pair of pliers to turn a screw. Even though it may accomplish your objective, there are better tools for the job. Of all my pet peeves about English, though, the biggest one was something that until recently I didn’t know the name for: a phenomenon known as hypercorrection. Linguistic Overcompensation Hypercorrection is what occurs when someone deliberately tries to avoid making an error in the use of language but overcompensates and in so doing makes another error. The classic example of hypercorrection is the use of “you and I” when “you and me” would actually be correct. The rule, which we were all taught as children, is never to use the word “me” in the subject of a sentence, so something like “You and me are friends” would be incorrect. But because this rule was so thoroughly hammered on, many people came to feel uncomfortable about using a construction like “you and me” anywhere in a sentence, even when it’s absolutely appropriate, as in “The inheritance will be split between you and me.” When someone mistakenly uses “you and I” in an attempt to avoid breaking the “don’t use ‘me' incorrectly” rule, he or she has hypercorrected, which is to say, flubbed. Another well-worn example of hypercorrection is substituting “whom” for “who” in a sentence like “I need to call my wife, who I know is going to be upset.” Because the rules for when to use “who” and “whom” are rather tricky and unintuitive, just like the conjugation of the verb “lie” or when to use “will” versus “shall,” most people automatically err in the direction of whatever sounds most pretentious. But in reality, it’s fine to begin a sentence with “but” or “and,” and not only is it OK to split infinitives, it’s OK to boldly split infinitives. You can tell your English teacher I said so. Here Is That About Which I’m Talking (About) Then there’s the supposed rule against ending sentences with prepositions. It is certainly true that in some cases, a sentence will be clearer if prepositions are in fact positioned “pre” (at the beginning of a phrase). But there is actually nothing at all wrong with ending a sentence in a preposition. That is often the best and most concise way to state something, as in “This is the stupidest rule I know of.” Almost everyone would agree that it’s less clear and more awkward to say, “This is the stupidest rule of which I know.” Nevertheless, plenty of people, in a misguided effort to avoid final prepositions, hypercorrect by making their sentences clumsier. My own little running joke, the point of which is to ridicule the absurdity of the “no final prepositions” rule, is to put prepositions both at the beginnings and ends of phrases, where they would in some languages be called “postpositions.” Thus, I say things like “Grammar is a subject in which I’m well versed in,” or, if I’m feeling particularly obnoxious, “Grammar is a subject with which I have a knack for. In.” Hypercorrection applies not just to grammar, but to all aspects of language—including word choice and pronunciation. One of my favorite examples of hypercorrection is the name of a dish consisting of cheese sauce over a slice of toast. It’s called “Welsh rabbit,” even though it doesn’t contain rabbit; the name was intended as a lighthearted dig at our friends from Wales. But a few centuries ago, someone decided that “rabbit” must have been a mistake and determined, using faulty etymology, that the word was supposed to be “rarebit.” Unfortunately, the error caught on, and now the dish is called “Welsh rarebit” more often than not. What’s both funny and sad about this is that the joke was not merely lost in the process, but turned against the non-Welsh users of the term. The Slippery Slope of Hypercorrection Although the issue of hypercorrection is covered at great length in modern style guides and classes in English as a second language, this has done little to stem the spread of the memes for frequently miscorrected terms. Part of the problem is that, given frequent enough exposure to a particular instance of hypercorrection, even people who should know better can become confused. So if I’m pretty sure that “thus” functions just fine as an adverb but hear lots of people modify it to “thusly,” I can begin to doubt whether my knowledge was correct in the first place and adopt that hypercorrection myself. There is no easy cure for hypercorrection. Despite the best efforts of scholars to reverse these trends, English teachers still tend to teach language the way they learned it—faulty rules and all. And most adults don’t like to sit around reading style guides to figure out what linguistic mistakes they’ve been making all their lives. So it may eventually happen that hypercorrect forms are accepted as normal, notwithstanding their dubious etymological provenance. That will be a sad day, but it’s an idea to which I may have to get used to. ",
		"avatarURL": "https://static.lingq.com/media/resources/collections/images/2007/10/26/itod-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/10/30/Hypercorrection.3ff2392d05d4.mp3"
	},
	{
		"title": "Dream Groups",
		"text": "Intramural introspection I’m going to let you in on a little secret. Unbeknownst to most of my friends and family, I’m really an action hero. Several times each month, I go on dangerous assignments to exotic locations, where I narrowly escape death, rescue the hostages, recover the stolen chip, round up the bad guys, and generally keep civilization safe from evil. Admirers call me “Indiana Joe.” Of course, it’s no big deal, thanks to my super powers that enable me to dodge bullets, read minds, and fly off into the sunset. When I return from one of my adventures, I can almost hear the fanfare…no, wait, that’s my alarm clock. Sometimes I awake from one of my dreams uncertain of whether it really happened or not, and with a nagging sense that a vital piece of information has been lost—that the dream was trying to tell me something important. When I need to get to the bottom of a dream, I take it to Dreams Group, a small circle of friends that meets monthly for a unique kind of dream analysis. The Woman of My Dreams I first became aware of dream groups a number of years ago, when someone made an announcement after a church service that such a group was going to form. At first, I wasn’t even sure what they meant by “dreams”—I thought it might have been dreams in the sense of aspirations, rather than the visions that occur while we sleep. Either way, I had plenty to work with, but I had no idea what I’d be getting myself into if I joined. A week later, the group’s leader asked all interested parties to gather for more information. I was still wavering when I saw a very attractive young woman join the group. At that point I immediately determined that I was interested. (I thought the group might be worthwhile too. ) The idea for this group and many others like it came from a book by Jeremy Taylor called Where People Fly and Water Runs Uphill. Taylor, a respected author and teacher, has been working with dreams and dream groups for decades. His central principle is that all dreams come in the service of health and wholeness. Whatever else you may believe about dreams, the assumption our group starts with is that they are a good and useful thing, that they exist in some respect to benefit the dreamer. Perchance to Dream It may be helpful to clarify what group dream work is not. First and foremost, it is not simply a matter of guessing or looking up things in dream dictionaries. At the other extreme, it’s also not formal psychoanalysis. Participants in dream groups are simply laypeople who have learned some basic skills—not professional therapists. Finally, it’s not a religious exercise. Someone may, of course, experience religious symbols in dreams, but dream work as such does not presuppose any religious framework for interpretation. Members are encouraged to write down any dreams they remember as soon as they wake up, then bring them to share in the meetings. Dream work can be very intimate, so all members agree to treat each other’s dreams with respect and discretion—and never to share the content of a meeting outside the group. As a member recounts a dream, the others listen quietly; when the dream is finished, we ask questions only if needed for clarification. Then we begin sharing our thoughts. Although someone may have a strong opinion about what another person’s dream means, only the dreamer can ultimately determine its meaning. In addition, because dreams are abstract and richly suggestive, there’s a strong tendency to read one’s own issues into someone else’s dream. For these reasons, we avoid saying, “This is what your dream means.” If someone has an insight or observation, the language we use is, “If it were my dream…” That way each person can put him or herself in the shoes of the dreamer with impunity, and the person sharing the dream can look at it more objectively too. Such Stuff As Dreams Are Made Of Taylor discusses numerous principles of dream work at length in his book, but a couple of notions come up with great regularity. For one thing, we assume that a given dream may have many different meanings, which may or may not be deep and profound. My action-adventure dream could mean both that I really enjoyed that James Bond film I just saw, and that I feel some situation in my life needs rescuing. Another postulate is that many or all of the different characters in a dream may represent the dreamer. So if I save the damsel in distress from the evil prince, it could be that my dream is about situations in which I feel helpless, or conversely, cause pain to others—not necessarily my role as the hero. These ideas, and many more, come into play as we discuss each other’s dreams. Often the person who shared the dream will have an “aha” moment—a sudden realization of the significance of a dream symbol that would not have occurred outside the group setting. Of course, it also sometimes happens that a dream remains entirely inscrutable even after an hour of intense discussion. Even so, the process of sharing and discussing dreams can have a very therapeutic effect. I Have a Dream Today Dream groups can have many different forms, and their structure can vary depending on how many people are involved, where the meetings take place, and how well the members know each other. The members of my group are quite comfortable with each other, and we have chosen to meet monthly, in a different person’s home each time. We begin with a potluck meal, and while we’re eating we take turns talking about the significant events in our lives. This is quite important, as it gives us a context to evaluate the significance of dream images. We also usually spend a short time discussing “meta-dream” issues—things like methods for improving dream recall, the phenomenon of lucid dreaming, or insights from a book one of us has read. Next we take a moment to center ourselves and mark the transition from ordinary discussion into dream work. Each person then very briefly shares a recent dream, and we determine who has a dream they’d like to examine in detail. Time permitting, we discuss two or three of these dreams using the principles from Taylor’s book and the “if it were my dream…” language. We finish with another simple centering exercise to mark the end of our dream discussion. Don’t Dream It’s Over Our meetings are not uniformly successful in revealing the inner workings of our minds, but more often than not, we all leave feeling we’ve learned a great deal more about ourselves and each other. During my first year in a dream group, I developed deep relationships with the other members—including that attractive young woman, whom I later married. And I acquired not only valuable introspective skills, but also some very good habits of deferential and attentive listening. But leaving aside all the touchy-feely stuff, the bottom line is that it is seriously fun. There are very few things I’d rather do than attend a Dreams Group meeting. Some scientists believe dreams are nothing more than residue from the brain’s “garbage collection” process as information is transferred into long-term memory. Others hold, somewhat more charitably, that dreams are the mechanism the brain uses to unconsciously work through issues that could not be dealt with in waking life. And then, of course, some people have a more mystical take on dreams, declaring that they are a direct communication channel to God, the collective unconscious, a “higher wisdom,” or whatever. Unlike my biblical namesake, I don’t pretend to any supernatural gifts when it comes to interpreting dreams, and I don’t have much of an opinion about either their neurological or metaphysical basis. All I can say is that after working on my dreams in groups, I feel I understand myself better. That dreams can accomplish this is enough for me. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/10/31/dream-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/10/31/Dream.6c4ae60db1e5.mp3"
	},
	{
		"title": "Truffles. Fungus of the gods",
		"text": "Last year on a trip to Paris, I had one of the most gastronomically memorable days of my life. On a single day, I had the best baguette, the best pain au chocolat, the best cherries, and the best melon I’d ever eaten. Without in any way meaning to slight the fine work of the bakers and produce sellers who contributed to the day’s find, something about the large number of factors that had to randomly converge to produce that experience struck me as cosmically significant. I don’t think it could have been planned or manipulated; it just had to happen, and I had to be in the right place at the right time, too. The very same thing could be said of the truffle, one of the world’s most expensive foods. I didn’t eat any truffles that day in Paris-they were long out of season. But I couldn’t help thinking that France has a strange power to alter the rules of randomness in such a way as to make exceptionally rare and tasty foods more likely to occur. Tastier Than Athlete’s Foot! Truffles are a type of fungus, and thus a not-too-distant relative of mushrooms. There are quite a few varieties of truffle, all in the genus Tuber-the best known varieties are the black truffles found in the Périgord region of France (Tuber melanosporum) and the Italian white truffle (Tuber magnatum). They don’t look like much: small knobby lumps that resemble-if you’re being generous-shrunken brains. An average truffle will be about the size of a walnut, though some are much smaller and others gigantic, weighing a kilogram or more. They have a distinctive odor, which is sometimes referred to as \"nutty\" or \"musky\"-or, by those of a less poetic bent, \"stinky.\" Cut a slice from one of the hard clumps and you’ll see tiny white veins running through the otherwise solid interior. But the look and the smell are secondary to the taste, which to palates more refined than mine is considered heavenly. That’s not to say I dislike the taste of truffles, it’s just that on the rare occasions when I’ve gotten to taste one, there was too little of it for me to form much of an opinion. Truffles are invariably served in very tiny pieces-whether in an omelette, shaved over a salad, or mixed into pâté. The main reason you’ll never see someone consume a whole truffle is that this taste sensation comes at a cost. High-quality black truffles can cost US$500 per pound; the even rarer white truffles can fetch as much as $2,000 per pound and sometimes more. No matter how much you like the taste, it’s a food to be enjoyed in moderation. Under the Spreading Chestnut Tree The reason truffles are so expensive is that they’re hard to find; despite many years of effort, no one has been able to cultivate them artificially. They grow under a few inches of soil on the roots of certain trees-mainly oak, but sometimes chestnut, hazelnut, and others. The only way to locate them reliably is by smell, but this requires a nose that is both sensitive and located closer to the ground than the human nose. Pigs are widely regarded as having the best nose for truffles, and are sometimes used to hunt them. The difficulty with pigs, however, is that they are passionately fond of the taste of truffles. It can be tricky-not to mention dangerous-to get between the snout of a pig and a truffle it’s trying to dig up. Certain breeds of dogs, after a period of training, can be nearly as effective as pigs at finding truffles, but less likely to eat them (and easier to restrain if they try). Thus most modern truffle-hunters work with a canine companion. However, there’s a third common method of locating truffles that relies on a still smaller animal: the Suillia fly. This insect likes to lay its eggs above truffles, so if you can spot one flying close to the ground, it’s a good bet there are truffles nearby. On the Trail of the Truffle Truffles grow only in the fall and winter, and only in a very few regions where temperatures and rainfall are just right. For black truffles, the growing season runs from November to March; for white truffles, it’s generally September to early January. Although France is reputed to have the best black truffles and Italy, the best white truffles, they also grow in other parts of the world, including the west coast of North America, from northern California through British Columbia (roughly the same region where temperate rain forests are found, by yet another random coincidence). Although it’s possible to find canned or jarred truffles out of season, truffles quickly lose their flavor after harvesting, and experts agree that it’s best to consume them within a few days after they’re removed from the ground. (Black truffles, by the way, release more aroma when heated, whereas heat destroys the flavor of white truffles. So truffle aficionados are always careful to match recipes to the available truffle varieties.) The upshot of this is that unless you live in an area near where truffles are produced, have enough money, and wait for the right time of year, you can’t have the quintessential truffle experience. Truffles enforce respect for randomness. Just a Dab Behind the Ear Truffles have long been considered an aphrodisiac, but as with all such foods, I’ve always taken that claim with a grain of salt. However, in this case there may actually be something to the claim: black truffles contain 5-alpha-androstenol, a sex hormone related to testosterone that is also found in the underarm perspiration of human males and the urine of human females. Many people believe that this very same hormone may explain the strong attraction pigs have for truffles, but experiments have shown that another chemical, dimethyl sulfide, is more likely what the pigs find interesting. The small chocolate candies called \"truffles\" are so named, apparently, because of their similarity in appearance to the real thing. Considering that chocolate truffles are not rare, expensive, or subject to the whims of nature, I’m tempted to feel they didn’t come by their name honestly. On the other hand, they, too, are allegedly aphrodisiacs, and they certainly go much better with a glass of milk. Just the thing, perhaps, to pass the long months until the next fungus harvest. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/04/27/truffels-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/08/17/Truffles.53b3011f3c25.mp3"
	},
	{
		"title": "Tree Tumbo",
		"text": "Mystery plant of the desert A couple of years ago, I began noticing that our home could use some brightening up, and I thought it might be a good idea to buy a few houseplants. But I’ve never done well with plants. I even managed to kill off several cacti, despite my best efforts. So I walked into a local plant store and asked what they had that could survive under my care. The owner assured me that African violets would be a safe choice. I said, “But no, really…flowers hate me. In fact, most plants run and hide when they see me coming.” But after listening to detailed instructions, I finally agreed that I could probably care for just this one small potted plant successfully. I found one with flowers just the right shade and took it home. Well, the good news is that the plant is still alive. The bad news is that its condition gives all new meaning to the expression “persistent vegetative state,” if you know what I mean. It hasn’t flowered in eons, some of its droopy leaves are a sickly shade of yellow, and it’s clearly hanging on simply to emphasize its ongoing contempt for me. My most sincere intentions notwithstanding, I just can’t seem to keep plants healthy. When I saw pictures of a plant called Welwitschia mirabilis (also known by such names as “tree tumbo” or “onion of the desert”) it looked very much like it could have been a previously beautiful specimen that had the misfortune of spending a season or two in my yard. In other words, it looked pretty sick and ugly. But appearances, in this case, are deceiving. This incredibly odd and unattractive plant can thrive in extraordinarily inhospitable conditions—and that’s just the start. The tree tumbo is without a doubt one of the world’s oddest plants. Good to the Last Drop The tree tumbo can be found growing naturally in just one place: the Namib Desert, a narrow, sandy strip of land about 1,300km (800 miles) long and up to 150km (100 miles) wide along the coast of Namibia and Angola in southwestern Africa. In this desert, daytime temperatures routinely reach 40°C (about 100°F). Years at a time may pass without any rainfall; the annual average near the coast is something like 25mm (1 inch). However, the area does get a great deal of fog, which provides the equivalent of another 50mm (2 inches) or so of rainfall per year. So the plants and animals that flourish in this desert have adapted to these extreme and unique conditions. If you were walking through the Namib Desert and came upon a tree tumbo, you’d see what appears to be a large mass of long, narrow, twisted leaves—green toward the center and brown at the ends—radiating from a central stem and lying on the ground. In fact, the plant has just two very broad leaves, but over time (especially with exposure to high winds), they split into shreds that give the appearance of being multiple leaves. The plant never sheds the leaves; the two leaves that appear when the plant sprouts keep growing for the tree tumbo’s entire lifetime. That lifetime is typically hundreds of years; carbon dating has shown some of the larger plants to be more than 2,000 years old. Some botanists consider this to be the world’s longest-living plant. Unlike typical desert plants, such as succulents—which store as much water as possible in thick stems or leaves—the tree tumbo has very thin leaves that absorb moisture from fog effectively but store almost none. Instead, water is stored in the trunk, most of which is underground. Beneath the trunk, a long taproot extends an additional several meters deep; this serves both to anchor the plant in high winds and to absorb moisture from deep underground. One of a Kind Almost everything about the plant makes it very hard to categorize. It has many of the characteristics of tropical plants, even though it lives only in the desert. Its seeds form on cones somewhat like those of a pine tree. That makes the Welwitschia a gymnosperm, but because it’s so unlike other gymnosperms in most respects, it doesn’t neatly fit anywhere in the plant kingdom. So this species is the lone member of a genus, which is in turn the lone member of a family in the Gnetales order of gymnosperms—itself a small and diverse order. Austrian botanist Friedrich Welwitsch is credited with the plant’s discovery and description in 1859, and it therefore bears his name. Despite the fact that the tree tumbo appears in just one small part of the world, it’s not considered endangered—there are plenty of them. (They can also, with some effort and patience, be cultivated in greenhouses and other environments.) All the same, I think it would be safer for the plants if I stayed far away from the Namib desert. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/06/18/Welwitschia-mirabilis-120_.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/06/18/tree-tumbo.cdff96a6f70d.mp3"
	},
	{
		"title": "The Truth About Bananas",
		"text": "Fingering the world’s most popular tropical fruit\n\nWhen I was in college, I had a professor who was known for being a bit on the odd side. Although he was smart, friendly, and much loved by the students, he had some strange and inexplicable habits. For one thing, he had a very peculiar way of speaking, including about a dozen idiosyncratic phrases that he repeated over and over. A friend and I, when we got bored, used to sit in the back of the classroom and keep a tally of how many times he used each of these phrases. The professor always kept a pen clipped to his collar, even if he was wearing a shirt with a pocket (a practice that amused me so much I adopted it myself—and keep it up to this day). And he encouraged us, on multiple-choice exams, to write in our own answers in the margin if we didn’t like any of his.\n\nEvery now and then, this professor came to class with the sticker from a banana on his shirt. The brand varied, but the position did not: it was stuck right above the spot where his pen would be, if he had kept it in his pocket the way normal people do. We assumed it was just another one of his silly habits, but one day, a student actually asked him—during class—what was with the stickers. He replied, solemnly, “Oh. Yeah. Well, whenever I have a banana for breakfast that has a sticker on it, I put the sticker on my shirt to remind me of the suffering of the banana pickers in Latin America, who sometimes earn just 50¢ for a 12-hour day of work in grueling conditions. I wear it to show my solidarity with them, as a silent protest for better treatment.” From that day on, we saw the professor in a completely new light—and we started thinking about bananas differently too. As I was later to discover, almost nothing about bananas is as it seems.\n\nFamily Trees\n\nOn a trip to Costa Rica, which is a major exporter of bananas, I saw endless banana plantations and also visited a botanical garden where a botanist shared some fascinating details about banana trees. He said there are about 300 varieties of banana (and their close relative the plantain—pronounced “PLANT-en,” not “plan-TAIN,” by the way), of which only some are edible, and an even smaller fraction cultivated commercially. The type of banana grown most often in Costa Rica is a hybrid that is larger and sweeter than its naturally occurring ancestors.\n\nAmong the other interesting tidbits we learned was that banana “trees” are not even trees—they’re the world’s largest perennial herbs. The distinction is not merely academic; the stems, which may appear to be solid trunks, are simply multiple layers of very large leaves that could be cut through with a regular knife. In fact, the stems often break under the weight of the bananas and need to be supported with poles.\n\nAlso surprising was that bananas grow upside down, seemingly showing contempt for gravity. Each plant has a flower shoot that produces a single bunch of bananas—by “bunch,” I mean a set of about 15 subgroups called hands, for a grand total of about 200 banana “fingers.” On commercial banana plantations, each plant’s bunch is usually covered with a large plastic bag saturated with pesticides, to ward off both insects and birds.\n\n\nBeing Fruitful and Multiplying\n\nBananas also have an unusual life cycle. Normally, the primary reason for a plant to bear any sort of fruit in the first place is to propagate itself, since the fruit contains the seed. Modern, commercial strains of banana don’t have seeds. (Well, they do, but they’re tiny and sterile, unlike wild and often inedible varieties of bananas, which have large and viable seeds.) Seedless fruit-bearing plants (think of navel oranges) normally propagate only with human help—as in transplanting cuttings—because the plant has no natural way to regenerate when it dies. Here again, bananas break the mold. Each banana plant produces just one bunch of fruit over its lifetime of about a year and then dies—or at least appears to. But the stem above ground is just a portion of the plant, the so-called pseudostem. There is also an underground stem, called a rhizome, which produces new shoots at the base of the visible stem. These begin growing into new, flowering stems just as the old one is dying. The new plant, then, really isn’t new at all, and is genetically identical to its predecessor.\n\nThese peculiarities aside, bananas are an excellent source of potassium, not to mention a highly effective device for keeping scoops of ice cream aligned in a dish. Bananas have been referred to as “the world’s most popular fruit,” “the world’s most popular tropical fruit,” “America’s most popular (or second- or third-most popular) fruit,” and a variety of other designations in the upper strata of fruit stardom, based on different metrics for assessing popularity. In any case, Americans—and much of the rest of the world—certainly consume immense quantities of bananas.\n\nBut what about the tale of the exploited banana pickers? I’m sorry to say it’s true. Though the situation is better in some areas than others, and has on the whole improved somewhat since I was in college, the life of the average banana picker is still rather bleak. Of course, if the producers paid their workers a living wage, bananas would become so expensive that few people would buy them, thus reducing demand, and so on—a tricky problem to solve. For my part, I wear banana stickers just as my professor did—not to advertise Dole, Chiquita, or Del Monte or because I think it will have any tangible impact, but to remind myself of the real price of bananas. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/06/18/bananas-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/06/18/the-truth-about.7f406f60b8da.mp3"
	},
	{
		"title": "The Story of Toilet Paper",
		"text": "What goes around, comes around For as long as I can remember, there’s been an ongoing conflict in my family regarding the complex moral issue of whether toilet paper (and paper towels) should be installed in a dispenser so that it rolls over or under. Some family members feel very strongly about one orientation; others feel equally strongly about the other. So whenever someone visits a relative’s house where the paper is rolling the “wrong” way, they’ll change it—prompting considerable ire from whoever lives there. Me…I’m agnostic. I roll both ways. I suppose if someone twisted my arm and demanded a decision, I’d side with the “over” camp, but it’s just not something I can get terribly worked up about. I’ve read lots of newspaper and magazine articles about this debate over the years, and I think the issues have been explored adequately elsewhere. What I have not, however, read enough about is how toilet paper (in the form in which we now know it) came to exist in the first place. For most of us in the modern western world, toilet paper is such a basic necessity of life that we simply can’t conceive of how we would function without it. But in fact, it’s not that old—and it has a rather interesting history. This is, I realize, a rather delicate topic, but one well worth a few minutes of consideration. Stocking the Reading Room Before toilet paper came into widespread use in the late 19th and early 20th centuries—yes, that recently!—personal hygiene was typically performed using materials that were a bit less soft and absorbent. Newspapers, catalogs, and similar reading materials were as likely as they are now to appear in bathrooms, but much less likely to leave the room (or outhouse, as the case may be) intact. Farther back in history (or when paper was otherwise unavailable), such items as rags, leaves, and even stones were used. The ancient Romans reportedly used sponges on sticks. Perhaps as far back as the sixth century A.D., paper was sometimes used for sanitary purposes in China—at least among the wealthy. In the late 14th century, toilet paper of a sort was made for the Chinese emperor—in large, 2 foot-by-3 foot (0.6 x 0.9m) sheets. But almost 300 years after the invention of the flush toilet in 1596, there was still no such thing as commercially produced paper designed exclusively as a toilet accessory—and certainly no paper that could safely be flushed. Paper Trail When it comes to the origin of what we would today recognize as toilet paper, the historical accounts are hopelessly inconsistent. (The Web, of course, is of little help, since—as usual—most accounts are plagiarized.) Here are what I believe to be the verifiable facts: * In 1857, Joseph Gayetty (not “Gayette” or “Cayetty,” as his name is often misspelled) produced the first commercially available toilet paper in the U.S. The tissue was moistened with aloe and sold in packages of 500 individual sheets—each one with a watermark bearing Gayetty’s name. It was sold as a medical product, and was not terribly successful. * Brothers Edward, Clarence, and Thomas Scott began selling some kind of toilet paper from a push cart in Philadelphia in 1867. (I have been unable to determine what sort of paper this was or where they obtained it, but I assume it was not rolled, perforated paper—they most likely would not have had the means to manufacture it and I could find no record of other companies making it at that time. ) * In 1879, Edward and Clarence Scott founded the Scott Paper Company (the third brother, Thomas, went into the publishing business instead). Scott toilet paper was sold in rolls that were, apparently, unperforated in the early years. In addition, the company did not market their products under the Scott brand initially—not wanting to, ah, soil the family’s good name. * The British Perforated Paper Company began selling some kind of toilet paper—probably not rolled—in England in 1880. * By 1883, at least one patent had been issued for a toilet paper roll holder that had a serrated cutting blade. * The Albany Perforated Wrapping (A.P.W.) Paper Company was selling rolled, perforated (and medicated) toilet paper by 1885—and possibly as early as 1877. * A 1935 ad for Northern Tissue boasted that it was “splinter-free,” but this does not in any way suggest that all toilet paper prior to that time had splinters! * The first two-ply paper was sold by St. Andrew’s Paper Mill in England in 1942. The biggest uncertainty in this timeline is whether the Scott brothers or the A.P.W. Company can lay claim to the first sale of the ubiquitous perforated roll. (Some sources, incidentally, claim that Scott didn’t begin selling rolled toilet paper until 1890—but also claim they were the first to do so.) In any case, by the early 1900s—at which time, not coincidentally, flush toilets began to achieve popularity—toilet paper as we now know it was easily found in both the U.S. and Europe. And in the 1990s, history came full circle (so to speak) as several major toilet paper manufacturers began offering their latest “innovation”—toilet paper treated with aloe. Progress rolls on. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/09/14/toilet-paper-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/09/14/toilet-paper.fd0e9b18f5d2.mp3"
	},
	{
		"title": "The Handshake",
		"text": "Coming to grips with gestures of greeting The other day I was at a restaurant with some friends, and one member of our party arrived a bit late. Before sitting down, he started heading toward the corner of the room, and when someone asked where he was going, he held up his hands and said, “Demunification.” Although I had never heard that word before, I understood immediately what he was saying: he was heading to the lavatory to wash his hands in order to “de-MUNI-fy” them—MUNI being short for San Francisco Municipal Railway, the transit authority that runs the city’s buses and streetcars. When you’re riding a bus or streetcar that’s so crowded you have to stand, you end up holding onto the handrails, which perpetually feel (and probably are) grimy from being handled by untold thousands of people before you. Almost everyone I know who rides MUNI habitually washes their hands as soon afterward as possible, which is probably an excellent idea. From time to time I’m in some sort of social situation where a handshake is expected, but my hands (whether MUNIfied or not) are not necessarily clean. This always makes me feel awkward—it’s one thing to decline a handshake when my hands are covered with motor oil or pastry flour, but in the absence of visible contaminants, North Americans typically consider it an insult not to accept a handshake. Meanwhile, personal observation informs me that an unknown but excessively high percentage of men routinely leave public restrooms without washing their hands. Thus, shaking hands strikes me as a relatively unsanitary gesture of greeting. Not that I’m hypersensitive about germs, but this made me wonder: considering the wide range of alternatives, how did the handshake come to be the standard greeting in this society? And hygiene aside, how can we make sense of all its supposedly deep and symbolic meanings? Left Behind I’ve read at least half a dozen contradictory accounts of the origin of the handshake. Because handshakes clearly predate written history, all these explanations are ultimately somewhat speculative. But the most popular story is that an open right hand showed you were not carrying a weapon; if two men met and displayed empty right hands, this presumably meant a basic level of trust existed that neither would stab the other. In one variant of this story, the handshake evolved from an elbow-to-wrist “patdown” to check for hidden knives; in another, the shaking motion was supposed to dislodge any sharp objects that may have been kept in the sleeve. Of course, this explanation, while plausible enough, doesn’t account for left-handed men, who presumably would have been happy to extend the right hand in greeting while wielding a dagger in the left. But in many parts of the world, since ancient times, the left hand has been considered the “bathroom” hand, the one never used for eating, giving, or receiving—nor, by extension, for greeting—whether you’re left-handed or not. Meanwhile, the “I’m-not-going-to-stab-you” story doesn’t tell us why the handshake won out over other greeting gestures in the West. After all, in some cultures the standard greeting (even between people who don’t know each other well) is a kiss on one or both cheeks; in others, people hug, rub noses, bow, or even stick out their tongues. Writer Margaret Visser suggests one possibility. As she noted in her book The Way We Are, at one time the English were more demonstrative with their gestures of greeting—for example, English men routinely greeted all women with a kiss on the mouth. As part of the Victorian behavioral “reforms,” public kissing of any kind became socially unacceptable and the handshake came into fashion for both men and women as a convenient way to keep a person at arm’s length. So to speak. The Left Hand Doesn’t Know What the Right Hand Is Doing At least in the United States, the handshake has become an extremely ambiguous symbol. At one level, it just means “hello” or “goodbye.” But it can also be construed to mean “we’re in agreement” or even that an informal contract has been reached, as in the proverbial handshake deal. And on a still deeper level, it can mean “everything’s OK between us,” particularly after some conflict has been resolved. But sometimes social convention awkwardly calls for shaking hands to signify the end of a meeting, even though no agreement has been reached or a state of conflict still exists. And heaven forbid that one world leader should shake hands with another whose ideology differs deeply, since people on both sides will judge this as a disingenuous move at best, and at worst, a betrayal of the leader’s values. But was the politician saying, “I accept you and your beliefs” or simply, “Hello”? Then, of course, business types will read all sorts of meaning into the very style of your handshake. Even if you execute it under exactly the right circumstances, it must be firm but not too firm; it must be held for exactly the right amount of time but no longer; it must be accompanied by direct eye contact; and, for bonus sincerity points, you should add your left hand to make a “hand sandwich.” You may also be judged on the angle of your hand and the number and intensity of shakes. And if this kind of confusion isn’t bad enough, that’s just the standard, run-of-the-mill handshake. Gangs sometimes use special handshakes to signify group membership, just as fraternal societies and children’s clubs use “secret handshakes” as a kind of password, a symbolic way of saying, “We’re insiders.” So if someone outside the group incorrectly attempts a handshake, the results can be quite serious. On the other hand, a high five (arguably a variety of handshake) pretty unambiguously expresses satisfaction or congratulations—but that’s the exception. I think the notion that we all need to perfect the art of shaking hands—and reading handshakes—is kind of silly. Even though I can’t proclaim universal standards of handshake meaning, I’d like to do my small part by offering you this easy guide to what my gestures of greeting mean: * Handshake: “This is my hand.” * Handshake refused: “I’ve got MUNI/motor oil/pastry flour/cooties on my hand—or you do.” * Handshake (left hand added): “Your hand is cold.” * Kiss on both cheeks: “Hello/goodbye, European acquaintance.” * High five: “Dude!” * Hug: “You don’t smell too bad.” * Palm raised, gap between middle two fingers: “Live long and prosper.” So then, how do we convey all those extra meanings that are supposed to be encoded in a handshake? My advice is to do what our parents told us when we were three years old: “Use your words.” —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/08/21/handshake-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/08/21/Handshake.c7272e3b3b59.mp3"
	},
	{
		"title": "The Fata Morgana Effect",
		"text": "When people accuse you of building castles in the air, they are not usually congratulating you on an incredible engineering feat, but more likely trying to bring you back down to earth with a thud. Synonymous with daydreams, pipe dreams, and all other dreams unlikely to come to fruition, castles in the air are at best a hopeful vision, and at worst, a hopeless illusion. Although the phrase “castles in the air” (the original phrase was “castles in Spain”) is most often used to describe imaginary constructions, it can also be used to describe a very real optical phenomenon—the fata morgana effect—in which different levels of hot and cold air distort the appearance of objects on the horizon to make them look like, well, castles in the air. Tempting Fata Fata Morgana is the Italian name for Morgan le Fay, the half-sister of King Arthur in Arthurian legend. Reputedly a sorceress and able to change shape at will, Morgan le Fay was sometimes said to live below the sea in a crystal palace that could also rise above the surface. The fata morgana effect was so named for the superstitious belief among sailors that she created illusory visions to lure men into a false port and to their death. The term first entered English usage in 1818, when it was used to describe an occurrence of the phenomenon in the Strait of Messina, a narrow body of water between Sicily and the region of Calabria in southern Italy. Technically, fata morganas are a type of mirage, related to those visions of water in the desert, or less exotically, to those seeming pools of water on the highway on a hot day. However, the latter two are examples of inferior mirages, while fata morganas are classified as superior mirages. It’s not that fata morganas are inherently better than the others; the difference lies in the way each mirage is produced. Refract Up Although the word mirage is derived from the French verb se mirer, meaning “to be reflected,” a more apt description of a mirage is that it is refracted. As light passes through layers of air with varying densities (density being determined by factors such as pressure and temperature), it bends, or more specifically, refracts, according to each layer’s characteristics. In the case of inferior mirages, light bends upwards when it moves from a denser layer of cold air into a less dense layer of hot air, like that created above a highway on a hot day. As light hits the surface of the road and bends upwards, it looks to our eyes as if we are seeing a reflection in the road of what is just above it—in this case, the blue sky. This is because we perceive that light travels in a straight line to our eyes, even when that is factually not so. Lake Superior A superior mirage is the reverse of this; what we perceive to be higher in the sky is actually lower to the ground. Light is bent downwards when it hits a layer of cold air, making it appear as if what is below our sight line is actually straight ahead or above us because we are seeing the inverted image of what is on the horizon projected above it. This can be further complicated when there are multiple layers of hot and cold air, creating a highly distorted image as the light refracts through them. Superior mirages occur wherever the surface temperature is colder than the air above it, usually over bodies of water and areas with ice or snow on the ground. The term fata morgana is most often used to describe superior mirages occurring over water. In these instances, objects on the horizon, such as ships, islands, cliffs, or icebergs, appear taller than they are because their inverted image is reflected above or superimposed on them. This elongation of objects on the horizon may make it appear as if there are turrets or towers rising up from the water, leading to the description of fata morganas as castles in the air. As this effect can occur with ships, making them look higher above the horizon than they are, some have speculated that this is the origin of the Flying Dutchman legend, in which a ghostly ship is doomed to sail the seas for eternity. There are many other types of superior mirages; one of them, the fata bromosa, or “fairy fog,” is created under the same conditions as the fata morgana, but has a different appearance. It appears as a bank of fog, with varying degrees of brightness, but without the fine detail of the fata morgana. Fata Complete Since its introduction into regular usage, the term fata morgana has come to mean more than just an optical phenomenon; although it has kept its original meaning of referring to something that is illusory, its use has been expanded throughout popular culture. It provided the title for a Henry Wadsworth Longfellow poem, an 1868 polka by Johann Strauss, and an Agatha Christie crime novel. It’s the name of a French publishing house, a character in Sergei Prokofiev’s opera, The Love for Three Oranges, and a film by Werner Herzog composed solely of desert landscape images. The enduring popularity of the term shows how compelling it is as an idea—that there are mysterious phenomena, benign or malevolent, that are beyond our understanding. Or it may be that we continue to be enamored of our castles in the air, despite the knowledge of their illusory nature, as the last stanzas of Longfellow’s poem conclude: So I wander and wander along, And forever before me gleams The shining city of song, In the beautiful land of dreams. But when I would enter the gate Of that golden atmosphere, It is gone, and I wonder and wait For the vision to reappear. —Morgen Jahnke Morgen Jahnke is a writer living in San Francisco, California. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/09/07/fata_morgana.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/09/07/Fata_morgana.c9c667780b61.mp3"
	},
	{
		"title": "Temperate Rain Forests. Trees of life",
		"text": "If you ask the average person to name any three countries that have rain forests, chances are their minds will jump to tropical regions—Central and South America, equatorial Africa, or the islands of southeast Asia. Most people would not include, say, Canada on their lists, because as everyone knows, rain forests are consistently hot places. And this is exactly what I always believed too. Several years ago when I was living in Canada, my wife, Morgen, mentioned in passing, “Oh, we’ve got rain forests here.” And I thought: “Yeah, right. And deserts too. What else did Santa Claus tell you?” But it seems Mr. Kringle was right after all. Canada does indeed have rain forests—just not of the tropical variety, which was the only kind I had ever heard of. (As a matter of fact, there are also deserts in Canada…but that’s a story for another day. ) Moisten and Seal The main thing that determines whether a forest should be considered a rain forest is the amount of rainfall it receives—generally, the threshold is about 100 inches (2.5m) per year. This high moisture content—concentrated still further into fog by the leaves that form the canopy—encourages the heavy growth of plants, which in turn support animal life. When evergreen forests appear along the coast of a landmass with mountains on the other side, the mountains tend to trap the moist air blowing in from the sea, producing an unusually heavy rainfall in the forest. Voilà: rain forest. Such conditions exist in several parts of the world, including the west coast of North America (from Alaska as far south as northern California), the west coast of Chile, parts of Tasmania and New Zealand, and even a small patch of Norway. Temperate rain forests are, on average, much cooler than tropical rain forests, and also subject to greater seasonal variations. Summer temperatures may go as high as only 80°F (27°C), and in the winter, the temperature may occasionally dip below freezing. But the weather is not the only thing that’s different. Temperate rain forests support a narrower variety of plant and animal life. Canopy trees include evergreens such as Sitka spruce, western hemlock, western red cedar, and Douglas fir, and some deciduous trees as well. Where a tropical rain forest would overflow with vines and climbing plants, a temperate rain forest has a profusion of ferns, moss, and lichens. (Having visited both tropical and temperate rain forests, I was amused to see an old episode of The X-Files whose opening scene was set in the rain forests of Costa Rica—but, having been filmed near Vancouver in a temperate rain forest, all the vegetation was completely wrong. ) In a tropical rain forest, most of the animal life makes its home in the canopy—not just birds but monkeys, sloths, snakes, and a variety of insects. In a temperate rain forest, by contrast, most of the animal life is on or near the ground. There’s a smaller and less exotic variety of animals, too, although a great deal of the animal life consists of insects that are normally unseen, living in rotting logs from huge fallen trees. Mass Quantities But even if there is less diversity of animal and plant life, the sheer quantity is much greater than in a tropical rain forest—or anywhere else on Earth, for that matter. Scientists estimate that each acre (0.4 hectare) of temperate rain forest contains 500 to 2000 tons of biomass (i.e., living matter), versus an average of about 300 tons in a tropical rain forest. Most of this difference is due to the sheer size of the trees, whose average diameter is much greater than what you’d find in hotter regions. What I find most interesting about temperate rain forests is simply that they exist—it was a bit of a shock to my system of categorizing the world to discover that rain forests are not strictly tropical phenomena. I must say, too, that temperate rain forests are much more comfortable to visit—fewer flying insects, poisonous animals, and so on, not to mention more tolerable temperatures—although you don’t get to see all the brightly colored birds, howling monkeys, and other exotic animals that are typical of the tropical rain forest. Alas, temperate rain forests are disappearing just as quickly as their tropical counterparts—in part due to the fact that their gigantic trees make such excellent lumber. But if there is a bright side of this sort of deforestation, it is that temperate rain forests are able to regenerate much more quickly after heavy logging than a tropical rain forest could. And for North Americans, at least, they’re much handier as an ecotourist destination, which could provide another reason to keep them intact. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/08/31/rain-forest.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/08/31/rain-forest.310cdbd0da8b.mp3"
	},
	{
		"title": "San Francisco's Terra Infirma",
		"text": "San Francisco’s Terra Infirma Ship to shore Several months ago I was walking down the street in San Francisco when I noticed a large brass plaque embedded in the sidewalk. It said that the spot on which I was standing was once a part of the shoreline of San Francisco Bay. I turned and looked in the direction of the Bay, from which I was now separated by several blocks and quite a few very large buildings. Up until that time, it had never occurred to me to doubt Jefferson Starship’s claim, \"We built this city on rock and roll.\" The band was from San Francisco, after all, and they should know. But thinking about this area’s significant seismic activity, I started to wonder what all these buildings really were sitting on, if not solid ground. The trivial answer, of course, is that the ground is made up of landfill. By itself, that’s nothing unusual, especially around here. Since the mid-1800s, the San Francisco Bay as a whole has lost 40% of its area to landfill. But in the northeast corner of San Francisco, the large, semicircular slice of land that was once called Yerba Buena Cove has a rather unusual makeup: it’s composed partly of the remains of hundreds of old ships. In 1847, the small settlement of Yerba Buena, which had just recently been claimed as United States territory, changed its name to San Francisco. At that time, the town consisted of just 79 buildings and a population of less than 800. But the following year, in 1848, gold was discovered nearby, and as the area’s major port, San Francisco rapidly ballooned in size. By the end of 1849, the population had skyrocketed to 100,000, making it the largest city in California. (A few years later, incidentally, the mining town of Bodie-a few hundred miles away in the Sierra Nevada mountains-would become the state’s second-largest city. It’s now the most famous ghost town in the United States.) San Francisco soon averaged 30 new houses built-and two murders committed-each day. And a plot of San Francisco real estate that cost $16 in 1847 sold for $45,000 just 18 months later. Meanwhile, many of the new arrivals in the port of San Francisco headed directly to the hills to search for gold. In fact, more than 200 ships were completely abandoned and left to rot in the Bay as their crews and passengers went off to seek their fortunes. This both caused and solved a problem. The empty ships were clogging up the harbor, while the rapidly growing downtown business area needed room to expand. So the townsfolk took matters into their own hands and decided to put the ships to good use. Some of the ships were salvaged for their wood, which came in handy as the city had to rebuild itself from no fewer than six major fires that nearly wiped it out between 1849 and 1851. Other ships were towed onto the beach and turned into buildings-a hotel, a jail, a store, or a warehouse. But quite a few of them were intentionally sunk in order to fill in the cove. In the late 1860s, what remained of the cove was enclosed by a seawall, running roughly along the path of what is now known as the Embarcadero. Over the years, as developers have demolished old buildings and excavated sites for new ones, numerous remains of the Gold Rush ships have been unearthed. In the late 1960s, as San Francisco was building its BART subway system, discoveries of ships and ship fragments occurred regularly. Over the following decades, ships and pieces of ships appeared during several major construction projects along the shore. As recently as 1994, construction workers digging a tunnel found a 200-foot-long (61-meter) ship 35 feet (11 meters) underground. Rather than attempt to remove the ship-which would have been both costly and dangerous-they simply tunneled right through it. When buried ships are found, they’re sometimes looted for bottles, coins, and other valuable antiques frequently found inside. Among the prizes found in the ships have been intact, sealed bottles of champagne and whiskey, nautical equipment, and a variety of personal effects from the passengers and crews. A couple of miles northwest along the city’s shore, the Marina District is also partly built on landfill-of a somewhat different kind. After the massive 1906 earthquake destroyed most of the city, developers needed someplace to dump all the rubble from the downtown area. They used the crumbled remains of buildings to extend yet another portion of the city out into the water, helping to create the site of the Panama-Pacific International Exposition to celebrate the opening of the Panama Canal in 1915. Landfill, of course, is not an ideal foundation for buildings in an area with lots of earthquakes-especially if that landfill is saturated with water. An earthquake can cause an effect called liquefaction, in which the ground behaves more like a liquid than a solid. Significant portions of San Francisco are prone to this effect-a major worry in the event of another serious earthquake. Builders minimize the danger when preparing for new construction by driving pilings through the landfill and into the bedrock below, though roads and smaller buildings still risk damage. In this respect, San Francisco stands in the illustrious company of Venice, which is built almost entirely on pilings and slowly sinking into the Adriatic Sea. Alas for the forty-niners who flocked to California, many of them searched in vain for the gold that drew them here. But had it not been for them, San Francisco would have been a much smaller city, both in population and in surface area. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/04/23/san_francisco-5-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/08/16/San-Francisco.bb230544ea16.mp3"
	},
	{
		"title": "Planning Your Own Funeral",
		"text": "When my mother returned from a vacation to Florida with her sister a number of months ago, I called to ask how it went. “Oh, we had the best time!” she said. “We spent most of the trip planning our funerals. It was hilarious!” Well, that wasn’t quite what I was expecting to hear. On previous vacations my mom has gone on cruises, even tried parasailing, and I thought I had a pretty good idea of what activities she considered fun. Funeral planning was a bit of a surprise. It’s not that she’s ill or expecting to die soon. But, as she put it, “If you want something done right, you have to do it yourself.” I’ve seen some of those late-night commercials trying to sell funeral insurance, with the idea being that you can save your grieving loved ones the considerable expense associated with funerals and burial. But that wasn’t what my mother had in mind at all. (In fact, she made a point of saying that since she’d relieved the family of the burden of funeral planning, the least we could do is pay for it!) Rather, she’d gone to some local funeral parlors and asked them for pre-planning forms she could fill out, detailing her background and family contact information, and specifying her wishes for things like burial versus cremation, type of casket, a minister to preside over the ceremony, and so on. Survivor: The Afterlife What made this all so funny? For starters, these forms—which, mind you, are intended to be filled out by the person on whose behalf the services will be performed—often begin by asking you to list your survivors. That whole idea gave Mom and Aunt Ruth the giggles—how would they know, now, who will survive them? But even though you may have to leave a few sections blank, planning your own funeral gives you the chance to approach the details of how your death will be observed with a rare mixture of detachment and subjectivity. In other words, while you’re alive and healthy, you can have fun with the activity in a way that your bereaved loved ones, under the stress of the moment, never could. Most pre-planning forms ask for basic things like whether you’d prefer a religious, secular, or military funeral. But you can get as detailed as you’d like. List the music you want to have played or sung. What kinds of flowers you want, if any. Scripture passages, poems, or other readings you’d like to have presented. Names of potential pallbearers. And even details about what clothes or jewelry you’ll be wearing while lying in that casket, whether you’ll have your glasses on, and what items should be added or removed before the casket goes in the ground. (My dad has always joked that he’d like to be buried with a plate of spare ribs. It could happen. ) Lay-Away Plan Although it has always been possible to state your own funeral preferences, either in a will or elsewhere, the trend of doing more involved funeral planning for oneself seems to be picking up steam. The topic is covered in various books and Web sites, and of course most funeral directors can supply you with brochures, forms, and other information about their particular services. But for some people, merely planning out a memorial service is not enough. Among the other things you can now arrange are the following: Have your ashes scattered at sea. The Neptune Society specializes in planning for cremation, and offers optional ceremonies at sea. Rebuild Atlantis. I am absolutely not making this up. You can have your ashes encased in concrete and used as one of the building blocks of an artificial reef being constructed off the coast of Miami. The Atlantis Memorial Reef is being designed as an underwater garden that looks like some artist’s idea of Atlantis, and you can spend eternity there if you want. Go into space. It’s not just for celebrity zillionaires and starship engineers. You, too, can have a small portion of your ashes sent into space by Memorial Spaceflights. Prices start at just $500 for a brief trip into zero gravity and back; $1,300 for an indefinite stay in orbit; or $12,500 to have your ashes sent to the moon—or even into deep space on a spacecraft powered by a solar sail. Cut glass. If you’d like to keep your eternal remains close to home, you can have your ashes compressed into an artificial diamond by a company called LifeGem. That’s right: you can wear Grandma around your neck. Prices start at $3,300 and go up to $25,000. Only slightly less creepy: the same company can make gems from a lock of someone’s hair—dead or alive. Furnish your home for the afterlife. If you think cremation offers more attractive options than burial, you haven’t visited CasketFurniture.com, which makes sofas, coffee tables, beds, entertainment centers, and other pieces of furniture that not only look like coffins—they can be converted, upon your death, to hold your remains. If you spend all your time lying on the couch anyway, why not buy one you can enjoy for centuries to come? One step my mother has not yet taken—but plans to—is writing her own obituary. She wants to make sure it hits all the most interesting and important highlights. Unfortunately, you can’t control everything that will happen after your death. Maybe it’ll rain the day you’re buried; maybe the cat will knock over your urn of ashes; maybe your eulogy will have irritating grammatical errors. These things happen. You may not get the very last laugh, but you can at least make the Reaper a bit less grim. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/08/21/coffin-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/08/21/planning-your-o.3af0d56a5b0a.mp3"
	},
	{
		"title": "Paris Catacombs ",
		"text": "Man-made calcium deposits Paris is a shockingly large city. There are many fine vantage points from which to view the panorama, including the Montparnasse Tower, Sacre Coeur, the Eiffel Tower, or the bell towers of Notre Dame. I’m sure everyone who looks out over the vast expanse of Paris has a different impression; mine has been, overwhelmingly, \"Gosh, that’s a lot of limestone.\" With very few exceptions, the buildings of Paris are uniformly beige, limestone being the preferred building material-and not just for the buildings either, but for bridges, sidewalks, and monuments. As far as the eye can see in every direction, the earth is covered with stone. A splash of green, like a park, or gray, like the Seine, seems strangely out of place. All that stone had to come from somewhere, but it never occurs to most people to wonder where that might have been. Most of it was quarried locally, and what’s particularly interesting about this is that the empty spaces left when the limestone was removed-mind-bogglingly huge volumes of space-are largely still vacant, hidden beneath the city streets. The Other French Empire On visits to France, I’ve spent a good bit of time underground in Paris. There have been countless trips on the Paris Metro, of course, and last spring I spent an enjoyable afternoon exploring the public portion of the vast Paris sewer system, not to mention visiting the archeological crypts near Notre Dame. But these are merely the tip of the iceberg. Underneath Paris the real action-so to speak-is in the hundreds of kilometers of abandoned limestone quarries, part of which have been turned into a depository for the bones of millions of former citizens. As with all the underground attractions in Paris, only a portion of the catacombs is officially open to the public; this visitor-friendly section is known as the Denfert-Rochereau Ossuary, or simply the Catacombs. Unlike the many lavish museums, cathedrals, and tombs in Paris, the entrance to the catacombs is a simple black door in a small building that you could easily miss if you blinked while walking by it. The clerk pretended not to understand my request for \"deux billets\" (two tickets) in order to reinforce the well-known meme that no foreigner can possibly speak French properly, but she eventually consented to take my money and let us in. We passed a sign reminding visitors that flash photography is strictly forbidden, then descended a long spiral staircase and entered a small gallery of photographs and drawings. Leaving the gallery, we began walking through long, dark, damp tunnels whose only significant features were signs at intervals stating when they had been built. Tourists zipped past us, talking loudly and snapping flash photos. I began to feel like the day would have been better spent sitting in a cafe drinking coffee and eating croissants. But then we passed through a larger chamber with a sign over the entrance to a dark hallway that said: \"Arrete! C’est ici l’empire de la mort.\" (\"Stop! This is the empire of death. \"). Dem Bones, Dem Bones, Dem Dry Bones Beyond that sign was another world-and one of the creepiest things I’ve ever seen. What at first appeared to be walls built of small stones were in fact huge, orderly piles of human bones. Tibias and femurs by the thousands were stacked neatly, interspersed with rows of skulls, which were sometimes arranged very artistically in a cross or other pattern. There were no intact skeletons; the goal of the arrangement had clearly been maximum compactness. I could only assume that the ribs, spines, and other bones filled in the spaces behind the walls of large leg bones. Most of the stacks of bones rose to a height of about 5 ft. (1.5m), and while some were just a couple of yards deep, there was at least one area where the bones stretched back for a good 20 yards (18m), as you could see from the narrow gap left on top. The tunnels of bones stretched on and on; many side passages were blocked with locked gates, but even the path designated for tourists was about a mile (1.5km) long. The bones began accumulating in the catacombs in 1786, just as momentum for the Revolution was building in Paris. Real estate was scarce while the cemeteries were becoming severely overcrowded. The government decided to reclaim the large swaths of land used for cemeteries by relocating the remains of the departed citizens to the empty limestone quarries, whose tunnels were at that time on the outskirts of town. The process of disinterring the bones from the cemeteries, moving them solemnly into the quarries, and arranging them there took several decades. No attempt was made to identify or separate individual bodies, but each set of bones was marked with a plaque signifying the cemetery they came from and the year in which they were moved. By the time the relocation was finished in 1860, an estimated five to six million skeletons had been moved to the catacombs. The Outer Limits of the Twilight Zone Even so, the bones filled only a tiny percentage of the empty quarries. Although no exhaustive modern map is known to exist, explorers have estimated that there are at least 185 miles (300km) of tunnels in the entire network of catacombs-that’s in addition to the 1,300 miles (2,100km) of sewer tunnels and 124 miles (199km) of subway tracks in the Metro system, though the three systems crisscross and interconnect at various points. Among a certain Paris subculture, exploring these forgotten tunnels is considered a sport. Despite the best efforts of maintenance workers to seal off illicit entrances and police patrols that slap heavy fines on trespassers, the maze of tunnels is so extensive that it is simply not possible to keep ahead of the so-called cataphiles. The catacombs are eerie-quiet (except for the sounds of water dripping from the ceiling and tourists chatting), dark (except for the dim floodlights and camera flashes), and in many ways, downright depressing. It’s hard not to notice that the bones of these millions of people are all pretty much the same. The skull of a revolutionary may be resting on the leg of an aristocrat; noble and corrupt, young and old, wealthy and poor, all are indistinguishable now. It can give you an entirely new perspective on the concept of human equality. It also, needless to say, gives visitors a very keen sense of their own mortality. It made me wonder fleetingly whether, centuries from now, someone might walk by my bones among millions of others and think, \"Gosh, that’s a lot of calcium. \" ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/05/07/catacombs-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/05/07/paris-catacombs.d8bd1e54ea50.mp3"
	},
	{
		"title": "Oil from Garbage ",
		"text": "Modern-day alchemy Well, I’ve got some good news and some bad news. The good news is that there may be an elegant solution on the horizon to the gigantic problem of garbage-and not just the kind that gets dumped in landfills, but sewage, too, along with agricultural wastes, used tires, and just about everything else. More good news: we might get to reduce dependence on foreign oil and pay less for gasoline in the process. The bad news? Forget about those electric cars or increased fuel efficiency; abandon hope of seeing your city skyline again-this solution, if it works, will keep internal combustion engines running forever. What many investors are hoping will be the Next Big Thing is a technology called the thermal depolymerization process, or TDP for short. This patented process is being developed by Changing World Technologies of West Hempstead, New York, with its first full-scale plant already in operation in Carthage, Missouri. The idea behind TDP is not new-in fact, it’s millions of years old. Take organic matter, subject it to heat and pressure, and eventually you get oil. Of course in nature, \"eventually\" is usually an inconvenient number of millennia; TDP shortens that time to hours, if you can believe that. A Well-Oiled Machine TDP is a surprisingly straightforward five-step process. First, raw materials are fed into an industrial-grade grinder where they’re chopped up into extremely small bits and mixed with water. The mixture is then subjected to heat and pressure, breaking molecular bonds and reducing the material to simpler components in as little as 15 minutes. The next step is reducing the pressure dramatically to drive off the water; in the process, some useful minerals such as calcium and magnesium settle out as a valuable byproduct. The remaining slurry is sent into a second reactor, which uses even higher temperatures to produce a hydrocarbon mixture. Finally, a distillation step divides the hydrocarbons into vaporous gas (a mixture of methane, propane, and butane), liquid oil (similar to a mixture of gasoline and motor oil), and powdered carbon. All that to say: garbage in, (black) gold out. The process produces no waste materials, unless you count water, which can be recycled in the system. The gas can be used to produce heat for the machine itself; oil can be sent to refineries to be made into a variety of useful products; carbon can be turned into everything from water filters to toner cartridges; and the remaining minerals can be used as fertilizer. Virtually any organic material can be fed into a TDP apparatus. By making adjustments to the combinations of temperature, pressure, and cooking times, various input products (referred to as feedstock) can produce a wide range of output products; the proportions of, say, gas to oil to carbon will depend on the composition of the feedstock. The first fully operational TDP system is being used to recycle the waste at a turkey processing plant. All the turkey parts that aren’t used as meat-skin, bones, feathers, and so on-are fed into the machine, thus solving a serious waste problem (up to 200 tons per day) while creating commercially valuable products. But TDP can also process discarded computers, tires (even steel-belted radials), plastic bottles, agricultural waste, municipal garbage?you name it. In fact, the city of Philadelphia is hoping to use TDP to convert the sludge that comes out of its sewage treatment plants into oil, which will later be used to generate electricity. Nothing is too messy or too scary for TDP to handle. It can make clean, safe materials out of nearly anything. Even medical wastes, dioxins, and other biohazardous materials. Even anthrax, for crying out loud. Apparently the only kind of material this system can’t handle is nuclear waste-I guess you can’t have everything. Pouring Oil on Troubled Water Thermal depolymerization is just now coming into commercial use, though similar processes have been known for decades. The problem was that they were always too expensive to operate; it cost more for the fuel to decompose the garbage than the resulting materials were worth. The inventors of TDP claim that it is highly energy-efficient-better than 85% in most cases. If that is true, and if it continues to be true on a large scale, then TDP may eventually be able to produce oil more cheaply than drilling, and get rid of garbage as a convenient side-effect-or vice-versa, if you prefer. As fantastic as TDP sounds, the process does have its critics. Some engineers have expressed skepticism that the energy efficiency could be even close to what Changing World Technologies claims. Even supposing that it were, the oil needs of the United States are currently so massive that if all the agricultural waste in the country were processed into oil, it would still be just a drop in the bucket (so to speak). In other words, so the argument goes, the process holds more promise as a method of recycling and waste reduction than it does as a source of fuel. The more optimistic viewpoint is that if TDP comes into widespread use, we won’t run out of oil as long as we have garbage. But that also means there will be less incentive to reduce oil consumption or seek out cleaner alternative power sources. Ah, but I suppose every silver lining must have its cloud. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/05/07/garbage-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/05/07/oil-from-garbage.a2e5fbf3543d.mp3"
	},
	{
		"title": "Museums of Interesting Things",
		"text": "There are two kinds of museums: museums where I get sleepy after about an hour of looking around, and museums of interesting things. I say this tongue in cheek ( tongue in cheek ) , of course: all museums contain things that are interesting to someone. But interesting is in the eye of the beholder. Personally, I don't get terribly excited viewing, say, Italian Renaissance paintings-even though I appreciate the quality and emotional depth of the art in principle. After looking at a few dozen of these, I slip quickly into a \"been-there-done-that-time-for-a-nap\" mood. On the other hand, a science museum can keep my attention indefinitely, while it has exactly the opposite effect on my wife, who will gladly ponder the da Vincis and Raphaels for hours on end. I've been to dozens, maybe hundreds, of museums in my life, ranging from massive institutions such as the Louvre and the British Museum to the tiny Voodoo Museum in New Orleans and San Francisco's Musee Mecanique, a collection of mechanical games and arcade amusements from the early 20th century. For me, what makes a museum interesting is not its size or fame but its ability to capture my imagination with things I've never encountered before. More often than not, this rules out the big, impressive museums of art, natural history, and the like. More to my liking are museums that hark back to the the original idea of a museum-a place where someone goes to listen to the muses or to be amused in the sense of engaged, fascinated, or amazed. Early museums were gathering places for scholars, containing as they did rare artifacts that provided insights into a wide variety of people, places, and ideas. A couple of centuries ago, it was fashionable in some parts of Europe for wealthy, well-traveled men to keep a \"cabinet of curiosities\"-a collection of rare and exotic objects from around the world-with which they could impress their friends and prove their sophistication. Some of these cabinets grew into rooms, and later on developed from private collections into public institutions of their own. But as travel became easier and less expensive, many of these curiosities began to seem less curious. The primary role of a museum shifted to that of a place for keeping valuable art and historical artifacts safe, while making them available for public inspection. But a few institutions kept alive the idea of displaying an eclectic collection of amazing objects from around the world in order to delight, inspire, and entertain visitors. Among the best examples are the dime museums from 19th-century America. Taking their name from their standard admission price, dime museums displayed bizarre, frequently grotesque specimens such as shrunken heads, two-headed animals (dead or alive), and other real or fabricated oddities of nature. They also featured live performances of many kinds, mostly in the vein of circus sideshows-the goat boy, the bearded lady, and so on. Part of the very appeal of dime museums was that visitors never quite knew how seriously to take any of it: if the things were real, they were impressive; if they were fake, they were still impressive, but for a different reason. Before movie theaters appeared, dime museums were some of the best and most economical entertainment an average citizen could buy. Today, you can still find descendants of the dime museum in operation, such as the American Dime Museum in Baltimore, the Freakatorium in New York City, and the Museum of Jurassic Technology in Culver City, California. Ripley's Believe It Or Not Museums also carry on that legacy in numerous cities around the world. Although they're cheesy and touristy, they serve the all-important function of making visitors go, \"Wow, I never imagined there could be such a thing! \" Something for EveryoneEver since the days of show-and-tell in kindergarten, I've had a fondness for learning about new and interesting things, so eclectic collections like dime museums strike my fancy. But there's another whole range of museums that focus very narrowly on just one kind of interesting thing. I couldn't begin to list all of them, but here are a few examples: The New Orleans Pharmacy Museum (pictured above) is housed in the former apothecary shop of Louis J. Dufilho, Jr., America's first licensed pharmacist. It includes some very scary-looking Civil War-era surgical instruments, bottles of patent medicine, and other artifacts from the days when leeches, cocaine, and opium were among the standard cures for common illnesses. The Museum of Pez Memorabilia in Burlingame, California contains more than 500 Pez dispensers, including rare pieces worth thousands of dollars. The Glore Psychiatric Museum in St. Joseph, Missouri, housed in a former mental hospital, features exhibits relating to both the symptoms and treatment of mental illness over the years, including a display of objects mental patients have swallowed (nails, cutlery, and so on). The Cockroach Museum of Plano, Texas, includes both living cockroaches and dead specimens that have been dressed up as characters (such as \"Liberoachi\") in dioramas of roach art. The Corkscrew Museum in Provence has more than 1,000 corkscrews of every shape and size. This is near the top of my list for a visit the next time I'm in France. (No kidding!) There are hundreds of other examples, too-some tending toward the absurd and others with a more serious educational focus. But all of them meet an important need-showing visitors things they can't find just anywhere, and exposing them to interesting ideas that are outside their normal experience. The Virtual Museum of Interesting ThingsYou may not have realized it, but you're standing (or sitting) in a museum right now. That's how I like to think of Interesting Thing of the Day: an intriguing collection of more or less random curiosities-carefully catalogued, displayed, and described for your enjoyment. You don't have to travel far to visit this museum; it's conveniently located just about everywhere. As in any other museum, our exhibits change regularly. In order to keep visitors coming back, we sometimes rearrange our galleries, move certain pieces into or out of storage, or rework exhibits to keep them current. Each time you return, you'll see some old things, some new things, and perhaps a renovation or two. As your curator, I spend my time locating new items for the collection, researching each object's background, and writing descriptions that help to interpret and explain the exhibits. In many museums, you can take an audio tour by carrying around a small device that plays recordings describing each item in more detail. You can do that here too, thanks to the Audio Edition of Interesting Thing of the Day. Want to get more information from a docent, or strike up a conversation with other visitors who share your interests? The ITotD-Talk discussion list provides a virtual forum for that, too! Every museum needs a means of support to pay its staff, maintain the facilities, and acquire new exhibits. In some cases, money comes from a city government, a foundation, or a wealthy benefactor. But smaller and quirkier museums usually rely on admission fees or voluntary donations from guests. Museums may ask visitors to consider becoming members, paying an annual fee in exchange for unlimited admission and other special benefits. We do these things as well and of course, like many good museums, we have a gift shop in the lobby! Interesting Thing of the Day is not, for the most part, about the bizarre or the unbelievable. It's more like show-and-tell from a cabinet of curiosities that's large enough to encompass ideas, historical events, other museums, and even things that might not exist. It's here to amuse you-in the very best sense of the word. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/04/18/venus-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/04/18/museums-of-inte.9cea88744501.mp3"
	},
	{
		"title": "Icewine",
		"text": "I may not be the most agriculturally sophisticated person in the world, but I always felt pretty confident in my basic belief that frost was a Bad Thing when it came to growing produce. If whatever crop you’re growing hasn’t been harvested by the time temperatures dip below freezing, serious damage can be done, right? Common sense, however, frequently turns out to be wrong. At least for grapes, freezing is eagerly anticipated by vintners in certain parts of the world. It’s a key factor in the production of an expensive variety of dessert wine known as icewine. Grapes are most comfortably grown in a Mediterranean climate—areas with hot, dry summers and mild, wet winters, such as France, Italy, Spain, Australia, and parts of California. But plenty of excellent wines also come from Germany, Austria, and the southeastern and southwestern corners of Canada, all places where freezing temperatures in winter are quite normal. And these are exactly the regions where icewine is produced. Crushed Ice To make icewine, you must wait until the grapes have frozen naturally on the vines—typically, you look for two solid days of temperatures in the range of 9°F (–13°C) to 14°F (–10°C). This implies a very late harvest, of course, which in turn means that the grapes will have a very high sugar content. Grapes are picked by hand (sometimes in the middle of the night to ensure that the temperature does not rise above freezing) and pressed while still frozen. This is the crucial step, because when frozen grapes are pressed, most of the water remains behind as ice crystals, and the juice obtained—just a drop or two per grape—is highly concentrated. (In fact, the colder the grapes, the higher the percentage of sugar in the juice, and this is exactly what you want for icewine—a minimum of 35% sugar.) This juice is then fermented naturally over a period of weeks or months and bottled more or less like regular wine. But because production is so labor-intensive, with yields around 10% of a regular harvest, icewine is sold in half bottles (375ml) at prices averaging about US$38 (CDN$50) per bottle. The smaller bottles are a good idea for another reason, too: icewine is very sweet (and usually high in alcohol, too), so it’s only consumed in very small quantities. What does it taste like? Imagine a sweet white wine, then imagine letting half the moisture evaporate away so that you have something not only sweeter but twice as viscous. That’s roughly the idea of icewine: it’s like a highly concentrated white wine. It’s always served chilled, usually with (or following) dessert. Saving Grapes Icewine was discovered by accident in 1794 in Franconia (which is now part of Germany). After an early freeze, vintners decided to press the grapes anyway to see what could be salvaged. The unexpected result was an exceptionally sweet wine, dubbed Eiswein. It was several decades before icewine was produced intentionally in Germany, and production in North America didn’t begin until about 30 years ago. Production is always a bit risky since the vineyard is at the mercy of the weather; yields, quality, and price vary significantly from region to region and from year to year. Icewine has now become a bit of a fad and a status symbol—it’s what fashion-conscious wine snobs finish expensive meals with. On the other hand, wine snobs who have not already been sold on how hip icewine is supposed to be often don’t like it. A comment I’ve heard from more than a couple of people is, “Ewww. This isn’t good wine; it’s way too sweet.” But there are also people who believe a martini with more than a misting of vermouth is too sweet, or even that the quality of any alcoholic beverage is determined by its position on the dry-sweet continuum, with sweeter meaning less desirable. I have no such prejudice myself. Besides, icewine is in the same league as port, sherry, and perhaps even mead—it’s not something you would generally drink in large quantities along with a meal, but a small glass as a sweet digestif can be quite nice. Icewine is not that much different from any other late-harvest dessert wine, except in cost. But that’s not to say it isn’t worth a little extra, if only to compensate the grape pickers for freezing their buns off in the middle of the night for your drinking pleasure. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/08/21/grape-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/08/21/Icewine.e6784dda2e08.mp3"
	},
	{
		"title": "Honey as Medicine",
		"text": "Sweet relief When I get a sore throat, I always find a cup of tea with some honey very soothing. But thanks to my proper Western scientific conditioning, I always assumed that the restorative power of honey was mostly in my head. Sure, it tastes good and has a pleasant texture that coats my irritated throat, but it’s practically pure sugar, after all. What good could it possibly do me other than diminishing my perception of discomfort for a few minutes? So I’ve been content in my belief that honey is little more than a tasty placebo. Now, ironically enough, my convictions are being challenged, as researchers are turning up new evidence of honey’s medical benefits left and right. Historically, honey has been used as a folk remedy in cultures around the world for millennia. It has been prescribed informally as a cure for smallpox, baldness, eye diseases, and indigestion. It’s even been used as a contraceptive. As with most natural “cures” unsupported by scientific studies, I sort of chuckle and sigh when I read about things like this—honey may be a silly substitute for real medicine, but at least it’s not bloodletting. However, in this case, the bees may have the last laugh. It turns out that honey’s properties make it a surprisingly effective cure-all. Or, let’s say, cure-much. Bee Fruitful and Multiply Honey’s salutary effects stem primarily from its antimicrobial properties. Most bacteria and other microorganisms cannot grow or reproduce in honey. I found this quite surprising, because all things being equal, bacteria love sugar. Honey contains around 40% fructose and 30% glucose—among other sugars—making it seemingly a great treat for microbes. However, honey is also somewhat acidic, and acids prevent the growth of some bacteria. More importantly, honey does not provide the water and oxygen needed to support bacterial growth. Although honey contains a fair amount of water, it’s supersaturated with sugar—meaning the water is not available to the microorganisms. So what happens when you dilute honey with water—the bacteria just multiply like crazy, right? Well…yes and no. Amazingly enough, diluted honey supports the growth of bacteria that are helpful to humans while killing off dangerous strains. Some microorganisms do indeed flourish in a dilute solution of honey—such as the yeast used to ferment it into mead. Also, certain types of beneficial bacteria that live in the human intestines and aid digestion do well in a mixture of honey and water. But honey also contains a substance called glucose oxidase. When combined with water and oxygen, glucose oxidase forms gluconic acid and hydrogen peroxide—the very same stuff you probably have in your medicine cabinet right now. This means that diluted honey can serve as an excellent antiseptic, while being far less likely than ordinary hydrogen peroxide to harm already-damaged tissue. Show Me the Honey What does all this mean in practical terms? For one thing, it means that honey applied topically to a wound can promote healing just as well as, or in many cases better than, conventional ointments and dressings. Its antibacterial properties prevent infection. It also functions as an anti-inflammatory agent, reducing both swelling and pain. As if that weren’t enough, it even reduces scarring. In studies around the world, honey has been shown to be extraordinarily effective in the treatment of wounds, burns, and surgical incisions. Honey also functions as a moisturizer, making it a useful treatment for sunburn as well as a general-purpose skin softener. But wait, there’s more! Honey is truly a head-to-toe cure. Honey has been shown to be effective in treating inflammation of the eyelid, some types of conjunctivitis, and keratitis (along with other forms of corneal damage). It can also, believe it or not, be used to treat athlete’s foot and other fungal infections. A Spoonful of Sugar Is the Medicine Lest you think that honey is only healthy if used on the outside of the body, it can help with a great many internal problems too. Thanks to its antimicrobial action, it not only soothes sore throats but can also kill the bacteria that sometimes cause them. Although research is inconclusive so far, there’s also the suggestion it could actually reduce tooth decay—all that sticky sugar notwithstanding. Moving down the esophagus and through the digestive tract, honey can help to heal ulcers and upset stomachs. It has also been proven to regulate intestinal function, alleviating both constipation and diarrhea. (In a similarly syzygial way, honey can be used both as a sleep aid and to increase alertness.) Honey also contains a variety of antioxidants, which may reduce the risk of cardiovascular disease and cancer. Manuka honey, made from the flowers of the Manuka bush (Leptospermum scoparium), comes from New Zealand. Some varieties of Manuka honey contain an antibacterial component called UMF (Unique Manuka Factor), which has been found to be even more useful than ordinary honey in combating infections. Intriguingly, honey with UMF is even effective against many so-called “superbugs”—strains of bacteria such as Staphylococcus aureus that are resistant to multiple types of antibiotics. An Australian company called Medihoney has obtained the blessing of the Therapeutic Goods Administration (comparable to the U.S. Food and Drug Administration) to sell this type of honey packaged as a dressing for wounds. The company also sells honey and honey-based products designed to treat digestive problems, oral irritations and sore throats, and even skin conditions such as psoriasis. The Color of Honey Now that you’ve worked yourself into a gleeful frenzy over the miraculous properties of honey, I want to temper your enthusiasm a bit. The bad news, if you can call it that, is that not all honey is created equal. The chemical composition of honey depends on a huge number of variables, the most important of which is the type or types of plant that provided the source nectar. Honeys vary not only in color and flavor, but in their medicinal properties, with some varieties being much more potent than others. Because it’s impossible to regulate the comings and goings of millions of bees, there’s also no way to guarantee that honey from any location will be chemically the same from year to year or free of contamination from pollutants the bees may have found their way into. Honey supplies must be tested thoroughly and regularly. I should mention one other caveat: never feed honey to a child under one year of age. Honey sometimes contains Clostridium botulinum spores. Although they’re inactive in the honey itself, once inside a digestive tract they can multiply and cause a potentially fatal disease of the nervous system called infant botulism. By the time of a child’s first birthday, there are usually enough beneficial bacteria in the digestive tract to make it an inhospitable environment for Clostridium botulinum, meaning that honey can be eaten safely. As I was reflecting on all the health benefits of honey, it suddenly occurred to me: I don’t think I’ve ever seen a sick bee. Coincidence? Probably. But honey may be one miracle cure that lives up to the buzz. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/08/24/honey-3-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/08/24/Honey.8abb794205c0.mp3"
	},
	{
		"title": "Fortune Cookies",
		"text": "For reasons I am at a loss to explain, I never tasted Chinese food until I went to college. Around the middle of my freshman year, I decided to make myself a “to do” list of experiences I’d always wanted to have. One of those things was trying Chinese food. Not long afterward, my roommate decided to take my cultural enlightenment into his own hands. “We’re going to Chinatown for supper tonight,” he said. Not only would he not take no for an answer, he even told me it was going to be a double date and who I was to ask out. I dutifully phoned the woman in question and off we all went, driving about an hour from the campus into the heart of Manhattan. That evening I had my first egg roll, my first wonton soup, and my first lo mein; I even managed to get the hang of chopsticks pretty readily. And needless to say, the meal ended with the obligatory fortune cookies, another novelty I’d never seen before. I’ve been a fan of Chinese cooking (and fortune cookies) ever since. My adopted hometown of San Francisco also has a large and vibrant Chinatown, and I was delighted to learn that fortune cookies were in fact invented here. When we got married, Morgen and I decided to have a San Francisco-themed wedding. In addition to the San Francisco-shaped wedding cake (really), we got a bunch of those cardboard Chinese take-out containers, filled them with treats, and distributed them to all of our guests. Among the goodies was a custom-made fortune cookie with a special message thanking guests for attending. You Will Have a Satisfying Dessert I have always liked the idea of fortune cookies. As confections go, a fortune cookie is about the lightest dessert I can imagine, which is usually just what I’d hope for after a Chinese meal. I can’t recall ever having a fortune from a cookie come true, but there have been fortunes that gave me food for thought (so to speak), and even a patently goofy saying seems like a delightfully quaint way to end dinner. But even though I knew fortune cookies were invented in California, it never really sank in until recently that this made them an American idea that probably would be (and indeed is) considered strange in China. It turns out that the story is even weirder than that—fortune cookies are not merely an American invention, they’re a Japanese invention that was adapted for Americans and then co-opted by Chinese restaurant owners. That the fortune cookie, given its mongrel roots, has become so iconic of Chinese restaurants in America is truly amazing. But I’m getting ahead of myself. There are several competing histories of the fortune cookie, none of which is entirely verifiable from recorded history. Many accounts trace the cookies' origin back to 13th- and 14th-century China, which was then occupied by the Mongols. According to legend, secret plans for an uprising were hidden in moon cakes that would ordinarily have contained lotus nut paste, which was unpalatable to the Mongols. The successful uprising, planned with the help of the hidden notes, led to the formation of the Ming Dynasty. This story may be true, but I have seen no evidence that it inspired the treats we know of today as fortune cookies. There can be no doubt that the modern fortune cookie design originated in California. Fame and Fortune Will Be Yours However, there is quite a controversy over who actually invented them. David Jung, a Chinese immigrant living in Los Angeles who founded the Hong Kong Noodle Company, claims to have invented fortune cookies in 1918—though no one seems to know where the recipe or idea came from. The alternative and generally accepted story is that they were invented in San Francisco by a Japanese immigrant. Makoto Hagiwara was the landscape designer who created the Japanese Tea Garden in Golden Gate Park. According to Hagiwara, the fortune cookie was based on a Japanese treat called Tsujiura sembei . He sweetened the recipe to appeal to American tastes, enclosed thank-you notes in the cookies, and served them to his guests with tea. Depending on which account you read, Hagiwara began distributing the cookies in either 1907 or 1914, but in any case they clearly made their appearance well before the 1918 date claimed by Jung. Within a few years, however, Chinese restaurant owners in San Francisco had copied the recipe, replacing the thank-you notes with fortunes. The rest, as they say, is history. Of course, over the past couple of decades, the fortunes that appear in fortune cookies have gotten sillier and more annoying. For one thing, they now almost always include “lucky numbers,” which mysteriously seem to match the pattern required for lottery entries. There’s also a trend toward smiley faces, which make me frown, and Chinese writing, which is just baffling considering the cookies' origin. Even the fortunes themselves make less and less sense. Whatever happened to the simple “You will lead a long and prosperous life” or “Never eat fish on a Monday”? But when it comes to fortune cookies, I suppose an appeal to tradition is missing the point. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/09/24/fortune-cookies.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/09/24/fortune-cookies.169008412bc0.mp3"
	},
	{
		"title": "Eye Language",
		"text": "A while back, someone remarked in passing that a mutual friend had “such beautiful blue eyes.” I was surprised—and a bit embarrassed—to realize that in all the years I'd known the woman in question, I had never noticed the color of her eyes. In North America, social convention dictates that we look someone directly in the eye while conversing, so failing to register my friend's eye color implied that my communication skills were faulty too. But if I can be forgiven for ignoring the iris, the pupil is something that clearly deserves a great deal of attention, because it can tell us much more than the words someone speaks. Would you believe that medical science has come up with two different words that mean “the measurement of pupil diameter”? It's true. The general term, pupillometry, refers to any pupil measurement—usually performed using infrared cameras or sensors, because visible light would cause the pupils to contract and throw off the readings. A more specific term, pupillometrics, refers to the evaluation of one's pupil size as an indicator of interest or emotion. University of Chicago biopsychologist Eckhard Hess coined the term in 1975. Hess discovered that when someone looks at something that causes positive feelings (or even just sparks interest), the pupils dilate—whereas the pupils contract when the person looks at unpleasant or uninteresting things. Moreover, we subconsciously pick up cues from others' pupil sizes and use them to help us form opinions about people. Hess performed an oft-cited study in which men were shown carefully retouched photographs of women. In half the photographs, the pupils were made to appear larger than normal, and in the other half, they were smaller. The men in the study invariably perceived the women with larger pupils as being more attractive and friendlier than the very same women in photographs where they appeared to have smaller pupils. And yet, none of the men in the study could say why they found one set of women more attractive than the other. Can pupillometrics help you to find true love? A number of books and articles suggest you can determine if the person you're dating is truly interested in you by paying attention to his or her pupils while talking. If they're consistently large, take it as a good sign. To convey the impression that you're interested in someone else, keep the lights dim to allow your own pupils to dilate. Beware, though: pupil size can indicate interest in anything—not necessarily romance. If you're hungry, the sight of food will make your pupils large. Be sure your date isn't really looking at someone behind you eating an ice cream cone. Pupils can give away even more information when examined electronically. Because your pupil's response to light varies measurably when you're tired, devices now being installed at checkpoints along major highways use pupil response to test whether truck drivers are too fatigued to drive safely. Pupil response has also been shown to be a surprisingly accurate indicator of drug use. Even some drugs that don't show up in urinalysis can be detected with a 30-second pupil response test. Because pupil tests are fast, inexpensive, and noninvasive, they are being used in some correctional facilities as a pre-screening mechanism: only those who fail the test are asked for urine samples. Look Both Ways Before Answering Pupil size isn't the only way your eyes communicate. The direction in which someone looks while talking can also speak volumes. As you're probably aware, the brain is divided into two hemispheres. The left hemisphere is primarily responsible for logic and analytical thought, while the right hemisphere is where emotional and creative thinking occur. Because the right brain governs the left side of the body and vice-versa, we tend to look to the left when using our right brains and to the right when using our left brains. Recalling existing information is largely a right-brain task, which means that when we're trying to remember something we usually look to the left. Conversely, we typically look to the right when trying to construct a description or a story, making use of the logical powers of the left brain. To make matters even more interesting, looking upward suggests that a person is using images or visual memories. Looking downward is associated with kinesthetic or emotional memories, while looking directly left or right usually means the person is processing auditory data. I've read in several places that because looking to the right means a person is constructing something new, this implies lying. But I've also read exactly the opposite—that looking to the left suggests lying (presumably because the creative right brain is being used). Still others claim that whichever direction you associate with lying, you have to switch it if the person is left-handed! In reality, the association between gaze direction and truthfulness is a tenuous one. Making up a new sentence doesn't necessarily involve making up a new fact, after all. And although left-handed people are slightly more likely to be right-brained than right-handed people, one's dominant hand doesn't necessarily have anything to do with one's dominant brain hemisphere. All the same, law-enforcement personnel are regularly taught to take note of a suspect's gaze direction during an interrogation. Although eye movement is much less foolproof than a polygraph, it can suggest areas in which someone is not being entirely forthcoming. I don't recommend accusing anyone of lying just because of a rightward glance. But it does pay to listen to what they eyes say, and to be aware of how other people may interpret your involuntary eye reactions. What you learn about your friends could be even more valuable than knowing their eye color. —Joe Kissell ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/08/21/eye-120.jpg",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/08/21/Eye-Language.b4ec1dde1a28.mp3"
	},
	{
		"title": "Esperanto",
		"text": "Like many people, I endured four years of high-school French only to find that I lacked the ability to order a croissant in a Paris bakery without making a fool of myself. I eventually got the hang of basic conversation in French, but then found myself traveling to places where Spanish, German, or Italian (for example) were spoken, and having to start all over again with the basics (“Where's the bathroom?” “How much does this cost?” “Where have you sent my luggage?”). As much as I enjoy and appreciate linguistic diversity, it can make travel, trade, and diplomacy challenging at times. In some heavily multilingual areas of the world, most people learn a lingua franca\n—a regional trade language—in addition to their mother tongue. It stands to reason, then, that this notion could be expanded more broadly. But when someone proposes English or French, say, as a trade language, objections inevitably arise. These languages are notoriously difficult to learn, with strange spellings and lots of grammatical rules and exceptions. But more importantly, they're loaded with historical and cultural baggage. If your country—not mentioning any names—has been a rival of English- or French-speaking nations, you will likely not jump at the chance to spend long years learning a language with such unpleasant associations. The only hope for a truly universal language would seem to be an artificial one—a language that is designed to be free from cultural biases and easy to learn. This was precisely the goal of Esperanto. Hoping for a New Language L.\nL. Zamenhof grew up in the late 1800s in Warsaw (part of Russia at that time). While still in high school he set out to design a universal artificial language that would facilitate communication within his linguistically diverse community. By the time he finished this side project ten years later, Zamenhof was a practicing ophthalmologist. In 1887, he published the first guide (in Russian) to the new language, which he called “Lingvo Internacia” (international language). Zamenhof wrote the textbook under the pseudonym “Esperanto,” meaning “a person who is hoping” in Lingvo Internacia. Fans of the language decided that “Esperanto” had a nicer ring to it, and they soon adopted it as the informal name of the language. Esperanto was designed to be both easy to learn and culturally neutral. According to some sources, an English speaker can learn Esperanto up to five times faster than Spanish. For starters, Esperanto uses strictly phonetic spelling—a given letter always makes exactly the same sound. Second, the structure of Esperanto is very simple, with only sixteen basic grammatical rules that need to be learned—and no exceptions to the rules (such as irregular verbs). And third, Esperanto has a very small core vocabulary; new words are constructed by combining words and adding prefixes and suffixes. (Esperanto is thus an agglutinative polysynthetic language, for those who need to have such things spelled out…) Something Old, Something New, Something Borrowed The vocabulary of Esperanto will have a familiar ring to anyone who knows a European language, as roots were borrowed from French, German, and Spanish, among other languages. (A few examples: bona means “good”; porko means “pig”; filo means “son”; hundo means “dog.”) One could argue that this selection represents not so much cultural neutrality as Euro-neutrality, but this hasn't prevented Esperanto from becoming popular in China and some other parts of Asia. For all its merits, Esperanto has not reached the level of acceptance its creator foresaw more than a century ago. There may be as many as two million people who speak Esperanto with at least a moderate level of proficiency, but probably no more than a few hundred who learned Esperanto at home as their first language—and no known speakers (over the age of three or so) who speak only Esperanto. Ironically, the cultural neutrality that is touted as such a benefit of the language also serves to limit its growth, because languages tend to spread along with the cultures that gave rise to them. Alas, unless or until the number of Esperanto speakers reaches a larger critical mass, it will be of little value as a trade language, and without a clear value, it will be difficult to convince people to learn it. ",
		"avatarURL": "https://static.lingq.com/media/resources/contents/images/2007/08/31/Flag_of_Esperanto-120.png",
		"mediaURL": "https://s3.amazonaws.com/media.lingq.com/resources/contents/audionorm/resources/contents/audio/2007/08/31/Esperanto.cff5a9f02bb3.mp3"
	}
];